{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"..\")\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from trading_simulator import TradingSimulator, DLSimulator\n",
    "from dl_solutions.dlsolutions import CryptoDLSolutions\n",
    "from data_processor.data_processing import DataProcessor\n",
    "from utils.crypto_utils import ModelAnalysis\n",
    "from keras import optimizers\n",
    "from keras.layers import LeakyReLU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "cryptos = ['ADA', 'BTC', 'ETH', 'LTC', 'LNK']\n",
    "sel = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading... ADA\n",
      "Total invested: 18100 €\n",
      "Balance: 13172.688982503865 €\n",
      "Orders won: 57\n",
      "Orders lost: 122\n",
      "Profit: 0.17528668411623566 \n",
      "\n",
      "Loading... BTC\n",
      "Total invested: 18000 €\n",
      "Balance: 15374.282899246477 €\n",
      "Orders won: 82\n",
      "Orders lost: 91\n",
      "Profit: 0.2985712721803598 \n",
      "\n",
      "Loading... ETH\n",
      "Total invested: 18900 €\n",
      "Balance: 15762.628160203021 €\n",
      "Orders won: 88\n",
      "Orders lost: 96\n",
      "Profit: 0.3049009608573027 \n",
      "\n",
      "Loading... LTC\n",
      "Total invested: 19400 €\n",
      "Balance: 10078.209866880738 €\n",
      "Orders won: 82\n",
      "Orders lost: 108\n",
      "Profit: 0.0040314364371514195 \n",
      "\n",
      "Loading... LNK\n",
      "Total invested: 14400 €\n",
      "Balance: 13667.667598362794 €\n",
      "Orders won: 70\n",
      "Orders lost: 73\n",
      "Profit: 0.254699138775194 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for crypto in cryptos:\n",
    "    processor = DataProcessor([crypto])\n",
    "    sim = TradingSimulator(processor, crypto, strategy = [1, 2, 3, 4, 5, 6, 7], loss_allowed = 0.2, log = False, stop_loss_take_profit_strategy = 2)\n",
    "    sim.simulate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading... LNK\n",
      "Loading... LNK\n",
      "Loading... LNK\n",
      "Loading... LNK\n",
      "Loading... LNK\n",
      "Loading... LNK\n",
      "Loading... LNK\n",
      "Loading... LNK\n"
     ]
    }
   ],
   "source": [
    "processor = DataProcessor([crypto])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading... ADA\n",
      "Total invested: 300 €\n",
      "Balance: 10057.462858859024 €\n",
      "Orders won: 1\n",
      "Orders lost: 2\n",
      "Profit: 0.19154286286341327 \n",
      "\n",
      "Loading... BTC\n",
      "Total invested: 400 €\n",
      "Balance: 10310.75244449828 €\n",
      "Orders won: 3\n",
      "Orders lost: 1\n",
      "Profit: 0.7768811112456979 \n",
      "\n",
      "Loading... ETH\n",
      "Total invested: 400 €\n",
      "Balance: 10097.541136767813 €\n",
      "Orders won: 2\n",
      "Orders lost: 2\n",
      "Profit: 0.2438528419195336 \n",
      "\n",
      "Loading... LTC\n",
      "Total invested: 500 €\n",
      "Balance: 9957.386864457305 €\n",
      "Orders won: 2\n",
      "Orders lost: 3\n",
      "Profit: -0.08522627108539019 \n",
      "\n",
      "Loading... LNK\n",
      "Total invested: 200 €\n",
      "Balance: 10001.092886477461 €\n",
      "Orders won: 1\n",
      "Orders lost: 1\n",
      "Profit: 0.00546443238730717 \n",
      "\n",
      "##########################\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Loading... ADA\n",
      "Total invested: 2400 €\n",
      "Balance: 10163.384828475693 €\n",
      "Orders won: 6\n",
      "Orders lost: 18\n",
      "Profit: 0.06807701186487217 \n",
      "\n",
      "Loading... BTC\n",
      "Total invested: 2000 €\n",
      "Balance: 10976.89511478925 €\n",
      "Orders won: 12\n",
      "Orders lost: 7\n",
      "Profit: 0.4884475573946247 \n",
      "\n",
      "Loading... ETH\n",
      "Total invested: 2500 €\n",
      "Balance: 10513.913693501721 €\n",
      "Orders won: 10\n",
      "Orders lost: 14\n",
      "Profit: 0.20556547740068853 \n",
      "\n",
      "Loading... LTC\n",
      "Total invested: 2400 €\n",
      "Balance: 10005.881406207694 €\n",
      "Orders won: 10\n",
      "Orders lost: 14\n",
      "Profit: 0.0024505859198726892 \n",
      "\n",
      "Loading... LNK\n",
      "Total invested: 1900 €\n",
      "Balance: 9957.6537887469 €\n",
      "Orders won: 7\n",
      "Orders lost: 12\n",
      "Profit: -0.022287479606894568 \n",
      "\n",
      "##########################\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Loading... ADA\n",
      "Total invested: 4600 €\n",
      "Balance: 11384.72360941027 €\n",
      "Orders won: 17\n",
      "Orders lost: 28\n",
      "Profit: 0.3010268716109283 \n",
      "\n",
      "Loading... BTC\n",
      "Total invested: 5000 €\n",
      "Balance: 11615.516345218772 €\n",
      "Orders won: 23\n",
      "Orders lost: 25\n",
      "Profit: 0.32310326904375436 \n",
      "\n",
      "Loading... ETH\n",
      "Total invested: 5200 €\n",
      "Balance: 11943.048168958408 €\n",
      "Orders won: 26\n",
      "Orders lost: 25\n",
      "Profit: 0.3736631094150786 \n",
      "\n",
      "Loading... LTC\n",
      "Total invested: 5200 €\n",
      "Balance: 10213.098987740255 €\n",
      "Orders won: 24\n",
      "Orders lost: 27\n",
      "Profit: 0.04098057456543372 \n",
      "\n",
      "Loading... LNK\n",
      "Total invested: 4100 €\n",
      "Balance: 11848.187766539322 €\n",
      "Orders won: 23\n",
      "Orders lost: 18\n",
      "Profit: 0.45077750403398104 \n",
      "\n",
      "##########################\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Loading... ADA\n",
      "Total invested: 1600 €\n",
      "Balance: 10078.897645189169 €\n",
      "Orders won: 5\n",
      "Orders lost: 11\n",
      "Profit: 0.04931102824323034 \n",
      "\n",
      "Loading... BTC\n",
      "Total invested: 1500 €\n",
      "Balance: 9878.944101491832 €\n",
      "Orders won: 6\n",
      "Orders lost: 8\n",
      "Profit: -0.08070393233877864 \n",
      "\n",
      "Loading... ETH\n",
      "Total invested: 1300 €\n",
      "Balance: 10430.514891215502 €\n",
      "Orders won: 7\n",
      "Orders lost: 5\n",
      "Profit: 0.3311653009350014 \n",
      "\n",
      "Loading... LTC\n",
      "Total invested: 1700 €\n",
      "Balance: 9965.963589292065 €\n",
      "Orders won: 7\n",
      "Orders lost: 9\n",
      "Profit: -0.020021418063491128 \n",
      "\n",
      "Loading... LNK\n",
      "Total invested: 1200 €\n",
      "Balance: 10028.064948273724 €\n",
      "Orders won: 5\n",
      "Orders lost: 7\n",
      "Profit: 0.023387456894770366 \n",
      "\n",
      "##########################\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Loading... ADA\n",
      "Total invested: 4700 €\n",
      "Balance: 11409.540329667505 €\n",
      "Orders won: 18\n",
      "Orders lost: 28\n",
      "Profit: 0.29990219780159677 \n",
      "\n",
      "Loading... BTC\n",
      "Total invested: 5100 €\n",
      "Balance: 11800.487239652923 €\n",
      "Orders won: 24\n",
      "Orders lost: 25\n",
      "Profit: 0.35303671365743583 \n",
      "\n",
      "Loading... ETH\n",
      "Total invested: 5500 €\n",
      "Balance: 11994.601764956133 €\n",
      "Orders won: 28\n",
      "Orders lost: 26\n",
      "Profit: 0.36265486635566047 \n",
      "\n",
      "Loading... LTC\n",
      "Total invested: 5300 €\n",
      "Balance: 10237.87705115071 €\n",
      "Orders won: 25\n",
      "Orders lost: 27\n",
      "Profit: 0.044882462481266046 \n",
      "\n",
      "Loading... LNK\n",
      "Total invested: 4200 €\n",
      "Balance: 11828.971354632646 €\n",
      "Orders won: 23\n",
      "Orders lost: 19\n",
      "Profit: 0.4354693701506299 \n",
      "\n",
      "##########################\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Loading... ADA\n",
      "Total invested: 4500 €\n",
      "Balance: 10078.67971090221 €\n",
      "Orders won: 10\n",
      "Orders lost: 35\n",
      "Profit: 0.01748438020049111 \n",
      "\n",
      "Loading... BTC\n",
      "Total invested: 3800 €\n",
      "Balance: 10824.503072299192 €\n",
      "Orders won: 14\n",
      "Orders lost: 23\n",
      "Profit: 0.21697449271031377 \n",
      "\n",
      "Loading... ETH\n",
      "Total invested: 4000 €\n",
      "Balance: 10783.008504803438 €\n",
      "Orders won: 15\n",
      "Orders lost: 24\n",
      "Profit: 0.1957521262008595 \n",
      "\n",
      "Loading... LTC\n",
      "Total invested: 4200 €\n",
      "Balance: 9732.435298202585 €\n",
      "Orders won: 14\n",
      "Orders lost: 27\n",
      "Profit: -0.06370588138033695 \n",
      "\n",
      "Loading... LNK\n",
      "Total invested: 2700 €\n",
      "Balance: 10029.630123909186 €\n",
      "Orders won: 11\n",
      "Orders lost: 15\n",
      "Profit: 0.010974119966365294 \n",
      "\n",
      "##########################\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Loading... ADA\n",
      "Total invested: 0 €\n",
      "Balance: 10000 €\n",
      "Orders won: 0\n",
      "Orders lost: 0\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-eaa4a563e1f8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0mprocessor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataProcessor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcrypto\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0msim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTradingSimulator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcrypto\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrategy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_allowed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop_loss_take_profit_strategy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0msim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimulate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'##########################\\n\\n\\n\\n\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Master IA/AIMaster/TFM/Code/crypto_bot/trading_simulation/trading_simulator.py\u001b[0m in \u001b[0;36msimulate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Orders won:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morders_won\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Orders lost:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal_orders\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morders_won\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Profit:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbalance\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitial_balance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal_invest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtrigger_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprev_row\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "for i in range(1, 8):\n",
    "    for crypto in cryptos:\n",
    "        processor = DataProcessor([crypto])\n",
    "        sim = TradingSimulator(processor, crypto, strategy = [i], loss_allowed = 0.2, log = False, stop_loss_take_profit_strategy = 2)\n",
    "        sim.simulate()\n",
    "    print('##########################\\n\\n\\n\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DL Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_analysis = ModelAnalysis()\n",
    "\n",
    "def execute_test(split_size = -1):\n",
    "    '''\n",
    "    Creates artificial test process to validate different hyperparameters\n",
    "    '''\n",
    "    sim = DLSimulator(crypto, prev_periods, pred_periods, columns, target,\n",
    "    norm_strat, model_sel, layers, neurons, batch_size, epochs, \n",
    "    activation, loss, metrics, optimizer, initial_learning_rate, callbacks)\n",
    "\n",
    "    df_train = sim.get_df().iloc[:split_size]\n",
    "    if split_size == -1:\n",
    "        df_test = sim.get_df().iloc[split_size:]\n",
    "    else:\n",
    "        df_test = sim.get_df().iloc[split_size:split_size+1]\n",
    "    \n",
    "    display(df_train)\n",
    "    display(df_test)\n",
    "\n",
    "    sim.train_model(df_train)\n",
    "    \n",
    "    pred = sim.predict(pd.DataFrame(df_test))\n",
    "    print('Predictions', pred)\n",
    "    h = sim.get_history()\n",
    "    model_analysis.draw_history(h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preparation\n",
    "\n",
    "Estos son los parametros ademas de otros pocos añadidos ad hoc al modelo (dropout). Estos parametros iran cambiando a lo largo del analisis.\n",
    "\n",
    "En este notebook no aparece todo el analisis por ser demasiado extenso (analisis por dias de la semana, otras metricas, cpas, cambios en la output layer, uso de previous y pred periods...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "crypto = 'ETH'\n",
    "\n",
    "#### PERIODS ####\n",
    "prev_periods = 20\n",
    "pred_periods = 20\n",
    "\n",
    "\n",
    "#### COLUMNS ####\n",
    "columns_1 = ['RSI', 'close']\n",
    "\n",
    "#### HYPERPARAMETERS ####\n",
    "layers = 4\n",
    "neurons = [25, 25, 25, 25, 25] # El primer valor son las neuronas de la base layer\n",
    "batch_size = 64\n",
    "epochs = 100\n",
    "#activations = ['relu', 'sigmoid', 'softmax']\n",
    "#losses = ['mse', 'binary_crossentropy', 'categorical_crossentropy']\n",
    "#metrics_opt = ['mse', 'accuracy']\n",
    "activation = 'relu'\n",
    "loss = 'mse'\n",
    "metrics = ['mse']\n",
    "optimizer = 'adam'\n",
    "initial_learning_rate = 0.01\n",
    "callbacks = ['mc', 'es']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DL parameters and training\n",
    "\n",
    "Creation of different strategies:\n",
    "\n",
    "- Based on result\n",
    "- Based on close/indicators normalized\n",
    "- Try with different close distances\n",
    "- Multioutput\n",
    "- Based on multiple operation (softmax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LSTM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_sel = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### One line feature\n",
    "\n",
    "Usaremos solo una característica como objetivo de predicción"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Análisis por periodos fijos:\n",
    "\n",
    "Analizaremos el impacot de los heprparámetros para posteriormente buscar los valores optimos de periodos previos y a predecir\n",
    "\n",
    "Fijaremos los periodos usados y a predecir en 20\n",
    "\n",
    "\n",
    "\n",
    "Cambiaremos lo siguiente en cuanto a hiperparámetros y modelo sobre dos metricas usadas: una métrica normalizada como RSI y otro sin normalizar como close:\n",
    "\n",
    "- Layers\n",
    "- Neurons\n",
    "- Epochs\n",
    "- Tipo de normalización\n",
    "- Activacion y función de pérdidas\n",
    "\n",
    "Probemos primero diferentes tipos de noramalización con la siguientes caracterisiticas del modelo:\n",
    "\n",
    "Normalizacion:\n",
    "- 0: Normalizar sobre todo el dataset\n",
    "- 1: Min Max Scaller (No valida al ser una sola line de test y por tanto normalizar con respecto a nada)\n",
    "- 2: Min Max por columnas sobre todo el dataset\n",
    "- 3: Ln\n",
    "- 4: Sin normalización\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'close'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = columns_1\n",
    "num_features = len(columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalizacion: 0\n",
      "Loading... ETH\n",
      "Extracting columns columns for ETH\n",
      "Proccessing and arranging columns for LSTM model\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>close_19</th>\n",
       "      <th>RSI_19</th>\n",
       "      <th>close_18</th>\n",
       "      <th>RSI_18</th>\n",
       "      <th>close_17</th>\n",
       "      <th>RSI_17</th>\n",
       "      <th>close_16</th>\n",
       "      <th>RSI_16</th>\n",
       "      <th>close_15</th>\n",
       "      <th>RSI_15</th>\n",
       "      <th>...</th>\n",
       "      <th>RSI_4</th>\n",
       "      <th>close_3</th>\n",
       "      <th>RSI_3</th>\n",
       "      <th>close_2</th>\n",
       "      <th>RSI_2</th>\n",
       "      <th>close_1</th>\n",
       "      <th>RSI_1</th>\n",
       "      <th>close_0</th>\n",
       "      <th>RSI_0</th>\n",
       "      <th>close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>754.99</td>\n",
       "      <td>51.874455</td>\n",
       "      <td>855.28</td>\n",
       "      <td>64.086633</td>\n",
       "      <td>934.03</td>\n",
       "      <td>70.431522</td>\n",
       "      <td>940.00</td>\n",
       "      <td>70.851945</td>\n",
       "      <td>959.30</td>\n",
       "      <td>72.226781</td>\n",
       "      <td>...</td>\n",
       "      <td>48.819684</td>\n",
       "      <td>1000.00</td>\n",
       "      <td>48.819684</td>\n",
       "      <td>994.00</td>\n",
       "      <td>48.493851</td>\n",
       "      <td>1032.50</td>\n",
       "      <td>50.764615</td>\n",
       "      <td>1152.75</td>\n",
       "      <td>57.122992</td>\n",
       "      <td>877.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>855.28</td>\n",
       "      <td>64.086633</td>\n",
       "      <td>934.03</td>\n",
       "      <td>70.431522</td>\n",
       "      <td>940.00</td>\n",
       "      <td>70.851945</td>\n",
       "      <td>959.30</td>\n",
       "      <td>72.226781</td>\n",
       "      <td>1004.11</td>\n",
       "      <td>75.156684</td>\n",
       "      <td>...</td>\n",
       "      <td>48.819684</td>\n",
       "      <td>994.00</td>\n",
       "      <td>48.493851</td>\n",
       "      <td>1032.50</td>\n",
       "      <td>50.764615</td>\n",
       "      <td>1152.75</td>\n",
       "      <td>57.122992</td>\n",
       "      <td>1049.00</td>\n",
       "      <td>51.002981</td>\n",
       "      <td>851.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>934.03</td>\n",
       "      <td>70.431522</td>\n",
       "      <td>940.00</td>\n",
       "      <td>70.851945</td>\n",
       "      <td>959.30</td>\n",
       "      <td>72.226781</td>\n",
       "      <td>1004.11</td>\n",
       "      <td>75.156684</td>\n",
       "      <td>1123.09</td>\n",
       "      <td>80.914056</td>\n",
       "      <td>...</td>\n",
       "      <td>48.493851</td>\n",
       "      <td>1032.50</td>\n",
       "      <td>50.764615</td>\n",
       "      <td>1152.75</td>\n",
       "      <td>57.122992</td>\n",
       "      <td>1049.00</td>\n",
       "      <td>51.002981</td>\n",
       "      <td>993.00</td>\n",
       "      <td>48.012894</td>\n",
       "      <td>808.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>940.00</td>\n",
       "      <td>70.851945</td>\n",
       "      <td>959.30</td>\n",
       "      <td>72.226781</td>\n",
       "      <td>1004.11</td>\n",
       "      <td>75.156684</td>\n",
       "      <td>1123.09</td>\n",
       "      <td>80.914056</td>\n",
       "      <td>1133.18</td>\n",
       "      <td>81.309636</td>\n",
       "      <td>...</td>\n",
       "      <td>50.764615</td>\n",
       "      <td>1152.75</td>\n",
       "      <td>57.122992</td>\n",
       "      <td>1049.00</td>\n",
       "      <td>51.002981</td>\n",
       "      <td>993.00</td>\n",
       "      <td>48.012894</td>\n",
       "      <td>980.00</td>\n",
       "      <td>47.319361</td>\n",
       "      <td>866.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>959.30</td>\n",
       "      <td>72.226781</td>\n",
       "      <td>1004.11</td>\n",
       "      <td>75.156684</td>\n",
       "      <td>1123.09</td>\n",
       "      <td>80.914056</td>\n",
       "      <td>1133.18</td>\n",
       "      <td>81.309636</td>\n",
       "      <td>1291.00</td>\n",
       "      <td>86.146268</td>\n",
       "      <td>...</td>\n",
       "      <td>57.122992</td>\n",
       "      <td>1049.00</td>\n",
       "      <td>51.002981</td>\n",
       "      <td>993.00</td>\n",
       "      <td>48.012894</td>\n",
       "      <td>980.00</td>\n",
       "      <td>47.319361</td>\n",
       "      <td>1061.00</td>\n",
       "      <td>51.974254</td>\n",
       "      <td>841.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1573</th>\n",
       "      <td>4287.80</td>\n",
       "      <td>47.095555</td>\n",
       "      <td>3996.90</td>\n",
       "      <td>39.023233</td>\n",
       "      <td>4294.76</td>\n",
       "      <td>48.716109</td>\n",
       "      <td>4412.17</td>\n",
       "      <td>51.957920</td>\n",
       "      <td>4258.31</td>\n",
       "      <td>47.702403</td>\n",
       "      <td>...</td>\n",
       "      <td>53.835840</td>\n",
       "      <td>4215.73</td>\n",
       "      <td>46.826530</td>\n",
       "      <td>4117.25</td>\n",
       "      <td>44.735958</td>\n",
       "      <td>4196.44</td>\n",
       "      <td>46.793026</td>\n",
       "      <td>4347.59</td>\n",
       "      <td>50.574650</td>\n",
       "      <td>4063.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1574</th>\n",
       "      <td>3996.90</td>\n",
       "      <td>39.023233</td>\n",
       "      <td>4294.76</td>\n",
       "      <td>48.716109</td>\n",
       "      <td>4412.17</td>\n",
       "      <td>51.957920</td>\n",
       "      <td>4258.31</td>\n",
       "      <td>47.702403</td>\n",
       "      <td>4085.97</td>\n",
       "      <td>43.413283</td>\n",
       "      <td>...</td>\n",
       "      <td>46.826530</td>\n",
       "      <td>4117.25</td>\n",
       "      <td>44.735958</td>\n",
       "      <td>4196.44</td>\n",
       "      <td>46.793026</td>\n",
       "      <td>4347.59</td>\n",
       "      <td>50.574650</td>\n",
       "      <td>4306.40</td>\n",
       "      <td>49.541304</td>\n",
       "      <td>4037.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1575</th>\n",
       "      <td>4294.76</td>\n",
       "      <td>48.716109</td>\n",
       "      <td>4412.17</td>\n",
       "      <td>51.957920</td>\n",
       "      <td>4258.31</td>\n",
       "      <td>47.702403</td>\n",
       "      <td>4085.97</td>\n",
       "      <td>43.413283</td>\n",
       "      <td>4339.44</td>\n",
       "      <td>50.467423</td>\n",
       "      <td>...</td>\n",
       "      <td>44.735958</td>\n",
       "      <td>4196.44</td>\n",
       "      <td>46.793026</td>\n",
       "      <td>4347.59</td>\n",
       "      <td>50.574650</td>\n",
       "      <td>4306.40</td>\n",
       "      <td>49.541304</td>\n",
       "      <td>4436.91</td>\n",
       "      <td>52.829940</td>\n",
       "      <td>3792.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1576</th>\n",
       "      <td>4412.17</td>\n",
       "      <td>51.957920</td>\n",
       "      <td>4258.31</td>\n",
       "      <td>47.702403</td>\n",
       "      <td>4085.97</td>\n",
       "      <td>43.413283</td>\n",
       "      <td>4339.44</td>\n",
       "      <td>50.467423</td>\n",
       "      <td>4269.36</td>\n",
       "      <td>48.661227</td>\n",
       "      <td>...</td>\n",
       "      <td>46.793026</td>\n",
       "      <td>4347.59</td>\n",
       "      <td>50.574650</td>\n",
       "      <td>4306.40</td>\n",
       "      <td>49.541304</td>\n",
       "      <td>4436.91</td>\n",
       "      <td>52.829940</td>\n",
       "      <td>4105.64</td>\n",
       "      <td>44.841174</td>\n",
       "      <td>3630.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1577</th>\n",
       "      <td>4258.31</td>\n",
       "      <td>47.702403</td>\n",
       "      <td>4085.97</td>\n",
       "      <td>43.413283</td>\n",
       "      <td>4339.44</td>\n",
       "      <td>50.467423</td>\n",
       "      <td>4269.36</td>\n",
       "      <td>48.661227</td>\n",
       "      <td>4524.85</td>\n",
       "      <td>54.986266</td>\n",
       "      <td>...</td>\n",
       "      <td>50.574650</td>\n",
       "      <td>4306.40</td>\n",
       "      <td>49.541304</td>\n",
       "      <td>4436.91</td>\n",
       "      <td>52.829940</td>\n",
       "      <td>4105.64</td>\n",
       "      <td>44.841174</td>\n",
       "      <td>3897.94</td>\n",
       "      <td>40.686916</td>\n",
       "      <td>3709.27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1421 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      close_19     RSI_19  close_18     RSI_18  close_17     RSI_17  close_16  \\\n",
       "157     754.99  51.874455    855.28  64.086633    934.03  70.431522    940.00   \n",
       "158     855.28  64.086633    934.03  70.431522    940.00  70.851945    959.30   \n",
       "159     934.03  70.431522    940.00  70.851945    959.30  72.226781   1004.11   \n",
       "160     940.00  70.851945    959.30  72.226781   1004.11  75.156684   1123.09   \n",
       "161     959.30  72.226781   1004.11  75.156684   1123.09  80.914056   1133.18   \n",
       "...        ...        ...       ...        ...       ...        ...       ...   \n",
       "1573   4287.80  47.095555   3996.90  39.023233   4294.76  48.716109   4412.17   \n",
       "1574   3996.90  39.023233   4294.76  48.716109   4412.17  51.957920   4258.31   \n",
       "1575   4294.76  48.716109   4412.17  51.957920   4258.31  47.702403   4085.97   \n",
       "1576   4412.17  51.957920   4258.31  47.702403   4085.97  43.413283   4339.44   \n",
       "1577   4258.31  47.702403   4085.97  43.413283   4339.44  50.467423   4269.36   \n",
       "\n",
       "         RSI_16  close_15     RSI_15  ...      RSI_4  close_3      RSI_3  \\\n",
       "157   70.851945    959.30  72.226781  ...  48.819684  1000.00  48.819684   \n",
       "158   72.226781   1004.11  75.156684  ...  48.819684   994.00  48.493851   \n",
       "159   75.156684   1123.09  80.914056  ...  48.493851  1032.50  50.764615   \n",
       "160   80.914056   1133.18  81.309636  ...  50.764615  1152.75  57.122992   \n",
       "161   81.309636   1291.00  86.146268  ...  57.122992  1049.00  51.002981   \n",
       "...         ...       ...        ...  ...        ...      ...        ...   \n",
       "1573  51.957920   4258.31  47.702403  ...  53.835840  4215.73  46.826530   \n",
       "1574  47.702403   4085.97  43.413283  ...  46.826530  4117.25  44.735958   \n",
       "1575  43.413283   4339.44  50.467423  ...  44.735958  4196.44  46.793026   \n",
       "1576  50.467423   4269.36  48.661227  ...  46.793026  4347.59  50.574650   \n",
       "1577  48.661227   4524.85  54.986266  ...  50.574650  4306.40  49.541304   \n",
       "\n",
       "      close_2      RSI_2  close_1      RSI_1  close_0      RSI_0    close  \n",
       "157    994.00  48.493851  1032.50  50.764615  1152.75  57.122992   877.00  \n",
       "158   1032.50  50.764615  1152.75  57.122992  1049.00  51.002981   851.15  \n",
       "159   1152.75  57.122992  1049.00  51.002981   993.00  48.012894   808.99  \n",
       "160   1049.00  51.002981   993.00  48.012894   980.00  47.319361   866.66  \n",
       "161    993.00  48.012894   980.00  47.319361  1061.00  51.974254   841.57  \n",
       "...       ...        ...      ...        ...      ...        ...      ...  \n",
       "1573  4117.25  44.735958  4196.44  46.793026  4347.59  50.574650  4063.56  \n",
       "1574  4196.44  46.793026  4347.59  50.574650  4306.40  49.541304  4037.23  \n",
       "1575  4347.59  50.574650  4306.40  49.541304  4436.91  52.829940  3792.75  \n",
       "1576  4306.40  49.541304  4436.91  52.829940  4105.64  44.841174  3630.19  \n",
       "1577  4436.91  52.829940  4105.64  44.841174  3897.94  40.686916  3709.27  \n",
       "\n",
       "[1421 rows x 41 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>close_19</th>\n",
       "      <th>RSI_19</th>\n",
       "      <th>close_18</th>\n",
       "      <th>RSI_18</th>\n",
       "      <th>close_17</th>\n",
       "      <th>RSI_17</th>\n",
       "      <th>close_16</th>\n",
       "      <th>RSI_16</th>\n",
       "      <th>close_15</th>\n",
       "      <th>RSI_15</th>\n",
       "      <th>...</th>\n",
       "      <th>RSI_4</th>\n",
       "      <th>close_3</th>\n",
       "      <th>RSI_3</th>\n",
       "      <th>close_2</th>\n",
       "      <th>RSI_2</th>\n",
       "      <th>close_1</th>\n",
       "      <th>RSI_1</th>\n",
       "      <th>close_0</th>\n",
       "      <th>RSI_0</th>\n",
       "      <th>close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1578</th>\n",
       "      <td>4085.97</td>\n",
       "      <td>43.413283</td>\n",
       "      <td>4339.44</td>\n",
       "      <td>50.467423</td>\n",
       "      <td>4269.36</td>\n",
       "      <td>48.661227</td>\n",
       "      <td>4524.85</td>\n",
       "      <td>54.986266</td>\n",
       "      <td>4041.2</td>\n",
       "      <td>43.948042</td>\n",
       "      <td>...</td>\n",
       "      <td>49.541304</td>\n",
       "      <td>4436.91</td>\n",
       "      <td>52.82994</td>\n",
       "      <td>4105.64</td>\n",
       "      <td>44.841174</td>\n",
       "      <td>3897.94</td>\n",
       "      <td>40.686916</td>\n",
       "      <td>4089.37</td>\n",
       "      <td>45.681743</td>\n",
       "      <td>3725.46</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      close_19     RSI_19  close_18     RSI_18  close_17     RSI_17  close_16  \\\n",
       "1578   4085.97  43.413283   4339.44  50.467423   4269.36  48.661227   4524.85   \n",
       "\n",
       "         RSI_16  close_15     RSI_15  ...      RSI_4  close_3     RSI_3  \\\n",
       "1578  54.986266    4041.2  43.948042  ...  49.541304  4436.91  52.82994   \n",
       "\n",
       "      close_2      RSI_2  close_1      RSI_1  close_0      RSI_0    close  \n",
       "1578  4105.64  44.841174  3897.94  40.686916  4089.37  45.681743  3725.46  \n",
       "\n",
       "[1 rows x 41 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (1421, 1, 40) (1421, 1)\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 1, 25)             6600      \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 1, 25)             5100      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1, 25)             0         \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 1, 25)             5100      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 1, 25)             0         \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 1, 25)             5100      \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 1, 25)             0         \n",
      "_________________________________________________________________\n",
      "lstm_5 (LSTM)                (None, 25)                5100      \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 25)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 26        \n",
      "=================================================================\n",
      "Total params: 27,026\n",
      "Trainable params: 27,026\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Y shape (1421, 1)\n",
      "Train on 1421 samples, validate on 285 samples\n",
      "Epoch 1/100\n",
      " - 11s - loss: 0.6710 - mse: 0.6710 - val_loss: 0.1038 - val_mse: 0.1038\n",
      "Epoch 2/100\n",
      " - 0s - loss: 0.4938 - mse: 0.4938 - val_loss: 0.0300 - val_mse: 0.0300\n",
      "Epoch 3/100\n",
      " - 0s - loss: 0.1943 - mse: 0.1943 - val_loss: 0.2281 - val_mse: 0.2281\n",
      "Epoch 4/100\n",
      " - 0s - loss: 0.0894 - mse: 0.0894 - val_loss: 0.1284 - val_mse: 0.1284\n",
      "Epoch 5/100\n",
      " - 0s - loss: 0.0870 - mse: 0.0870 - val_loss: 0.1588 - val_mse: 0.1588\n",
      "Epoch 6/100\n",
      " - 0s - loss: 0.0697 - mse: 0.0697 - val_loss: 0.1151 - val_mse: 0.1151\n",
      "Epoch 7/100\n",
      " - 0s - loss: 0.0607 - mse: 0.0607 - val_loss: 0.0794 - val_mse: 0.0794\n",
      "Epoch 8/100\n",
      " - 0s - loss: 0.0471 - mse: 0.0471 - val_loss: 0.0466 - val_mse: 0.0466\n",
      "Epoch 9/100\n",
      " - 0s - loss: 0.0374 - mse: 0.0374 - val_loss: 0.0265 - val_mse: 0.0265\n",
      "Epoch 10/100\n",
      " - 0s - loss: 0.0305 - mse: 0.0305 - val_loss: 0.0202 - val_mse: 0.0202\n",
      "Epoch 11/100\n",
      " - 0s - loss: 0.0266 - mse: 0.0266 - val_loss: 0.0193 - val_mse: 0.0193\n",
      "Epoch 12/100\n",
      " - 0s - loss: 0.0254 - mse: 0.0254 - val_loss: 0.0195 - val_mse: 0.0195\n",
      "Epoch 13/100\n",
      " - 0s - loss: 0.0261 - mse: 0.0261 - val_loss: 0.0194 - val_mse: 0.0194\n",
      "Epoch 14/100\n",
      " - 1s - loss: 0.0287 - mse: 0.0287 - val_loss: 0.0192 - val_mse: 0.0192\n",
      "Epoch 15/100\n",
      " - 1s - loss: 0.0265 - mse: 0.0265 - val_loss: 0.0191 - val_mse: 0.0191\n",
      "Epoch 16/100\n",
      " - 0s - loss: 0.0265 - mse: 0.0265 - val_loss: 0.0193 - val_mse: 0.0193\n",
      "Epoch 17/100\n",
      " - 0s - loss: 0.0253 - mse: 0.0253 - val_loss: 0.0193 - val_mse: 0.0193\n",
      "Epoch 18/100\n",
      " - 0s - loss: 0.0233 - mse: 0.0233 - val_loss: 0.0193 - val_mse: 0.0193\n",
      "Epoch 19/100\n",
      " - 0s - loss: 0.0225 - mse: 0.0225 - val_loss: 0.0193 - val_mse: 0.0193\n",
      "Epoch 20/100\n",
      " - 0s - loss: 0.0227 - mse: 0.0227 - val_loss: 0.0193 - val_mse: 0.0193\n",
      "Epoch 21/100\n",
      " - 0s - loss: 0.0229 - mse: 0.0229 - val_loss: 0.0197 - val_mse: 0.0197\n",
      "Epoch 22/100\n",
      " - 1s - loss: 0.0224 - mse: 0.0224 - val_loss: 0.0196 - val_mse: 0.0196\n",
      "Epoch 23/100\n",
      " - 0s - loss: 0.0231 - mse: 0.0231 - val_loss: 0.0196 - val_mse: 0.0196\n",
      "Epoch 24/100\n",
      " - 1s - loss: 0.0223 - mse: 0.0223 - val_loss: 0.0194 - val_mse: 0.0194\n",
      "Epoch 25/100\n",
      " - 1s - loss: 0.0205 - mse: 0.0205 - val_loss: 0.0196 - val_mse: 0.0196\n",
      "Epoch 26/100\n",
      " - 1s - loss: 0.0202 - mse: 0.0202 - val_loss: 0.0197 - val_mse: 0.0197\n",
      "Epoch 27/100\n",
      " - 0s - loss: 0.0211 - mse: 0.0211 - val_loss: 0.0197 - val_mse: 0.0197\n",
      "Epoch 28/100\n",
      " - 0s - loss: 0.0199 - mse: 0.0199 - val_loss: 0.0195 - val_mse: 0.0195\n",
      "Epoch 29/100\n",
      " - 0s - loss: 0.0198 - mse: 0.0198 - val_loss: 0.0198 - val_mse: 0.0198\n",
      "Epoch 30/100\n",
      " - 1s - loss: 0.0191 - mse: 0.0191 - val_loss: 0.0199 - val_mse: 0.0199\n",
      "Epoch 31/100\n",
      " - 0s - loss: 0.0188 - mse: 0.0188 - val_loss: 0.0199 - val_mse: 0.0199\n",
      "Epoch 32/100\n",
      " - 1s - loss: 0.0190 - mse: 0.0190 - val_loss: 0.0201 - val_mse: 0.0201\n",
      "Epoch 33/100\n",
      " - 0s - loss: 0.0190 - mse: 0.0190 - val_loss: 0.0200 - val_mse: 0.0200\n",
      "Epoch 34/100\n",
      " - 0s - loss: 0.0174 - mse: 0.0174 - val_loss: 0.0201 - val_mse: 0.0201\n",
      "Epoch 35/100\n",
      " - 0s - loss: 0.0178 - mse: 0.0178 - val_loss: 0.0202 - val_mse: 0.0202\n",
      "Epoch 36/100\n",
      " - 0s - loss: 0.0174 - mse: 0.0174 - val_loss: 0.0197 - val_mse: 0.0197\n",
      "Epoch 37/100\n",
      " - 0s - loss: 0.0167 - mse: 0.0167 - val_loss: 0.0196 - val_mse: 0.0196\n",
      "Epoch 38/100\n",
      " - 0s - loss: 0.0163 - mse: 0.0163 - val_loss: 0.0201 - val_mse: 0.0201\n",
      "Epoch 39/100\n",
      " - 0s - loss: 0.0160 - mse: 0.0160 - val_loss: 0.0199 - val_mse: 0.0199\n",
      "Epoch 40/100\n",
      " - 0s - loss: 0.0162 - mse: 0.0162 - val_loss: 0.0203 - val_mse: 0.0203\n",
      "Epoch 41/100\n",
      " - 0s - loss: 0.0162 - mse: 0.0162 - val_loss: 0.0199 - val_mse: 0.0199\n",
      "Epoch 42/100\n",
      " - 0s - loss: 0.0162 - mse: 0.0162 - val_loss: 0.0204 - val_mse: 0.0204\n",
      "Epoch 43/100\n",
      " - 0s - loss: 0.0154 - mse: 0.0154 - val_loss: 0.0204 - val_mse: 0.0204\n",
      "Epoch 44/100\n",
      " - 0s - loss: 0.0152 - mse: 0.0152 - val_loss: 0.0198 - val_mse: 0.0198\n",
      "Epoch 45/100\n",
      " - 0s - loss: 0.0154 - mse: 0.0154 - val_loss: 0.0203 - val_mse: 0.0203\n",
      "Epoch 46/100\n",
      " - 0s - loss: 0.0156 - mse: 0.0156 - val_loss: 0.0199 - val_mse: 0.0199\n",
      "Epoch 47/100\n",
      " - 0s - loss: 0.0150 - mse: 0.0150 - val_loss: 0.0202 - val_mse: 0.0202\n",
      "Epoch 48/100\n",
      " - 0s - loss: 0.0144 - mse: 0.0144 - val_loss: 0.0199 - val_mse: 0.0199\n",
      "Epoch 49/100\n",
      " - 1s - loss: 0.0152 - mse: 0.0152 - val_loss: 0.0201 - val_mse: 0.0201\n",
      "Epoch 50/100\n",
      " - 1s - loss: 0.0149 - mse: 0.0149 - val_loss: 0.0199 - val_mse: 0.0199\n",
      "Epoch 51/100\n",
      " - 1s - loss: 0.0146 - mse: 0.0146 - val_loss: 0.0202 - val_mse: 0.0202\n",
      "Epoch 52/100\n",
      " - 1s - loss: 0.0140 - mse: 0.0140 - val_loss: 0.0199 - val_mse: 0.0199\n",
      "Epoch 53/100\n",
      " - 1s - loss: 0.0141 - mse: 0.0141 - val_loss: 0.0204 - val_mse: 0.0204\n",
      "Epoch 54/100\n",
      " - 1s - loss: 0.0137 - mse: 0.0137 - val_loss: 0.0202 - val_mse: 0.0202\n",
      "Epoch 55/100\n",
      " - 1s - loss: 0.0137 - mse: 0.0137 - val_loss: 0.0201 - val_mse: 0.0201\n",
      "Epoch 56/100\n",
      " - 1s - loss: 0.0149 - mse: 0.0149 - val_loss: 0.0204 - val_mse: 0.0204\n",
      "Epoch 57/100\n",
      " - 1s - loss: 0.0142 - mse: 0.0142 - val_loss: 0.0201 - val_mse: 0.0201\n",
      "Epoch 58/100\n",
      " - 1s - loss: 0.0133 - mse: 0.0133 - val_loss: 0.0197 - val_mse: 0.0197\n",
      "Epoch 59/100\n",
      " - 1s - loss: 0.0138 - mse: 0.0138 - val_loss: 0.0200 - val_mse: 0.0200\n",
      "Epoch 60/100\n",
      " - 1s - loss: 0.0137 - mse: 0.0137 - val_loss: 0.0198 - val_mse: 0.0198\n",
      "Epoch 61/100\n",
      " - 0s - loss: 0.0131 - mse: 0.0131 - val_loss: 0.0204 - val_mse: 0.0204\n",
      "Epoch 62/100\n",
      " - 0s - loss: 0.0133 - mse: 0.0133 - val_loss: 0.0200 - val_mse: 0.0200\n",
      "Epoch 63/100\n",
      " - 0s - loss: 0.0134 - mse: 0.0134 - val_loss: 0.0197 - val_mse: 0.0197\n",
      "Epoch 64/100\n",
      " - 0s - loss: 0.0133 - mse: 0.0133 - val_loss: 0.0201 - val_mse: 0.0201\n",
      "Epoch 65/100\n",
      " - 0s - loss: 0.0134 - mse: 0.0134 - val_loss: 0.0196 - val_mse: 0.0196\n",
      "Epoch 66/100\n",
      " - 0s - loss: 0.0130 - mse: 0.0130 - val_loss: 0.0198 - val_mse: 0.0198\n",
      "Epoch 67/100\n",
      " - 0s - loss: 0.0129 - mse: 0.0129 - val_loss: 0.0195 - val_mse: 0.0195\n",
      "Epoch 68/100\n",
      " - 0s - loss: 0.0125 - mse: 0.0125 - val_loss: 0.0195 - val_mse: 0.0195\n",
      "Epoch 69/100\n",
      " - 0s - loss: 0.0117 - mse: 0.0117 - val_loss: 0.0191 - val_mse: 0.0191\n",
      "Epoch 70/100\n",
      " - 0s - loss: 0.0124 - mse: 0.0124 - val_loss: 0.0195 - val_mse: 0.0195\n",
      "Epoch 71/100\n",
      " - 0s - loss: 0.0127 - mse: 0.0127 - val_loss: 0.0192 - val_mse: 0.0192\n",
      "Epoch 72/100\n",
      " - 0s - loss: 0.0117 - mse: 0.0117 - val_loss: 0.0193 - val_mse: 0.0193\n",
      "Epoch 73/100\n",
      " - 0s - loss: 0.0123 - mse: 0.0123 - val_loss: 0.0196 - val_mse: 0.0196\n",
      "Epoch 74/100\n",
      " - 0s - loss: 0.0120 - mse: 0.0120 - val_loss: 0.0192 - val_mse: 0.0192\n",
      "Epoch 75/100\n",
      " - 0s - loss: 0.0126 - mse: 0.0126 - val_loss: 0.0190 - val_mse: 0.0190\n",
      "Epoch 76/100\n",
      " - 0s - loss: 0.0117 - mse: 0.0117 - val_loss: 0.0189 - val_mse: 0.0189\n",
      "Epoch 77/100\n",
      " - 0s - loss: 0.0116 - mse: 0.0116 - val_loss: 0.0190 - val_mse: 0.0190\n",
      "Epoch 78/100\n",
      " - 0s - loss: 0.0111 - mse: 0.0111 - val_loss: 0.0187 - val_mse: 0.0187\n",
      "Epoch 79/100\n",
      " - 0s - loss: 0.0113 - mse: 0.0113 - val_loss: 0.0188 - val_mse: 0.0188\n",
      "Epoch 80/100\n",
      " - 1s - loss: 0.0123 - mse: 0.0123 - val_loss: 0.0189 - val_mse: 0.0189\n",
      "Epoch 81/100\n",
      " - 0s - loss: 0.0122 - mse: 0.0122 - val_loss: 0.0188 - val_mse: 0.0188\n",
      "Epoch 82/100\n",
      " - 0s - loss: 0.0112 - mse: 0.0112 - val_loss: 0.0186 - val_mse: 0.0186\n",
      "Epoch 83/100\n",
      " - 0s - loss: 0.0120 - mse: 0.0120 - val_loss: 0.0185 - val_mse: 0.0185\n",
      "Epoch 84/100\n",
      " - 0s - loss: 0.0107 - mse: 0.0107 - val_loss: 0.0182 - val_mse: 0.0182\n",
      "Epoch 85/100\n",
      " - 0s - loss: 0.0114 - mse: 0.0114 - val_loss: 0.0185 - val_mse: 0.0185\n",
      "Epoch 86/100\n",
      " - 0s - loss: 0.0120 - mse: 0.0120 - val_loss: 0.0187 - val_mse: 0.0187\n",
      "Epoch 87/100\n",
      " - 0s - loss: 0.0113 - mse: 0.0113 - val_loss: 0.0186 - val_mse: 0.0186\n",
      "Epoch 88/100\n",
      " - 0s - loss: 0.0113 - mse: 0.0113 - val_loss: 0.0181 - val_mse: 0.0181\n",
      "Epoch 89/100\n",
      " - 0s - loss: 0.0118 - mse: 0.0118 - val_loss: 0.0178 - val_mse: 0.0178\n",
      "Epoch 90/100\n",
      " - 0s - loss: 0.0111 - mse: 0.0111 - val_loss: 0.0182 - val_mse: 0.0182\n",
      "Epoch 91/100\n",
      " - 0s - loss: 0.0118 - mse: 0.0118 - val_loss: 0.0182 - val_mse: 0.0182\n",
      "Epoch 92/100\n",
      " - 0s - loss: 0.0113 - mse: 0.0113 - val_loss: 0.0177 - val_mse: 0.0177\n",
      "Epoch 93/100\n",
      " - 0s - loss: 0.0114 - mse: 0.0114 - val_loss: 0.0180 - val_mse: 0.0180\n",
      "Epoch 94/100\n",
      " - 0s - loss: 0.0113 - mse: 0.0113 - val_loss: 0.0177 - val_mse: 0.0177\n",
      "Epoch 95/100\n",
      " - 0s - loss: 0.0107 - mse: 0.0107 - val_loss: 0.0178 - val_mse: 0.0178\n",
      "Epoch 96/100\n",
      " - 0s - loss: 0.0107 - mse: 0.0107 - val_loss: 0.0176 - val_mse: 0.0176\n",
      "Epoch 97/100\n",
      " - 0s - loss: 0.0107 - mse: 0.0107 - val_loss: 0.0172 - val_mse: 0.0172\n",
      "Epoch 98/100\n",
      " - 0s - loss: 0.0111 - mse: 0.0111 - val_loss: 0.0177 - val_mse: 0.0177\n",
      "Epoch 99/100\n",
      " - 0s - loss: 0.0109 - mse: 0.0109 - val_loss: 0.0172 - val_mse: 0.0172\n",
      "Epoch 100/100\n",
      " - 0s - loss: 0.0104 - mse: 0.0104 - val_loss: 0.0170 - val_mse: 0.0170\n",
      "real [[3725.46]]\n",
      "Test RMSE: 46.822\n",
      "Diff [[-46.8222923]]\n",
      "% Diff [[-1.25681909]] %\n",
      "Predictions [[3772.2822923]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "norm_strat = 0\n",
    "print('Normalizacion:', norm_strat)\n",
    "execute_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalizacion: 2\n",
      "Loading... ETH\n",
      "Extracting columns columns for ETH\n",
      "Proccessing and arranging columns for LSTM model\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>close_19</th>\n",
       "      <th>RSI_19</th>\n",
       "      <th>close_18</th>\n",
       "      <th>RSI_18</th>\n",
       "      <th>close_17</th>\n",
       "      <th>RSI_17</th>\n",
       "      <th>close_16</th>\n",
       "      <th>RSI_16</th>\n",
       "      <th>close_15</th>\n",
       "      <th>RSI_15</th>\n",
       "      <th>...</th>\n",
       "      <th>RSI_4</th>\n",
       "      <th>close_3</th>\n",
       "      <th>RSI_3</th>\n",
       "      <th>close_2</th>\n",
       "      <th>RSI_2</th>\n",
       "      <th>close_1</th>\n",
       "      <th>RSI_1</th>\n",
       "      <th>close_0</th>\n",
       "      <th>RSI_0</th>\n",
       "      <th>close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>754.99</td>\n",
       "      <td>51.874455</td>\n",
       "      <td>855.28</td>\n",
       "      <td>64.086633</td>\n",
       "      <td>934.03</td>\n",
       "      <td>70.431522</td>\n",
       "      <td>940.00</td>\n",
       "      <td>70.851945</td>\n",
       "      <td>959.30</td>\n",
       "      <td>72.226781</td>\n",
       "      <td>...</td>\n",
       "      <td>48.819684</td>\n",
       "      <td>1000.00</td>\n",
       "      <td>48.819684</td>\n",
       "      <td>994.00</td>\n",
       "      <td>48.493851</td>\n",
       "      <td>1032.50</td>\n",
       "      <td>50.764615</td>\n",
       "      <td>1152.75</td>\n",
       "      <td>57.122992</td>\n",
       "      <td>877.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>855.28</td>\n",
       "      <td>64.086633</td>\n",
       "      <td>934.03</td>\n",
       "      <td>70.431522</td>\n",
       "      <td>940.00</td>\n",
       "      <td>70.851945</td>\n",
       "      <td>959.30</td>\n",
       "      <td>72.226781</td>\n",
       "      <td>1004.11</td>\n",
       "      <td>75.156684</td>\n",
       "      <td>...</td>\n",
       "      <td>48.819684</td>\n",
       "      <td>994.00</td>\n",
       "      <td>48.493851</td>\n",
       "      <td>1032.50</td>\n",
       "      <td>50.764615</td>\n",
       "      <td>1152.75</td>\n",
       "      <td>57.122992</td>\n",
       "      <td>1049.00</td>\n",
       "      <td>51.002981</td>\n",
       "      <td>851.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>934.03</td>\n",
       "      <td>70.431522</td>\n",
       "      <td>940.00</td>\n",
       "      <td>70.851945</td>\n",
       "      <td>959.30</td>\n",
       "      <td>72.226781</td>\n",
       "      <td>1004.11</td>\n",
       "      <td>75.156684</td>\n",
       "      <td>1123.09</td>\n",
       "      <td>80.914056</td>\n",
       "      <td>...</td>\n",
       "      <td>48.493851</td>\n",
       "      <td>1032.50</td>\n",
       "      <td>50.764615</td>\n",
       "      <td>1152.75</td>\n",
       "      <td>57.122992</td>\n",
       "      <td>1049.00</td>\n",
       "      <td>51.002981</td>\n",
       "      <td>993.00</td>\n",
       "      <td>48.012894</td>\n",
       "      <td>808.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>940.00</td>\n",
       "      <td>70.851945</td>\n",
       "      <td>959.30</td>\n",
       "      <td>72.226781</td>\n",
       "      <td>1004.11</td>\n",
       "      <td>75.156684</td>\n",
       "      <td>1123.09</td>\n",
       "      <td>80.914056</td>\n",
       "      <td>1133.18</td>\n",
       "      <td>81.309636</td>\n",
       "      <td>...</td>\n",
       "      <td>50.764615</td>\n",
       "      <td>1152.75</td>\n",
       "      <td>57.122992</td>\n",
       "      <td>1049.00</td>\n",
       "      <td>51.002981</td>\n",
       "      <td>993.00</td>\n",
       "      <td>48.012894</td>\n",
       "      <td>980.00</td>\n",
       "      <td>47.319361</td>\n",
       "      <td>866.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>959.30</td>\n",
       "      <td>72.226781</td>\n",
       "      <td>1004.11</td>\n",
       "      <td>75.156684</td>\n",
       "      <td>1123.09</td>\n",
       "      <td>80.914056</td>\n",
       "      <td>1133.18</td>\n",
       "      <td>81.309636</td>\n",
       "      <td>1291.00</td>\n",
       "      <td>86.146268</td>\n",
       "      <td>...</td>\n",
       "      <td>57.122992</td>\n",
       "      <td>1049.00</td>\n",
       "      <td>51.002981</td>\n",
       "      <td>993.00</td>\n",
       "      <td>48.012894</td>\n",
       "      <td>980.00</td>\n",
       "      <td>47.319361</td>\n",
       "      <td>1061.00</td>\n",
       "      <td>51.974254</td>\n",
       "      <td>841.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1573</th>\n",
       "      <td>4287.80</td>\n",
       "      <td>47.095555</td>\n",
       "      <td>3996.90</td>\n",
       "      <td>39.023233</td>\n",
       "      <td>4294.76</td>\n",
       "      <td>48.716109</td>\n",
       "      <td>4412.17</td>\n",
       "      <td>51.957920</td>\n",
       "      <td>4258.31</td>\n",
       "      <td>47.702403</td>\n",
       "      <td>...</td>\n",
       "      <td>53.835840</td>\n",
       "      <td>4215.73</td>\n",
       "      <td>46.826530</td>\n",
       "      <td>4117.25</td>\n",
       "      <td>44.735958</td>\n",
       "      <td>4196.44</td>\n",
       "      <td>46.793026</td>\n",
       "      <td>4347.59</td>\n",
       "      <td>50.574650</td>\n",
       "      <td>4063.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1574</th>\n",
       "      <td>3996.90</td>\n",
       "      <td>39.023233</td>\n",
       "      <td>4294.76</td>\n",
       "      <td>48.716109</td>\n",
       "      <td>4412.17</td>\n",
       "      <td>51.957920</td>\n",
       "      <td>4258.31</td>\n",
       "      <td>47.702403</td>\n",
       "      <td>4085.97</td>\n",
       "      <td>43.413283</td>\n",
       "      <td>...</td>\n",
       "      <td>46.826530</td>\n",
       "      <td>4117.25</td>\n",
       "      <td>44.735958</td>\n",
       "      <td>4196.44</td>\n",
       "      <td>46.793026</td>\n",
       "      <td>4347.59</td>\n",
       "      <td>50.574650</td>\n",
       "      <td>4306.40</td>\n",
       "      <td>49.541304</td>\n",
       "      <td>4037.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1575</th>\n",
       "      <td>4294.76</td>\n",
       "      <td>48.716109</td>\n",
       "      <td>4412.17</td>\n",
       "      <td>51.957920</td>\n",
       "      <td>4258.31</td>\n",
       "      <td>47.702403</td>\n",
       "      <td>4085.97</td>\n",
       "      <td>43.413283</td>\n",
       "      <td>4339.44</td>\n",
       "      <td>50.467423</td>\n",
       "      <td>...</td>\n",
       "      <td>44.735958</td>\n",
       "      <td>4196.44</td>\n",
       "      <td>46.793026</td>\n",
       "      <td>4347.59</td>\n",
       "      <td>50.574650</td>\n",
       "      <td>4306.40</td>\n",
       "      <td>49.541304</td>\n",
       "      <td>4436.91</td>\n",
       "      <td>52.829940</td>\n",
       "      <td>3792.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1576</th>\n",
       "      <td>4412.17</td>\n",
       "      <td>51.957920</td>\n",
       "      <td>4258.31</td>\n",
       "      <td>47.702403</td>\n",
       "      <td>4085.97</td>\n",
       "      <td>43.413283</td>\n",
       "      <td>4339.44</td>\n",
       "      <td>50.467423</td>\n",
       "      <td>4269.36</td>\n",
       "      <td>48.661227</td>\n",
       "      <td>...</td>\n",
       "      <td>46.793026</td>\n",
       "      <td>4347.59</td>\n",
       "      <td>50.574650</td>\n",
       "      <td>4306.40</td>\n",
       "      <td>49.541304</td>\n",
       "      <td>4436.91</td>\n",
       "      <td>52.829940</td>\n",
       "      <td>4105.64</td>\n",
       "      <td>44.841174</td>\n",
       "      <td>3630.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1577</th>\n",
       "      <td>4258.31</td>\n",
       "      <td>47.702403</td>\n",
       "      <td>4085.97</td>\n",
       "      <td>43.413283</td>\n",
       "      <td>4339.44</td>\n",
       "      <td>50.467423</td>\n",
       "      <td>4269.36</td>\n",
       "      <td>48.661227</td>\n",
       "      <td>4524.85</td>\n",
       "      <td>54.986266</td>\n",
       "      <td>...</td>\n",
       "      <td>50.574650</td>\n",
       "      <td>4306.40</td>\n",
       "      <td>49.541304</td>\n",
       "      <td>4436.91</td>\n",
       "      <td>52.829940</td>\n",
       "      <td>4105.64</td>\n",
       "      <td>44.841174</td>\n",
       "      <td>3897.94</td>\n",
       "      <td>40.686916</td>\n",
       "      <td>3709.27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1421 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      close_19     RSI_19  close_18     RSI_18  close_17     RSI_17  close_16  \\\n",
       "157     754.99  51.874455    855.28  64.086633    934.03  70.431522    940.00   \n",
       "158     855.28  64.086633    934.03  70.431522    940.00  70.851945    959.30   \n",
       "159     934.03  70.431522    940.00  70.851945    959.30  72.226781   1004.11   \n",
       "160     940.00  70.851945    959.30  72.226781   1004.11  75.156684   1123.09   \n",
       "161     959.30  72.226781   1004.11  75.156684   1123.09  80.914056   1133.18   \n",
       "...        ...        ...       ...        ...       ...        ...       ...   \n",
       "1573   4287.80  47.095555   3996.90  39.023233   4294.76  48.716109   4412.17   \n",
       "1574   3996.90  39.023233   4294.76  48.716109   4412.17  51.957920   4258.31   \n",
       "1575   4294.76  48.716109   4412.17  51.957920   4258.31  47.702403   4085.97   \n",
       "1576   4412.17  51.957920   4258.31  47.702403   4085.97  43.413283   4339.44   \n",
       "1577   4258.31  47.702403   4085.97  43.413283   4339.44  50.467423   4269.36   \n",
       "\n",
       "         RSI_16  close_15     RSI_15  ...      RSI_4  close_3      RSI_3  \\\n",
       "157   70.851945    959.30  72.226781  ...  48.819684  1000.00  48.819684   \n",
       "158   72.226781   1004.11  75.156684  ...  48.819684   994.00  48.493851   \n",
       "159   75.156684   1123.09  80.914056  ...  48.493851  1032.50  50.764615   \n",
       "160   80.914056   1133.18  81.309636  ...  50.764615  1152.75  57.122992   \n",
       "161   81.309636   1291.00  86.146268  ...  57.122992  1049.00  51.002981   \n",
       "...         ...       ...        ...  ...        ...      ...        ...   \n",
       "1573  51.957920   4258.31  47.702403  ...  53.835840  4215.73  46.826530   \n",
       "1574  47.702403   4085.97  43.413283  ...  46.826530  4117.25  44.735958   \n",
       "1575  43.413283   4339.44  50.467423  ...  44.735958  4196.44  46.793026   \n",
       "1576  50.467423   4269.36  48.661227  ...  46.793026  4347.59  50.574650   \n",
       "1577  48.661227   4524.85  54.986266  ...  50.574650  4306.40  49.541304   \n",
       "\n",
       "      close_2      RSI_2  close_1      RSI_1  close_0      RSI_0    close  \n",
       "157    994.00  48.493851  1032.50  50.764615  1152.75  57.122992   877.00  \n",
       "158   1032.50  50.764615  1152.75  57.122992  1049.00  51.002981   851.15  \n",
       "159   1152.75  57.122992  1049.00  51.002981   993.00  48.012894   808.99  \n",
       "160   1049.00  51.002981   993.00  48.012894   980.00  47.319361   866.66  \n",
       "161    993.00  48.012894   980.00  47.319361  1061.00  51.974254   841.57  \n",
       "...       ...        ...      ...        ...      ...        ...      ...  \n",
       "1573  4117.25  44.735958  4196.44  46.793026  4347.59  50.574650  4063.56  \n",
       "1574  4196.44  46.793026  4347.59  50.574650  4306.40  49.541304  4037.23  \n",
       "1575  4347.59  50.574650  4306.40  49.541304  4436.91  52.829940  3792.75  \n",
       "1576  4306.40  49.541304  4436.91  52.829940  4105.64  44.841174  3630.19  \n",
       "1577  4436.91  52.829940  4105.64  44.841174  3897.94  40.686916  3709.27  \n",
       "\n",
       "[1421 rows x 41 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>close_19</th>\n",
       "      <th>RSI_19</th>\n",
       "      <th>close_18</th>\n",
       "      <th>RSI_18</th>\n",
       "      <th>close_17</th>\n",
       "      <th>RSI_17</th>\n",
       "      <th>close_16</th>\n",
       "      <th>RSI_16</th>\n",
       "      <th>close_15</th>\n",
       "      <th>RSI_15</th>\n",
       "      <th>...</th>\n",
       "      <th>RSI_4</th>\n",
       "      <th>close_3</th>\n",
       "      <th>RSI_3</th>\n",
       "      <th>close_2</th>\n",
       "      <th>RSI_2</th>\n",
       "      <th>close_1</th>\n",
       "      <th>RSI_1</th>\n",
       "      <th>close_0</th>\n",
       "      <th>RSI_0</th>\n",
       "      <th>close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1578</th>\n",
       "      <td>4085.97</td>\n",
       "      <td>43.413283</td>\n",
       "      <td>4339.44</td>\n",
       "      <td>50.467423</td>\n",
       "      <td>4269.36</td>\n",
       "      <td>48.661227</td>\n",
       "      <td>4524.85</td>\n",
       "      <td>54.986266</td>\n",
       "      <td>4041.2</td>\n",
       "      <td>43.948042</td>\n",
       "      <td>...</td>\n",
       "      <td>49.541304</td>\n",
       "      <td>4436.91</td>\n",
       "      <td>52.82994</td>\n",
       "      <td>4105.64</td>\n",
       "      <td>44.841174</td>\n",
       "      <td>3897.94</td>\n",
       "      <td>40.686916</td>\n",
       "      <td>4089.37</td>\n",
       "      <td>45.681743</td>\n",
       "      <td>3725.46</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      close_19     RSI_19  close_18     RSI_18  close_17     RSI_17  close_16  \\\n",
       "1578   4085.97  43.413283   4339.44  50.467423   4269.36  48.661227   4524.85   \n",
       "\n",
       "         RSI_16  close_15     RSI_15  ...      RSI_4  close_3     RSI_3  \\\n",
       "1578  54.986266    4041.2  43.948042  ...  49.541304  4436.91  52.82994   \n",
       "\n",
       "      close_2      RSI_2  close_1      RSI_1  close_0      RSI_0    close  \n",
       "1578  4105.64  44.841174  3897.94  40.686916  4089.37  45.681743  3725.46  \n",
       "\n",
       "[1 rows x 41 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (1421, 1, 40) (1421, 1)\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_6 (LSTM)                (None, 1, 25)             6600      \n",
      "_________________________________________________________________\n",
      "lstm_7 (LSTM)                (None, 1, 25)             5100      \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 1, 25)             0         \n",
      "_________________________________________________________________\n",
      "lstm_8 (LSTM)                (None, 1, 25)             5100      \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 1, 25)             0         \n",
      "_________________________________________________________________\n",
      "lstm_9 (LSTM)                (None, 1, 25)             5100      \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 1, 25)             0         \n",
      "_________________________________________________________________\n",
      "lstm_10 (LSTM)               (None, 25)                5100      \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 25)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 26        \n",
      "=================================================================\n",
      "Total params: 27,026\n",
      "Trainable params: 27,026\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Y shape (1421, 1)\n",
      "Train on 1421 samples, validate on 285 samples\n",
      "Epoch 1/100\n",
      " - 13s - loss: 0.0863 - mse: 0.0863 - val_loss: 0.3846 - val_mse: 0.3846\n",
      "Epoch 2/100\n",
      " - 0s - loss: 0.0736 - mse: 0.0736 - val_loss: 0.3270 - val_mse: 0.3270\n",
      "Epoch 3/100\n",
      " - 0s - loss: 0.0660 - mse: 0.0660 - val_loss: 0.2739 - val_mse: 0.2739\n",
      "Epoch 4/100\n",
      " - 0s - loss: 0.0630 - mse: 0.0630 - val_loss: 0.2261 - val_mse: 0.2261\n",
      "Epoch 5/100\n",
      " - 0s - loss: 0.0559 - mse: 0.0559 - val_loss: 0.1572 - val_mse: 0.1572\n",
      "Epoch 6/100\n",
      " - 0s - loss: 0.0321 - mse: 0.0321 - val_loss: 0.0358 - val_mse: 0.0358\n",
      "Epoch 7/100\n",
      " - 0s - loss: 0.0252 - mse: 0.0252 - val_loss: 0.0285 - val_mse: 0.0285\n",
      "Epoch 8/100\n",
      " - 0s - loss: 0.0420 - mse: 0.0420 - val_loss: 0.1389 - val_mse: 0.1389\n",
      "Epoch 9/100\n",
      " - 0s - loss: 0.0106 - mse: 0.0106 - val_loss: 0.0196 - val_mse: 0.0196\n",
      "Epoch 10/100\n",
      " - 1s - loss: 0.0121 - mse: 0.0121 - val_loss: 0.0189 - val_mse: 0.0189\n",
      "Epoch 11/100\n",
      " - 1s - loss: 0.0116 - mse: 0.0116 - val_loss: 0.0230 - val_mse: 0.0230\n",
      "Epoch 12/100\n",
      " - 1s - loss: 0.0120 - mse: 0.0120 - val_loss: 0.0187 - val_mse: 0.0187\n",
      "Epoch 13/100\n",
      " - 1s - loss: 0.0114 - mse: 0.0114 - val_loss: 0.0206 - val_mse: 0.0206\n",
      "Epoch 14/100\n",
      " - 1s - loss: 0.0107 - mse: 0.0107 - val_loss: 0.0186 - val_mse: 0.0186\n",
      "Epoch 15/100\n",
      " - 1s - loss: 0.0108 - mse: 0.0108 - val_loss: 0.0225 - val_mse: 0.0225\n",
      "Epoch 16/100\n",
      " - 1s - loss: 0.0103 - mse: 0.0103 - val_loss: 0.0182 - val_mse: 0.0182\n",
      "Epoch 17/100\n",
      " - 0s - loss: 0.0122 - mse: 0.0122 - val_loss: 0.0238 - val_mse: 0.0238\n",
      "Epoch 18/100\n",
      " - 0s - loss: 0.0107 - mse: 0.0107 - val_loss: 0.0185 - val_mse: 0.0185\n",
      "Epoch 19/100\n",
      " - 1s - loss: 0.0092 - mse: 0.0092 - val_loss: 0.0192 - val_mse: 0.0192\n",
      "Epoch 20/100\n",
      " - 0s - loss: 0.0114 - mse: 0.0114 - val_loss: 0.0180 - val_mse: 0.0180\n",
      "Epoch 21/100\n",
      " - 0s - loss: 0.0107 - mse: 0.0107 - val_loss: 0.0215 - val_mse: 0.0215\n",
      "Epoch 22/100\n",
      " - 1s - loss: 0.0103 - mse: 0.0103 - val_loss: 0.0179 - val_mse: 0.0179\n",
      "Epoch 23/100\n",
      " - 0s - loss: 0.0100 - mse: 0.0100 - val_loss: 0.0212 - val_mse: 0.0212\n",
      "Epoch 24/100\n",
      " - 0s - loss: 0.0102 - mse: 0.0102 - val_loss: 0.0178 - val_mse: 0.0178\n",
      "Epoch 25/100\n",
      " - 0s - loss: 0.0098 - mse: 0.0098 - val_loss: 0.0214 - val_mse: 0.0214\n",
      "Epoch 26/100\n",
      " - 0s - loss: 0.0100 - mse: 0.0100 - val_loss: 0.0177 - val_mse: 0.0177\n",
      "Epoch 27/100\n",
      " - 0s - loss: 0.0090 - mse: 0.0090 - val_loss: 0.0211 - val_mse: 0.0211\n",
      "Epoch 28/100\n",
      " - 0s - loss: 0.0092 - mse: 0.0092 - val_loss: 0.0176 - val_mse: 0.0176\n",
      "Epoch 29/100\n",
      " - 1s - loss: 0.0092 - mse: 0.0092 - val_loss: 0.0201 - val_mse: 0.0201\n",
      "Epoch 30/100\n",
      " - 0s - loss: 0.0094 - mse: 0.0094 - val_loss: 0.0176 - val_mse: 0.0176\n",
      "Epoch 31/100\n",
      " - 1s - loss: 0.0080 - mse: 0.0080 - val_loss: 0.0175 - val_mse: 0.0175\n",
      "Epoch 32/100\n",
      " - 3s - loss: 0.0083 - mse: 0.0083 - val_loss: 0.0173 - val_mse: 0.0173\n",
      "Epoch 33/100\n",
      " - 1s - loss: 0.0087 - mse: 0.0087 - val_loss: 0.0177 - val_mse: 0.0177\n",
      "Epoch 34/100\n",
      " - 1s - loss: 0.0084 - mse: 0.0084 - val_loss: 0.0172 - val_mse: 0.0172\n",
      "Epoch 35/100\n",
      " - 1s - loss: 0.0083 - mse: 0.0083 - val_loss: 0.0178 - val_mse: 0.0178\n",
      "Epoch 36/100\n",
      " - 1s - loss: 0.0094 - mse: 0.0094 - val_loss: 0.0172 - val_mse: 0.0172\n",
      "Epoch 37/100\n",
      " - 0s - loss: 0.0106 - mse: 0.0106 - val_loss: 0.0211 - val_mse: 0.0211\n",
      "Epoch 38/100\n",
      " - 0s - loss: 0.0105 - mse: 0.0105 - val_loss: 0.0172 - val_mse: 0.0172\n",
      "Epoch 39/100\n",
      " - 0s - loss: 0.0108 - mse: 0.0108 - val_loss: 0.0214 - val_mse: 0.0214\n",
      "Epoch 40/100\n",
      " - 0s - loss: 0.0108 - mse: 0.0108 - val_loss: 0.0175 - val_mse: 0.0175\n",
      "Epoch 41/100\n",
      " - 0s - loss: 0.0099 - mse: 0.0099 - val_loss: 0.0216 - val_mse: 0.0216\n",
      "Epoch 42/100\n",
      " - 0s - loss: 0.0089 - mse: 0.0089 - val_loss: 0.0176 - val_mse: 0.0176\n",
      "Epoch 43/100\n",
      " - 0s - loss: 0.0079 - mse: 0.0079 - val_loss: 0.0184 - val_mse: 0.0184\n",
      "Epoch 44/100\n",
      " - 0s - loss: 0.0073 - mse: 0.0073 - val_loss: 0.0173 - val_mse: 0.0173\n",
      "Epoch 45/100\n",
      " - 0s - loss: 0.0070 - mse: 0.0070 - val_loss: 0.0177 - val_mse: 0.0177\n",
      "Epoch 46/100\n",
      " - 0s - loss: 0.0074 - mse: 0.0074 - val_loss: 0.0171 - val_mse: 0.0171\n",
      "Epoch 47/100\n",
      " - 0s - loss: 0.0068 - mse: 0.0068 - val_loss: 0.0175 - val_mse: 0.0175\n",
      "Epoch 48/100\n",
      " - 0s - loss: 0.0071 - mse: 0.0071 - val_loss: 0.0169 - val_mse: 0.0169\n",
      "Epoch 49/100\n",
      " - 0s - loss: 0.0070 - mse: 0.0070 - val_loss: 0.0169 - val_mse: 0.0169\n",
      "Epoch 50/100\n",
      " - 0s - loss: 0.0068 - mse: 0.0068 - val_loss: 0.0167 - val_mse: 0.0167\n",
      "Epoch 51/100\n",
      " - 0s - loss: 0.0066 - mse: 0.0066 - val_loss: 0.0170 - val_mse: 0.0170\n",
      "Epoch 52/100\n",
      " - 0s - loss: 0.0084 - mse: 0.0084 - val_loss: 0.0167 - val_mse: 0.0167\n",
      "Epoch 53/100\n",
      " - 0s - loss: 0.0075 - mse: 0.0075 - val_loss: 0.0173 - val_mse: 0.0173\n",
      "Epoch 54/100\n",
      " - 0s - loss: 0.0089 - mse: 0.0089 - val_loss: 0.0167 - val_mse: 0.0167\n",
      "Epoch 55/100\n",
      " - 0s - loss: 0.0087 - mse: 0.0087 - val_loss: 0.0174 - val_mse: 0.0174\n",
      "Epoch 56/100\n",
      " - 0s - loss: 0.0083 - mse: 0.0083 - val_loss: 0.0167 - val_mse: 0.0167\n",
      "Epoch 57/100\n",
      " - 0s - loss: 0.0077 - mse: 0.0077 - val_loss: 0.0177 - val_mse: 0.0177\n",
      "Epoch 58/100\n",
      " - 0s - loss: 0.0077 - mse: 0.0077 - val_loss: 0.0168 - val_mse: 0.0168\n",
      "Epoch 59/100\n",
      " - 0s - loss: 0.0079 - mse: 0.0079 - val_loss: 0.0176 - val_mse: 0.0176\n",
      "Epoch 60/100\n",
      " - 1s - loss: 0.0090 - mse: 0.0090 - val_loss: 0.0168 - val_mse: 0.0168\n",
      "Epoch 61/100\n",
      " - 1s - loss: 0.0081 - mse: 0.0081 - val_loss: 0.0180 - val_mse: 0.0180\n",
      "Epoch 62/100\n",
      " - 1s - loss: 0.0077 - mse: 0.0077 - val_loss: 0.0168 - val_mse: 0.0168\n",
      "Epoch 63/100\n",
      " - 1s - loss: 0.0067 - mse: 0.0067 - val_loss: 0.0171 - val_mse: 0.0171\n",
      "Epoch 64/100\n",
      " - 0s - loss: 0.0073 - mse: 0.0073 - val_loss: 0.0166 - val_mse: 0.0166\n",
      "Epoch 65/100\n",
      " - 0s - loss: 0.0070 - mse: 0.0070 - val_loss: 0.0172 - val_mse: 0.0172\n",
      "Epoch 66/100\n",
      " - 0s - loss: 0.0072 - mse: 0.0072 - val_loss: 0.0166 - val_mse: 0.0166\n",
      "Epoch 67/100\n",
      " - 0s - loss: 0.0071 - mse: 0.0071 - val_loss: 0.0171 - val_mse: 0.0171\n",
      "Epoch 68/100\n",
      " - 0s - loss: 0.0078 - mse: 0.0078 - val_loss: 0.0165 - val_mse: 0.0165\n",
      "Epoch 69/100\n",
      " - 0s - loss: 0.0076 - mse: 0.0076 - val_loss: 0.0166 - val_mse: 0.0166\n",
      "Epoch 70/100\n",
      " - 1s - loss: 0.0076 - mse: 0.0076 - val_loss: 0.0164 - val_mse: 0.0164\n",
      "Epoch 71/100\n",
      " - 1s - loss: 0.0078 - mse: 0.0078 - val_loss: 0.0172 - val_mse: 0.0172\n",
      "Epoch 72/100\n",
      " - 0s - loss: 0.0081 - mse: 0.0081 - val_loss: 0.0165 - val_mse: 0.0165\n",
      "Epoch 73/100\n",
      " - 1s - loss: 0.0070 - mse: 0.0070 - val_loss: 0.0166 - val_mse: 0.0166\n",
      "Epoch 74/100\n",
      " - 1s - loss: 0.0083 - mse: 0.0083 - val_loss: 0.0164 - val_mse: 0.0164\n",
      "Epoch 75/100\n",
      " - 1s - loss: 0.0077 - mse: 0.0077 - val_loss: 0.0174 - val_mse: 0.0174\n",
      "Epoch 76/100\n",
      " - 1s - loss: 0.0073 - mse: 0.0073 - val_loss: 0.0164 - val_mse: 0.0164\n",
      "real [[3725.46]]\n",
      "Test RMSE: 172.100\n",
      "Diff [[-172.10015977]]\n",
      "% Diff [[-4.61956805]] %\n",
      "Predictions [[3897.56015977]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAA1kElEQVR4nO3deZxcZZno8d9TW1fvexa6E7KQhYAQIIQgKKDCTVAIjohB1HGbiMoI3nHBGbdxuVfvHb2jDhgjgyuLDBLMYAQERVQWk0AICVtCSEhn7XR6X2t57h/vqU6lU52u7vRJVbqf7+dTn6o657znPFVdfZ7zvuec9xVVxRhjjBkokOsAjDHG5CdLEMYYYzKyBGGMMSYjSxDGGGMysgRhjDEmI0sQxhhjMrIEYQwgIj8VkW9kuex2EXmb3zEZk2uWIIwxxmRkCcKYMUREQrmOwYwdliDMCcNr2vmsiGwUkU4R+U8RmSgivxORdhF5REQq05a/UkQ2i0iLiDwmIqemzTtLRJ7xyv0KiA7Y1jtEZINX9gkROSPLGN8uIs+KSJuI7BSRrw6Yf6G3vhZv/ge96YUi8h0R2SEirSLyF2/axSLSkOF7eJv3+qsicq+I/FJE2oAPishCEXnS28YeEfkPEYmklT9NRH4vIgdFZJ+I/LOITBKRLhGpTlvuHBFpFJFwNp/djD2WIMyJ5l3ApcBs4Argd8A/AzW43/OnAERkNnAXcBNQC6wB/ltEIt7O8n7gF0AV8F/eevHKng3cDnwMqAZ+BKwWkYIs4usEPgBUAG8HPi4iV3nrnerF+wMvpvnABq/cvwHnAG/0YvockMzyO1kK3Ott8w4gAXwa952cD7wV+IQXQynwCPAgcBJwCvCoqu4FHgOuSVvv+4C7VTWWZRxmjLEEYU40P1DVfaq6C/gz8LSqPquqvcAq4CxvufcAv1XV33s7uH8DCnE74EVAGPh3VY2p6r3A2rRt/APwI1V9WlUTqvozoNcrd1Sq+piqPq+qSVXdiEtSF3mzrwMeUdW7vO02qeoGEQkAHwZuVNVd3jaf8D5TNp5U1fu9bXar6npVfUpV46q6HZfgUjG8A9irqt9R1R5VbVfVp715P8MlBUQkCFyLS6JmnLIEYU40+9Jed2d4X+K9PgnYkZqhqklgJ1Dnzdulh/dUuSPt9cnAP3lNNC0i0gJM8codlYicJyJ/9JpmWoHrcUfyeOt4NUOxGlwTV6Z52dg5IIbZIvKAiOz1mp3+VxYxAPwGmCciM3C1tFZV/dsIYzJjgCUIM1btxu3oARARwe0cdwF7gDpvWsrUtNc7gW+qakXao0hV78piu3cCq4EpqloOrABS29kJzMxQ5gDQM8i8TqAo7XMEcc1T6QZ2yfxD4CVglqqW4ZrghooBVe0B7sHVdN6P1R7GPUsQZqy6B3i7iLzVO8n6T7hmoieAJ4E48CkRCYnI3wEL08r+GLjeqw2IiBR7J59Ls9huKXBQVXtEZCHw3rR5dwBvE5FrvO1Wi8h8r3ZzO/BdETlJRIIicr53zuMVIOptPwx8ERjqXEgp0AZ0iMhc4ONp8x4AJonITSJSICKlInJe2vyfAx8ErgR+mcXnNWOYJQgzJqnqy7j29B/gjtCvAK5Q1T5V7QP+DrcjbMadr7gvrew63HmI//Dmb/WWzcYngK+JSDvwZVyiSq33deByXLI6iDtBfaY3+zPA87hzIQeBbwMBVW311nkbrvbTCRx2VVMGn8ElpnZcsvtVWgztuOajK4C9wBbgkrT5f8WdHH/GO39hxjGxAYOMMelE5A/Anap6W65jMbllCcIY009EzgV+jzuH0p7reExuWROTMQYAEfkZ7h6Jmyw5GLAahDHGmEH4WoMQkcUi8rKIbBWRm4+y3LkikhCRq4db1hhjjD98q0F412u/grtiogF3dca1qvpChuV+j7sO/HZVvTfbsgPV1NTotGnTRvujGGPMmLV+/foDqjrw3hoA/Oz5cSGwVVW3AYjI3bg+Ywbu5P8R+DVw7gjKHmbatGmsW7dudKI3xphxQER2DDbPzyamOg7vAqDBm9ZPROqAd+LuNh1W2bR1LBeRdSKyrrGx8ZiDNsYY4/iZICTDtIHtWf8OfF5VEyMo6yaqrlTVBaq6oLY2Yy3JGGPMCPjZxNSA6/smpR7XP066BcDdXpc4NcDlIhLPsqwxxhgf+Zkg1gKzRGQ6rouAZRzeLw2qOj31WkR+CjygqveLGxXrqGWzFYvFaGhooKenZ2Sf4gQRjUapr68nHLaxXYwxo8O3BKGqcRG5AXgICOKuUNosItd78weedxiy7EjiaGhooLS0lGnTpnF4551jh6rS1NREQ0MD06dPH7qAMcZkwdfxa1V1DW4kr/RpGRODqn5wqLIj0dPTM6aTA4CIUF1djZ2kN8aMpnHR1cZYTg4p4+EzGmOOr3GRII5KFdr3Qk9briMxxpi8YglCBDr2Q0+rL6tvaWnh1ltvHXa5yy+/nJaWltEPyBhjsmQJAiAUgUS248MPz2AJIpEYeOvH4dasWUNFRYUvMRljTDZ8PUl9wggWQKzbl1XffPPNvPrqq8yfP59wOExJSQmTJ09mw4YNvPDCC1x11VXs3LmTnp4ebrzxRpYvXw4c6jako6ODJUuWcOGFF/LEE09QV1fHb37zGwoLC32J1xhjUsZVgvjX/97MC7sznGtI9LlHZPjNTPNOKuMrV5w26PxvfetbbNq0iQ0bNvDYY4/x9re/nU2bNvVfjnr77bdTVVVFd3c35557Lu9617uorq4+bB1btmzhrrvu4sc//jHXXHMNv/71r3nf+9437FiNMWY4xlWCGFTqCiBNgvjb6rZw4cLD7lX4/ve/z6pVqwDYuXMnW7ZsOSJBTJ8+nfnz5wNwzjnnsH37dl9jNMYYGGcJYtAj/d52aNoK1adAQamvMRQXF/e/fuyxx3jkkUd48sknKSoq4uKLL854x3dBQUH/62AwSHe3P81hxhiTzk5SAwQj7jk++ieqS0tLaW/PPHpja2srlZWVFBUV8dJLL/HUU0+N+vaNMWakxlUNYlDBCCDuPMQoq66u5oILLuD000+nsLCQiRMn9s9bvHgxK1as4IwzzmDOnDksWrRo1LdvjDEjNabGpF6wYIEOHDDoxRdf5NRTTx268L4XIFwIVSduX0ZZf1ZjjPGIyHpVXZBpnjUxpfh4L4QxxpyILEGkBAsgPvpNTMYYc6KyBJESioAmIBnPdSTGGJMXLEGkBL1LSa0WYYwxgCWIQ0JegrDzEMYYA1iCOMTHeyGMMeZE5GuCEJHFIvKyiGwVkZszzF8qIhtFZIOIrBORC9PmbReR51Pz/IwTgEAQAiFf7oUYjpKSkpxu3xhjUny7UU5EgsAtwKVAA7BWRFar6gtpiz0KrFZVFZEzgHuAuWnzL1HVA37FeIRgxGoQxhjj8fNO6oXAVlXdBiAidwNLgf4EoaodacsXA7m9ay9UAH2do7rKz3/+85x88sl84hOfAOCrX/0qIsLjjz9Oc3MzsViMb3zjGyxdunRUt2uMMcfKzwRRB+xMe98AnDdwIRF5J/C/gQnA29NmKfCwiCjwI1VdmWkjIrIcWA4wderUo0f0u5th7/ODz0/0et1+lwBZjvE86Q2w5FuDzl62bBk33XRTf4K45557ePDBB/n0pz9NWVkZBw4cYNGiRVx55ZU2rrQxJq/4mSAy7e2OqCGo6ipglYi8Gfg68DZv1gWqultEJgC/F5GXVPXxDOVXAivBdbVxbBEHUis91AX4MTrrrLPYv38/u3fvprGxkcrKSiZPnsynP/1pHn/8cQKBALt27WLfvn1MmjRpVLZpjDGjwc8E0QBMSXtfD+webGFVfVxEZopIjaoeUNXd3vT9IrIK12R1RIIYlqMc6QPQ2wFNW6BqJkTLjmlT6a6++mruvfde9u7dy7Jly7jjjjtobGxk/fr1hMNhpk2blrGbb2OMySU/r2JaC8wSkekiEgGWAavTFxCRU8RrVxGRs4EI0CQixSJS6k0vBi4DNvkYqxPyLnUd5Xshli1bxt133829997L1VdfTWtrKxMmTCAcDvPHP/6RHTt2jOr2jDFmNPhWg1DVuIjcADwEBIHbVXWziFzvzV8BvAv4gIjEgG7gPd4VTRNxzU6pGO9U1Qf9irVfIAzIqN9Nfdppp9He3k5dXR2TJ0/muuuu44orrmDBggXMnz+fuXPnDr0SY4w5znwdD0JV1wBrBkxbkfb628C3M5TbBpzpZ2wZibgrmXy4m/r55w+dHK+pqeHJJ5/MuFxHR0fG6cYYc7zZndQDBSPWH5MxxmAJ4kipGsQYGkjJGGNGYlwkiGGNmheMgCZPuG6/x9LIgMaY/DDmE0Q0GqWpqSn7HWh/r64nTjOTqtLU1EQ0Gs11KMaYMcTXk9T5oL6+noaGBhobG7MrkIhB+35oTECk2N/gRlE0GqW+vj7XYRhjxpAxnyDC4TDTp0/PvkCsB775JrjkX+Ciz/kXmDHG5Lkx38Q0bOEolNXBwW25jsQYY3LKEkQmVTOg6dVcR2GMMTllCSKT6pnQtDXXURhjTE5Zgsik+hToPghdB3MdiTHG5IwliEyqZrpnOw9hjBnHLEFkUn2Ke7bzEMaYccwSRCaV09zgQXYewhgzjlmCyCQUgfIpcNBqEMaY8csSxGCqT7EmJmPMuGYJYjDVM12CsE7wjDHjlCWIwVSfAn3t0JllH07GGDPG+JogRGSxiLwsIltF5OYM85eKyEYR2SAi60TkwmzL+i51qaudqDbGjFO+JQgRCQK3AEuAecC1IjJvwGKPAmeq6nzgw8Btwyjrr+pUgrDzEMaY8cnPGsRCYKuqblPVPuBuYGn6AqraoYcGaigGNNuyviufAoGw1SCMMeOWnwmiDtiZ9r7Bm3YYEXmniLwE/BZXi8i6rFd+udc8tS7rMR+yEQy5+yHsUldjzDjlZ4KQDNOOuCRIVVep6lzgKuDrwynrlV+pqgtUdUFtbe1IY83MLnU1xoxjfiaIBmBK2vt6YPdgC6vq48BMEakZblnfVM90/TElk8d908YYk2t+Joi1wCwRmS4iEWAZsDp9ARE5RUTEe302EAGasil7XFTPhHgPtO067ps2xphc823IUVWNi8gNwENAELhdVTeLyPXe/BXAu4APiEgM6Abe4520zljWr1gH1d+r66tQMeXoyxpjzBjj65jUqroGWDNg2oq0198Gvp1t2eOuv1fXrTDj4pyGYowxx5vdSX00pZMhVAhNNi6EMWb8sQRxNIGADT9qjBm3LEEMpWqG3QthjBmXLEEMpXomNG+HRDzXkRhjzHFlCWIo1adAMg4tO3IdiTHGHFeWIIbSf6mrnag2xowvliCGkn6pqzHGjCOWIIZSXAMFZZYgjDHjjiWIoYi4WsSBLbmOxBhjjitLENmonQMHXsl1FMYYc1xZgshG7Rxo3wM9rbmOxBhjjhtLENmomeOeG60WYYwZPyxBZKM2lSBeym0cxhhzHFmCyEblNAgWwIGXcx2JMcYcN5YgshEIQs0saLQEYYwZPyxBZKtmtiUIY8y4YgkiW7VzoeV16OvMdSTGGHNc+JogRGSxiLwsIltF5OYM868TkY3e4wkROTNt3nYReV5ENojIOj/jzErtHEDthjljzLjh25CjIhIEbgEuBRqAtSKyWlVfSFvsNeAiVW0WkSXASuC8tPmXqOoBv2IcltSVTAdegZPm5zQUY4w5HvysQSwEtqrqNlXtA+4GlqYvoKpPqGqz9/YpoN7HeI5N1UyQoF3qaowZN/xMEHXAzrT3Dd60wXwE+F3aewUeFpH1IrLch/iGJxRxo8vZiWpjzDjhWxMTIBmmacYFRS7BJYgL0yZfoKq7RWQC8HsReUlVH89QdjmwHGDq1KnHHvXR1M6xBGGMGTf8rEE0AFPS3tcDuwcuJCJnALcBS1W1KTVdVXd7z/uBVbgmqyOo6kpVXaCqC2pra0cx/Axq57iBg+J9/m7HGGPygJ8JYi0wS0Smi0gEWAasTl9ARKYC9wHvV9VX0qYXi0hp6jVwGbDJx1izUzsXNAEHX811JMYY4zvfmphUNS4iNwAPAUHgdlXdLCLXe/NXAF8GqoFbRQQgrqoLgInAKm9aCLhTVR/0K9as1cx2z40vw4RTcxuLMcb4zM9zEKjqGmDNgGkr0l5/FPhohnLbgDMHTs+5mtmA2HkIY8y4YHdSD0ekCCqmWKd9xphxwRLEcNXOtRqEMWZcsAQxXDWzXXcbyUSuIzHGGF9Zghiu2rmQ6IXm7bmOxBhjfGUJYrjS+2QyxpgxzBLEcPVf6mp9MhljxjZLEMNVWAElk6DRahDGmLHNEsRIVJ/iutwwxpgxzBLESJTXQduuXEdhjDG+sgQxEmV10LbbLnU1xoxpliBGorzOddrXsT/XkRhjjG8sQYxEmTfwnTUzGWPGMEsQI1F2kntubchtHMYY4yNLECNRbjUIY8zYZwliJAorIVQIrZYgjDFjlyWIkRDxLnW1JiZjzNhlCWKkyuqsBmGMGdOyShAicqOIlInznyLyjIhc5ndwea283t0LYYwxY1S2NYgPq2obcBlQC3wI+NZQhURksYi8LCJbReTmDPOvE5GN3uMJETkz27I5V1YHHXshEc91JMYY44tsE4R4z5cDP1HV59KmZS4gEgRuAZYA84BrRWTegMVeAy5S1TOArwMrh1E2t8pOAk1C+55cR2KMMb7INkGsF5GHcQniIREpBZJDlFkIbFXVbaraB9wNLE1fQFWfUNVm7+1TQH22ZXPOLnU1xoxx2SaIjwA3A+eqahcQxjUzHU0dsDPtfYM37Wjb+N1wy4rIchFZJyLrGhsbhwhpFJV54djNcsaYMSrbBHE+8LKqtojI+4AvAq1DlMnUBKUZFxS5BJcgPj/csqq6UlUXqOqC2traIUIaReVegrAahDFmjMo2QfwQ6PJOIn8O2AH8fIgyDcCUtPf1wBGX/YjIGcBtwFJVbRpO2ZyKlkOk1C51NcaMWdkmiLiqKu48wPdU9XtA6RBl1gKzRGS6iESAZcDq9AVEZCpwH/B+VX1lOGXzgo0LYYwZw0JZLtcuIl8A3g+8ybvKKHy0AqoaF5EbgIeAIHC7qm4Wkeu9+SuALwPVwK0iAi4RLRis7Ag+n7/KLEEYY8aubBPEe4D34u6H2Osd+f/foQqp6hpgzYBpK9JefxT4aLZl807ZSbD3+VxHYYwxvsiqiUlV9wJ3AOUi8g6gR1WHOgcx9pXXQ+d+iPfmOhJjjBl12Xa1cQ3wN+DdwDXA0yJytZ+BnRBSl7palxvGmDEo2yamf8HdA7EfQERqgUeAe/0K7ISQfqlr1fTcxmKMMaMs26uYAqnk4GkaRtmxq3/oUatBGGPGnmxrEA+KyEPAXd7795DvJ5CPBxt61BgzhmWVIFT1syLyLuAC3F3OK1V1la+RnQgKStwNc3apqzFmDMq2BoGq/hr4tY+xnJjK6u1uamPMmHTUBCEi7WTuA0kAVdUyX6I6kdjQo8aYMeqoCUJVh+pOw5TVQcO6XEdhjDGjzq5EOlblddB9EPq6ch2JMcaMKksQxyp1qauNLGeMGWMsQRyrchs4yBgzNlmCOFZlNnCQMWZssgRxrPpvlrMEYYwZWyxBHKtwIRRV26WuxpgxxxLEaCirsxqEMWbMsQQxGkonuXEhjDFmDPE1QYjIYhF5WUS2isjNGebPFZEnRaRXRD4zYN52EXleRDaISH7fiRatgJ7WXEdhjDGjKuu+mIbLG7f6FuBSoAFYKyKrVfWFtMUOAp8CrhpkNZeo6gG/Yhw10XLobsl1FMYYM6r8rEEsBLaq6jZV7QPuBpamL6Cq+1V1LRDzMQ7/Rcuhtw2SyVxHYowxo8bPBFEH7Ex73+BNy5YCD4vIehFZPthCIrJcRNaJyLrGxsYRhnqMCitAk9DXkZvtG2OMD/xMEJJhWqaeYQdzgaqeDSwBPikib860kKquVNUFqrqgtrZ2JHEeu2i5e+5pyc32jTHGB34miAZgStr7eiDrsTlVdbf3vB9YhWuyyk/9CcJOVBtjxg4/E8RaYJaITBeRCLAMWJ1NQREpFpHS1GvgMmCTb5Eeq2iFe7YEYYwZQ3y7iklV4yJyA/AQEARuV9XNInK9N3+FiEwC1gFlQFJEbgLmATXAKhFJxXinqj7oV6zHLFWDsCuZjDFjiG8JAkBV1wBrBkxbkfZ6L67paaA24Ew/YxtVhRXuOdsaxN9+DM/+Aj72uG8hGWPMsbI7qUfDcM9B7HnOPZIJ/2IyxphjZAliNBR4Q3NnexVTd7O3vJ2zMMbkL0sQoyEQhILy7Hf4qXMVliCMMXnMEsRoiQ4nQaRqEC2+hWOMMcfKEsRoGU5/TKkEYVc9GWPymCWI0VJYMYIahDUxGWPylyWI0ZJtE1OsG+Ld7rU1MRlj8pgliNESLc9uh5/erGQ1CGNMHrMEMVqyHTQo1bwEdg7CGJPXLEGMlmi56+47McTQFukJwpqYjDF5zBLEaOnvbqPt6MsdliCsickYk78sQYyWbMeESCWI4gnWxGSMyWuWIEbLcBNE5TRrYjLG5DVLEKMl2zEhupshEILyemtiMsbkNUsQoyXbHl27m6Gw0p2zsCYmY0weswQxWrIdNCiVIFL3Tehwhuk2xpjjxxLEaMl20KD+BFEByTjEuvyOzBhjRsTXBCEii0XkZRHZKiI3Z5g/V0SeFJFeEfnMcMrmnXCRO7cwnCYmsGYmY0ze8i1BiEgQuAVYghtn+loRmTdgsYPAp4B/G0HZ/CLi3U3dcvTlulsONTGBXclkjMlbftYgFgJbVXWbqvYBdwNL0xdQ1f2quhYYePvxkGXzUjYd9qU3MYFdyWSMyVt+Jog6YGfa+wZv2qiWFZHlIrJORNY1NjaOKNBRM1SCSMSgr92amIwxJwQ/E4RkmJbtJTtZl1XVlaq6QFUX1NbWZh2cL4a6dDU177AmJqtBGGPyk58JogGYkva+Hth9HMrmzlA1iNRd1Ic1MbX4HZUxxoyInwliLTBLRKaLSARYBqw+DmVzJ+sEUZH9fRPGGJMjIb9WrKpxEbkBeAgIArer6mYRud6bv0JEJgHrgDIgKSI3AfNUtS1TWb9iHTWpq5hU3VVNA6XXIAJBKCizJiZjTN7yLUEAqOoaYM2AaSvSXu/FNR9lVTbvRcsh0QfxHggXHjk/PUFAdpfFGmNMjoz7O6n74klufWwr63ccPPaVDdVsdESCKLcmJmNM3hr3CSKWSPLLJ3fwL6s2EUskj21lQ3W30d0MCBSUH1rempiMMXlq3CeI4oIQX7nyNF7a285P/7r92FY21KWr3c0uKQQCh5a3JiZjTJ4a9wkC4LJ5E3nr3An8v0deYXdL98hXFPWajgbb6afuou5fvsKamIwxecsSBCAifPXK00iq8q//fQwXS2VVg0hLENbEZIzJY5YgPFOqivjUW2fx0OZ9/OGlfSNbyXATRLQCYp2uCw5jjMkzliDSfPTCGcyaUMKXf7OZ7r7E8FeQzVVMhyUI627DGJO/LEGkiYQCfP2q02lo7uZrD2xGhzvaWyjixoXI9hyEddhnjMljliAGWDSjmo9fPJO7/raTL/1mE8nkMJPEYN1tJBNu+sAmJrArmYwxecnXO6lPVJ/7H3NQhRV/epVEEr551ekEApk6mM1gsLuje1oBHaSJKcPyxhiTY5YgMhARPr94DsEA3PLHV0kkk3zr787ILkkMVoMYeBc1WBOTMSavWYIYhIjwmcvmEAwE+P6jW9jW2Ml1i6ay+LTJFEaCgxeMlkPH3iOnp48F0b9shXu2GoQxJg/ZOYijEBH+56Wz+fpVp7O/vZdP/+o5Fn7zEb5w30a27GvPXGiwQYMy1SDsKiZjTB6zGkQW3r/oZK5bOJW/bT/IPet2cv+zu1m9YTcrP7CAC06pOXzh4TQxhaMQiloTkzEmL1kNIkuBgLBoRjXfvWY+j332Yuori/jQT9by2417Dl8wWgG9bZAc0PFfpgSRWt6amIwxecgSxAhMLItyz8fO54z6cm646xl+8dSOQzOj5aBJ6BvQBJVKEKnzDunLWxOTMSYPWYIYofKiML/4yHm8Zc4EvnT/Jm778zY3Y7DzCt3NbgS54IBWvcHOWRhjTI75miBEZLGIvCwiW0Xk5gzzRUS+783fKCJnp83bLiLPi8gGEVnnZ5wjVRgJsuL953DR7Fp+8IetbjyJwS5dTXX1PZB1+W2MyVO+JQgRCQK3AEuAecC1IjJvwGJLgFneYznwwwHzL1HV+aq6wK84j1U4GOB9i06mtTvGk682Hb0GMfD8A3jnIKyJyRiTf/ysQSwEtqrqNlXtA+4Glg5YZinwc3WeAipEZLKPMfniTbNqKI4E+d2mvcNPENbEZIzJU34miDpgZ9r7Bm9atsso8LCIrBeR5YNtRESWi8g6EVnX2Ng4CmEPXzQc5C2nTuThzXtJFAzSfcagNYjyzFc9GWNMjvmZIDL1SzGw57ujLXOBqp6Na4b6pIi8OdNGVHWlqi5Q1QW1tbUjj/YYLTl9Ek2dfazf54U/nCamTFc9GWNMjvmZIBqAKWnv64Hd2S6jqqnn/cAqXJNV3rp4Ti3RcIDfvtwOyOEJQvXoTUxgzUzGmLzjZ4JYC8wSkekiEgGWAasHLLMa+IB3NdMioFVV94hIsYiUAohIMXAZsMnHWI9ZUSTExbMn8LvN+9Fo2eE7/N520ER/gmju7OP5Bi+BWHcbxpg85VuCUNU4cAPwEPAicI+qbhaR60Xkem+xNcA2YCvwY+AT3vSJwF9E5Dngb8BvVfVBv2IdLUveMIn97b30hUoP3+EPuIv65vs28u4fPUFPLGEd9hlj8pavfTGp6hpcEkiftiLttQKfzFBuG3Cmn7H54S1zJxAJBjiYLGLyIAni1cYOHn5hH6rw7OstnF9c4S3TcrzDNcaYo7I7qUdRaTTMm2bVsLsngqbXCNISxG1/3kYkGEAEnn7tKPdNGGNMjlmCGGVL3jCZPbESEntfgMZX3EQvQTQlivj1+l28e0E9p04q4+ltB62JyRiTtyxBjLJLT53Ircl30psMwE8Ww+4N/Qnirk0dxJNJPnrhDBbNqOaZ15vpDRaBBKyJyRiTdyxBjLLyojATTjmba+JfpVei8NN3wJbfA/CTZ5pZcvpkptUUc96MKnrjSZ5raLMeXY0xeckShA++vvR0ukumcWnrP9NRMAFe+R2xQJSmngDL3zwDgIXTqgB4eluTjQlhjMlLliB8MKWqiHs//kaqJk/nogOf5UDZPHZqLefPqObMKRUAVBZHmDuplKdfO+hulrMahDEmz1iC8ElVcYQ7/+E8zpg9k/P2f4Gl3V/hYxfNOGyZRTOqWb+jmWRBuZ2DMMbkHUsQPiqKhFj5gQVcd/4MFs2bzkWzD+8r6rzpVXTHErRo0dGbmNr2wIv/DbGekQfT0Th4h4D7XoCfL4W//D9IJka+DWPMmOLrjXLGjRfxtaWnZ5y3cLo7D7Gnt4CqTE1M3c3wl3+Hp1dAvAfKp8BbvwKnvwsCabk9mYC2XVBWf/h0gIb18MdvwquPwuQz4bJvwvQ3uXmq8LeV8PCX3JVU2x6Dl9bAO1dA9czsP2TnAXj2FxAsgLOuO3RvR0oiDq/8ziW4U6+AcPTI+S/cD60NMP86KMnQ6eKBLbBvE8y6DCLF2cd2vCQTsOVhd7f81EVHzo/3wcZfQTIOZ1575HfQ1wXrbofORjjvY1B20vGJ25ijEHcz89iwYMECXbcuLwefG9Sl3/0TN+oveUfnfXD+DVAyEUomQPN2eOL70NMGZ1wDcy6HP38H9m6Ek86GC29yy2z/K7z+FPS2up3TtAth+kVQNcPt/F95EAqrYP57YfP90NYAs5fABTfCX77rdmqzLoOlt7oEseafIBGDS78Gp7zN7bA69kPnfrfjr57lkkekGPa/BE/dCs/dDYle94EipXDO38Oij0MoCut/6nZ8bbvc/OJaOPcf4NyPuHU8+0t44gfQ4o3rHSp05d/4j1BWB9v+CE/90MUJ7oT+gg/DwuVQNtl9P1sehhdXw57n4OQLYd6VMONiCBX4/wdMJt22H/vf0PiSmzb9zXDxP8PJ57v5m++DP3zd/b0ASifDhf8Tzv4ABILwzM/hT/8HOva6RB2MwLkfhQtuOjJZqoJk6gTZmJERkfWDDcpmCSLHvnT/JvY/8wArKn6OdOxzR5gpsxfDW74Ek7waSDIJz98Dj37t0A63ehZMuwAmng57NsC2x6H1dTcvWuF2tOd9DApKIdbtaiN//q4bgyJYAJd9Axb+w6GdTttu+M0NrsZxNCWT3A4tFHVHxIs+AX0d8OR/wOZVbkcnAUj0uZ31wo9BpAievBW2POS2HSmG7oNQfy5c+Gn3Wf76Pdh4t9tG+RRofg2KJ7gd5pRzXbJ58QEIhKDubNj9rNtGyUQ46SzY8YT7bAVlMPMSlxyDYQiE3XjggZB7HQi5zxzrdp0p9ra7+CPFUFTtkm1hJcS6oKvJexx0n7e4xi0TKYENd8K+56FmDlz8eWjf62p9nfthxiWu3N6N7u/z1q+4pPXYt+D1J6D0JPe++TWYsgje9hVXc/jT/4Hn7nLJctal7jtq3+uaGuM9UDnNHQBUz3SfO9blEmVvu0vUhZVQVANFVe57iHUe+oyxbjetqMotF61w30vq7yUB7zsKed9byB0wxHvduhN9IEH3PYQK3KOv89D3093syqXWX1jlynTsh459rrYZCLi/aclElwATcWh53R0ktLzuOrYsnwIVU91zKOp+72273O8z1g2lk1yiLZvs/p5NW+HAK+7RdRCqprvfU80st45k3H2GeI97XVACBeXuoCdc6C4S6T7oyqZ+P0XVh34LsS43vafN/U7CRYd+I4WV7ntLxl3X/cmES/zBsEv2gbBrQu7Y5/6OHfvdvJKJhw4Iw4Xue07G3Pch4r7bYIH7+/R1QvMOd5DRvN19pxVToOJk9z0V1474wMESRB57YONubrjzWe7/5AXMry93/2Ad+90PrnZ25kJ9XbDzKZgwz/2jpFN1P6B9m9yR7MDmHnD/pM/8zNUkJg4cBdZbx0sPuH+Gkgnux1dc62Jr2uL+GZu2QfUMOOfDUFx9ePnmHa72kkzAgg9B7ZzD5ze+4hJVV5OrCZz8xsN/3C07Xe2p8SU4871w+t8dXhs4uA2e/hHs+KurLZ16BdQvdDueeC9s+xO8+BuXLGNd7h83Gff+AeNuB5QiQZc8C8pcAuvrdDuJWOehZQLhQzuKeI+3E/GaBCunw8VfgDdc7XYKqb/Puv90iSJSBJd8Ed7w7kPNf6rw2uPw+P9163vzZ10tLv07OLDFJZKGtW4nUjbZ7RCDEZdQDr7mvodYFyDeZyh187ubBzmnJW5nG+/OMC9PFNe6v0nH3szzQ4WueS7VfU26cLFLCEVV7vtp2eF22Cc6CQz9OYonwGe3jGz1liDy1/72HhZ+81FuXjKX6y8aRru/GTlVl7w04XaomY68Yj1uJxQpcslj4DLxPje/qNod4Q22HT+bg1RdQgsXHXnuKRH3EkWrqxUVlLpnEZcou5u9R4v7HjR56Og3mXBHsqmkGgy7xBKMuIcmvKNx74g8UpJWY6hMW//BQ7WuEu8go6jGbSe96TIQOlRbiBR532+vOyfV8rp7XV7nmhwLK72aX49LIm17XM2meparfaV/3/Fel0Tbdru4Q1EIRVwC6uvwal1tLslGy11tp6jKfVc9bYdqjt3N7juOlrnlIiWuTP932Oz+FoGgW3cg6L7DRJ9XI4i531DJBHdAVzLRTevY59Ws9rplU7XbYNh9R/Fet1yi18VeOc0dkFROc5+jZadX83rdJf0LbhzRz8gSRJ57y3ceo66ikJuXzOWF3W1s3t3GrpZuSgtClBWGKYuGKAgH6eyN094Tp70nRm88SXlhmOqSCFXFBVQXR6gqjlBdEqG6uIDK4jABEVRBvUH6XCeBh/6BOnvjrN/RzFPbmnj29RaqSiK8oa6cN9SVc/pJ5ZQXhTPG2xNLsH5HM529cWpKC6gtKaCmpIDCSPC4fF8nIlWlO5YgllBEICCC4IarDQbsnILJnaMlCLuKKQ8smlHNnU+/zp+3/AWAokiQKZVFdMXitHXHaeuJoQrBgFAaDVEaDRENBWnpjnGws49EMrskH/LKl3jlXzvQSTypBAPCvMll7Gzu4rcb9/QvP6WqkNMml3N6XRmnTi5j58Eu/vRKI09ua6IndmSVtyAUcOsvcNsoDAcpCAWJhAJEggECAeiLK/FkklgiiSAUFwQpLghRWuCSYCyRJJ5Q4kklFBDqKguZUlnElKpCakoKiCWS9MSS9MYT9MWTiAiB1A5XoDeepCeWoCeWJKnKzNpiplUXEwqO3hXd8USSPa097GjqYtuBDrbu72DLvg5ebeyguy9BMCiEAgFCASGeVLr64nTHEmQ6FgsGhEllUSaXR5lcUchJFVHqK4uoryikvrKQuspCiiIn7r9pTyxBbyxJQThAQejwA5TR0N2XoL03Rk1xAQFLtKPuxP3ljSHL3zSDmpICTplQwmknlTGtuviwo8pkUulLJDP+gyWTSltPjAMdfRzs7ONgZy9NnX20dMVIJt3RqoigqnT1JWjvidPRG6ezN85lp03kvOnVnHNyJcUF7qfQ3NnHpt2tPL+rlc2729i8q5UHNx9qD55eU8yyc6dy0exaqksiHOjo5UB7H40dvbR1x2j31t3eE6e7L0F3LEFrd4zeeIKkust+I0EhHAyQVKWxvZeOXlcr6kskCQcChIJCKBigN5agrSfOsSoIBZg9sZRTJpQgpCWReILO3kT/99HRGycUECKhQH9iCwcDhINCMCCEAsL+9l52NXcTT0vKpQUhZk4o4c2zaymLhoknk8STSjyRJBQMUBQOUlQQoigSJOT9XVUhqUp7T5zdrd3sbulmY0MLD27qJpY4PJPUlBQwtaqQk6uLqaso7K8pVhVHqCiMEA0HXBIOBQiK0NWXoLMvTlefS6KHapoRCkJBVJXeeJLO3jg98SQBgVDAfU73ed3rwXbm7T0x1u9oZt32Zp7d2UwoEHAJrryQiWUFHOjo5cU97by4p43Xmjr7E6OI+1sUR0IUFxw6kCiLhqksClNZHKGiKExROHjYtuNJpTfuEk1vPElLVx+vHehkR1MXe9vcvUGRYICTKqLUVRYyqazwsAOV8sIwk8uj1FcWclKFS7jxRJK2njjNXX109MQJBwNEwwEKwkEiwQCJpNIXT9KXcLW+gLjfQDDgDkhaumIc6OilqaOPps4+FCXifXehoBBIi18VEkkXeyzh1tsbd/8bPTH3WyyLhpheU8z02hJm1BQTTyqv7Gtny752XtnXQWdvnPLCMGWF4f7nsmiI0qh7Li8Kc9pJGc43HiNrYjJDauuJ8fLediaUFnBy9fG9B6GtJ0bDwW52NndxsLOPSDBANBwkGnb/jIrb0SaTiioUhN38glAAVdi6v4OX9rbx4p52tjV2ICJEw6l1BL0dVbB/p5XaMfTGE/3/0PFkqlaTpLqkgJOriphaVcTU6iJm1JQwsaxg1I6Mk0mlsaOXhuYuGpq72Xmwi50Hu3n9YBevH+xiT2s3WVYYM4qGA/TFk1mtI5UwUjXASChAMCDsPNhF0qvRzptcBsCe1h4OdPT2l51aVcSpk0uZO6mMssKwV5NI0BNP0tUXp8M7UGnvidPaHaOlK0ZzVx+98aOfjI2EApRFw0yrLuLk6mKm1xRRGg2zu7WbXc3dNDR3s6+thw4v4WfavRVHgnT25faG0FBAXA3b+y23dMXo6M18MFRXUUhZYZi27lj/QdhANSUR1n3x0hHFkrNzECKyGPgeEARuU9VvDZgv3vzLgS7gg6r6TDZlM7EEYca6ZFJp7Y7R1OlqjC1dffQlkl5SS5JIKkWRIEURdwQdCgotXa4psqmjl9buGNFwkCIvKUbDAZLqms1iCXVNfF6SjHnrjSXcut0RdZJTJpRw7rQqzppacVjzV288wf62XiqKwpRGM5+/Gkqq1pkuKEJBONVMmX0iTp33ae6KsbvFJZBdLd0c6OilLBqmoihMZVGE0miov+myJ5agL5EkFDhUKwsHBMXVZJJJJZFUygvD1JQWUOOd8xOBWOJQDWGgUCrZerWzgU2equ7A4LXGTrYd6CQYkP5ab0nB4Q098USyP7m29cRo74mTSCoXnFKT/RedJicJQkSCwCvApUADsBa4VlVfSFvmcuAfcQniPOB7qnpeNmUzsQRhjDHDc7QE4WdfTAuBraq6TVX7gLuBpQOWWQr8XJ2ngAoRmZxlWWOMMT7yM0HUATvT3jd407JZJpuyAIjIchFZJyLrGhsbjzloY4wxjp8JIlNj4cD2rMGWyaasm6i6UlUXqOqC2toMnbwZY4wZET8vc20ApqS9rwd2Z7lMJIuyxhhjfORnDWItMEtEpotIBFgGrB6wzGrgA+IsAlpVdU+WZY0xxvjItxqEqsZF5AbgIdylqrer6mYRud6bvwJYg7uCaSvuMtcPHa2sX7EaY4w5kt0oZ4wx41iuLnM1xhhzAhtTNQgRaQR2jLB4DXBgFMMZbfkeH1iMoyHf44P8jzHf44P8ivFkVc14CeiYShDHQkTWDVbNygf5Hh9YjKMh3+OD/I8x3+ODEyNGsCYmY4wxg7AEYYwxJiNLEIeszHUAQ8j3+MBiHA35Hh/kf4z5Hh+cGDHaOQhjjDGZWQ3CGGNMRpYgjDHGZDTuE4SILBaRl0Vkq4jcnOt4AETkdhHZLyKb0qZVicjvRWSL91yZw/imiMgfReRFEdksIjfmYYxREfmbiDznxfiv+RajF09QRJ4VkQfyNL7tIvK8iGwQkXV5GmOFiNwrIi95v8nz8yVGEZnjfXepR5uI3JQv8Q1lXCcIb+S6W4AlwDzgWhGZl9uoAPgpsHjAtJuBR1V1FvCo9z5X4sA/qeqpwCLgk973lk8x9gJvUdUzgfnAYq9DyHyKEeBG4MW09/kWH8Alqjo/7br9fIvxe8CDqjoXOBP3feZFjKr6svfdzQfOwfU5typf4huSqo7bB3A+8FDa+y8AX8h1XF4s04BNae9fBiZ7rycDL+c6xrTYfoMbHjYvYwSKgGdww9rmTYy4buwfBd4CPJCPf2dgO1AzYFrexAiUAa/hXXCTjzGmxXQZ8Nd8jS/TY1zXIBjGyHV5YKK6rtDxnifkOB4ARGQacBbwNHkWo9d8swHYD/xeVfMtxn8HPgekj3KfT/GBG6jrYRFZLyLLvWn5FOMMoBH4iddUd5uIFOdZjCnLgLu81/kY3xHGe4LIeuQ6cyQRKQF+Ddykqm25jmcgVU2oq9rXAwtF5PQch9RPRN4B7FfV9bmOZQgXqOrZuGbYT4rIm3Md0AAh4Gzgh6p6FtBJHjbXeOPaXAn8V65jGY7xniCyGfUuX+wTkckA3vP+XAYjImFccrhDVe/zJudVjCmq2gI8hjuvky8xXgBcKSLbgbuBt4jIL/MoPgBUdbf3vB/Xdr6Q/IqxAWjwaocA9+ISRj7FCC7BPqOq+7z3+RZfRuM9QZxII9etBv7ee/33uHb/nBARAf4TeFFVv5s2K59irBWRCu91IfA24CXyJEZV/YKq1qvqNNzv7g+q+r58iQ9ARIpFpDT1GteGvok8ilFV9wI7RWSON+mtwAvkUYyeaznUvAT5F19muT4JkusHbkS7V4BXgX/JdTxeTHcBe4AY7gjpI0A17oTmFu+5KofxXYhritsIbPAel+dZjGcAz3oxbgK+7E3PmxjTYr2YQyep8yY+XPv+c95jc+r/I59i9OKZD6zz/tb3A5X5FCPuIokmoDxtWt7Ed7SHdbVhjDEmo/HexGSMMWYQliCMMcZkZAnCGGNMRpYgjDHGZGQJwhhjTEaWIIzJAyJycapHV2PyhSUIY4wxGVmCMGYYROR93jgTG0TkR16HgB0i8h0ReUZEHhWRWm/Z+SLylIhsFJFVqT7/ReQUEXnEG6viGRGZ6a2+JG1cgzu8O9aNyRlLEMZkSUROBd6D68BuPpAArgOKcf3snA38CfiKV+TnwOdV9Qzg+bTpdwC3qBur4o24u+bB9Yp7E25skhm4/pqMyZlQrgMw5gTyVtygL2u9g/tCXCdrSeBX3jK/BO4TkXKgQlX/5E3/GfBfXt9Gdaq6CkBVewC89f1NVRu89xtwY4L8xfdPZcwgLEEYkz0BfqaqXzhsosiXBix3tP5rjtZs1Jv2OoH9f5ocsyYmY7L3KHC1iEyA/rGZT8b9H13tLfNe4C+q2go0i8ibvOnvB/6kbtyMBhG5yltHgYgUHc8PYUy27AjFmCyp6gsi8kXcCGsBXG+7n8QNUnOaiKwHWnHnKcB147zCSwDbgA95098P/EhEvuat493H8WMYkzXrzdWYYyQiHapakus4jBlt1sRkjDEmI6tBGGOMychqEMYYYzKyBGGMMSYjSxDGGGMysgRhjDEmI0sQxhhjMvr/kMw08pq9GhAAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "norm_strat = 2\n",
    "print('Normalizacion:', norm_strat)\n",
    "execute_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalizacion: 3\n",
      "Loading... ETH\n",
      "Extracting columns columns for ETH\n",
      "Proccessing and arranging columns for LSTM model\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>close_19</th>\n",
       "      <th>RSI_19</th>\n",
       "      <th>close_18</th>\n",
       "      <th>RSI_18</th>\n",
       "      <th>close_17</th>\n",
       "      <th>RSI_17</th>\n",
       "      <th>close_16</th>\n",
       "      <th>RSI_16</th>\n",
       "      <th>close_15</th>\n",
       "      <th>RSI_15</th>\n",
       "      <th>...</th>\n",
       "      <th>RSI_4</th>\n",
       "      <th>close_3</th>\n",
       "      <th>RSI_3</th>\n",
       "      <th>close_2</th>\n",
       "      <th>RSI_2</th>\n",
       "      <th>close_1</th>\n",
       "      <th>RSI_1</th>\n",
       "      <th>close_0</th>\n",
       "      <th>RSI_0</th>\n",
       "      <th>close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>754.99</td>\n",
       "      <td>51.874455</td>\n",
       "      <td>855.28</td>\n",
       "      <td>64.086633</td>\n",
       "      <td>934.03</td>\n",
       "      <td>70.431522</td>\n",
       "      <td>940.00</td>\n",
       "      <td>70.851945</td>\n",
       "      <td>959.30</td>\n",
       "      <td>72.226781</td>\n",
       "      <td>...</td>\n",
       "      <td>48.819684</td>\n",
       "      <td>1000.00</td>\n",
       "      <td>48.819684</td>\n",
       "      <td>994.00</td>\n",
       "      <td>48.493851</td>\n",
       "      <td>1032.50</td>\n",
       "      <td>50.764615</td>\n",
       "      <td>1152.75</td>\n",
       "      <td>57.122992</td>\n",
       "      <td>877.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>855.28</td>\n",
       "      <td>64.086633</td>\n",
       "      <td>934.03</td>\n",
       "      <td>70.431522</td>\n",
       "      <td>940.00</td>\n",
       "      <td>70.851945</td>\n",
       "      <td>959.30</td>\n",
       "      <td>72.226781</td>\n",
       "      <td>1004.11</td>\n",
       "      <td>75.156684</td>\n",
       "      <td>...</td>\n",
       "      <td>48.819684</td>\n",
       "      <td>994.00</td>\n",
       "      <td>48.493851</td>\n",
       "      <td>1032.50</td>\n",
       "      <td>50.764615</td>\n",
       "      <td>1152.75</td>\n",
       "      <td>57.122992</td>\n",
       "      <td>1049.00</td>\n",
       "      <td>51.002981</td>\n",
       "      <td>851.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>934.03</td>\n",
       "      <td>70.431522</td>\n",
       "      <td>940.00</td>\n",
       "      <td>70.851945</td>\n",
       "      <td>959.30</td>\n",
       "      <td>72.226781</td>\n",
       "      <td>1004.11</td>\n",
       "      <td>75.156684</td>\n",
       "      <td>1123.09</td>\n",
       "      <td>80.914056</td>\n",
       "      <td>...</td>\n",
       "      <td>48.493851</td>\n",
       "      <td>1032.50</td>\n",
       "      <td>50.764615</td>\n",
       "      <td>1152.75</td>\n",
       "      <td>57.122992</td>\n",
       "      <td>1049.00</td>\n",
       "      <td>51.002981</td>\n",
       "      <td>993.00</td>\n",
       "      <td>48.012894</td>\n",
       "      <td>808.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>940.00</td>\n",
       "      <td>70.851945</td>\n",
       "      <td>959.30</td>\n",
       "      <td>72.226781</td>\n",
       "      <td>1004.11</td>\n",
       "      <td>75.156684</td>\n",
       "      <td>1123.09</td>\n",
       "      <td>80.914056</td>\n",
       "      <td>1133.18</td>\n",
       "      <td>81.309636</td>\n",
       "      <td>...</td>\n",
       "      <td>50.764615</td>\n",
       "      <td>1152.75</td>\n",
       "      <td>57.122992</td>\n",
       "      <td>1049.00</td>\n",
       "      <td>51.002981</td>\n",
       "      <td>993.00</td>\n",
       "      <td>48.012894</td>\n",
       "      <td>980.00</td>\n",
       "      <td>47.319361</td>\n",
       "      <td>866.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>959.30</td>\n",
       "      <td>72.226781</td>\n",
       "      <td>1004.11</td>\n",
       "      <td>75.156684</td>\n",
       "      <td>1123.09</td>\n",
       "      <td>80.914056</td>\n",
       "      <td>1133.18</td>\n",
       "      <td>81.309636</td>\n",
       "      <td>1291.00</td>\n",
       "      <td>86.146268</td>\n",
       "      <td>...</td>\n",
       "      <td>57.122992</td>\n",
       "      <td>1049.00</td>\n",
       "      <td>51.002981</td>\n",
       "      <td>993.00</td>\n",
       "      <td>48.012894</td>\n",
       "      <td>980.00</td>\n",
       "      <td>47.319361</td>\n",
       "      <td>1061.00</td>\n",
       "      <td>51.974254</td>\n",
       "      <td>841.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1573</th>\n",
       "      <td>4287.80</td>\n",
       "      <td>47.095555</td>\n",
       "      <td>3996.90</td>\n",
       "      <td>39.023233</td>\n",
       "      <td>4294.76</td>\n",
       "      <td>48.716109</td>\n",
       "      <td>4412.17</td>\n",
       "      <td>51.957920</td>\n",
       "      <td>4258.31</td>\n",
       "      <td>47.702403</td>\n",
       "      <td>...</td>\n",
       "      <td>53.835840</td>\n",
       "      <td>4215.73</td>\n",
       "      <td>46.826530</td>\n",
       "      <td>4117.25</td>\n",
       "      <td>44.735958</td>\n",
       "      <td>4196.44</td>\n",
       "      <td>46.793026</td>\n",
       "      <td>4347.59</td>\n",
       "      <td>50.574650</td>\n",
       "      <td>4063.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1574</th>\n",
       "      <td>3996.90</td>\n",
       "      <td>39.023233</td>\n",
       "      <td>4294.76</td>\n",
       "      <td>48.716109</td>\n",
       "      <td>4412.17</td>\n",
       "      <td>51.957920</td>\n",
       "      <td>4258.31</td>\n",
       "      <td>47.702403</td>\n",
       "      <td>4085.97</td>\n",
       "      <td>43.413283</td>\n",
       "      <td>...</td>\n",
       "      <td>46.826530</td>\n",
       "      <td>4117.25</td>\n",
       "      <td>44.735958</td>\n",
       "      <td>4196.44</td>\n",
       "      <td>46.793026</td>\n",
       "      <td>4347.59</td>\n",
       "      <td>50.574650</td>\n",
       "      <td>4306.40</td>\n",
       "      <td>49.541304</td>\n",
       "      <td>4037.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1575</th>\n",
       "      <td>4294.76</td>\n",
       "      <td>48.716109</td>\n",
       "      <td>4412.17</td>\n",
       "      <td>51.957920</td>\n",
       "      <td>4258.31</td>\n",
       "      <td>47.702403</td>\n",
       "      <td>4085.97</td>\n",
       "      <td>43.413283</td>\n",
       "      <td>4339.44</td>\n",
       "      <td>50.467423</td>\n",
       "      <td>...</td>\n",
       "      <td>44.735958</td>\n",
       "      <td>4196.44</td>\n",
       "      <td>46.793026</td>\n",
       "      <td>4347.59</td>\n",
       "      <td>50.574650</td>\n",
       "      <td>4306.40</td>\n",
       "      <td>49.541304</td>\n",
       "      <td>4436.91</td>\n",
       "      <td>52.829940</td>\n",
       "      <td>3792.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1576</th>\n",
       "      <td>4412.17</td>\n",
       "      <td>51.957920</td>\n",
       "      <td>4258.31</td>\n",
       "      <td>47.702403</td>\n",
       "      <td>4085.97</td>\n",
       "      <td>43.413283</td>\n",
       "      <td>4339.44</td>\n",
       "      <td>50.467423</td>\n",
       "      <td>4269.36</td>\n",
       "      <td>48.661227</td>\n",
       "      <td>...</td>\n",
       "      <td>46.793026</td>\n",
       "      <td>4347.59</td>\n",
       "      <td>50.574650</td>\n",
       "      <td>4306.40</td>\n",
       "      <td>49.541304</td>\n",
       "      <td>4436.91</td>\n",
       "      <td>52.829940</td>\n",
       "      <td>4105.64</td>\n",
       "      <td>44.841174</td>\n",
       "      <td>3630.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1577</th>\n",
       "      <td>4258.31</td>\n",
       "      <td>47.702403</td>\n",
       "      <td>4085.97</td>\n",
       "      <td>43.413283</td>\n",
       "      <td>4339.44</td>\n",
       "      <td>50.467423</td>\n",
       "      <td>4269.36</td>\n",
       "      <td>48.661227</td>\n",
       "      <td>4524.85</td>\n",
       "      <td>54.986266</td>\n",
       "      <td>...</td>\n",
       "      <td>50.574650</td>\n",
       "      <td>4306.40</td>\n",
       "      <td>49.541304</td>\n",
       "      <td>4436.91</td>\n",
       "      <td>52.829940</td>\n",
       "      <td>4105.64</td>\n",
       "      <td>44.841174</td>\n",
       "      <td>3897.94</td>\n",
       "      <td>40.686916</td>\n",
       "      <td>3709.27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1421 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      close_19     RSI_19  close_18     RSI_18  close_17     RSI_17  close_16  \\\n",
       "157     754.99  51.874455    855.28  64.086633    934.03  70.431522    940.00   \n",
       "158     855.28  64.086633    934.03  70.431522    940.00  70.851945    959.30   \n",
       "159     934.03  70.431522    940.00  70.851945    959.30  72.226781   1004.11   \n",
       "160     940.00  70.851945    959.30  72.226781   1004.11  75.156684   1123.09   \n",
       "161     959.30  72.226781   1004.11  75.156684   1123.09  80.914056   1133.18   \n",
       "...        ...        ...       ...        ...       ...        ...       ...   \n",
       "1573   4287.80  47.095555   3996.90  39.023233   4294.76  48.716109   4412.17   \n",
       "1574   3996.90  39.023233   4294.76  48.716109   4412.17  51.957920   4258.31   \n",
       "1575   4294.76  48.716109   4412.17  51.957920   4258.31  47.702403   4085.97   \n",
       "1576   4412.17  51.957920   4258.31  47.702403   4085.97  43.413283   4339.44   \n",
       "1577   4258.31  47.702403   4085.97  43.413283   4339.44  50.467423   4269.36   \n",
       "\n",
       "         RSI_16  close_15     RSI_15  ...      RSI_4  close_3      RSI_3  \\\n",
       "157   70.851945    959.30  72.226781  ...  48.819684  1000.00  48.819684   \n",
       "158   72.226781   1004.11  75.156684  ...  48.819684   994.00  48.493851   \n",
       "159   75.156684   1123.09  80.914056  ...  48.493851  1032.50  50.764615   \n",
       "160   80.914056   1133.18  81.309636  ...  50.764615  1152.75  57.122992   \n",
       "161   81.309636   1291.00  86.146268  ...  57.122992  1049.00  51.002981   \n",
       "...         ...       ...        ...  ...        ...      ...        ...   \n",
       "1573  51.957920   4258.31  47.702403  ...  53.835840  4215.73  46.826530   \n",
       "1574  47.702403   4085.97  43.413283  ...  46.826530  4117.25  44.735958   \n",
       "1575  43.413283   4339.44  50.467423  ...  44.735958  4196.44  46.793026   \n",
       "1576  50.467423   4269.36  48.661227  ...  46.793026  4347.59  50.574650   \n",
       "1577  48.661227   4524.85  54.986266  ...  50.574650  4306.40  49.541304   \n",
       "\n",
       "      close_2      RSI_2  close_1      RSI_1  close_0      RSI_0    close  \n",
       "157    994.00  48.493851  1032.50  50.764615  1152.75  57.122992   877.00  \n",
       "158   1032.50  50.764615  1152.75  57.122992  1049.00  51.002981   851.15  \n",
       "159   1152.75  57.122992  1049.00  51.002981   993.00  48.012894   808.99  \n",
       "160   1049.00  51.002981   993.00  48.012894   980.00  47.319361   866.66  \n",
       "161    993.00  48.012894   980.00  47.319361  1061.00  51.974254   841.57  \n",
       "...       ...        ...      ...        ...      ...        ...      ...  \n",
       "1573  4117.25  44.735958  4196.44  46.793026  4347.59  50.574650  4063.56  \n",
       "1574  4196.44  46.793026  4347.59  50.574650  4306.40  49.541304  4037.23  \n",
       "1575  4347.59  50.574650  4306.40  49.541304  4436.91  52.829940  3792.75  \n",
       "1576  4306.40  49.541304  4436.91  52.829940  4105.64  44.841174  3630.19  \n",
       "1577  4436.91  52.829940  4105.64  44.841174  3897.94  40.686916  3709.27  \n",
       "\n",
       "[1421 rows x 41 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>close_19</th>\n",
       "      <th>RSI_19</th>\n",
       "      <th>close_18</th>\n",
       "      <th>RSI_18</th>\n",
       "      <th>close_17</th>\n",
       "      <th>RSI_17</th>\n",
       "      <th>close_16</th>\n",
       "      <th>RSI_16</th>\n",
       "      <th>close_15</th>\n",
       "      <th>RSI_15</th>\n",
       "      <th>...</th>\n",
       "      <th>RSI_4</th>\n",
       "      <th>close_3</th>\n",
       "      <th>RSI_3</th>\n",
       "      <th>close_2</th>\n",
       "      <th>RSI_2</th>\n",
       "      <th>close_1</th>\n",
       "      <th>RSI_1</th>\n",
       "      <th>close_0</th>\n",
       "      <th>RSI_0</th>\n",
       "      <th>close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1578</th>\n",
       "      <td>4085.97</td>\n",
       "      <td>43.413283</td>\n",
       "      <td>4339.44</td>\n",
       "      <td>50.467423</td>\n",
       "      <td>4269.36</td>\n",
       "      <td>48.661227</td>\n",
       "      <td>4524.85</td>\n",
       "      <td>54.986266</td>\n",
       "      <td>4041.2</td>\n",
       "      <td>43.948042</td>\n",
       "      <td>...</td>\n",
       "      <td>49.541304</td>\n",
       "      <td>4436.91</td>\n",
       "      <td>52.82994</td>\n",
       "      <td>4105.64</td>\n",
       "      <td>44.841174</td>\n",
       "      <td>3897.94</td>\n",
       "      <td>40.686916</td>\n",
       "      <td>4089.37</td>\n",
       "      <td>45.681743</td>\n",
       "      <td>3725.46</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      close_19     RSI_19  close_18     RSI_18  close_17     RSI_17  close_16  \\\n",
       "1578   4085.97  43.413283   4339.44  50.467423   4269.36  48.661227   4524.85   \n",
       "\n",
       "         RSI_16  close_15     RSI_15  ...      RSI_4  close_3     RSI_3  \\\n",
       "1578  54.986266    4041.2  43.948042  ...  49.541304  4436.91  52.82994   \n",
       "\n",
       "      close_2      RSI_2  close_1      RSI_1  close_0      RSI_0    close  \n",
       "1578  4105.64  44.841174  3897.94  40.686916  4089.37  45.681743  3725.46  \n",
       "\n",
       "[1 rows x 41 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (1421, 1, 40) (1421, 1)\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_11 (LSTM)               (None, 1, 25)             6600      \n",
      "_________________________________________________________________\n",
      "lstm_12 (LSTM)               (None, 1, 25)             5100      \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 1, 25)             0         \n",
      "_________________________________________________________________\n",
      "lstm_13 (LSTM)               (None, 1, 25)             5100      \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 1, 25)             0         \n",
      "_________________________________________________________________\n",
      "lstm_14 (LSTM)               (None, 1, 25)             5100      \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 1, 25)             0         \n",
      "_________________________________________________________________\n",
      "lstm_15 (LSTM)               (None, 25)                5100      \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 25)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 26        \n",
      "=================================================================\n",
      "Total params: 27,026\n",
      "Trainable params: 27,026\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Y shape (1421, 1)\n",
      "Train on 1421 samples, validate on 285 samples\n",
      "Epoch 1/100\n",
      " - 10s - loss: 38.3074 - mse: 38.3074 - val_loss: 62.5358 - val_mse: 62.5358\n",
      "Epoch 2/100\n",
      " - 0s - loss: 35.4870 - mse: 35.4870 - val_loss: 54.5568 - val_mse: 54.5568\n",
      "Epoch 3/100\n",
      " - 0s - loss: 21.8233 - mse: 21.8233 - val_loss: 22.9937 - val_mse: 22.9937\n",
      "Epoch 4/100\n",
      " - 0s - loss: 4.3622 - mse: 4.3622 - val_loss: 6.1282 - val_mse: 6.1282\n",
      "Epoch 5/100\n",
      " - 0s - loss: 1.8951 - mse: 1.8951 - val_loss: 3.3219 - val_mse: 3.3219\n",
      "Epoch 6/100\n",
      " - 0s - loss: 2.0264 - mse: 2.0264 - val_loss: 3.0396 - val_mse: 3.0396\n",
      "Epoch 7/100\n",
      " - 0s - loss: 1.9974 - mse: 1.9974 - val_loss: 3.0793 - val_mse: 3.0793\n",
      "Epoch 8/100\n",
      " - 1s - loss: 2.0144 - mse: 2.0144 - val_loss: 3.1942 - val_mse: 3.1942\n",
      "Epoch 9/100\n",
      " - 1s - loss: 1.9590 - mse: 1.9590 - val_loss: 3.2190 - val_mse: 3.2190\n",
      "Epoch 10/100\n",
      " - 0s - loss: 1.9240 - mse: 1.9240 - val_loss: 3.1752 - val_mse: 3.1752\n",
      "Epoch 11/100\n",
      " - 1s - loss: 1.9323 - mse: 1.9323 - val_loss: 3.2093 - val_mse: 3.2093\n",
      "Epoch 12/100\n",
      " - 1s - loss: 2.0015 - mse: 2.0015 - val_loss: 3.2180 - val_mse: 3.2180\n",
      "Epoch 13/100\n",
      " - 0s - loss: 2.0369 - mse: 2.0369 - val_loss: 3.2371 - val_mse: 3.2371\n",
      "Epoch 14/100\n",
      " - 0s - loss: 1.9891 - mse: 1.9891 - val_loss: 3.2700 - val_mse: 3.2700\n",
      "Epoch 15/100\n",
      " - 0s - loss: 1.8895 - mse: 1.8895 - val_loss: 3.2155 - val_mse: 3.2155\n",
      "Epoch 16/100\n",
      " - 0s - loss: 1.9822 - mse: 1.9822 - val_loss: 3.3107 - val_mse: 3.3107\n",
      "Epoch 17/100\n",
      " - 0s - loss: 1.9004 - mse: 1.9004 - val_loss: 3.3032 - val_mse: 3.3032\n",
      "Epoch 18/100\n",
      " - 1s - loss: 1.9148 - mse: 1.9148 - val_loss: 3.3107 - val_mse: 3.3107\n",
      "Epoch 19/100\n",
      " - 1s - loss: 1.9477 - mse: 1.9477 - val_loss: 3.3597 - val_mse: 3.3597\n",
      "Epoch 20/100\n",
      " - 1s - loss: 2.0256 - mse: 2.0256 - val_loss: 3.2197 - val_mse: 3.2197\n",
      "Epoch 21/100\n",
      " - 1s - loss: 2.0228 - mse: 2.0228 - val_loss: 3.2273 - val_mse: 3.2273\n",
      "Epoch 22/100\n",
      " - 1s - loss: 1.9177 - mse: 1.9177 - val_loss: 3.1304 - val_mse: 3.1304\n",
      "Epoch 23/100\n",
      " - 1s - loss: 1.8569 - mse: 1.8569 - val_loss: 3.3093 - val_mse: 3.3093\n",
      "Epoch 24/100\n",
      " - 1s - loss: 1.8999 - mse: 1.8999 - val_loss: 3.2476 - val_mse: 3.2476\n",
      "Epoch 25/100\n",
      " - 1s - loss: 1.9091 - mse: 1.9091 - val_loss: 3.2378 - val_mse: 3.2378\n",
      "Epoch 26/100\n",
      " - 1s - loss: 1.9510 - mse: 1.9510 - val_loss: 3.1800 - val_mse: 3.1800\n",
      "Epoch 27/100\n",
      " - 1s - loss: 2.0025 - mse: 2.0025 - val_loss: 3.2411 - val_mse: 3.2411\n",
      "Epoch 28/100\n",
      " - 1s - loss: 1.8913 - mse: 1.8913 - val_loss: 3.2270 - val_mse: 3.2270\n",
      "Epoch 29/100\n",
      " - 1s - loss: 1.9153 - mse: 1.9153 - val_loss: 3.2438 - val_mse: 3.2438\n",
      "Epoch 30/100\n",
      " - 1s - loss: 1.8724 - mse: 1.8724 - val_loss: 3.2584 - val_mse: 3.2584\n",
      "Epoch 31/100\n",
      " - 1s - loss: 1.8471 - mse: 1.8471 - val_loss: 3.2296 - val_mse: 3.2296\n",
      "Epoch 32/100\n",
      " - 1s - loss: 1.8317 - mse: 1.8317 - val_loss: 3.2146 - val_mse: 3.2146\n",
      "Epoch 33/100\n",
      " - 1s - loss: 1.8852 - mse: 1.8852 - val_loss: 3.2368 - val_mse: 3.2368\n",
      "Epoch 34/100\n",
      " - 1s - loss: 1.9988 - mse: 1.9988 - val_loss: 3.2711 - val_mse: 3.2711\n",
      "Epoch 35/100\n",
      " - 1s - loss: 1.8716 - mse: 1.8716 - val_loss: 3.1998 - val_mse: 3.1998\n",
      "Epoch 36/100\n",
      " - 1s - loss: 1.8698 - mse: 1.8698 - val_loss: 3.2270 - val_mse: 3.2270\n",
      "Epoch 37/100\n",
      " - 1s - loss: 1.9435 - mse: 1.9435 - val_loss: 3.3058 - val_mse: 3.3058\n",
      "Epoch 38/100\n",
      " - 1s - loss: 1.8522 - mse: 1.8522 - val_loss: 3.2179 - val_mse: 3.2179\n",
      "Epoch 39/100\n",
      " - 1s - loss: 1.8273 - mse: 1.8273 - val_loss: 3.1554 - val_mse: 3.1554\n",
      "Epoch 40/100\n",
      " - 1s - loss: 1.9236 - mse: 1.9236 - val_loss: 3.1822 - val_mse: 3.1822\n",
      "Epoch 41/100\n",
      " - 1s - loss: 1.8115 - mse: 1.8115 - val_loss: 3.1047 - val_mse: 3.1047\n",
      "Epoch 42/100\n",
      " - 0s - loss: 1.7836 - mse: 1.7836 - val_loss: 3.0928 - val_mse: 3.0928\n",
      "Epoch 43/100\n",
      " - 0s - loss: 1.8274 - mse: 1.8274 - val_loss: 3.0780 - val_mse: 3.0780\n",
      "Epoch 44/100\n",
      " - 0s - loss: 1.8095 - mse: 1.8095 - val_loss: 2.9698 - val_mse: 2.9698\n",
      "Epoch 45/100\n",
      " - 0s - loss: 1.8622 - mse: 1.8622 - val_loss: 2.9689 - val_mse: 2.9689\n",
      "Epoch 46/100\n",
      " - 0s - loss: 1.6463 - mse: 1.6463 - val_loss: 2.5188 - val_mse: 2.5188\n",
      "Epoch 47/100\n",
      " - 0s - loss: 1.7513 - mse: 1.7513 - val_loss: 2.5843 - val_mse: 2.5843\n",
      "Epoch 48/100\n",
      " - 0s - loss: 1.8661 - mse: 1.8661 - val_loss: 2.4021 - val_mse: 2.4021\n",
      "Epoch 49/100\n",
      " - 0s - loss: 2.0653 - mse: 2.0653 - val_loss: 2.5594 - val_mse: 2.5594\n",
      "Epoch 50/100\n",
      " - 0s - loss: 1.8342 - mse: 1.8342 - val_loss: 3.0225 - val_mse: 3.0225\n",
      "Epoch 51/100\n",
      " - 0s - loss: 1.6770 - mse: 1.6770 - val_loss: 2.8910 - val_mse: 2.8910\n",
      "Epoch 52/100\n",
      " - 0s - loss: 1.6435 - mse: 1.6435 - val_loss: 2.6836 - val_mse: 2.6836\n",
      "Epoch 53/100\n",
      " - 1s - loss: 1.5611 - mse: 1.5611 - val_loss: 2.3602 - val_mse: 2.3602\n",
      "Epoch 54/100\n",
      " - 1s - loss: 1.6761 - mse: 1.6761 - val_loss: 2.3736 - val_mse: 2.3736\n",
      "Epoch 55/100\n",
      " - 0s - loss: 1.4354 - mse: 1.4354 - val_loss: 1.8904 - val_mse: 1.8904\n",
      "Epoch 56/100\n",
      " - 0s - loss: 1.6081 - mse: 1.6081 - val_loss: 2.0020 - val_mse: 2.0020\n",
      "Epoch 57/100\n",
      " - 0s - loss: 1.1943 - mse: 1.1943 - val_loss: 1.5099 - val_mse: 1.5099\n",
      "Epoch 58/100\n",
      " - 0s - loss: 1.6706 - mse: 1.6706 - val_loss: 1.8738 - val_mse: 1.8738\n",
      "Epoch 59/100\n",
      " - 0s - loss: 1.2635 - mse: 1.2635 - val_loss: 1.4429 - val_mse: 1.4429\n",
      "Epoch 60/100\n",
      " - 0s - loss: 1.6741 - mse: 1.6741 - val_loss: 1.7138 - val_mse: 1.7138\n",
      "Epoch 61/100\n",
      " - 0s - loss: 1.2868 - mse: 1.2868 - val_loss: 1.2922 - val_mse: 1.2922\n",
      "Epoch 62/100\n",
      " - 0s - loss: 1.6595 - mse: 1.6595 - val_loss: 1.5270 - val_mse: 1.5270\n",
      "Epoch 63/100\n",
      " - 0s - loss: 1.1943 - mse: 1.1943 - val_loss: 1.2332 - val_mse: 1.2332\n",
      "Epoch 64/100\n",
      " - 0s - loss: 1.4287 - mse: 1.4287 - val_loss: 1.3269 - val_mse: 1.3269\n",
      "Epoch 65/100\n",
      " - 0s - loss: 1.2322 - mse: 1.2322 - val_loss: 1.0427 - val_mse: 1.0427\n",
      "Epoch 66/100\n",
      " - 0s - loss: 1.4783 - mse: 1.4783 - val_loss: 1.2625 - val_mse: 1.2625\n",
      "Epoch 67/100\n",
      " - 0s - loss: 1.1736 - mse: 1.1736 - val_loss: 0.9594 - val_mse: 0.9594\n",
      "Epoch 68/100\n",
      " - 0s - loss: 1.3855 - mse: 1.3855 - val_loss: 1.0623 - val_mse: 1.0623\n",
      "Epoch 69/100\n",
      " - 0s - loss: 1.1787 - mse: 1.1787 - val_loss: 0.9031 - val_mse: 0.9031\n",
      "Epoch 70/100\n",
      " - 0s - loss: 1.2872 - mse: 1.2872 - val_loss: 0.9136 - val_mse: 0.9136\n",
      "Epoch 71/100\n",
      " - 0s - loss: 1.2465 - mse: 1.2465 - val_loss: 0.7785 - val_mse: 0.7785\n",
      "Epoch 72/100\n",
      " - 0s - loss: 1.3872 - mse: 1.3872 - val_loss: 0.9116 - val_mse: 0.9116\n",
      "Epoch 73/100\n",
      " - 0s - loss: 1.1062 - mse: 1.1062 - val_loss: 0.7934 - val_mse: 0.7934\n",
      "Epoch 74/100\n",
      " - 1s - loss: 1.2106 - mse: 1.2106 - val_loss: 0.7787 - val_mse: 0.7787\n",
      "Epoch 75/100\n",
      " - 1s - loss: 1.1529 - mse: 1.1529 - val_loss: 0.6928 - val_mse: 0.6928\n",
      "Epoch 76/100\n",
      " - 1s - loss: 1.2493 - mse: 1.2493 - val_loss: 0.7483 - val_mse: 0.7483\n",
      "Epoch 77/100\n",
      " - 1s - loss: 1.0644 - mse: 1.0644 - val_loss: 0.6507 - val_mse: 0.6507\n",
      "Epoch 78/100\n",
      " - 1s - loss: 1.1262 - mse: 1.1262 - val_loss: 0.6074 - val_mse: 0.6074\n",
      "Epoch 79/100\n",
      " - 1s - loss: 1.1585 - mse: 1.1585 - val_loss: 0.6220 - val_mse: 0.6220\n",
      "Epoch 80/100\n",
      " - 0s - loss: 1.0614 - mse: 1.0614 - val_loss: 0.5725 - val_mse: 0.5725\n",
      "Epoch 81/100\n",
      " - 0s - loss: 1.1541 - mse: 1.1541 - val_loss: 0.5583 - val_mse: 0.5583\n",
      "Epoch 82/100\n",
      " - 1s - loss: 1.1185 - mse: 1.1185 - val_loss: 0.5392 - val_mse: 0.5392\n",
      "Epoch 83/100\n",
      " - 1s - loss: 1.1485 - mse: 1.1485 - val_loss: 0.5075 - val_mse: 0.5075\n",
      "Epoch 84/100\n",
      " - 0s - loss: 1.1565 - mse: 1.1565 - val_loss: 0.5486 - val_mse: 0.5486\n",
      "Epoch 85/100\n",
      " - 0s - loss: 1.0299 - mse: 1.0299 - val_loss: 0.4749 - val_mse: 0.4749\n",
      "Epoch 86/100\n",
      " - 0s - loss: 1.0987 - mse: 1.0987 - val_loss: 0.5104 - val_mse: 0.5104\n",
      "Epoch 87/100\n",
      " - 0s - loss: 1.0371 - mse: 1.0371 - val_loss: 0.4621 - val_mse: 0.4621\n",
      "Epoch 88/100\n",
      " - 0s - loss: 1.1070 - mse: 1.1070 - val_loss: 0.4592 - val_mse: 0.4592\n",
      "Epoch 89/100\n",
      " - 0s - loss: 1.0039 - mse: 1.0039 - val_loss: 0.4437 - val_mse: 0.4437\n",
      "Epoch 90/100\n",
      " - 1s - loss: 0.9828 - mse: 0.9828 - val_loss: 0.3905 - val_mse: 0.3905\n",
      "Epoch 91/100\n",
      " - 0s - loss: 1.0846 - mse: 1.0846 - val_loss: 0.4282 - val_mse: 0.4282\n",
      "Epoch 92/100\n",
      " - 0s - loss: 0.9686 - mse: 0.9686 - val_loss: 0.3861 - val_mse: 0.3861\n",
      "Epoch 93/100\n",
      " - 0s - loss: 0.9481 - mse: 0.9481 - val_loss: 0.3565 - val_mse: 0.3565\n",
      "Epoch 94/100\n",
      " - 0s - loss: 1.0642 - mse: 1.0642 - val_loss: 0.3454 - val_mse: 0.3454\n",
      "Epoch 95/100\n",
      " - 0s - loss: 0.9691 - mse: 0.9691 - val_loss: 0.2978 - val_mse: 0.2978\n",
      "Epoch 96/100\n",
      " - 0s - loss: 1.0269 - mse: 1.0269 - val_loss: 0.2928 - val_mse: 0.2928\n",
      "Epoch 97/100\n",
      " - 0s - loss: 1.0209 - mse: 1.0209 - val_loss: 0.2871 - val_mse: 0.2871\n",
      "Epoch 98/100\n",
      " - 0s - loss: 1.0169 - mse: 1.0169 - val_loss: 0.2589 - val_mse: 0.2589\n",
      "Epoch 99/100\n",
      " - 0s - loss: 0.9822 - mse: 0.9822 - val_loss: 0.2721 - val_mse: 0.2721\n",
      "Epoch 100/100\n",
      " - 0s - loss: 0.9516 - mse: 0.9516 - val_loss: 0.2346 - val_mse: 0.2346\n",
      "real [[3725.46]]\n",
      "Test RMSE: 1542.989\n",
      "Diff [[1542.98928058]]\n",
      "% Diff [[41.41741639]] %\n",
      "Predictions [[2182.47071942]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "norm_strat = 3\n",
    "print('Normalizacion:', norm_strat)\n",
    "execute_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalizacion: 4\n",
      "Loading... ETH\n",
      "Extracting columns columns for ETH\n",
      "Proccessing and arranging columns for LSTM model\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>close_19</th>\n",
       "      <th>RSI_19</th>\n",
       "      <th>close_18</th>\n",
       "      <th>RSI_18</th>\n",
       "      <th>close_17</th>\n",
       "      <th>RSI_17</th>\n",
       "      <th>close_16</th>\n",
       "      <th>RSI_16</th>\n",
       "      <th>close_15</th>\n",
       "      <th>RSI_15</th>\n",
       "      <th>...</th>\n",
       "      <th>RSI_4</th>\n",
       "      <th>close_3</th>\n",
       "      <th>RSI_3</th>\n",
       "      <th>close_2</th>\n",
       "      <th>RSI_2</th>\n",
       "      <th>close_1</th>\n",
       "      <th>RSI_1</th>\n",
       "      <th>close_0</th>\n",
       "      <th>RSI_0</th>\n",
       "      <th>close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>754.99</td>\n",
       "      <td>51.874455</td>\n",
       "      <td>855.28</td>\n",
       "      <td>64.086633</td>\n",
       "      <td>934.03</td>\n",
       "      <td>70.431522</td>\n",
       "      <td>940.00</td>\n",
       "      <td>70.851945</td>\n",
       "      <td>959.30</td>\n",
       "      <td>72.226781</td>\n",
       "      <td>...</td>\n",
       "      <td>48.819684</td>\n",
       "      <td>1000.00</td>\n",
       "      <td>48.819684</td>\n",
       "      <td>994.00</td>\n",
       "      <td>48.493851</td>\n",
       "      <td>1032.50</td>\n",
       "      <td>50.764615</td>\n",
       "      <td>1152.75</td>\n",
       "      <td>57.122992</td>\n",
       "      <td>877.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>855.28</td>\n",
       "      <td>64.086633</td>\n",
       "      <td>934.03</td>\n",
       "      <td>70.431522</td>\n",
       "      <td>940.00</td>\n",
       "      <td>70.851945</td>\n",
       "      <td>959.30</td>\n",
       "      <td>72.226781</td>\n",
       "      <td>1004.11</td>\n",
       "      <td>75.156684</td>\n",
       "      <td>...</td>\n",
       "      <td>48.819684</td>\n",
       "      <td>994.00</td>\n",
       "      <td>48.493851</td>\n",
       "      <td>1032.50</td>\n",
       "      <td>50.764615</td>\n",
       "      <td>1152.75</td>\n",
       "      <td>57.122992</td>\n",
       "      <td>1049.00</td>\n",
       "      <td>51.002981</td>\n",
       "      <td>851.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>934.03</td>\n",
       "      <td>70.431522</td>\n",
       "      <td>940.00</td>\n",
       "      <td>70.851945</td>\n",
       "      <td>959.30</td>\n",
       "      <td>72.226781</td>\n",
       "      <td>1004.11</td>\n",
       "      <td>75.156684</td>\n",
       "      <td>1123.09</td>\n",
       "      <td>80.914056</td>\n",
       "      <td>...</td>\n",
       "      <td>48.493851</td>\n",
       "      <td>1032.50</td>\n",
       "      <td>50.764615</td>\n",
       "      <td>1152.75</td>\n",
       "      <td>57.122992</td>\n",
       "      <td>1049.00</td>\n",
       "      <td>51.002981</td>\n",
       "      <td>993.00</td>\n",
       "      <td>48.012894</td>\n",
       "      <td>808.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>940.00</td>\n",
       "      <td>70.851945</td>\n",
       "      <td>959.30</td>\n",
       "      <td>72.226781</td>\n",
       "      <td>1004.11</td>\n",
       "      <td>75.156684</td>\n",
       "      <td>1123.09</td>\n",
       "      <td>80.914056</td>\n",
       "      <td>1133.18</td>\n",
       "      <td>81.309636</td>\n",
       "      <td>...</td>\n",
       "      <td>50.764615</td>\n",
       "      <td>1152.75</td>\n",
       "      <td>57.122992</td>\n",
       "      <td>1049.00</td>\n",
       "      <td>51.002981</td>\n",
       "      <td>993.00</td>\n",
       "      <td>48.012894</td>\n",
       "      <td>980.00</td>\n",
       "      <td>47.319361</td>\n",
       "      <td>866.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>959.30</td>\n",
       "      <td>72.226781</td>\n",
       "      <td>1004.11</td>\n",
       "      <td>75.156684</td>\n",
       "      <td>1123.09</td>\n",
       "      <td>80.914056</td>\n",
       "      <td>1133.18</td>\n",
       "      <td>81.309636</td>\n",
       "      <td>1291.00</td>\n",
       "      <td>86.146268</td>\n",
       "      <td>...</td>\n",
       "      <td>57.122992</td>\n",
       "      <td>1049.00</td>\n",
       "      <td>51.002981</td>\n",
       "      <td>993.00</td>\n",
       "      <td>48.012894</td>\n",
       "      <td>980.00</td>\n",
       "      <td>47.319361</td>\n",
       "      <td>1061.00</td>\n",
       "      <td>51.974254</td>\n",
       "      <td>841.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1573</th>\n",
       "      <td>4287.80</td>\n",
       "      <td>47.095555</td>\n",
       "      <td>3996.90</td>\n",
       "      <td>39.023233</td>\n",
       "      <td>4294.76</td>\n",
       "      <td>48.716109</td>\n",
       "      <td>4412.17</td>\n",
       "      <td>51.957920</td>\n",
       "      <td>4258.31</td>\n",
       "      <td>47.702403</td>\n",
       "      <td>...</td>\n",
       "      <td>53.835840</td>\n",
       "      <td>4215.73</td>\n",
       "      <td>46.826530</td>\n",
       "      <td>4117.25</td>\n",
       "      <td>44.735958</td>\n",
       "      <td>4196.44</td>\n",
       "      <td>46.793026</td>\n",
       "      <td>4347.59</td>\n",
       "      <td>50.574650</td>\n",
       "      <td>4063.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1574</th>\n",
       "      <td>3996.90</td>\n",
       "      <td>39.023233</td>\n",
       "      <td>4294.76</td>\n",
       "      <td>48.716109</td>\n",
       "      <td>4412.17</td>\n",
       "      <td>51.957920</td>\n",
       "      <td>4258.31</td>\n",
       "      <td>47.702403</td>\n",
       "      <td>4085.97</td>\n",
       "      <td>43.413283</td>\n",
       "      <td>...</td>\n",
       "      <td>46.826530</td>\n",
       "      <td>4117.25</td>\n",
       "      <td>44.735958</td>\n",
       "      <td>4196.44</td>\n",
       "      <td>46.793026</td>\n",
       "      <td>4347.59</td>\n",
       "      <td>50.574650</td>\n",
       "      <td>4306.40</td>\n",
       "      <td>49.541304</td>\n",
       "      <td>4037.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1575</th>\n",
       "      <td>4294.76</td>\n",
       "      <td>48.716109</td>\n",
       "      <td>4412.17</td>\n",
       "      <td>51.957920</td>\n",
       "      <td>4258.31</td>\n",
       "      <td>47.702403</td>\n",
       "      <td>4085.97</td>\n",
       "      <td>43.413283</td>\n",
       "      <td>4339.44</td>\n",
       "      <td>50.467423</td>\n",
       "      <td>...</td>\n",
       "      <td>44.735958</td>\n",
       "      <td>4196.44</td>\n",
       "      <td>46.793026</td>\n",
       "      <td>4347.59</td>\n",
       "      <td>50.574650</td>\n",
       "      <td>4306.40</td>\n",
       "      <td>49.541304</td>\n",
       "      <td>4436.91</td>\n",
       "      <td>52.829940</td>\n",
       "      <td>3792.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1576</th>\n",
       "      <td>4412.17</td>\n",
       "      <td>51.957920</td>\n",
       "      <td>4258.31</td>\n",
       "      <td>47.702403</td>\n",
       "      <td>4085.97</td>\n",
       "      <td>43.413283</td>\n",
       "      <td>4339.44</td>\n",
       "      <td>50.467423</td>\n",
       "      <td>4269.36</td>\n",
       "      <td>48.661227</td>\n",
       "      <td>...</td>\n",
       "      <td>46.793026</td>\n",
       "      <td>4347.59</td>\n",
       "      <td>50.574650</td>\n",
       "      <td>4306.40</td>\n",
       "      <td>49.541304</td>\n",
       "      <td>4436.91</td>\n",
       "      <td>52.829940</td>\n",
       "      <td>4105.64</td>\n",
       "      <td>44.841174</td>\n",
       "      <td>3630.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1577</th>\n",
       "      <td>4258.31</td>\n",
       "      <td>47.702403</td>\n",
       "      <td>4085.97</td>\n",
       "      <td>43.413283</td>\n",
       "      <td>4339.44</td>\n",
       "      <td>50.467423</td>\n",
       "      <td>4269.36</td>\n",
       "      <td>48.661227</td>\n",
       "      <td>4524.85</td>\n",
       "      <td>54.986266</td>\n",
       "      <td>...</td>\n",
       "      <td>50.574650</td>\n",
       "      <td>4306.40</td>\n",
       "      <td>49.541304</td>\n",
       "      <td>4436.91</td>\n",
       "      <td>52.829940</td>\n",
       "      <td>4105.64</td>\n",
       "      <td>44.841174</td>\n",
       "      <td>3897.94</td>\n",
       "      <td>40.686916</td>\n",
       "      <td>3709.27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1421 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      close_19     RSI_19  close_18     RSI_18  close_17     RSI_17  close_16  \\\n",
       "157     754.99  51.874455    855.28  64.086633    934.03  70.431522    940.00   \n",
       "158     855.28  64.086633    934.03  70.431522    940.00  70.851945    959.30   \n",
       "159     934.03  70.431522    940.00  70.851945    959.30  72.226781   1004.11   \n",
       "160     940.00  70.851945    959.30  72.226781   1004.11  75.156684   1123.09   \n",
       "161     959.30  72.226781   1004.11  75.156684   1123.09  80.914056   1133.18   \n",
       "...        ...        ...       ...        ...       ...        ...       ...   \n",
       "1573   4287.80  47.095555   3996.90  39.023233   4294.76  48.716109   4412.17   \n",
       "1574   3996.90  39.023233   4294.76  48.716109   4412.17  51.957920   4258.31   \n",
       "1575   4294.76  48.716109   4412.17  51.957920   4258.31  47.702403   4085.97   \n",
       "1576   4412.17  51.957920   4258.31  47.702403   4085.97  43.413283   4339.44   \n",
       "1577   4258.31  47.702403   4085.97  43.413283   4339.44  50.467423   4269.36   \n",
       "\n",
       "         RSI_16  close_15     RSI_15  ...      RSI_4  close_3      RSI_3  \\\n",
       "157   70.851945    959.30  72.226781  ...  48.819684  1000.00  48.819684   \n",
       "158   72.226781   1004.11  75.156684  ...  48.819684   994.00  48.493851   \n",
       "159   75.156684   1123.09  80.914056  ...  48.493851  1032.50  50.764615   \n",
       "160   80.914056   1133.18  81.309636  ...  50.764615  1152.75  57.122992   \n",
       "161   81.309636   1291.00  86.146268  ...  57.122992  1049.00  51.002981   \n",
       "...         ...       ...        ...  ...        ...      ...        ...   \n",
       "1573  51.957920   4258.31  47.702403  ...  53.835840  4215.73  46.826530   \n",
       "1574  47.702403   4085.97  43.413283  ...  46.826530  4117.25  44.735958   \n",
       "1575  43.413283   4339.44  50.467423  ...  44.735958  4196.44  46.793026   \n",
       "1576  50.467423   4269.36  48.661227  ...  46.793026  4347.59  50.574650   \n",
       "1577  48.661227   4524.85  54.986266  ...  50.574650  4306.40  49.541304   \n",
       "\n",
       "      close_2      RSI_2  close_1      RSI_1  close_0      RSI_0    close  \n",
       "157    994.00  48.493851  1032.50  50.764615  1152.75  57.122992   877.00  \n",
       "158   1032.50  50.764615  1152.75  57.122992  1049.00  51.002981   851.15  \n",
       "159   1152.75  57.122992  1049.00  51.002981   993.00  48.012894   808.99  \n",
       "160   1049.00  51.002981   993.00  48.012894   980.00  47.319361   866.66  \n",
       "161    993.00  48.012894   980.00  47.319361  1061.00  51.974254   841.57  \n",
       "...       ...        ...      ...        ...      ...        ...      ...  \n",
       "1573  4117.25  44.735958  4196.44  46.793026  4347.59  50.574650  4063.56  \n",
       "1574  4196.44  46.793026  4347.59  50.574650  4306.40  49.541304  4037.23  \n",
       "1575  4347.59  50.574650  4306.40  49.541304  4436.91  52.829940  3792.75  \n",
       "1576  4306.40  49.541304  4436.91  52.829940  4105.64  44.841174  3630.19  \n",
       "1577  4436.91  52.829940  4105.64  44.841174  3897.94  40.686916  3709.27  \n",
       "\n",
       "[1421 rows x 41 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>close_19</th>\n",
       "      <th>RSI_19</th>\n",
       "      <th>close_18</th>\n",
       "      <th>RSI_18</th>\n",
       "      <th>close_17</th>\n",
       "      <th>RSI_17</th>\n",
       "      <th>close_16</th>\n",
       "      <th>RSI_16</th>\n",
       "      <th>close_15</th>\n",
       "      <th>RSI_15</th>\n",
       "      <th>...</th>\n",
       "      <th>RSI_4</th>\n",
       "      <th>close_3</th>\n",
       "      <th>RSI_3</th>\n",
       "      <th>close_2</th>\n",
       "      <th>RSI_2</th>\n",
       "      <th>close_1</th>\n",
       "      <th>RSI_1</th>\n",
       "      <th>close_0</th>\n",
       "      <th>RSI_0</th>\n",
       "      <th>close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1578</th>\n",
       "      <td>4085.97</td>\n",
       "      <td>43.413283</td>\n",
       "      <td>4339.44</td>\n",
       "      <td>50.467423</td>\n",
       "      <td>4269.36</td>\n",
       "      <td>48.661227</td>\n",
       "      <td>4524.85</td>\n",
       "      <td>54.986266</td>\n",
       "      <td>4041.2</td>\n",
       "      <td>43.948042</td>\n",
       "      <td>...</td>\n",
       "      <td>49.541304</td>\n",
       "      <td>4436.91</td>\n",
       "      <td>52.82994</td>\n",
       "      <td>4105.64</td>\n",
       "      <td>44.841174</td>\n",
       "      <td>3897.94</td>\n",
       "      <td>40.686916</td>\n",
       "      <td>4089.37</td>\n",
       "      <td>45.681743</td>\n",
       "      <td>3725.46</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      close_19     RSI_19  close_18     RSI_18  close_17     RSI_17  close_16  \\\n",
       "1578   4085.97  43.413283   4339.44  50.467423   4269.36  48.661227   4524.85   \n",
       "\n",
       "         RSI_16  close_15     RSI_15  ...      RSI_4  close_3     RSI_3  \\\n",
       "1578  54.986266    4041.2  43.948042  ...  49.541304  4436.91  52.82994   \n",
       "\n",
       "      close_2      RSI_2  close_1      RSI_1  close_0      RSI_0    close  \n",
       "1578  4105.64  44.841174  3897.94  40.686916  4089.37  45.681743  3725.46  \n",
       "\n",
       "[1 rows x 41 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (1421, 1, 40) (1421, 1)\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_16 (LSTM)               (None, 1, 25)             6600      \n",
      "_________________________________________________________________\n",
      "lstm_17 (LSTM)               (None, 1, 25)             5100      \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 1, 25)             0         \n",
      "_________________________________________________________________\n",
      "lstm_18 (LSTM)               (None, 1, 25)             5100      \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 1, 25)             0         \n",
      "_________________________________________________________________\n",
      "lstm_19 (LSTM)               (None, 1, 25)             5100      \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 1, 25)             0         \n",
      "_________________________________________________________________\n",
      "lstm_20 (LSTM)               (None, 25)                5100      \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 25)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 26        \n",
      "=================================================================\n",
      "Total params: 27,026\n",
      "Trainable params: 27,026\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Y shape (1421, 1)\n",
      "Train on 1421 samples, validate on 285 samples\n",
      "Epoch 1/100\n",
      " - 10s - loss: 2331438.0172 - mse: 2331438.0000 - val_loss: 10515165.6596 - val_mse: 10515166.0000\n",
      "Epoch 2/100\n",
      " - 0s - loss: 2331256.9031 - mse: 2331257.0000 - val_loss: 10514406.8035 - val_mse: 10514407.0000\n",
      "Epoch 3/100\n",
      " - 0s - loss: 2330735.2240 - mse: 2330735.2500 - val_loss: 10511731.7158 - val_mse: 10511732.0000\n",
      "Epoch 4/100\n",
      " - 0s - loss: 2328636.0067 - mse: 2328636.0000 - val_loss: 10501254.8281 - val_mse: 10501254.0000\n",
      "Epoch 5/100\n",
      " - 0s - loss: 2324327.0623 - mse: 2324327.0000 - val_loss: 10486103.2351 - val_mse: 10486103.0000\n",
      "Epoch 6/100\n",
      " - 0s - loss: 2320755.2558 - mse: 2320755.2500 - val_loss: 10476267.0421 - val_mse: 10476267.0000\n",
      "Epoch 7/100\n",
      " - 0s - loss: 2318636.2401 - mse: 2318636.2500 - val_loss: 10470427.8842 - val_mse: 10470428.0000\n",
      "Epoch 8/100\n",
      " - 0s - loss: 2317366.4932 - mse: 2317366.5000 - val_loss: 10466230.8281 - val_mse: 10466230.0000\n",
      "Epoch 9/100\n",
      " - 0s - loss: 2316260.9629 - mse: 2316261.0000 - val_loss: 10462819.0456 - val_mse: 10462819.0000\n",
      "Epoch 10/100\n",
      " - 1s - loss: 2315269.1040 - mse: 2315269.2500 - val_loss: 10459785.3298 - val_mse: 10459785.0000\n",
      "Epoch 11/100\n",
      " - 0s - loss: 2314405.1114 - mse: 2314405.0000 - val_loss: 10457004.7123 - val_mse: 10457004.0000\n",
      "Epoch 12/100\n",
      " - 0s - loss: 2313570.1407 - mse: 2313570.0000 - val_loss: 10454397.2632 - val_mse: 10454398.0000\n",
      "Epoch 13/100\n",
      " - 0s - loss: 2312890.2920 - mse: 2312890.0000 - val_loss: 10451906.3439 - val_mse: 10451905.0000\n",
      "Epoch 14/100\n",
      " - 0s - loss: 2312160.7724 - mse: 2312160.7500 - val_loss: 10449525.8316 - val_mse: 10449527.0000\n",
      "Epoch 15/100\n",
      " - 0s - loss: 2311514.7645 - mse: 2311514.7500 - val_loss: 10447211.7018 - val_mse: 10447211.0000\n",
      "Epoch 16/100\n",
      " - 0s - loss: 2310807.4903 - mse: 2310807.2500 - val_loss: 10444968.0140 - val_mse: 10444969.0000\n",
      "Epoch 17/100\n",
      " - 1s - loss: 2310182.6711 - mse: 2310182.5000 - val_loss: 10442765.3228 - val_mse: 10442765.0000\n",
      "Epoch 18/100\n",
      " - 0s - loss: 2309492.6257 - mse: 2309492.5000 - val_loss: 10440602.2807 - val_mse: 10440603.0000\n",
      "Epoch 19/100\n",
      " - 1s - loss: 2308878.7621 - mse: 2308878.7500 - val_loss: 10438474.8982 - val_mse: 10438475.0000\n",
      "Epoch 20/100\n",
      " - 1s - loss: 2308218.5759 - mse: 2308218.7500 - val_loss: 10436378.4316 - val_mse: 10436378.0000\n",
      "Epoch 21/100\n",
      " - 0s - loss: 2307721.4325 - mse: 2307721.7500 - val_loss: 10434306.1158 - val_mse: 10434307.0000\n",
      "Epoch 22/100\n",
      " - 0s - loss: 2307094.2426 - mse: 2307094.2500 - val_loss: 10432278.4386 - val_mse: 10432278.0000\n",
      "Epoch 23/100\n",
      " - 0s - loss: 2306488.5747 - mse: 2306488.5000 - val_loss: 10430258.6281 - val_mse: 10430258.0000\n",
      "Epoch 24/100\n",
      " - 1s - loss: 2305882.4677 - mse: 2305882.5000 - val_loss: 10428257.2246 - val_mse: 10428258.0000\n",
      "Epoch 25/100\n",
      " - 0s - loss: 2305406.8346 - mse: 2305406.7500 - val_loss: 10426263.8702 - val_mse: 10426264.0000\n",
      "Epoch 26/100\n",
      " - 0s - loss: 2304508.5015 - mse: 2304508.5000 - val_loss: 10424292.3614 - val_mse: 10424292.0000\n",
      "Epoch 27/100\n",
      " - 0s - loss: 2304210.2074 - mse: 2304210.2500 - val_loss: 10422327.9228 - val_mse: 10422329.0000\n",
      "Epoch 28/100\n",
      " - 0s - loss: 2303571.7695 - mse: 2303571.7500 - val_loss: 10420385.9018 - val_mse: 10420386.0000\n",
      "Epoch 29/100\n",
      " - 0s - loss: 2302911.8651 - mse: 2302911.7500 - val_loss: 10418439.6351 - val_mse: 10418440.0000\n",
      "Epoch 30/100\n",
      " - 0s - loss: 2302221.6944 - mse: 2302221.7500 - val_loss: 10416508.2246 - val_mse: 10416508.0000\n",
      "Epoch 31/100\n",
      " - 0s - loss: 2301830.4729 - mse: 2301830.5000 - val_loss: 10414581.4667 - val_mse: 10414582.0000\n",
      "Epoch 32/100\n",
      " - 0s - loss: 2301430.9701 - mse: 2301431.0000 - val_loss: 10412670.3298 - val_mse: 10412670.0000\n",
      "Epoch 33/100\n",
      " - 0s - loss: 2300682.9425 - mse: 2300683.0000 - val_loss: 10410768.4982 - val_mse: 10410769.0000\n",
      "Epoch 34/100\n",
      " - 0s - loss: 2300013.7502 - mse: 2300014.0000 - val_loss: 10408874.9825 - val_mse: 10408876.0000\n",
      "Epoch 35/100\n",
      " - 0s - loss: 2299747.6838 - mse: 2299747.7500 - val_loss: 10406979.8947 - val_mse: 10406980.0000\n",
      "Epoch 36/100\n",
      " - 0s - loss: 2298956.5474 - mse: 2298956.5000 - val_loss: 10405100.0000 - val_mse: 10405099.0000\n",
      "Epoch 37/100\n",
      " - 0s - loss: 2298590.4668 - mse: 2298590.2500 - val_loss: 10403217.8807 - val_mse: 10403218.0000\n",
      "Epoch 38/100\n",
      " - 0s - loss: 2297988.4332 - mse: 2297988.5000 - val_loss: 10401353.3825 - val_mse: 10401354.0000\n",
      "Epoch 39/100\n",
      " - 0s - loss: 2297370.0214 - mse: 2297370.0000 - val_loss: 10399495.8632 - val_mse: 10399496.0000\n",
      "Epoch 40/100\n",
      " - 0s - loss: 2296767.4768 - mse: 2296767.5000 - val_loss: 10397629.0491 - val_mse: 10397630.0000\n",
      "Epoch 41/100\n",
      " - 0s - loss: 2296309.8023 - mse: 2296309.7500 - val_loss: 10395764.8772 - val_mse: 10395765.0000\n",
      "Epoch 42/100\n",
      " - 0s - loss: 2295914.5245 - mse: 2295914.5000 - val_loss: 10393920.9895 - val_mse: 10393921.0000\n",
      "Epoch 43/100\n",
      " - 0s - loss: 2295118.7588 - mse: 2295118.7500 - val_loss: 10392073.8772 - val_mse: 10392074.0000\n",
      "Epoch 44/100\n",
      " - 1s - loss: 2294741.6600 - mse: 2294741.5000 - val_loss: 10390227.5404 - val_mse: 10390227.0000\n",
      "Epoch 45/100\n",
      " - 1s - loss: 2294226.3585 - mse: 2294226.2500 - val_loss: 10388389.8561 - val_mse: 10388390.0000\n",
      "Epoch 46/100\n",
      " - 1s - loss: 2293748.5838 - mse: 2293748.5000 - val_loss: 10386556.4982 - val_mse: 10386556.0000\n",
      "Epoch 47/100\n",
      " - 0s - loss: 2292941.7496 - mse: 2292941.7500 - val_loss: 10384727.3333 - val_mse: 10384727.0000\n",
      "Epoch 48/100\n",
      " - 0s - loss: 2292340.6649 - mse: 2292340.7500 - val_loss: 10382901.0351 - val_mse: 10382900.0000\n",
      "Epoch 49/100\n",
      " - 0s - loss: 2291933.8484 - mse: 2291934.0000 - val_loss: 10381068.3509 - val_mse: 10381069.0000\n",
      "Epoch 50/100\n",
      " - 1s - loss: 2291445.0162 - mse: 2291445.0000 - val_loss: 10379246.6035 - val_mse: 10379246.0000\n",
      "Epoch 51/100\n",
      " - 1s - loss: 2290876.2854 - mse: 2290876.2500 - val_loss: 10377427.7544 - val_mse: 10377428.0000\n",
      "Epoch 52/100\n",
      " - 0s - loss: 2290580.3879 - mse: 2290580.2500 - val_loss: 10375618.7614 - val_mse: 10375619.0000\n",
      "Epoch 53/100\n",
      " - 1s - loss: 2289862.8013 - mse: 2289862.7500 - val_loss: 10373807.3193 - val_mse: 10373807.0000\n",
      "Epoch 54/100\n",
      " - 0s - loss: 2289314.2501 - mse: 2289314.2500 - val_loss: 10371989.5719 - val_mse: 10371990.0000\n",
      "Epoch 55/100\n",
      " - 0s - loss: 2288992.3058 - mse: 2288992.5000 - val_loss: 10370181.8035 - val_mse: 10370181.0000\n",
      "Epoch 56/100\n",
      " - 0s - loss: 2288013.0817 - mse: 2288013.0000 - val_loss: 10368373.6772 - val_mse: 10368374.0000\n",
      "Epoch 57/100\n",
      " - 0s - loss: 2287439.9912 - mse: 2287440.0000 - val_loss: 10366561.3684 - val_mse: 10366561.0000\n",
      "Epoch 58/100\n",
      " - 0s - loss: 2287205.5927 - mse: 2287205.5000 - val_loss: 10364749.0491 - val_mse: 10364750.0000\n",
      "Epoch 59/100\n",
      " - 0s - loss: 2286245.4481 - mse: 2286245.5000 - val_loss: 10362948.5860 - val_mse: 10362948.0000\n",
      "Epoch 60/100\n",
      " - 0s - loss: 2285838.4109 - mse: 2285838.5000 - val_loss: 10361133.1649 - val_mse: 10361133.0000\n",
      "Epoch 61/100\n",
      " - 0s - loss: 2285731.3678 - mse: 2285731.5000 - val_loss: 10359326.0596 - val_mse: 10359327.0000\n",
      "Epoch 62/100\n",
      " - 0s - loss: 2285236.9350 - mse: 2285237.0000 - val_loss: 10357536.6772 - val_mse: 10357536.0000\n",
      "Epoch 63/100\n",
      " - 1s - loss: 2284772.8723 - mse: 2284772.7500 - val_loss: 10355759.0491 - val_mse: 10355759.0000\n",
      "Epoch 64/100\n",
      " - 1s - loss: 2283851.6314 - mse: 2283851.7500 - val_loss: 10353967.3193 - val_mse: 10353968.0000\n",
      "Epoch 65/100\n",
      " - 0s - loss: 2283391.3397 - mse: 2283391.2500 - val_loss: 10352181.9263 - val_mse: 10352182.0000\n",
      "Epoch 66/100\n",
      " - 0s - loss: 2283319.9682 - mse: 2283320.0000 - val_loss: 10350399.8491 - val_mse: 10350400.0000\n",
      "Epoch 67/100\n",
      " - 0s - loss: 2282552.8263 - mse: 2282553.0000 - val_loss: 10348625.8737 - val_mse: 10348627.0000\n",
      "Epoch 68/100\n",
      " - 0s - loss: 2281792.8238 - mse: 2281792.7500 - val_loss: 10346840.9193 - val_mse: 10346841.0000\n",
      "Epoch 69/100\n",
      " - 0s - loss: 2281200.8876 - mse: 2281200.7500 - val_loss: 10345054.7509 - val_mse: 10345055.0000\n",
      "Epoch 70/100\n",
      " - 0s - loss: 2280694.7013 - mse: 2280694.7500 - val_loss: 10343263.8175 - val_mse: 10343264.0000\n",
      "Epoch 71/100\n",
      " - 0s - loss: 2280450.4320 - mse: 2280450.2500 - val_loss: 10341479.6386 - val_mse: 10341479.0000\n",
      "Epoch 72/100\n",
      " - 0s - loss: 2280220.7248 - mse: 2280220.7500 - val_loss: 10339709.3158 - val_mse: 10339710.0000\n",
      "Epoch 73/100\n",
      " - 0s - loss: 2279501.1531 - mse: 2279501.0000 - val_loss: 10337944.7368 - val_mse: 10337945.0000\n",
      "Epoch 74/100\n",
      " - 0s - loss: 2279091.7032 - mse: 2279091.5000 - val_loss: 10336178.8526 - val_mse: 10336179.0000\n",
      "Epoch 75/100\n",
      " - 0s - loss: 2278330.3480 - mse: 2278330.2500 - val_loss: 10334413.6211 - val_mse: 10334414.0000\n",
      "Epoch 76/100\n",
      " - 0s - loss: 2277646.1040 - mse: 2277646.2500 - val_loss: 10332648.1754 - val_mse: 10332649.0000\n",
      "Epoch 77/100\n",
      " - 0s - loss: 2277581.7318 - mse: 2277581.7500 - val_loss: 10330872.4140 - val_mse: 10330872.0000\n",
      "Epoch 78/100\n",
      " - 0s - loss: 2276303.8858 - mse: 2276304.0000 - val_loss: 10329115.0596 - val_mse: 10329115.0000\n",
      "Epoch 79/100\n",
      " - 0s - loss: 2276104.2200 - mse: 2276104.0000 - val_loss: 10327344.0526 - val_mse: 10327344.0000\n",
      "Epoch 80/100\n",
      " - 1s - loss: 2275386.3319 - mse: 2275386.2500 - val_loss: 10325571.6281 - val_mse: 10325571.0000\n",
      "Epoch 81/100\n",
      " - 0s - loss: 2275197.2799 - mse: 2275197.5000 - val_loss: 10323805.8561 - val_mse: 10323806.0000\n",
      "Epoch 82/100\n",
      " - 0s - loss: 2274643.0980 - mse: 2274643.2500 - val_loss: 10322034.0947 - val_mse: 10322034.0000\n",
      "Epoch 83/100\n",
      " - 0s - loss: 2274148.4814 - mse: 2274148.5000 - val_loss: 10320272.3018 - val_mse: 10320273.0000\n",
      "Epoch 84/100\n",
      " - 0s - loss: 2273846.7538 - mse: 2273846.7500 - val_loss: 10318522.2526 - val_mse: 10318522.0000\n",
      "Epoch 85/100\n",
      " - 0s - loss: 2273212.3570 - mse: 2273212.2500 - val_loss: 10316760.3368 - val_mse: 10316760.0000\n",
      "Epoch 86/100\n",
      " - 0s - loss: 2272777.4751 - mse: 2272777.2500 - val_loss: 10315005.8702 - val_mse: 10315006.0000\n",
      "Epoch 87/100\n",
      " - 0s - loss: 2272086.6616 - mse: 2272086.7500 - val_loss: 10313261.4632 - val_mse: 10313262.0000\n",
      "Epoch 88/100\n",
      " - 0s - loss: 2271719.0299 - mse: 2271719.0000 - val_loss: 10311503.9860 - val_mse: 10311504.0000\n",
      "Epoch 89/100\n",
      " - 0s - loss: 2270982.1966 - mse: 2270982.2500 - val_loss: 10309749.7439 - val_mse: 10309750.0000\n",
      "Epoch 90/100\n",
      " - 0s - loss: 2270465.5155 - mse: 2270465.5000 - val_loss: 10307997.3684 - val_mse: 10307997.0000\n",
      "Epoch 91/100\n",
      " - 0s - loss: 2270037.5931 - mse: 2270037.5000 - val_loss: 10306244.7789 - val_mse: 10306245.0000\n",
      "Epoch 92/100\n",
      " - 0s - loss: 2269659.0717 - mse: 2269659.0000 - val_loss: 10304486.9754 - val_mse: 10304488.0000\n",
      "Epoch 93/100\n",
      " - 0s - loss: 2269308.2671 - mse: 2269308.5000 - val_loss: 10302737.2632 - val_mse: 10302737.0000\n",
      "Epoch 94/100\n",
      " - 0s - loss: 2268073.9099 - mse: 2268074.0000 - val_loss: 10300992.5298 - val_mse: 10300993.0000\n",
      "Epoch 95/100\n",
      " - 0s - loss: 2268344.9835 - mse: 2268344.7500 - val_loss: 10299239.2772 - val_mse: 10299239.0000\n",
      "Epoch 96/100\n",
      " - 0s - loss: 2267466.2272 - mse: 2267466.2500 - val_loss: 10297505.1860 - val_mse: 10297506.0000\n",
      "Epoch 97/100\n",
      " - 0s - loss: 2266688.6071 - mse: 2266688.7500 - val_loss: 10295754.4737 - val_mse: 10295754.0000\n",
      "Epoch 98/100\n",
      " - 0s - loss: 2266944.0867 - mse: 2266944.2500 - val_loss: 10294008.6386 - val_mse: 10294008.0000\n",
      "Epoch 99/100\n",
      " - 0s - loss: 2266442.0055 - mse: 2266442.0000 - val_loss: 10292280.1895 - val_mse: 10292280.0000\n",
      "Epoch 100/100\n",
      " - 0s - loss: 2265597.7903 - mse: 2265597.7500 - val_loss: 10290550.6386 - val_mse: 10290551.0000\n",
      "real [[3725.46]]\n",
      "Test RMSE: 3689.234\n",
      "Diff [[3689.23364349]]\n",
      "% Diff [[99.02760044]] %\n",
      "Predictions [[36.22635651]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "norm_strat = 4\n",
    "print('Normalizacion:', norm_strat)\n",
    "execute_test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mejor metodo de normalizacion es el 2\n",
    "\n",
    "Nos centramos ahora en la seleccion de columnas. Queremos la mayor información posible. Ahora en vez de selccionar solo una columna como target, seleccionaremos varias para proveer a nuestro futuro bucle de prediccion e inversion de mas información.\n",
    "\n",
    "Para esto, lo mejor será tener la información del precio (suavizada o sin suavizar con SMA o EMA) y algun indicador del momento como RSI, ADX o SO."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Multiples features\n",
    "\n",
    "Usaremos multiples características como objetivos de predicción. De esta manera nuestro modelo final proveera mayor información.\n",
    "\n",
    "Usaremos indicadores ya normalizados entre ciertos valores como RSI, ADX y SO. Entre estos tres ADX suele tener mejores capacidades a la hora de indicar la fuerza de la tendencia. Utilizaremos ADX combinado con algun valor del precio:\n",
    "- close\n",
    "- SMA\n",
    "- EMA\n",
    "\n",
    "Esta vez cambiaremos entre disferentes monedas para dar más validez al resultado final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cryptos = ['ETH', 'ADA', 'BTC', 'LNK', 'LTC']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_2 = ['ADX', 'close']\n",
    "columns_3 = ['ADX', 'EMA_50']\n",
    "columns_4 = ['ADX', 'SMA 50']\n",
    "columns_5 = ['ADX', 'EMA_200']\n",
    "columns_6 = ['ADX', 'SMA 200']\n",
    "\n",
    "target = 'close'\n",
    "norm_strat = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading... ETH\n",
      "Extracting columns columns for ETH\n",
      "Proccessing and arranging columns for LSTM model\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>close_19</th>\n",
       "      <th>ADX_19</th>\n",
       "      <th>close_18</th>\n",
       "      <th>ADX_18</th>\n",
       "      <th>close_17</th>\n",
       "      <th>ADX_17</th>\n",
       "      <th>close_16</th>\n",
       "      <th>ADX_16</th>\n",
       "      <th>close_15</th>\n",
       "      <th>ADX_15</th>\n",
       "      <th>...</th>\n",
       "      <th>ADX_4</th>\n",
       "      <th>close_3</th>\n",
       "      <th>ADX_3</th>\n",
       "      <th>close_2</th>\n",
       "      <th>ADX_2</th>\n",
       "      <th>close_1</th>\n",
       "      <th>ADX_1</th>\n",
       "      <th>close_0</th>\n",
       "      <th>ADX_0</th>\n",
       "      <th>close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>754.99</td>\n",
       "      <td>41.418230</td>\n",
       "      <td>855.28</td>\n",
       "      <td>36.212628</td>\n",
       "      <td>934.03</td>\n",
       "      <td>24.312204</td>\n",
       "      <td>940.00</td>\n",
       "      <td>21.025032</td>\n",
       "      <td>959.30</td>\n",
       "      <td>21.223914</td>\n",
       "      <td>...</td>\n",
       "      <td>28.656861</td>\n",
       "      <td>1000.00</td>\n",
       "      <td>27.861915</td>\n",
       "      <td>994.00</td>\n",
       "      <td>27.314258</td>\n",
       "      <td>1032.50</td>\n",
       "      <td>26.829022</td>\n",
       "      <td>1152.75</td>\n",
       "      <td>26.295579</td>\n",
       "      <td>877.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>855.28</td>\n",
       "      <td>36.212628</td>\n",
       "      <td>934.03</td>\n",
       "      <td>24.312204</td>\n",
       "      <td>940.00</td>\n",
       "      <td>21.025032</td>\n",
       "      <td>959.30</td>\n",
       "      <td>21.223914</td>\n",
       "      <td>1004.11</td>\n",
       "      <td>22.305116</td>\n",
       "      <td>...</td>\n",
       "      <td>27.861915</td>\n",
       "      <td>994.00</td>\n",
       "      <td>27.314258</td>\n",
       "      <td>1032.50</td>\n",
       "      <td>26.829022</td>\n",
       "      <td>1152.75</td>\n",
       "      <td>26.295579</td>\n",
       "      <td>1049.00</td>\n",
       "      <td>25.001883</td>\n",
       "      <td>851.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>934.03</td>\n",
       "      <td>24.312204</td>\n",
       "      <td>940.00</td>\n",
       "      <td>21.025032</td>\n",
       "      <td>959.30</td>\n",
       "      <td>21.223914</td>\n",
       "      <td>1004.11</td>\n",
       "      <td>22.305116</td>\n",
       "      <td>1123.09</td>\n",
       "      <td>23.246794</td>\n",
       "      <td>...</td>\n",
       "      <td>27.314258</td>\n",
       "      <td>1032.50</td>\n",
       "      <td>26.829022</td>\n",
       "      <td>1152.75</td>\n",
       "      <td>26.295579</td>\n",
       "      <td>1049.00</td>\n",
       "      <td>25.001883</td>\n",
       "      <td>993.00</td>\n",
       "      <td>24.131656</td>\n",
       "      <td>808.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>940.00</td>\n",
       "      <td>21.025032</td>\n",
       "      <td>959.30</td>\n",
       "      <td>21.223914</td>\n",
       "      <td>1004.11</td>\n",
       "      <td>22.305116</td>\n",
       "      <td>1123.09</td>\n",
       "      <td>23.246794</td>\n",
       "      <td>1133.18</td>\n",
       "      <td>25.900560</td>\n",
       "      <td>...</td>\n",
       "      <td>26.829022</td>\n",
       "      <td>1152.75</td>\n",
       "      <td>26.295579</td>\n",
       "      <td>1049.00</td>\n",
       "      <td>25.001883</td>\n",
       "      <td>993.00</td>\n",
       "      <td>24.131656</td>\n",
       "      <td>980.00</td>\n",
       "      <td>23.956457</td>\n",
       "      <td>866.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>959.30</td>\n",
       "      <td>21.223914</td>\n",
       "      <td>1004.11</td>\n",
       "      <td>22.305116</td>\n",
       "      <td>1123.09</td>\n",
       "      <td>23.246794</td>\n",
       "      <td>1133.18</td>\n",
       "      <td>25.900560</td>\n",
       "      <td>1291.00</td>\n",
       "      <td>26.950869</td>\n",
       "      <td>...</td>\n",
       "      <td>26.295579</td>\n",
       "      <td>1049.00</td>\n",
       "      <td>25.001883</td>\n",
       "      <td>993.00</td>\n",
       "      <td>24.131656</td>\n",
       "      <td>980.00</td>\n",
       "      <td>23.956457</td>\n",
       "      <td>1061.00</td>\n",
       "      <td>23.763680</td>\n",
       "      <td>841.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1573</th>\n",
       "      <td>4287.80</td>\n",
       "      <td>19.071649</td>\n",
       "      <td>3996.90</td>\n",
       "      <td>19.441324</td>\n",
       "      <td>4294.76</td>\n",
       "      <td>19.895549</td>\n",
       "      <td>4412.17</td>\n",
       "      <td>20.260773</td>\n",
       "      <td>4258.31</td>\n",
       "      <td>19.858133</td>\n",
       "      <td>...</td>\n",
       "      <td>17.630929</td>\n",
       "      <td>4215.73</td>\n",
       "      <td>16.807307</td>\n",
       "      <td>4117.25</td>\n",
       "      <td>16.765313</td>\n",
       "      <td>4196.44</td>\n",
       "      <td>17.981035</td>\n",
       "      <td>4347.59</td>\n",
       "      <td>19.049911</td>\n",
       "      <td>4063.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1574</th>\n",
       "      <td>3996.90</td>\n",
       "      <td>19.441324</td>\n",
       "      <td>4294.76</td>\n",
       "      <td>19.895549</td>\n",
       "      <td>4412.17</td>\n",
       "      <td>20.260773</td>\n",
       "      <td>4258.31</td>\n",
       "      <td>19.858133</td>\n",
       "      <td>4085.97</td>\n",
       "      <td>19.464946</td>\n",
       "      <td>...</td>\n",
       "      <td>16.807307</td>\n",
       "      <td>4117.25</td>\n",
       "      <td>16.765313</td>\n",
       "      <td>4196.44</td>\n",
       "      <td>17.981035</td>\n",
       "      <td>4347.59</td>\n",
       "      <td>19.049911</td>\n",
       "      <td>4306.40</td>\n",
       "      <td>19.747824</td>\n",
       "      <td>4037.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1575</th>\n",
       "      <td>4294.76</td>\n",
       "      <td>19.895549</td>\n",
       "      <td>4412.17</td>\n",
       "      <td>20.260773</td>\n",
       "      <td>4258.31</td>\n",
       "      <td>19.858133</td>\n",
       "      <td>4085.97</td>\n",
       "      <td>19.464946</td>\n",
       "      <td>4339.44</td>\n",
       "      <td>19.925177</td>\n",
       "      <td>...</td>\n",
       "      <td>16.765313</td>\n",
       "      <td>4196.44</td>\n",
       "      <td>17.981035</td>\n",
       "      <td>4347.59</td>\n",
       "      <td>19.049911</td>\n",
       "      <td>4306.40</td>\n",
       "      <td>19.747824</td>\n",
       "      <td>4436.91</td>\n",
       "      <td>20.202159</td>\n",
       "      <td>3792.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1576</th>\n",
       "      <td>4412.17</td>\n",
       "      <td>20.260773</td>\n",
       "      <td>4258.31</td>\n",
       "      <td>19.858133</td>\n",
       "      <td>4085.97</td>\n",
       "      <td>19.464946</td>\n",
       "      <td>4339.44</td>\n",
       "      <td>19.925177</td>\n",
       "      <td>4269.36</td>\n",
       "      <td>19.969782</td>\n",
       "      <td>...</td>\n",
       "      <td>17.981035</td>\n",
       "      <td>4347.59</td>\n",
       "      <td>19.049911</td>\n",
       "      <td>4306.40</td>\n",
       "      <td>19.747824</td>\n",
       "      <td>4436.91</td>\n",
       "      <td>20.202159</td>\n",
       "      <td>4105.64</td>\n",
       "      <td>20.614088</td>\n",
       "      <td>3630.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1577</th>\n",
       "      <td>4258.31</td>\n",
       "      <td>19.858133</td>\n",
       "      <td>4085.97</td>\n",
       "      <td>19.464946</td>\n",
       "      <td>4339.44</td>\n",
       "      <td>19.925177</td>\n",
       "      <td>4269.36</td>\n",
       "      <td>19.969782</td>\n",
       "      <td>4524.85</td>\n",
       "      <td>19.934622</td>\n",
       "      <td>...</td>\n",
       "      <td>19.049911</td>\n",
       "      <td>4306.40</td>\n",
       "      <td>19.747824</td>\n",
       "      <td>4436.91</td>\n",
       "      <td>20.202159</td>\n",
       "      <td>4105.64</td>\n",
       "      <td>20.614088</td>\n",
       "      <td>3897.94</td>\n",
       "      <td>21.222026</td>\n",
       "      <td>3709.27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1421 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      close_19     ADX_19  close_18     ADX_18  close_17     ADX_17  close_16  \\\n",
       "157     754.99  41.418230    855.28  36.212628    934.03  24.312204    940.00   \n",
       "158     855.28  36.212628    934.03  24.312204    940.00  21.025032    959.30   \n",
       "159     934.03  24.312204    940.00  21.025032    959.30  21.223914   1004.11   \n",
       "160     940.00  21.025032    959.30  21.223914   1004.11  22.305116   1123.09   \n",
       "161     959.30  21.223914   1004.11  22.305116   1123.09  23.246794   1133.18   \n",
       "...        ...        ...       ...        ...       ...        ...       ...   \n",
       "1573   4287.80  19.071649   3996.90  19.441324   4294.76  19.895549   4412.17   \n",
       "1574   3996.90  19.441324   4294.76  19.895549   4412.17  20.260773   4258.31   \n",
       "1575   4294.76  19.895549   4412.17  20.260773   4258.31  19.858133   4085.97   \n",
       "1576   4412.17  20.260773   4258.31  19.858133   4085.97  19.464946   4339.44   \n",
       "1577   4258.31  19.858133   4085.97  19.464946   4339.44  19.925177   4269.36   \n",
       "\n",
       "         ADX_16  close_15     ADX_15  ...      ADX_4  close_3      ADX_3  \\\n",
       "157   21.025032    959.30  21.223914  ...  28.656861  1000.00  27.861915   \n",
       "158   21.223914   1004.11  22.305116  ...  27.861915   994.00  27.314258   \n",
       "159   22.305116   1123.09  23.246794  ...  27.314258  1032.50  26.829022   \n",
       "160   23.246794   1133.18  25.900560  ...  26.829022  1152.75  26.295579   \n",
       "161   25.900560   1291.00  26.950869  ...  26.295579  1049.00  25.001883   \n",
       "...         ...       ...        ...  ...        ...      ...        ...   \n",
       "1573  20.260773   4258.31  19.858133  ...  17.630929  4215.73  16.807307   \n",
       "1574  19.858133   4085.97  19.464946  ...  16.807307  4117.25  16.765313   \n",
       "1575  19.464946   4339.44  19.925177  ...  16.765313  4196.44  17.981035   \n",
       "1576  19.925177   4269.36  19.969782  ...  17.981035  4347.59  19.049911   \n",
       "1577  19.969782   4524.85  19.934622  ...  19.049911  4306.40  19.747824   \n",
       "\n",
       "      close_2      ADX_2  close_1      ADX_1  close_0      ADX_0    close  \n",
       "157    994.00  27.314258  1032.50  26.829022  1152.75  26.295579   877.00  \n",
       "158   1032.50  26.829022  1152.75  26.295579  1049.00  25.001883   851.15  \n",
       "159   1152.75  26.295579  1049.00  25.001883   993.00  24.131656   808.99  \n",
       "160   1049.00  25.001883   993.00  24.131656   980.00  23.956457   866.66  \n",
       "161    993.00  24.131656   980.00  23.956457  1061.00  23.763680   841.57  \n",
       "...       ...        ...      ...        ...      ...        ...      ...  \n",
       "1573  4117.25  16.765313  4196.44  17.981035  4347.59  19.049911  4063.56  \n",
       "1574  4196.44  17.981035  4347.59  19.049911  4306.40  19.747824  4037.23  \n",
       "1575  4347.59  19.049911  4306.40  19.747824  4436.91  20.202159  3792.75  \n",
       "1576  4306.40  19.747824  4436.91  20.202159  4105.64  20.614088  3630.19  \n",
       "1577  4436.91  20.202159  4105.64  20.614088  3897.94  21.222026  3709.27  \n",
       "\n",
       "[1421 rows x 41 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>close_19</th>\n",
       "      <th>ADX_19</th>\n",
       "      <th>close_18</th>\n",
       "      <th>ADX_18</th>\n",
       "      <th>close_17</th>\n",
       "      <th>ADX_17</th>\n",
       "      <th>close_16</th>\n",
       "      <th>ADX_16</th>\n",
       "      <th>close_15</th>\n",
       "      <th>ADX_15</th>\n",
       "      <th>...</th>\n",
       "      <th>ADX_4</th>\n",
       "      <th>close_3</th>\n",
       "      <th>ADX_3</th>\n",
       "      <th>close_2</th>\n",
       "      <th>ADX_2</th>\n",
       "      <th>close_1</th>\n",
       "      <th>ADX_1</th>\n",
       "      <th>close_0</th>\n",
       "      <th>ADX_0</th>\n",
       "      <th>close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1578</th>\n",
       "      <td>4085.97</td>\n",
       "      <td>19.464946</td>\n",
       "      <td>4339.44</td>\n",
       "      <td>19.925177</td>\n",
       "      <td>4269.36</td>\n",
       "      <td>19.969782</td>\n",
       "      <td>4524.85</td>\n",
       "      <td>19.934622</td>\n",
       "      <td>4041.2</td>\n",
       "      <td>19.004087</td>\n",
       "      <td>...</td>\n",
       "      <td>19.747824</td>\n",
       "      <td>4436.91</td>\n",
       "      <td>20.202159</td>\n",
       "      <td>4105.64</td>\n",
       "      <td>20.614088</td>\n",
       "      <td>3897.94</td>\n",
       "      <td>21.222026</td>\n",
       "      <td>4089.37</td>\n",
       "      <td>22.210426</td>\n",
       "      <td>3725.46</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      close_19     ADX_19  close_18     ADX_18  close_17     ADX_17  close_16  \\\n",
       "1578   4085.97  19.464946   4339.44  19.925177   4269.36  19.969782   4524.85   \n",
       "\n",
       "         ADX_16  close_15     ADX_15  ...      ADX_4  close_3      ADX_3  \\\n",
       "1578  19.934622    4041.2  19.004087  ...  19.747824  4436.91  20.202159   \n",
       "\n",
       "      close_2      ADX_2  close_1      ADX_1  close_0      ADX_0    close  \n",
       "1578  4105.64  20.614088  3897.94  21.222026  4089.37  22.210426  3725.46  \n",
       "\n",
       "[1 rows x 41 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (1421, 1, 40) (1421, 1)\n",
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_41 (LSTM)               (None, 1, 25)             6600      \n",
      "_________________________________________________________________\n",
      "lstm_42 (LSTM)               (None, 1, 25)             5100      \n",
      "_________________________________________________________________\n",
      "dropout_33 (Dropout)         (None, 1, 25)             0         \n",
      "_________________________________________________________________\n",
      "lstm_43 (LSTM)               (None, 1, 25)             5100      \n",
      "_________________________________________________________________\n",
      "dropout_34 (Dropout)         (None, 1, 25)             0         \n",
      "_________________________________________________________________\n",
      "lstm_44 (LSTM)               (None, 1, 25)             5100      \n",
      "_________________________________________________________________\n",
      "dropout_35 (Dropout)         (None, 1, 25)             0         \n",
      "_________________________________________________________________\n",
      "lstm_45 (LSTM)               (None, 25)                5100      \n",
      "_________________________________________________________________\n",
      "dropout_36 (Dropout)         (None, 25)                0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1)                 26        \n",
      "=================================================================\n",
      "Total params: 27,026\n",
      "Trainable params: 27,026\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Y shape (1421, 1)\n",
      "Train on 1421 samples, validate on 285 samples\n",
      "Epoch 1/100\n",
      " - 11s - loss: 0.0875 - mse: 0.0875 - val_loss: 0.3925 - val_mse: 0.3925\n",
      "Epoch 2/100\n",
      " - 0s - loss: 0.0757 - mse: 0.0757 - val_loss: 0.3405 - val_mse: 0.3405\n",
      "Epoch 3/100\n",
      " - 0s - loss: 0.0666 - mse: 0.0666 - val_loss: 0.2840 - val_mse: 0.2840\n",
      "Epoch 4/100\n",
      " - 0s - loss: 0.0599 - mse: 0.0599 - val_loss: 0.2167 - val_mse: 0.2167\n",
      "Epoch 5/100\n",
      " - 0s - loss: 0.0466 - mse: 0.0466 - val_loss: 0.1168 - val_mse: 0.1168\n",
      "Epoch 6/100\n",
      " - 0s - loss: 0.0227 - mse: 0.0227 - val_loss: 0.0222 - val_mse: 0.0222\n",
      "Epoch 7/100\n",
      " - 0s - loss: 0.0151 - mse: 0.0151 - val_loss: 0.0164 - val_mse: 0.0164\n",
      "Epoch 8/100\n",
      " - 0s - loss: 0.0165 - mse: 0.0165 - val_loss: 0.0246 - val_mse: 0.0246\n",
      "Epoch 9/100\n",
      " - 0s - loss: 0.0163 - mse: 0.0163 - val_loss: 0.0156 - val_mse: 0.0156\n",
      "Epoch 10/100\n",
      " - 0s - loss: 0.0233 - mse: 0.0233 - val_loss: 0.0551 - val_mse: 0.0551\n",
      "Epoch 11/100\n",
      " - 1s - loss: 0.0108 - mse: 0.0108 - val_loss: 0.0161 - val_mse: 0.0161\n",
      "Epoch 12/100\n",
      " - 1s - loss: 0.0103 - mse: 0.0103 - val_loss: 0.0182 - val_mse: 0.0182\n",
      "Epoch 13/100\n",
      " - 0s - loss: 0.0101 - mse: 0.0101 - val_loss: 0.0150 - val_mse: 0.0150\n",
      "Epoch 14/100\n",
      " - 1s - loss: 0.0100 - mse: 0.0100 - val_loss: 0.0152 - val_mse: 0.0152\n",
      "Epoch 15/100\n",
      " - 1s - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0138 - val_mse: 0.0138\n",
      "Epoch 16/100\n",
      " - 0s - loss: 0.0091 - mse: 0.0091 - val_loss: 0.0143 - val_mse: 0.0143\n",
      "Epoch 17/100\n",
      " - 0s - loss: 0.0089 - mse: 0.0089 - val_loss: 0.0135 - val_mse: 0.0135\n",
      "Epoch 18/100\n",
      " - 1s - loss: 0.0092 - mse: 0.0092 - val_loss: 0.0141 - val_mse: 0.0141\n",
      "Epoch 19/100\n",
      " - 1s - loss: 0.0093 - mse: 0.0093 - val_loss: 0.0135 - val_mse: 0.0135\n",
      "Epoch 20/100\n",
      " - 0s - loss: 0.0093 - mse: 0.0093 - val_loss: 0.0134 - val_mse: 0.0134\n",
      "Epoch 21/100\n",
      " - 0s - loss: 0.0091 - mse: 0.0091 - val_loss: 0.0132 - val_mse: 0.0132\n",
      "Epoch 22/100\n",
      " - 0s - loss: 0.0083 - mse: 0.0083 - val_loss: 0.0127 - val_mse: 0.0127\n",
      "Epoch 23/100\n",
      " - 0s - loss: 0.0086 - mse: 0.0086 - val_loss: 0.0130 - val_mse: 0.0130\n",
      "Epoch 24/100\n",
      " - 0s - loss: 0.0080 - mse: 0.0080 - val_loss: 0.0123 - val_mse: 0.0123\n",
      "Epoch 25/100\n",
      " - 0s - loss: 0.0087 - mse: 0.0087 - val_loss: 0.0120 - val_mse: 0.0120\n",
      "Epoch 26/100\n",
      " - 0s - loss: 0.0083 - mse: 0.0083 - val_loss: 0.0120 - val_mse: 0.0120\n",
      "Epoch 27/100\n",
      " - 1s - loss: 0.0071 - mse: 0.0071 - val_loss: 0.0120 - val_mse: 0.0120\n",
      "Epoch 28/100\n",
      " - 1s - loss: 0.0086 - mse: 0.0086 - val_loss: 0.0113 - val_mse: 0.0113\n",
      "Epoch 29/100\n",
      " - 1s - loss: 0.0086 - mse: 0.0086 - val_loss: 0.0130 - val_mse: 0.0130\n",
      "Epoch 30/100\n",
      " - 0s - loss: 0.0092 - mse: 0.0092 - val_loss: 0.0112 - val_mse: 0.0112\n",
      "Epoch 31/100\n",
      " - 0s - loss: 0.0091 - mse: 0.0091 - val_loss: 0.0135 - val_mse: 0.0135\n",
      "Epoch 32/100\n",
      " - 0s - loss: 0.0090 - mse: 0.0090 - val_loss: 0.0114 - val_mse: 0.0114\n",
      "Epoch 33/100\n",
      " - 0s - loss: 0.0105 - mse: 0.0105 - val_loss: 0.0186 - val_mse: 0.0186\n",
      "Epoch 34/100\n",
      " - 1s - loss: 0.0104 - mse: 0.0104 - val_loss: 0.0117 - val_mse: 0.0117\n",
      "Epoch 35/100\n",
      " - 1s - loss: 0.0110 - mse: 0.0110 - val_loss: 0.0171 - val_mse: 0.0171\n",
      "Epoch 36/100\n",
      " - 1s - loss: 0.0094 - mse: 0.0094 - val_loss: 0.0125 - val_mse: 0.0125\n",
      "Epoch 37/100\n",
      " - 0s - loss: 0.0102 - mse: 0.0102 - val_loss: 0.0150 - val_mse: 0.0150\n",
      "Epoch 38/100\n",
      " - 0s - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0116 - val_mse: 0.0116\n",
      "Epoch 39/100\n",
      " - 0s - loss: 0.0093 - mse: 0.0093 - val_loss: 0.0157 - val_mse: 0.0157\n",
      "Epoch 40/100\n",
      " - 1s - loss: 0.0061 - mse: 0.0061 - val_loss: 0.0121 - val_mse: 0.0121\n",
      "Epoch 41/100\n",
      " - 1s - loss: 0.0063 - mse: 0.0063 - val_loss: 0.0110 - val_mse: 0.0110\n",
      "Epoch 42/100\n",
      " - 1s - loss: 0.0065 - mse: 0.0065 - val_loss: 0.0105 - val_mse: 0.0105\n",
      "Epoch 43/100\n",
      " - 1s - loss: 0.0071 - mse: 0.0071 - val_loss: 0.0112 - val_mse: 0.0112\n",
      "Epoch 44/100\n",
      " - 0s - loss: 0.0063 - mse: 0.0063 - val_loss: 0.0105 - val_mse: 0.0105\n",
      "Epoch 45/100\n",
      " - 1s - loss: 0.0063 - mse: 0.0063 - val_loss: 0.0105 - val_mse: 0.0105\n",
      "Epoch 46/100\n",
      " - 1s - loss: 0.0061 - mse: 0.0061 - val_loss: 0.0103 - val_mse: 0.0103\n",
      "Epoch 47/100\n",
      " - 1s - loss: 0.0052 - mse: 0.0052 - val_loss: 0.0105 - val_mse: 0.0105\n",
      "Epoch 48/100\n",
      " - 1s - loss: 0.0057 - mse: 0.0057 - val_loss: 0.0104 - val_mse: 0.0104\n",
      "Epoch 49/100\n",
      " - 0s - loss: 0.0053 - mse: 0.0053 - val_loss: 0.0103 - val_mse: 0.0103\n",
      "Epoch 50/100\n",
      " - 0s - loss: 0.0063 - mse: 0.0063 - val_loss: 0.0101 - val_mse: 0.0101\n",
      "Epoch 51/100\n",
      " - 0s - loss: 0.0060 - mse: 0.0060 - val_loss: 0.0104 - val_mse: 0.0104\n",
      "Epoch 52/100\n",
      " - 0s - loss: 0.0056 - mse: 0.0056 - val_loss: 0.0101 - val_mse: 0.0101\n",
      "Epoch 53/100\n",
      " - 1s - loss: 0.0061 - mse: 0.0061 - val_loss: 0.0122 - val_mse: 0.0122\n",
      "Epoch 54/100\n",
      " - 0s - loss: 0.0062 - mse: 0.0062 - val_loss: 0.0107 - val_mse: 0.0107\n",
      "Epoch 55/100\n",
      " - 1s - loss: 0.0053 - mse: 0.0053 - val_loss: 0.0102 - val_mse: 0.0102\n",
      "Epoch 56/100\n",
      " - 1s - loss: 0.0053 - mse: 0.0053 - val_loss: 0.0100 - val_mse: 0.0100\n",
      "Epoch 57/100\n",
      " - 1s - loss: 0.0054 - mse: 0.0054 - val_loss: 0.0102 - val_mse: 0.0102\n",
      "Epoch 58/100\n",
      " - 1s - loss: 0.0060 - mse: 0.0060 - val_loss: 0.0106 - val_mse: 0.0106\n",
      "Epoch 59/100\n",
      " - 0s - loss: 0.0056 - mse: 0.0056 - val_loss: 0.0102 - val_mse: 0.0102\n",
      "Epoch 60/100\n",
      " - 1s - loss: 0.0052 - mse: 0.0052 - val_loss: 0.0102 - val_mse: 0.0102\n",
      "Epoch 61/100\n",
      " - 1s - loss: 0.0056 - mse: 0.0056 - val_loss: 0.0101 - val_mse: 0.0101\n",
      "Epoch 62/100\n",
      " - 1s - loss: 0.0052 - mse: 0.0052 - val_loss: 0.0101 - val_mse: 0.0101\n",
      "Epoch 63/100\n",
      " - 1s - loss: 0.0052 - mse: 0.0052 - val_loss: 0.0098 - val_mse: 0.0098\n",
      "Epoch 64/100\n",
      " - 0s - loss: 0.0052 - mse: 0.0052 - val_loss: 0.0098 - val_mse: 0.0098\n",
      "Epoch 65/100\n",
      " - 0s - loss: 0.0054 - mse: 0.0054 - val_loss: 0.0100 - val_mse: 0.0100\n",
      "Epoch 66/100\n",
      " - 1s - loss: 0.0054 - mse: 0.0054 - val_loss: 0.0105 - val_mse: 0.0105\n",
      "Epoch 67/100\n",
      " - 0s - loss: 0.0055 - mse: 0.0055 - val_loss: 0.0099 - val_mse: 0.0099\n",
      "Epoch 68/100\n",
      " - 0s - loss: 0.0057 - mse: 0.0057 - val_loss: 0.0101 - val_mse: 0.0101\n",
      "Epoch 69/100\n",
      " - 0s - loss: 0.0064 - mse: 0.0064 - val_loss: 0.0098 - val_mse: 0.0098\n",
      "Epoch 70/100\n",
      " - 1s - loss: 0.0071 - mse: 0.0071 - val_loss: 0.0108 - val_mse: 0.0108\n",
      "Epoch 71/100\n",
      " - 0s - loss: 0.0079 - mse: 0.0079 - val_loss: 0.0102 - val_mse: 0.0102\n",
      "Epoch 72/100\n",
      " - 1s - loss: 0.0089 - mse: 0.0089 - val_loss: 0.0138 - val_mse: 0.0138\n",
      "Epoch 73/100\n",
      " - 1s - loss: 0.0087 - mse: 0.0087 - val_loss: 0.0105 - val_mse: 0.0105\n",
      "Epoch 74/100\n",
      " - 0s - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0151 - val_mse: 0.0151\n",
      "Epoch 75/100\n",
      " - 0s - loss: 0.0070 - mse: 0.0070 - val_loss: 0.0111 - val_mse: 0.0111\n",
      "Epoch 76/100\n",
      " - 1s - loss: 0.0066 - mse: 0.0066 - val_loss: 0.0121 - val_mse: 0.0121\n",
      "Epoch 77/100\n",
      " - 1s - loss: 0.0056 - mse: 0.0056 - val_loss: 0.0103 - val_mse: 0.0103\n",
      "Epoch 78/100\n",
      " - 1s - loss: 0.0061 - mse: 0.0061 - val_loss: 0.0111 - val_mse: 0.0111\n",
      "Epoch 79/100\n",
      " - 1s - loss: 0.0058 - mse: 0.0058 - val_loss: 0.0103 - val_mse: 0.0103\n",
      "Epoch 80/100\n",
      " - 1s - loss: 0.0058 - mse: 0.0058 - val_loss: 0.0099 - val_mse: 0.0099\n",
      "Epoch 81/100\n",
      " - 1s - loss: 0.0061 - mse: 0.0061 - val_loss: 0.0099 - val_mse: 0.0099\n",
      "Epoch 82/100\n",
      " - 1s - loss: 0.0064 - mse: 0.0064 - val_loss: 0.0107 - val_mse: 0.0107\n",
      "Epoch 83/100\n",
      " - 1s - loss: 0.0060 - mse: 0.0060 - val_loss: 0.0105 - val_mse: 0.0105\n",
      "Epoch 84/100\n",
      " - 1s - loss: 0.0056 - mse: 0.0056 - val_loss: 0.0102 - val_mse: 0.0102\n",
      "Epoch 85/100\n",
      " - 1s - loss: 0.0059 - mse: 0.0059 - val_loss: 0.0099 - val_mse: 0.0099\n",
      "Epoch 86/100\n",
      " - 1s - loss: 0.0054 - mse: 0.0054 - val_loss: 0.0109 - val_mse: 0.0109\n",
      "Epoch 87/100\n",
      " - 1s - loss: 0.0056 - mse: 0.0056 - val_loss: 0.0101 - val_mse: 0.0101\n",
      "Epoch 88/100\n",
      " - 1s - loss: 0.0050 - mse: 0.0050 - val_loss: 0.0101 - val_mse: 0.0101\n",
      "Epoch 89/100\n",
      " - 1s - loss: 0.0053 - mse: 0.0053 - val_loss: 0.0098 - val_mse: 0.0098\n",
      "Epoch 90/100\n",
      " - 1s - loss: 0.0055 - mse: 0.0055 - val_loss: 0.0107 - val_mse: 0.0107\n",
      "Epoch 91/100\n",
      " - 1s - loss: 0.0055 - mse: 0.0055 - val_loss: 0.0101 - val_mse: 0.0101\n",
      "Epoch 92/100\n",
      " - 1s - loss: 0.0049 - mse: 0.0049 - val_loss: 0.0104 - val_mse: 0.0104\n",
      "Epoch 93/100\n",
      " - 1s - loss: 0.0047 - mse: 0.0047 - val_loss: 0.0099 - val_mse: 0.0099\n",
      "Epoch 94/100\n",
      " - 1s - loss: 0.0049 - mse: 0.0049 - val_loss: 0.0099 - val_mse: 0.0099\n",
      "Epoch 95/100\n",
      " - 1s - loss: 0.0044 - mse: 0.0044 - val_loss: 0.0097 - val_mse: 0.0097\n",
      "Epoch 96/100\n",
      " - 1s - loss: 0.0054 - mse: 0.0054 - val_loss: 0.0099 - val_mse: 0.0099\n",
      "Epoch 97/100\n",
      " - 1s - loss: 0.0058 - mse: 0.0058 - val_loss: 0.0099 - val_mse: 0.0099\n",
      "Epoch 98/100\n",
      " - 1s - loss: 0.0055 - mse: 0.0055 - val_loss: 0.0102 - val_mse: 0.0102\n",
      "Epoch 99/100\n",
      " - 0s - loss: 0.0057 - mse: 0.0057 - val_loss: 0.0098 - val_mse: 0.0098\n",
      "Epoch 100/100\n",
      " - 0s - loss: 0.0061 - mse: 0.0061 - val_loss: 0.0106 - val_mse: 0.0106\n",
      "real [[3725.46]]\n",
      "Test RMSE: 332.328\n",
      "Diff [[-332.32847851]]\n",
      "% Diff [[-8.9204683]] %\n",
      "Predictions [[4057.78847851]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "target = 'close'\n",
    "\n",
    "columns = columns_2\n",
    "num_features = len(columns)\n",
    "crypto = cryptos[0]\n",
    "execute_test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EMA 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading... ETH\n",
      "Extracting columns columns for ETH\n",
      "Proccessing and arranging columns for LSTM model\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EMA_50_19</th>\n",
       "      <th>ADX_19</th>\n",
       "      <th>EMA_50_18</th>\n",
       "      <th>ADX_18</th>\n",
       "      <th>EMA_50_17</th>\n",
       "      <th>ADX_17</th>\n",
       "      <th>EMA_50_16</th>\n",
       "      <th>ADX_16</th>\n",
       "      <th>EMA_50_15</th>\n",
       "      <th>ADX_15</th>\n",
       "      <th>...</th>\n",
       "      <th>ADX_4</th>\n",
       "      <th>EMA_50_3</th>\n",
       "      <th>ADX_3</th>\n",
       "      <th>EMA_50_2</th>\n",
       "      <th>ADX_2</th>\n",
       "      <th>EMA_50_1</th>\n",
       "      <th>ADX_1</th>\n",
       "      <th>EMA_50_0</th>\n",
       "      <th>ADX_0</th>\n",
       "      <th>EMA_50</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>757.484690</td>\n",
       "      <td>41.418230</td>\n",
       "      <td>761.319800</td>\n",
       "      <td>36.212628</td>\n",
       "      <td>768.092749</td>\n",
       "      <td>24.312204</td>\n",
       "      <td>774.834210</td>\n",
       "      <td>21.025032</td>\n",
       "      <td>782.068162</td>\n",
       "      <td>21.223914</td>\n",
       "      <td>...</td>\n",
       "      <td>28.656861</td>\n",
       "      <td>935.027584</td>\n",
       "      <td>27.861915</td>\n",
       "      <td>937.340228</td>\n",
       "      <td>27.314258</td>\n",
       "      <td>941.071984</td>\n",
       "      <td>26.829022</td>\n",
       "      <td>949.373082</td>\n",
       "      <td>26.295579</td>\n",
       "      <td>952.866927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>761.319800</td>\n",
       "      <td>36.212628</td>\n",
       "      <td>768.092749</td>\n",
       "      <td>24.312204</td>\n",
       "      <td>774.834210</td>\n",
       "      <td>21.025032</td>\n",
       "      <td>782.068162</td>\n",
       "      <td>21.223914</td>\n",
       "      <td>790.775685</td>\n",
       "      <td>22.305116</td>\n",
       "      <td>...</td>\n",
       "      <td>27.861915</td>\n",
       "      <td>937.340228</td>\n",
       "      <td>27.314258</td>\n",
       "      <td>941.071984</td>\n",
       "      <td>26.829022</td>\n",
       "      <td>949.373082</td>\n",
       "      <td>26.295579</td>\n",
       "      <td>953.280020</td>\n",
       "      <td>25.001883</td>\n",
       "      <td>948.878028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>768.092749</td>\n",
       "      <td>24.312204</td>\n",
       "      <td>774.834210</td>\n",
       "      <td>21.025032</td>\n",
       "      <td>782.068162</td>\n",
       "      <td>21.223914</td>\n",
       "      <td>790.775685</td>\n",
       "      <td>22.305116</td>\n",
       "      <td>803.807619</td>\n",
       "      <td>23.246794</td>\n",
       "      <td>...</td>\n",
       "      <td>27.314258</td>\n",
       "      <td>941.071984</td>\n",
       "      <td>26.829022</td>\n",
       "      <td>949.373082</td>\n",
       "      <td>26.295579</td>\n",
       "      <td>953.280020</td>\n",
       "      <td>25.001883</td>\n",
       "      <td>954.837667</td>\n",
       "      <td>24.131656</td>\n",
       "      <td>943.392223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>774.834210</td>\n",
       "      <td>21.025032</td>\n",
       "      <td>782.068162</td>\n",
       "      <td>21.223914</td>\n",
       "      <td>790.775685</td>\n",
       "      <td>22.305116</td>\n",
       "      <td>803.807619</td>\n",
       "      <td>23.246794</td>\n",
       "      <td>816.724183</td>\n",
       "      <td>25.900560</td>\n",
       "      <td>...</td>\n",
       "      <td>26.829022</td>\n",
       "      <td>949.373082</td>\n",
       "      <td>26.295579</td>\n",
       "      <td>953.280020</td>\n",
       "      <td>25.001883</td>\n",
       "      <td>954.837667</td>\n",
       "      <td>24.131656</td>\n",
       "      <td>955.824425</td>\n",
       "      <td>23.956457</td>\n",
       "      <td>940.383116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>782.068162</td>\n",
       "      <td>21.223914</td>\n",
       "      <td>790.775685</td>\n",
       "      <td>22.305116</td>\n",
       "      <td>803.807619</td>\n",
       "      <td>23.246794</td>\n",
       "      <td>816.724183</td>\n",
       "      <td>25.900560</td>\n",
       "      <td>835.323235</td>\n",
       "      <td>26.950869</td>\n",
       "      <td>...</td>\n",
       "      <td>26.295579</td>\n",
       "      <td>953.280020</td>\n",
       "      <td>25.001883</td>\n",
       "      <td>954.837667</td>\n",
       "      <td>24.131656</td>\n",
       "      <td>955.824425</td>\n",
       "      <td>23.956457</td>\n",
       "      <td>959.948957</td>\n",
       "      <td>23.763680</td>\n",
       "      <td>936.508092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1573</th>\n",
       "      <td>4119.107937</td>\n",
       "      <td>19.071649</td>\n",
       "      <td>4114.315469</td>\n",
       "      <td>19.441324</td>\n",
       "      <td>4121.391725</td>\n",
       "      <td>19.895549</td>\n",
       "      <td>4132.794794</td>\n",
       "      <td>20.260773</td>\n",
       "      <td>4137.716959</td>\n",
       "      <td>19.858133</td>\n",
       "      <td>...</td>\n",
       "      <td>17.630929</td>\n",
       "      <td>4217.844136</td>\n",
       "      <td>16.807307</td>\n",
       "      <td>4213.899268</td>\n",
       "      <td>16.765313</td>\n",
       "      <td>4213.214591</td>\n",
       "      <td>17.981035</td>\n",
       "      <td>4218.484215</td>\n",
       "      <td>19.049911</td>\n",
       "      <td>4110.703230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1574</th>\n",
       "      <td>4114.315469</td>\n",
       "      <td>19.441324</td>\n",
       "      <td>4121.391725</td>\n",
       "      <td>19.895549</td>\n",
       "      <td>4132.794794</td>\n",
       "      <td>20.260773</td>\n",
       "      <td>4137.716959</td>\n",
       "      <td>19.858133</td>\n",
       "      <td>4135.687667</td>\n",
       "      <td>19.464946</td>\n",
       "      <td>...</td>\n",
       "      <td>16.807307</td>\n",
       "      <td>4213.899268</td>\n",
       "      <td>16.765313</td>\n",
       "      <td>4213.214591</td>\n",
       "      <td>17.981035</td>\n",
       "      <td>4218.484215</td>\n",
       "      <td>19.049911</td>\n",
       "      <td>4221.931893</td>\n",
       "      <td>19.747824</td>\n",
       "      <td>4107.821927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1575</th>\n",
       "      <td>4121.391725</td>\n",
       "      <td>19.895549</td>\n",
       "      <td>4132.794794</td>\n",
       "      <td>20.260773</td>\n",
       "      <td>4137.716959</td>\n",
       "      <td>19.858133</td>\n",
       "      <td>4135.687667</td>\n",
       "      <td>19.464946</td>\n",
       "      <td>4143.677954</td>\n",
       "      <td>19.925177</td>\n",
       "      <td>...</td>\n",
       "      <td>16.765313</td>\n",
       "      <td>4213.214591</td>\n",
       "      <td>17.981035</td>\n",
       "      <td>4218.484215</td>\n",
       "      <td>19.049911</td>\n",
       "      <td>4221.931893</td>\n",
       "      <td>19.747824</td>\n",
       "      <td>4230.362407</td>\n",
       "      <td>20.202159</td>\n",
       "      <td>4095.466165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1576</th>\n",
       "      <td>4132.794794</td>\n",
       "      <td>20.260773</td>\n",
       "      <td>4137.716959</td>\n",
       "      <td>19.858133</td>\n",
       "      <td>4135.687667</td>\n",
       "      <td>19.464946</td>\n",
       "      <td>4143.677954</td>\n",
       "      <td>19.925177</td>\n",
       "      <td>4148.606662</td>\n",
       "      <td>19.969782</td>\n",
       "      <td>...</td>\n",
       "      <td>17.981035</td>\n",
       "      <td>4218.484215</td>\n",
       "      <td>19.049911</td>\n",
       "      <td>4221.931893</td>\n",
       "      <td>19.747824</td>\n",
       "      <td>4230.362407</td>\n",
       "      <td>20.202159</td>\n",
       "      <td>4225.471332</td>\n",
       "      <td>20.614088</td>\n",
       "      <td>4077.220041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1577</th>\n",
       "      <td>4137.716959</td>\n",
       "      <td>19.858133</td>\n",
       "      <td>4135.687667</td>\n",
       "      <td>19.464946</td>\n",
       "      <td>4143.677954</td>\n",
       "      <td>19.925177</td>\n",
       "      <td>4148.606662</td>\n",
       "      <td>19.969782</td>\n",
       "      <td>4163.361303</td>\n",
       "      <td>19.934622</td>\n",
       "      <td>...</td>\n",
       "      <td>19.049911</td>\n",
       "      <td>4221.931893</td>\n",
       "      <td>19.747824</td>\n",
       "      <td>4230.362407</td>\n",
       "      <td>20.202159</td>\n",
       "      <td>4225.471332</td>\n",
       "      <td>20.614088</td>\n",
       "      <td>4212.626966</td>\n",
       "      <td>21.222026</td>\n",
       "      <td>4062.790628</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1421 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        EMA_50_19     ADX_19    EMA_50_18     ADX_18    EMA_50_17     ADX_17  \\\n",
       "157    757.484690  41.418230   761.319800  36.212628   768.092749  24.312204   \n",
       "158    761.319800  36.212628   768.092749  24.312204   774.834210  21.025032   \n",
       "159    768.092749  24.312204   774.834210  21.025032   782.068162  21.223914   \n",
       "160    774.834210  21.025032   782.068162  21.223914   790.775685  22.305116   \n",
       "161    782.068162  21.223914   790.775685  22.305116   803.807619  23.246794   \n",
       "...           ...        ...          ...        ...          ...        ...   \n",
       "1573  4119.107937  19.071649  4114.315469  19.441324  4121.391725  19.895549   \n",
       "1574  4114.315469  19.441324  4121.391725  19.895549  4132.794794  20.260773   \n",
       "1575  4121.391725  19.895549  4132.794794  20.260773  4137.716959  19.858133   \n",
       "1576  4132.794794  20.260773  4137.716959  19.858133  4135.687667  19.464946   \n",
       "1577  4137.716959  19.858133  4135.687667  19.464946  4143.677954  19.925177   \n",
       "\n",
       "        EMA_50_16     ADX_16    EMA_50_15     ADX_15  ...      ADX_4  \\\n",
       "157    774.834210  21.025032   782.068162  21.223914  ...  28.656861   \n",
       "158    782.068162  21.223914   790.775685  22.305116  ...  27.861915   \n",
       "159    790.775685  22.305116   803.807619  23.246794  ...  27.314258   \n",
       "160    803.807619  23.246794   816.724183  25.900560  ...  26.829022   \n",
       "161    816.724183  25.900560   835.323235  26.950869  ...  26.295579   \n",
       "...           ...        ...          ...        ...  ...        ...   \n",
       "1573  4132.794794  20.260773  4137.716959  19.858133  ...  17.630929   \n",
       "1574  4137.716959  19.858133  4135.687667  19.464946  ...  16.807307   \n",
       "1575  4135.687667  19.464946  4143.677954  19.925177  ...  16.765313   \n",
       "1576  4143.677954  19.925177  4148.606662  19.969782  ...  17.981035   \n",
       "1577  4148.606662  19.969782  4163.361303  19.934622  ...  19.049911   \n",
       "\n",
       "         EMA_50_3      ADX_3     EMA_50_2      ADX_2     EMA_50_1      ADX_1  \\\n",
       "157    935.027584  27.861915   937.340228  27.314258   941.071984  26.829022   \n",
       "158    937.340228  27.314258   941.071984  26.829022   949.373082  26.295579   \n",
       "159    941.071984  26.829022   949.373082  26.295579   953.280020  25.001883   \n",
       "160    949.373082  26.295579   953.280020  25.001883   954.837667  24.131656   \n",
       "161    953.280020  25.001883   954.837667  24.131656   955.824425  23.956457   \n",
       "...           ...        ...          ...        ...          ...        ...   \n",
       "1573  4217.844136  16.807307  4213.899268  16.765313  4213.214591  17.981035   \n",
       "1574  4213.899268  16.765313  4213.214591  17.981035  4218.484215  19.049911   \n",
       "1575  4213.214591  17.981035  4218.484215  19.049911  4221.931893  19.747824   \n",
       "1576  4218.484215  19.049911  4221.931893  19.747824  4230.362407  20.202159   \n",
       "1577  4221.931893  19.747824  4230.362407  20.202159  4225.471332  20.614088   \n",
       "\n",
       "         EMA_50_0      ADX_0       EMA_50  \n",
       "157    949.373082  26.295579   952.866927  \n",
       "158    953.280020  25.001883   948.878028  \n",
       "159    954.837667  24.131656   943.392223  \n",
       "160    955.824425  23.956457   940.383116  \n",
       "161    959.948957  23.763680   936.508092  \n",
       "...           ...        ...          ...  \n",
       "1573  4218.484215  19.049911  4110.703230  \n",
       "1574  4221.931893  19.747824  4107.821927  \n",
       "1575  4230.362407  20.202159  4095.466165  \n",
       "1576  4225.471332  20.614088  4077.220041  \n",
       "1577  4212.626966  21.222026  4062.790628  \n",
       "\n",
       "[1421 rows x 41 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EMA_50_19</th>\n",
       "      <th>ADX_19</th>\n",
       "      <th>EMA_50_18</th>\n",
       "      <th>ADX_18</th>\n",
       "      <th>EMA_50_17</th>\n",
       "      <th>ADX_17</th>\n",
       "      <th>EMA_50_16</th>\n",
       "      <th>ADX_16</th>\n",
       "      <th>EMA_50_15</th>\n",
       "      <th>ADX_15</th>\n",
       "      <th>...</th>\n",
       "      <th>ADX_4</th>\n",
       "      <th>EMA_50_3</th>\n",
       "      <th>ADX_3</th>\n",
       "      <th>EMA_50_2</th>\n",
       "      <th>ADX_2</th>\n",
       "      <th>EMA_50_1</th>\n",
       "      <th>ADX_1</th>\n",
       "      <th>EMA_50_0</th>\n",
       "      <th>ADX_0</th>\n",
       "      <th>EMA_50</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1578</th>\n",
       "      <td>4135.687667</td>\n",
       "      <td>19.464946</td>\n",
       "      <td>4143.677954</td>\n",
       "      <td>19.925177</td>\n",
       "      <td>4148.606662</td>\n",
       "      <td>19.969782</td>\n",
       "      <td>4163.361303</td>\n",
       "      <td>19.934622</td>\n",
       "      <td>4158.570663</td>\n",
       "      <td>19.004087</td>\n",
       "      <td>...</td>\n",
       "      <td>19.747824</td>\n",
       "      <td>4230.362407</td>\n",
       "      <td>20.202159</td>\n",
       "      <td>4225.471332</td>\n",
       "      <td>20.614088</td>\n",
       "      <td>4212.626966</td>\n",
       "      <td>21.222026</td>\n",
       "      <td>4207.793359</td>\n",
       "      <td>22.210426</td>\n",
       "      <td>4049.561976</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        EMA_50_19     ADX_19    EMA_50_18     ADX_18    EMA_50_17     ADX_17  \\\n",
       "1578  4135.687667  19.464946  4143.677954  19.925177  4148.606662  19.969782   \n",
       "\n",
       "        EMA_50_16     ADX_16    EMA_50_15     ADX_15  ...      ADX_4  \\\n",
       "1578  4163.361303  19.934622  4158.570663  19.004087  ...  19.747824   \n",
       "\n",
       "         EMA_50_3      ADX_3     EMA_50_2      ADX_2     EMA_50_1      ADX_1  \\\n",
       "1578  4230.362407  20.202159  4225.471332  20.614088  4212.626966  21.222026   \n",
       "\n",
       "         EMA_50_0      ADX_0       EMA_50  \n",
       "1578  4207.793359  22.210426  4049.561976  \n",
       "\n",
       "[1 rows x 41 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (1421, 1, 40) (1421, 1)\n",
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_46 (LSTM)               (None, 1, 25)             6600      \n",
      "_________________________________________________________________\n",
      "lstm_47 (LSTM)               (None, 1, 25)             5100      \n",
      "_________________________________________________________________\n",
      "dropout_37 (Dropout)         (None, 1, 25)             0         \n",
      "_________________________________________________________________\n",
      "lstm_48 (LSTM)               (None, 1, 25)             5100      \n",
      "_________________________________________________________________\n",
      "dropout_38 (Dropout)         (None, 1, 25)             0         \n",
      "_________________________________________________________________\n",
      "lstm_49 (LSTM)               (None, 1, 25)             5100      \n",
      "_________________________________________________________________\n",
      "dropout_39 (Dropout)         (None, 1, 25)             0         \n",
      "_________________________________________________________________\n",
      "lstm_50 (LSTM)               (None, 25)                5100      \n",
      "_________________________________________________________________\n",
      "dropout_40 (Dropout)         (None, 25)                0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 1)                 26        \n",
      "=================================================================\n",
      "Total params: 27,026\n",
      "Trainable params: 27,026\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Y shape (1421, 1)\n",
      "Train on 1421 samples, validate on 285 samples\n",
      "Epoch 1/100\n",
      " - 21s - loss: 0.0963 - mse: 0.0963 - val_loss: 0.4370 - val_mse: 0.4370\n",
      "Epoch 2/100\n",
      " - 0s - loss: 0.0835 - mse: 0.0835 - val_loss: 0.3797 - val_mse: 0.3797\n",
      "Epoch 3/100\n",
      " - 0s - loss: 0.0753 - mse: 0.0753 - val_loss: 0.3229 - val_mse: 0.3229\n",
      "Epoch 4/100\n",
      " - 0s - loss: 0.0691 - mse: 0.0691 - val_loss: 0.2614 - val_mse: 0.2614\n",
      "Epoch 5/100\n",
      " - 0s - loss: 0.0566 - mse: 0.0566 - val_loss: 0.1561 - val_mse: 0.1561\n",
      "Epoch 6/100\n",
      " - 0s - loss: 0.0258 - mse: 0.0258 - val_loss: 0.0163 - val_mse: 0.0163\n",
      "Epoch 7/100\n",
      " - 0s - loss: 0.0300 - mse: 0.0300 - val_loss: 0.0085 - val_mse: 0.0085\n",
      "Epoch 8/100\n",
      " - 0s - loss: 0.0350 - mse: 0.0350 - val_loss: 0.1112 - val_mse: 0.1112\n",
      "Epoch 9/100\n",
      " - 0s - loss: 0.0103 - mse: 0.0103 - val_loss: 0.0099 - val_mse: 0.0099\n",
      "Epoch 10/100\n",
      " - 1s - loss: 0.0121 - mse: 0.0121 - val_loss: 0.0104 - val_mse: 0.0104\n",
      "Epoch 11/100\n",
      " - 1s - loss: 0.0110 - mse: 0.0110 - val_loss: 0.0117 - val_mse: 0.0117\n",
      "Epoch 12/100\n",
      " - 1s - loss: 0.0116 - mse: 0.0116 - val_loss: 0.0095 - val_mse: 0.0095\n",
      "Epoch 13/100\n",
      " - 1s - loss: 0.0103 - mse: 0.0103 - val_loss: 0.0115 - val_mse: 0.0115\n",
      "Epoch 14/100\n",
      " - 1s - loss: 0.0099 - mse: 0.0099 - val_loss: 0.0085 - val_mse: 0.0085\n",
      "Epoch 15/100\n",
      " - 0s - loss: 0.0091 - mse: 0.0091 - val_loss: 0.0090 - val_mse: 0.0090\n",
      "Epoch 16/100\n",
      " - 1s - loss: 0.0110 - mse: 0.0110 - val_loss: 0.0083 - val_mse: 0.0083\n",
      "Epoch 17/100\n",
      " - 1s - loss: 0.0126 - mse: 0.0126 - val_loss: 0.0147 - val_mse: 0.0147\n",
      "Epoch 18/100\n",
      " - 1s - loss: 0.0135 - mse: 0.0135 - val_loss: 0.0092 - val_mse: 0.0092\n",
      "Epoch 19/100\n",
      " - 1s - loss: 0.0117 - mse: 0.0117 - val_loss: 0.0140 - val_mse: 0.0140\n",
      "Epoch 20/100\n",
      " - 0s - loss: 0.0105 - mse: 0.0105 - val_loss: 0.0089 - val_mse: 0.0089\n",
      "Epoch 21/100\n",
      " - 1s - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0115 - val_mse: 0.0115\n",
      "Epoch 22/100\n",
      " - 0s - loss: 0.0107 - mse: 0.0107 - val_loss: 0.0082 - val_mse: 0.0082\n",
      "Epoch 23/100\n",
      " - 1s - loss: 0.0098 - mse: 0.0098 - val_loss: 0.0109 - val_mse: 0.0109\n",
      "Epoch 24/100\n",
      " - 1s - loss: 0.0105 - mse: 0.0105 - val_loss: 0.0079 - val_mse: 0.0079\n",
      "Epoch 25/100\n",
      " - 0s - loss: 0.0092 - mse: 0.0092 - val_loss: 0.0116 - val_mse: 0.0116\n",
      "Epoch 26/100\n",
      " - 0s - loss: 0.0088 - mse: 0.0088 - val_loss: 0.0082 - val_mse: 0.0082\n",
      "Epoch 27/100\n",
      " - 0s - loss: 0.0077 - mse: 0.0077 - val_loss: 0.0082 - val_mse: 0.0082\n",
      "Epoch 28/100\n",
      " - 0s - loss: 0.0080 - mse: 0.0080 - val_loss: 0.0074 - val_mse: 0.0074\n",
      "Epoch 29/100\n",
      " - 1s - loss: 0.0079 - mse: 0.0079 - val_loss: 0.0070 - val_mse: 0.0070\n",
      "Epoch 30/100\n",
      " - 0s - loss: 0.0088 - mse: 0.0088 - val_loss: 0.0082 - val_mse: 0.0082\n",
      "Epoch 31/100\n",
      " - 1s - loss: 0.0086 - mse: 0.0086 - val_loss: 0.0078 - val_mse: 0.0078\n",
      "Epoch 32/100\n",
      " - 1s - loss: 0.0082 - mse: 0.0082 - val_loss: 0.0068 - val_mse: 0.0068\n",
      "Epoch 33/100\n",
      " - 1s - loss: 0.0111 - mse: 0.0111 - val_loss: 0.0063 - val_mse: 0.0063\n",
      "Epoch 34/100\n",
      " - 1s - loss: 0.0157 - mse: 0.0157 - val_loss: 0.0236 - val_mse: 0.0236\n",
      "Epoch 35/100\n",
      " - 1s - loss: 0.0116 - mse: 0.0116 - val_loss: 0.0092 - val_mse: 0.0092\n",
      "Epoch 36/100\n",
      " - 1s - loss: 0.0101 - mse: 0.0101 - val_loss: 0.0157 - val_mse: 0.0157\n",
      "Epoch 37/100\n",
      " - 0s - loss: 0.0094 - mse: 0.0094 - val_loss: 0.0082 - val_mse: 0.0082\n",
      "Epoch 38/100\n",
      " - 1s - loss: 0.0074 - mse: 0.0074 - val_loss: 0.0106 - val_mse: 0.0106\n",
      "Epoch 39/100\n",
      " - 0s - loss: 0.0086 - mse: 0.0086 - val_loss: 0.0071 - val_mse: 0.0071\n",
      "Epoch 40/100\n",
      " - 0s - loss: 0.0069 - mse: 0.0069 - val_loss: 0.0103 - val_mse: 0.0103\n",
      "Epoch 41/100\n",
      " - 0s - loss: 0.0063 - mse: 0.0063 - val_loss: 0.0070 - val_mse: 0.0070\n",
      "Epoch 42/100\n",
      " - 0s - loss: 0.0050 - mse: 0.0050 - val_loss: 0.0070 - val_mse: 0.0070\n",
      "Epoch 43/100\n",
      " - 1s - loss: 0.0058 - mse: 0.0058 - val_loss: 0.0062 - val_mse: 0.0062\n",
      "Epoch 44/100\n",
      " - 0s - loss: 0.0055 - mse: 0.0055 - val_loss: 0.0063 - val_mse: 0.0063\n",
      "Epoch 45/100\n",
      " - 0s - loss: 0.0059 - mse: 0.0059 - val_loss: 0.0064 - val_mse: 0.0064\n",
      "Epoch 46/100\n",
      " - 0s - loss: 0.0056 - mse: 0.0056 - val_loss: 0.0059 - val_mse: 0.0059\n",
      "Epoch 47/100\n",
      " - 1s - loss: 0.0061 - mse: 0.0061 - val_loss: 0.0059 - val_mse: 0.0059\n",
      "Epoch 48/100\n",
      " - 1s - loss: 0.0066 - mse: 0.0066 - val_loss: 0.0065 - val_mse: 0.0065\n",
      "Epoch 49/100\n",
      " - 0s - loss: 0.0051 - mse: 0.0051 - val_loss: 0.0056 - val_mse: 0.0056\n",
      "Epoch 50/100\n",
      " - 0s - loss: 0.0059 - mse: 0.0059 - val_loss: 0.0066 - val_mse: 0.0066\n",
      "Epoch 51/100\n",
      " - 0s - loss: 0.0074 - mse: 0.0074 - val_loss: 0.0055 - val_mse: 0.0055\n",
      "Epoch 52/100\n",
      " - 0s - loss: 0.0083 - mse: 0.0083 - val_loss: 0.0107 - val_mse: 0.0107\n",
      "Epoch 53/100\n",
      " - 0s - loss: 0.0082 - mse: 0.0082 - val_loss: 0.0068 - val_mse: 0.0068\n",
      "Epoch 54/100\n",
      " - 0s - loss: 0.0078 - mse: 0.0078 - val_loss: 0.0096 - val_mse: 0.0096\n",
      "Epoch 55/100\n",
      " - 0s - loss: 0.0073 - mse: 0.0073 - val_loss: 0.0066 - val_mse: 0.0066\n",
      "Epoch 56/100\n",
      " - 0s - loss: 0.0069 - mse: 0.0069 - val_loss: 0.0087 - val_mse: 0.0087\n",
      "Epoch 57/100\n",
      " - 0s - loss: 0.0059 - mse: 0.0059 - val_loss: 0.0066 - val_mse: 0.0066\n",
      "Epoch 58/100\n",
      " - 0s - loss: 0.0055 - mse: 0.0055 - val_loss: 0.0063 - val_mse: 0.0063\n",
      "Epoch 59/100\n",
      " - 0s - loss: 0.0058 - mse: 0.0058 - val_loss: 0.0057 - val_mse: 0.0057\n",
      "Epoch 60/100\n",
      " - 0s - loss: 0.0051 - mse: 0.0051 - val_loss: 0.0054 - val_mse: 0.0054\n",
      "Epoch 61/100\n",
      " - 0s - loss: 0.0043 - mse: 0.0043 - val_loss: 0.0052 - val_mse: 0.0052\n",
      "Epoch 62/100\n",
      " - 1s - loss: 0.0046 - mse: 0.0046 - val_loss: 0.0050 - val_mse: 0.0050\n",
      "Epoch 63/100\n",
      " - 0s - loss: 0.0042 - mse: 0.0042 - val_loss: 0.0051 - val_mse: 0.0051\n",
      "Epoch 64/100\n",
      " - 1s - loss: 0.0049 - mse: 0.0049 - val_loss: 0.0049 - val_mse: 0.0049\n",
      "Epoch 65/100\n",
      " - 1s - loss: 0.0045 - mse: 0.0045 - val_loss: 0.0049 - val_mse: 0.0049\n",
      "Epoch 66/100\n",
      " - 1s - loss: 0.0043 - mse: 0.0043 - val_loss: 0.0048 - val_mse: 0.0048\n",
      "Epoch 67/100\n",
      " - 0s - loss: 0.0045 - mse: 0.0045 - val_loss: 0.0048 - val_mse: 0.0048\n",
      "Epoch 68/100\n",
      " - 0s - loss: 0.0044 - mse: 0.0044 - val_loss: 0.0052 - val_mse: 0.0052\n",
      "Epoch 69/100\n",
      " - 0s - loss: 0.0045 - mse: 0.0045 - val_loss: 0.0049 - val_mse: 0.0049\n",
      "Epoch 70/100\n",
      " - 0s - loss: 0.0046 - mse: 0.0046 - val_loss: 0.0049 - val_mse: 0.0049\n",
      "Epoch 71/100\n",
      " - 0s - loss: 0.0044 - mse: 0.0044 - val_loss: 0.0051 - val_mse: 0.0051\n",
      "Epoch 72/100\n",
      " - 1s - loss: 0.0045 - mse: 0.0045 - val_loss: 0.0057 - val_mse: 0.0057\n",
      "Epoch 73/100\n",
      " - 1s - loss: 0.0049 - mse: 0.0049 - val_loss: 0.0053 - val_mse: 0.0053\n",
      "Epoch 74/100\n",
      " - 1s - loss: 0.0045 - mse: 0.0045 - val_loss: 0.0050 - val_mse: 0.0050\n",
      "Epoch 75/100\n",
      " - 0s - loss: 0.0042 - mse: 0.0042 - val_loss: 0.0052 - val_mse: 0.0052\n",
      "Epoch 76/100\n",
      " - 1s - loss: 0.0043 - mse: 0.0043 - val_loss: 0.0047 - val_mse: 0.0047\n",
      "Epoch 77/100\n",
      " - 1s - loss: 0.0041 - mse: 0.0041 - val_loss: 0.0048 - val_mse: 0.0048\n",
      "Epoch 78/100\n",
      " - 1s - loss: 0.0042 - mse: 0.0042 - val_loss: 0.0046 - val_mse: 0.0046\n",
      "Epoch 79/100\n",
      " - 0s - loss: 0.0044 - mse: 0.0044 - val_loss: 0.0046 - val_mse: 0.0046\n",
      "Epoch 80/100\n",
      " - 0s - loss: 0.0049 - mse: 0.0049 - val_loss: 0.0044 - val_mse: 0.0044\n",
      "Epoch 81/100\n",
      " - 1s - loss: 0.0057 - mse: 0.0057 - val_loss: 0.0048 - val_mse: 0.0048\n",
      "Epoch 82/100\n",
      " - 0s - loss: 0.0067 - mse: 0.0067 - val_loss: 0.0046 - val_mse: 0.0046\n",
      "Epoch 83/100\n",
      " - 0s - loss: 0.0087 - mse: 0.0087 - val_loss: 0.0092 - val_mse: 0.0092\n",
      "Epoch 84/100\n",
      " - 0s - loss: 0.0082 - mse: 0.0082 - val_loss: 0.0064 - val_mse: 0.0064\n",
      "Epoch 85/100\n",
      " - 0s - loss: 0.0084 - mse: 0.0084 - val_loss: 0.0112 - val_mse: 0.0112\n",
      "Epoch 86/100\n",
      " - 0s - loss: 0.0076 - mse: 0.0076 - val_loss: 0.0061 - val_mse: 0.0061\n",
      "Epoch 87/100\n",
      " - 0s - loss: 0.0068 - mse: 0.0068 - val_loss: 0.0087 - val_mse: 0.0087\n",
      "Epoch 88/100\n",
      " - 0s - loss: 0.0058 - mse: 0.0058 - val_loss: 0.0065 - val_mse: 0.0065\n",
      "Epoch 89/100\n",
      " - 0s - loss: 0.0045 - mse: 0.0045 - val_loss: 0.0054 - val_mse: 0.0054\n",
      "Epoch 90/100\n",
      " - 0s - loss: 0.0042 - mse: 0.0042 - val_loss: 0.0048 - val_mse: 0.0048\n",
      "Epoch 91/100\n",
      " - 0s - loss: 0.0046 - mse: 0.0046 - val_loss: 0.0052 - val_mse: 0.0052\n",
      "Epoch 92/100\n",
      " - 0s - loss: 0.0038 - mse: 0.0038 - val_loss: 0.0051 - val_mse: 0.0051\n",
      "Epoch 93/100\n",
      " - 1s - loss: 0.0041 - mse: 0.0041 - val_loss: 0.0046 - val_mse: 0.0046\n",
      "Epoch 94/100\n",
      " - 0s - loss: 0.0045 - mse: 0.0045 - val_loss: 0.0046 - val_mse: 0.0046\n",
      "Epoch 95/100\n",
      " - 0s - loss: 0.0040 - mse: 0.0040 - val_loss: 0.0047 - val_mse: 0.0047\n",
      "Epoch 96/100\n",
      " - 1s - loss: 0.0044 - mse: 0.0044 - val_loss: 0.0044 - val_mse: 0.0044\n",
      "Epoch 97/100\n",
      " - 0s - loss: 0.0052 - mse: 0.0052 - val_loss: 0.0051 - val_mse: 0.0051\n",
      "Epoch 98/100\n",
      " - 1s - loss: 0.0051 - mse: 0.0051 - val_loss: 0.0050 - val_mse: 0.0050\n",
      "Epoch 99/100\n",
      " - 1s - loss: 0.0050 - mse: 0.0050 - val_loss: 0.0061 - val_mse: 0.0061\n",
      "Epoch 100/100\n",
      " - 0s - loss: 0.0050 - mse: 0.0050 - val_loss: 0.0044 - val_mse: 0.0044\n",
      "real [[4049.56197554]]\n",
      "Test RMSE: 113.718\n",
      "Diff [[-113.71794003]]\n",
      "% Diff [[-2.80815408]] %\n",
      "Predictions [[4163.27991557]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "target = 'EMA_50'\n",
    "\n",
    "columns = columns_3\n",
    "num_features = len(columns)\n",
    "crypto = cryptos[0]\n",
    "execute_test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SMA 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading... ETH\n",
      "Extracting columns columns for ETH\n",
      "Proccessing and arranging columns for LSTM model\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SMA 50_19</th>\n",
       "      <th>ADX_19</th>\n",
       "      <th>SMA 50_18</th>\n",
       "      <th>ADX_18</th>\n",
       "      <th>SMA 50_17</th>\n",
       "      <th>ADX_17</th>\n",
       "      <th>SMA 50_16</th>\n",
       "      <th>ADX_16</th>\n",
       "      <th>SMA 50_15</th>\n",
       "      <th>ADX_15</th>\n",
       "      <th>...</th>\n",
       "      <th>ADX_4</th>\n",
       "      <th>SMA 50_3</th>\n",
       "      <th>ADX_3</th>\n",
       "      <th>SMA 50_2</th>\n",
       "      <th>ADX_2</th>\n",
       "      <th>SMA 50_1</th>\n",
       "      <th>ADX_1</th>\n",
       "      <th>SMA 50_0</th>\n",
       "      <th>ADX_0</th>\n",
       "      <th>SMA 50</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>967.5256</td>\n",
       "      <td>18.764118</td>\n",
       "      <td>967.4306</td>\n",
       "      <td>20.493217</td>\n",
       "      <td>966.5506</td>\n",
       "      <td>22.303508</td>\n",
       "      <td>966.3796</td>\n",
       "      <td>23.454945</td>\n",
       "      <td>968.2714</td>\n",
       "      <td>24.441875</td>\n",
       "      <td>...</td>\n",
       "      <td>17.797676</td>\n",
       "      <td>1009.9178</td>\n",
       "      <td>17.470375</td>\n",
       "      <td>1007.2670</td>\n",
       "      <td>17.748928</td>\n",
       "      <td>1005.4990</td>\n",
       "      <td>18.222022</td>\n",
       "      <td>1002.9918</td>\n",
       "      <td>18.477033</td>\n",
       "      <td>859.0894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>967.4306</td>\n",
       "      <td>20.493217</td>\n",
       "      <td>966.5506</td>\n",
       "      <td>22.303508</td>\n",
       "      <td>966.3796</td>\n",
       "      <td>23.454945</td>\n",
       "      <td>968.2714</td>\n",
       "      <td>24.441875</td>\n",
       "      <td>972.5750</td>\n",
       "      <td>24.385214</td>\n",
       "      <td>...</td>\n",
       "      <td>17.470375</td>\n",
       "      <td>1007.2670</td>\n",
       "      <td>17.748928</td>\n",
       "      <td>1005.4990</td>\n",
       "      <td>18.222022</td>\n",
       "      <td>1002.9918</td>\n",
       "      <td>18.477033</td>\n",
       "      <td>999.7334</td>\n",
       "      <td>18.713222</td>\n",
       "      <td>849.0078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>966.5506</td>\n",
       "      <td>22.303508</td>\n",
       "      <td>966.3796</td>\n",
       "      <td>23.454945</td>\n",
       "      <td>968.2714</td>\n",
       "      <td>24.441875</td>\n",
       "      <td>972.5750</td>\n",
       "      <td>24.385214</td>\n",
       "      <td>975.9480</td>\n",
       "      <td>24.078679</td>\n",
       "      <td>...</td>\n",
       "      <td>17.748928</td>\n",
       "      <td>1005.4990</td>\n",
       "      <td>18.222022</td>\n",
       "      <td>1002.9918</td>\n",
       "      <td>18.477033</td>\n",
       "      <td>999.7334</td>\n",
       "      <td>18.713222</td>\n",
       "      <td>994.6312</td>\n",
       "      <td>18.890864</td>\n",
       "      <td>837.3680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>966.3796</td>\n",
       "      <td>23.454945</td>\n",
       "      <td>968.2714</td>\n",
       "      <td>24.441875</td>\n",
       "      <td>972.5750</td>\n",
       "      <td>24.385214</td>\n",
       "      <td>975.9480</td>\n",
       "      <td>24.078679</td>\n",
       "      <td>980.1212</td>\n",
       "      <td>23.976865</td>\n",
       "      <td>...</td>\n",
       "      <td>18.222022</td>\n",
       "      <td>1002.9918</td>\n",
       "      <td>18.477033</td>\n",
       "      <td>999.7334</td>\n",
       "      <td>18.713222</td>\n",
       "      <td>994.6312</td>\n",
       "      <td>18.890864</td>\n",
       "      <td>989.3698</td>\n",
       "      <td>18.501906</td>\n",
       "      <td>823.4664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>968.2714</td>\n",
       "      <td>24.441875</td>\n",
       "      <td>972.5750</td>\n",
       "      <td>24.385214</td>\n",
       "      <td>975.9480</td>\n",
       "      <td>24.078679</td>\n",
       "      <td>980.1212</td>\n",
       "      <td>23.976865</td>\n",
       "      <td>982.6536</td>\n",
       "      <td>23.677467</td>\n",
       "      <td>...</td>\n",
       "      <td>18.477033</td>\n",
       "      <td>999.7334</td>\n",
       "      <td>18.713222</td>\n",
       "      <td>994.6312</td>\n",
       "      <td>18.890864</td>\n",
       "      <td>989.3698</td>\n",
       "      <td>18.501906</td>\n",
       "      <td>980.6198</td>\n",
       "      <td>17.904245</td>\n",
       "      <td>811.0662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1573</th>\n",
       "      <td>4034.8430</td>\n",
       "      <td>19.071649</td>\n",
       "      <td>4057.7720</td>\n",
       "      <td>19.441324</td>\n",
       "      <td>4083.6550</td>\n",
       "      <td>19.895549</td>\n",
       "      <td>4105.7002</td>\n",
       "      <td>20.260773</td>\n",
       "      <td>4123.1112</td>\n",
       "      <td>19.858133</td>\n",
       "      <td>...</td>\n",
       "      <td>17.630929</td>\n",
       "      <td>4314.5094</td>\n",
       "      <td>16.807307</td>\n",
       "      <td>4319.4746</td>\n",
       "      <td>16.765313</td>\n",
       "      <td>4326.8042</td>\n",
       "      <td>17.981035</td>\n",
       "      <td>4336.8190</td>\n",
       "      <td>19.049911</td>\n",
       "      <td>4255.1132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1574</th>\n",
       "      <td>4057.7720</td>\n",
       "      <td>19.441324</td>\n",
       "      <td>4083.6550</td>\n",
       "      <td>19.895549</td>\n",
       "      <td>4105.7002</td>\n",
       "      <td>20.260773</td>\n",
       "      <td>4123.1112</td>\n",
       "      <td>19.858133</td>\n",
       "      <td>4136.4760</td>\n",
       "      <td>19.464946</td>\n",
       "      <td>...</td>\n",
       "      <td>16.807307</td>\n",
       "      <td>4319.4746</td>\n",
       "      <td>16.765313</td>\n",
       "      <td>4326.8042</td>\n",
       "      <td>17.981035</td>\n",
       "      <td>4336.8190</td>\n",
       "      <td>19.049911</td>\n",
       "      <td>4348.0478</td>\n",
       "      <td>19.747824</td>\n",
       "      <td>4243.6060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1575</th>\n",
       "      <td>4083.6550</td>\n",
       "      <td>19.895549</td>\n",
       "      <td>4105.7002</td>\n",
       "      <td>20.260773</td>\n",
       "      <td>4123.1112</td>\n",
       "      <td>19.858133</td>\n",
       "      <td>4136.4760</td>\n",
       "      <td>19.464946</td>\n",
       "      <td>4155.5386</td>\n",
       "      <td>19.925177</td>\n",
       "      <td>...</td>\n",
       "      <td>16.765313</td>\n",
       "      <td>4326.8042</td>\n",
       "      <td>17.981035</td>\n",
       "      <td>4336.8190</td>\n",
       "      <td>19.049911</td>\n",
       "      <td>4348.0478</td>\n",
       "      <td>19.747824</td>\n",
       "      <td>4359.2454</td>\n",
       "      <td>20.202159</td>\n",
       "      <td>4223.3014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1576</th>\n",
       "      <td>4105.7002</td>\n",
       "      <td>20.260773</td>\n",
       "      <td>4123.1112</td>\n",
       "      <td>19.858133</td>\n",
       "      <td>4136.4760</td>\n",
       "      <td>19.464946</td>\n",
       "      <td>4155.5386</td>\n",
       "      <td>19.925177</td>\n",
       "      <td>4170.6204</td>\n",
       "      <td>19.969782</td>\n",
       "      <td>...</td>\n",
       "      <td>17.981035</td>\n",
       "      <td>4336.8190</td>\n",
       "      <td>19.049911</td>\n",
       "      <td>4348.0478</td>\n",
       "      <td>19.747824</td>\n",
       "      <td>4359.2454</td>\n",
       "      <td>20.202159</td>\n",
       "      <td>4358.1352</td>\n",
       "      <td>20.614088</td>\n",
       "      <td>4201.2586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1577</th>\n",
       "      <td>4123.1112</td>\n",
       "      <td>19.858133</td>\n",
       "      <td>4136.4760</td>\n",
       "      <td>19.464946</td>\n",
       "      <td>4155.5386</td>\n",
       "      <td>19.925177</td>\n",
       "      <td>4170.6204</td>\n",
       "      <td>19.969782</td>\n",
       "      <td>4189.6196</td>\n",
       "      <td>19.934622</td>\n",
       "      <td>...</td>\n",
       "      <td>19.049911</td>\n",
       "      <td>4348.0478</td>\n",
       "      <td>19.747824</td>\n",
       "      <td>4359.2454</td>\n",
       "      <td>20.202159</td>\n",
       "      <td>4358.1352</td>\n",
       "      <td>20.614088</td>\n",
       "      <td>4355.0342</td>\n",
       "      <td>21.222026</td>\n",
       "      <td>4182.8684</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1386 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      SMA 50_19     ADX_19  SMA 50_18     ADX_18  SMA 50_17     ADX_17  \\\n",
       "192    967.5256  18.764118   967.4306  20.493217   966.5506  22.303508   \n",
       "193    967.4306  20.493217   966.5506  22.303508   966.3796  23.454945   \n",
       "194    966.5506  22.303508   966.3796  23.454945   968.2714  24.441875   \n",
       "195    966.3796  23.454945   968.2714  24.441875   972.5750  24.385214   \n",
       "196    968.2714  24.441875   972.5750  24.385214   975.9480  24.078679   \n",
       "...         ...        ...        ...        ...        ...        ...   \n",
       "1573  4034.8430  19.071649  4057.7720  19.441324  4083.6550  19.895549   \n",
       "1574  4057.7720  19.441324  4083.6550  19.895549  4105.7002  20.260773   \n",
       "1575  4083.6550  19.895549  4105.7002  20.260773  4123.1112  19.858133   \n",
       "1576  4105.7002  20.260773  4123.1112  19.858133  4136.4760  19.464946   \n",
       "1577  4123.1112  19.858133  4136.4760  19.464946  4155.5386  19.925177   \n",
       "\n",
       "      SMA 50_16     ADX_16  SMA 50_15     ADX_15  ...      ADX_4   SMA 50_3  \\\n",
       "192    966.3796  23.454945   968.2714  24.441875  ...  17.797676  1009.9178   \n",
       "193    968.2714  24.441875   972.5750  24.385214  ...  17.470375  1007.2670   \n",
       "194    972.5750  24.385214   975.9480  24.078679  ...  17.748928  1005.4990   \n",
       "195    975.9480  24.078679   980.1212  23.976865  ...  18.222022  1002.9918   \n",
       "196    980.1212  23.976865   982.6536  23.677467  ...  18.477033   999.7334   \n",
       "...         ...        ...        ...        ...  ...        ...        ...   \n",
       "1573  4105.7002  20.260773  4123.1112  19.858133  ...  17.630929  4314.5094   \n",
       "1574  4123.1112  19.858133  4136.4760  19.464946  ...  16.807307  4319.4746   \n",
       "1575  4136.4760  19.464946  4155.5386  19.925177  ...  16.765313  4326.8042   \n",
       "1576  4155.5386  19.925177  4170.6204  19.969782  ...  17.981035  4336.8190   \n",
       "1577  4170.6204  19.969782  4189.6196  19.934622  ...  19.049911  4348.0478   \n",
       "\n",
       "          ADX_3   SMA 50_2      ADX_2   SMA 50_1      ADX_1   SMA 50_0  \\\n",
       "192   17.470375  1007.2670  17.748928  1005.4990  18.222022  1002.9918   \n",
       "193   17.748928  1005.4990  18.222022  1002.9918  18.477033   999.7334   \n",
       "194   18.222022  1002.9918  18.477033   999.7334  18.713222   994.6312   \n",
       "195   18.477033   999.7334  18.713222   994.6312  18.890864   989.3698   \n",
       "196   18.713222   994.6312  18.890864   989.3698  18.501906   980.6198   \n",
       "...         ...        ...        ...        ...        ...        ...   \n",
       "1573  16.807307  4319.4746  16.765313  4326.8042  17.981035  4336.8190   \n",
       "1574  16.765313  4326.8042  17.981035  4336.8190  19.049911  4348.0478   \n",
       "1575  17.981035  4336.8190  19.049911  4348.0478  19.747824  4359.2454   \n",
       "1576  19.049911  4348.0478  19.747824  4359.2454  20.202159  4358.1352   \n",
       "1577  19.747824  4359.2454  20.202159  4358.1352  20.614088  4355.0342   \n",
       "\n",
       "          ADX_0     SMA 50  \n",
       "192   18.477033   859.0894  \n",
       "193   18.713222   849.0078  \n",
       "194   18.890864   837.3680  \n",
       "195   18.501906   823.4664  \n",
       "196   17.904245   811.0662  \n",
       "...         ...        ...  \n",
       "1573  19.049911  4255.1132  \n",
       "1574  19.747824  4243.6060  \n",
       "1575  20.202159  4223.3014  \n",
       "1576  20.614088  4201.2586  \n",
       "1577  21.222026  4182.8684  \n",
       "\n",
       "[1386 rows x 41 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SMA 50_19</th>\n",
       "      <th>ADX_19</th>\n",
       "      <th>SMA 50_18</th>\n",
       "      <th>ADX_18</th>\n",
       "      <th>SMA 50_17</th>\n",
       "      <th>ADX_17</th>\n",
       "      <th>SMA 50_16</th>\n",
       "      <th>ADX_16</th>\n",
       "      <th>SMA 50_15</th>\n",
       "      <th>ADX_15</th>\n",
       "      <th>...</th>\n",
       "      <th>ADX_4</th>\n",
       "      <th>SMA 50_3</th>\n",
       "      <th>ADX_3</th>\n",
       "      <th>SMA 50_2</th>\n",
       "      <th>ADX_2</th>\n",
       "      <th>SMA 50_1</th>\n",
       "      <th>ADX_1</th>\n",
       "      <th>SMA 50_0</th>\n",
       "      <th>ADX_0</th>\n",
       "      <th>SMA 50</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1578</th>\n",
       "      <td>4136.476</td>\n",
       "      <td>19.464946</td>\n",
       "      <td>4155.5386</td>\n",
       "      <td>19.925177</td>\n",
       "      <td>4170.6204</td>\n",
       "      <td>19.969782</td>\n",
       "      <td>4189.6196</td>\n",
       "      <td>19.934622</td>\n",
       "      <td>4198.6942</td>\n",
       "      <td>19.004087</td>\n",
       "      <td>...</td>\n",
       "      <td>19.747824</td>\n",
       "      <td>4359.2454</td>\n",
       "      <td>20.202159</td>\n",
       "      <td>4358.1352</td>\n",
       "      <td>20.614088</td>\n",
       "      <td>4355.0342</td>\n",
       "      <td>21.222026</td>\n",
       "      <td>4357.3776</td>\n",
       "      <td>22.210426</td>\n",
       "      <td>4162.9976</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      SMA 50_19     ADX_19  SMA 50_18     ADX_18  SMA 50_17     ADX_17  \\\n",
       "1578   4136.476  19.464946  4155.5386  19.925177  4170.6204  19.969782   \n",
       "\n",
       "      SMA 50_16     ADX_16  SMA 50_15     ADX_15  ...      ADX_4   SMA 50_3  \\\n",
       "1578  4189.6196  19.934622  4198.6942  19.004087  ...  19.747824  4359.2454   \n",
       "\n",
       "          ADX_3   SMA 50_2      ADX_2   SMA 50_1      ADX_1   SMA 50_0  \\\n",
       "1578  20.202159  4358.1352  20.614088  4355.0342  21.222026  4357.3776   \n",
       "\n",
       "          ADX_0     SMA 50  \n",
       "1578  22.210426  4162.9976  \n",
       "\n",
       "[1 rows x 41 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (1386, 1, 40) (1386, 1)\n",
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_51 (LSTM)               (None, 1, 25)             6600      \n",
      "_________________________________________________________________\n",
      "lstm_52 (LSTM)               (None, 1, 25)             5100      \n",
      "_________________________________________________________________\n",
      "dropout_41 (Dropout)         (None, 1, 25)             0         \n",
      "_________________________________________________________________\n",
      "lstm_53 (LSTM)               (None, 1, 25)             5100      \n",
      "_________________________________________________________________\n",
      "dropout_42 (Dropout)         (None, 1, 25)             0         \n",
      "_________________________________________________________________\n",
      "lstm_54 (LSTM)               (None, 1, 25)             5100      \n",
      "_________________________________________________________________\n",
      "dropout_43 (Dropout)         (None, 1, 25)             0         \n",
      "_________________________________________________________________\n",
      "lstm_55 (LSTM)               (None, 25)                5100      \n",
      "_________________________________________________________________\n",
      "dropout_44 (Dropout)         (None, 25)                0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 1)                 26        \n",
      "=================================================================\n",
      "Total params: 27,026\n",
      "Trainable params: 27,026\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Y shape (1386, 1)\n",
      "Train on 1386 samples, validate on 278 samples\n",
      "Epoch 1/100\n",
      " - 10s - loss: 0.0940 - mse: 0.0940 - val_loss: 0.4306 - val_mse: 0.4306\n",
      "Epoch 2/100\n",
      " - 0s - loss: 0.0832 - mse: 0.0832 - val_loss: 0.3827 - val_mse: 0.3827\n",
      "Epoch 3/100\n",
      " - 0s - loss: 0.0752 - mse: 0.0752 - val_loss: 0.3329 - val_mse: 0.3329\n",
      "Epoch 4/100\n",
      " - 0s - loss: 0.0680 - mse: 0.0680 - val_loss: 0.2750 - val_mse: 0.2750\n",
      "Epoch 5/100\n",
      " - 0s - loss: 0.0567 - mse: 0.0567 - val_loss: 0.1843 - val_mse: 0.1843\n",
      "Epoch 6/100\n",
      " - 0s - loss: 0.0292 - mse: 0.0292 - val_loss: 0.0378 - val_mse: 0.0378\n",
      "Epoch 7/100\n",
      " - 0s - loss: 0.0259 - mse: 0.0259 - val_loss: 0.0120 - val_mse: 0.0120\n",
      "Epoch 8/100\n",
      " - 0s - loss: 0.0279 - mse: 0.0279 - val_loss: 0.0744 - val_mse: 0.0744\n",
      "Epoch 9/100\n",
      " - 0s - loss: 0.0119 - mse: 0.0119 - val_loss: 0.0128 - val_mse: 0.0128\n",
      "Epoch 10/100\n",
      " - 0s - loss: 0.0102 - mse: 0.0102 - val_loss: 0.0135 - val_mse: 0.0135\n",
      "Epoch 11/100\n",
      " - 0s - loss: 0.0094 - mse: 0.0094 - val_loss: 0.0123 - val_mse: 0.0123\n",
      "Epoch 12/100\n",
      " - 0s - loss: 0.0093 - mse: 0.0093 - val_loss: 0.0123 - val_mse: 0.0123\n",
      "Epoch 13/100\n",
      " - 0s - loss: 0.0093 - mse: 0.0093 - val_loss: 0.0121 - val_mse: 0.0121\n",
      "Epoch 14/100\n",
      " - 0s - loss: 0.0099 - mse: 0.0099 - val_loss: 0.0146 - val_mse: 0.0146\n",
      "Epoch 15/100\n",
      " - 0s - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0119 - val_mse: 0.0119\n",
      "Epoch 16/100\n",
      " - 0s - loss: 0.0089 - mse: 0.0089 - val_loss: 0.0142 - val_mse: 0.0142\n",
      "Epoch 17/100\n",
      " - 1s - loss: 0.0105 - mse: 0.0105 - val_loss: 0.0122 - val_mse: 0.0122\n",
      "Epoch 18/100\n",
      " - 1s - loss: 0.0101 - mse: 0.0101 - val_loss: 0.0155 - val_mse: 0.0155\n",
      "Epoch 19/100\n",
      " - 1s - loss: 0.0108 - mse: 0.0108 - val_loss: 0.0122 - val_mse: 0.0122\n",
      "Epoch 20/100\n",
      " - 1s - loss: 0.0094 - mse: 0.0094 - val_loss: 0.0165 - val_mse: 0.0165\n",
      "Epoch 21/100\n",
      " - 1s - loss: 0.0094 - mse: 0.0094 - val_loss: 0.0122 - val_mse: 0.0122\n",
      "Epoch 22/100\n",
      " - 1s - loss: 0.0082 - mse: 0.0082 - val_loss: 0.0126 - val_mse: 0.0126\n",
      "Epoch 23/100\n",
      " - 1s - loss: 0.0106 - mse: 0.0106 - val_loss: 0.0118 - val_mse: 0.0118\n",
      "Epoch 24/100\n",
      " - 1s - loss: 0.0093 - mse: 0.0093 - val_loss: 0.0155 - val_mse: 0.0155\n",
      "Epoch 25/100\n",
      " - 1s - loss: 0.0093 - mse: 0.0093 - val_loss: 0.0121 - val_mse: 0.0121\n",
      "Epoch 26/100\n",
      " - 1s - loss: 0.0098 - mse: 0.0098 - val_loss: 0.0157 - val_mse: 0.0157\n",
      "Epoch 27/100\n",
      " - 0s - loss: 0.0091 - mse: 0.0091 - val_loss: 0.0123 - val_mse: 0.0123\n",
      "Epoch 28/100\n",
      " - 1s - loss: 0.0079 - mse: 0.0079 - val_loss: 0.0138 - val_mse: 0.0138\n",
      "Epoch 29/100\n",
      " - 0s - loss: 0.0089 - mse: 0.0089 - val_loss: 0.0121 - val_mse: 0.0121\n",
      "Epoch 30/100\n",
      " - 0s - loss: 0.0079 - mse: 0.0079 - val_loss: 0.0148 - val_mse: 0.0148\n",
      "Epoch 31/100\n",
      " - 0s - loss: 0.0086 - mse: 0.0086 - val_loss: 0.0113 - val_mse: 0.0113\n",
      "Epoch 32/100\n",
      " - 0s - loss: 0.0083 - mse: 0.0083 - val_loss: 0.0156 - val_mse: 0.0156\n",
      "Epoch 33/100\n",
      " - 0s - loss: 0.0088 - mse: 0.0088 - val_loss: 0.0121 - val_mse: 0.0121\n",
      "Epoch 34/100\n",
      " - 0s - loss: 0.0077 - mse: 0.0077 - val_loss: 0.0132 - val_mse: 0.0132\n",
      "Epoch 35/100\n",
      " - 0s - loss: 0.0074 - mse: 0.0074 - val_loss: 0.0108 - val_mse: 0.0108\n",
      "Epoch 36/100\n",
      " - 0s - loss: 0.0069 - mse: 0.0069 - val_loss: 0.0111 - val_mse: 0.0111\n",
      "Epoch 37/100\n",
      " - 0s - loss: 0.0070 - mse: 0.0070 - val_loss: 0.0098 - val_mse: 0.0098\n",
      "Epoch 38/100\n",
      " - 0s - loss: 0.0080 - mse: 0.0080 - val_loss: 0.0121 - val_mse: 0.0121\n",
      "Epoch 39/100\n",
      " - 0s - loss: 0.0091 - mse: 0.0091 - val_loss: 0.0107 - val_mse: 0.0107\n",
      "Epoch 40/100\n",
      " - 0s - loss: 0.0092 - mse: 0.0092 - val_loss: 0.0147 - val_mse: 0.0147\n",
      "Epoch 41/100\n",
      " - 0s - loss: 0.0093 - mse: 0.0093 - val_loss: 0.0123 - val_mse: 0.0123\n",
      "Epoch 42/100\n",
      " - 0s - loss: 0.0090 - mse: 0.0090 - val_loss: 0.0145 - val_mse: 0.0145\n",
      "Epoch 43/100\n",
      " - 0s - loss: 0.0087 - mse: 0.0087 - val_loss: 0.0116 - val_mse: 0.0116\n",
      "Epoch 44/100\n",
      " - 0s - loss: 0.0080 - mse: 0.0080 - val_loss: 0.0140 - val_mse: 0.0140\n",
      "Epoch 45/100\n",
      " - 0s - loss: 0.0065 - mse: 0.0065 - val_loss: 0.0113 - val_mse: 0.0113\n",
      "Epoch 46/100\n",
      " - 0s - loss: 0.0063 - mse: 0.0063 - val_loss: 0.0113 - val_mse: 0.0113\n",
      "Epoch 47/100\n",
      " - 0s - loss: 0.0065 - mse: 0.0065 - val_loss: 0.0101 - val_mse: 0.0101\n",
      "Epoch 48/100\n",
      " - 0s - loss: 0.0063 - mse: 0.0063 - val_loss: 0.0098 - val_mse: 0.0098\n",
      "Epoch 49/100\n",
      " - 0s - loss: 0.0056 - mse: 0.0056 - val_loss: 0.0095 - val_mse: 0.0095\n",
      "Epoch 50/100\n",
      " - 0s - loss: 0.0058 - mse: 0.0058 - val_loss: 0.0087 - val_mse: 0.0087\n",
      "Epoch 51/100\n",
      " - 0s - loss: 0.0053 - mse: 0.0053 - val_loss: 0.0086 - val_mse: 0.0086\n",
      "Epoch 52/100\n",
      " - 0s - loss: 0.0054 - mse: 0.0054 - val_loss: 0.0082 - val_mse: 0.0082\n",
      "Epoch 53/100\n",
      " - 0s - loss: 0.0056 - mse: 0.0056 - val_loss: 0.0080 - val_mse: 0.0080\n",
      "Epoch 54/100\n",
      " - 1s - loss: 0.0055 - mse: 0.0055 - val_loss: 0.0081 - val_mse: 0.0081\n",
      "Epoch 55/100\n",
      " - 1s - loss: 0.0061 - mse: 0.0061 - val_loss: 0.0077 - val_mse: 0.0077\n",
      "Epoch 56/100\n",
      " - 0s - loss: 0.0062 - mse: 0.0062 - val_loss: 0.0083 - val_mse: 0.0083\n",
      "Epoch 57/100\n",
      " - 1s - loss: 0.0078 - mse: 0.0078 - val_loss: 0.0082 - val_mse: 0.0082\n",
      "Epoch 58/100\n",
      " - 1s - loss: 0.0090 - mse: 0.0090 - val_loss: 0.0108 - val_mse: 0.0108\n",
      "Epoch 59/100\n",
      " - 1s - loss: 0.0107 - mse: 0.0107 - val_loss: 0.0101 - val_mse: 0.0101\n",
      "Epoch 60/100\n",
      " - 1s - loss: 0.0119 - mse: 0.0119 - val_loss: 0.0192 - val_mse: 0.0192\n",
      "Epoch 61/100\n",
      " - 1s - loss: 0.0087 - mse: 0.0087 - val_loss: 0.0120 - val_mse: 0.0120\n",
      "Epoch 62/100\n",
      " - 1s - loss: 0.0069 - mse: 0.0069 - val_loss: 0.0127 - val_mse: 0.0127\n",
      "Epoch 63/100\n",
      " - 1s - loss: 0.0059 - mse: 0.0059 - val_loss: 0.0098 - val_mse: 0.0098\n",
      "Epoch 64/100\n",
      " - 1s - loss: 0.0059 - mse: 0.0059 - val_loss: 0.0098 - val_mse: 0.0098\n",
      "Epoch 65/100\n",
      " - 1s - loss: 0.0060 - mse: 0.0060 - val_loss: 0.0087 - val_mse: 0.0087\n",
      "Epoch 66/100\n",
      " - 1s - loss: 0.0059 - mse: 0.0059 - val_loss: 0.0088 - val_mse: 0.0088\n",
      "Epoch 67/100\n",
      " - 0s - loss: 0.0068 - mse: 0.0068 - val_loss: 0.0086 - val_mse: 0.0086\n",
      "Epoch 68/100\n",
      " - 0s - loss: 0.0056 - mse: 0.0056 - val_loss: 0.0091 - val_mse: 0.0091\n",
      "Epoch 69/100\n",
      " - 0s - loss: 0.0058 - mse: 0.0058 - val_loss: 0.0086 - val_mse: 0.0086\n",
      "Epoch 70/100\n",
      " - 0s - loss: 0.0051 - mse: 0.0051 - val_loss: 0.0080 - val_mse: 0.0080\n",
      "Epoch 71/100\n",
      " - 0s - loss: 0.0054 - mse: 0.0054 - val_loss: 0.0076 - val_mse: 0.0076\n",
      "Epoch 72/100\n",
      " - 1s - loss: 0.0052 - mse: 0.0052 - val_loss: 0.0073 - val_mse: 0.0073\n",
      "Epoch 73/100\n",
      " - 0s - loss: 0.0056 - mse: 0.0056 - val_loss: 0.0077 - val_mse: 0.0077\n",
      "Epoch 74/100\n",
      " - 1s - loss: 0.0064 - mse: 0.0064 - val_loss: 0.0087 - val_mse: 0.0087\n",
      "Epoch 75/100\n",
      " - 0s - loss: 0.0072 - mse: 0.0072 - val_loss: 0.0081 - val_mse: 0.0081\n",
      "Epoch 76/100\n",
      " - 0s - loss: 0.0075 - mse: 0.0075 - val_loss: 0.0096 - val_mse: 0.0096\n",
      "Epoch 77/100\n",
      " - 1s - loss: 0.0078 - mse: 0.0078 - val_loss: 0.0091 - val_mse: 0.0091\n",
      "Epoch 78/100\n",
      " - 1s - loss: 0.0077 - mse: 0.0077 - val_loss: 0.0109 - val_mse: 0.0109\n",
      "Epoch 79/100\n",
      " - 0s - loss: 0.0075 - mse: 0.0075 - val_loss: 0.0097 - val_mse: 0.0097\n",
      "Epoch 80/100\n",
      " - 1s - loss: 0.0064 - mse: 0.0064 - val_loss: 0.0114 - val_mse: 0.0114\n",
      "Epoch 81/100\n",
      " - 1s - loss: 0.0051 - mse: 0.0051 - val_loss: 0.0092 - val_mse: 0.0092\n",
      "Epoch 82/100\n",
      " - 0s - loss: 0.0048 - mse: 0.0048 - val_loss: 0.0078 - val_mse: 0.0078\n",
      "Epoch 83/100\n",
      " - 0s - loss: 0.0048 - mse: 0.0048 - val_loss: 0.0074 - val_mse: 0.0074\n",
      "Epoch 84/100\n",
      " - 1s - loss: 0.0044 - mse: 0.0044 - val_loss: 0.0074 - val_mse: 0.0074\n",
      "Epoch 85/100\n",
      " - 1s - loss: 0.0045 - mse: 0.0045 - val_loss: 0.0068 - val_mse: 0.0068\n",
      "Epoch 86/100\n",
      " - 1s - loss: 0.0050 - mse: 0.0050 - val_loss: 0.0065 - val_mse: 0.0065\n",
      "Epoch 87/100\n",
      " - 1s - loss: 0.0047 - mse: 0.0047 - val_loss: 0.0068 - val_mse: 0.0068\n",
      "Epoch 88/100\n",
      " - 1s - loss: 0.0044 - mse: 0.0044 - val_loss: 0.0061 - val_mse: 0.0061\n",
      "Epoch 89/100\n",
      " - 0s - loss: 0.0046 - mse: 0.0046 - val_loss: 0.0059 - val_mse: 0.0059\n",
      "Epoch 90/100\n",
      " - 1s - loss: 0.0044 - mse: 0.0044 - val_loss: 0.0059 - val_mse: 0.0059\n",
      "Epoch 91/100\n",
      " - 1s - loss: 0.0042 - mse: 0.0042 - val_loss: 0.0057 - val_mse: 0.0057\n",
      "Epoch 92/100\n",
      " - 1s - loss: 0.0045 - mse: 0.0045 - val_loss: 0.0058 - val_mse: 0.0058\n",
      "Epoch 93/100\n",
      " - 0s - loss: 0.0055 - mse: 0.0055 - val_loss: 0.0059 - val_mse: 0.0059\n",
      "Epoch 94/100\n",
      " - 1s - loss: 0.0073 - mse: 0.0073 - val_loss: 0.0081 - val_mse: 0.0081\n",
      "Epoch 95/100\n",
      " - 1s - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0078 - val_mse: 0.0078\n",
      "Epoch 96/100\n",
      " - 0s - loss: 0.0117 - mse: 0.0117 - val_loss: 0.0179 - val_mse: 0.0179\n",
      "Epoch 97/100\n",
      " - 0s - loss: 0.0103 - mse: 0.0103 - val_loss: 0.0098 - val_mse: 0.0098\n",
      "Epoch 98/100\n",
      " - 1s - loss: 0.0092 - mse: 0.0092 - val_loss: 0.0158 - val_mse: 0.0158\n",
      "Epoch 99/100\n",
      " - 0s - loss: 0.0063 - mse: 0.0063 - val_loss: 0.0101 - val_mse: 0.0101\n",
      "Epoch 100/100\n",
      " - 0s - loss: 0.0054 - mse: 0.0054 - val_loss: 0.0083 - val_mse: 0.0083\n",
      "real [[4162.9976]]\n",
      "Test RMSE: 144.125\n",
      "Diff [[-144.12504457]]\n",
      "% Diff [[-3.46204967]] %\n",
      "Predictions [[4307.12264457]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAtCklEQVR4nO3de5wddX3/8dfnXPZy9r65ZzeQACEhQQgQAtYbKlouQqhSRAW12iJVq/KrF2xta29W+6ttbZUiAhUrggpy+WEEBaGI3BIgckkIJEDI5p5N9r579lw+vz9mNjlZNptN2JOTPfN+PrKPPWdmzsz3u7uZ98z3O/Mdc3dERCS6YqUugIiIlJaCQEQk4hQEIiIRpyAQEYk4BYGISMQpCEREIk5BIJFiZt83s38Y47KvmNmZxS6TSKkpCEREIk5BIDIBmVmi1GWQ8qEgkMNO2CTzBTN72sx6zew6M5tmZr8ws24zu9fMmgqWP9/MnjOzDjN7wMyOK5h3kpk9GX7ux0DVsG29x8xWhp992MxOGGMZzzWzp8ysy8w2mNlXh81/c7i+jnD+R8Pp1Wb2TTNbb2adZvZQOO0MM2sb4edwZvj6q2Z2i5n90My6gI+a2RIzeyTcxmYz+7aZVRR8fqGZ/crMdprZVjP7CzObbmZ9ZjapYLlTzGy7mSXHUncpPwoCOVy9D3gXcCxwHvAL4C+AyQR/t58BMLNjgZuAzwFTgGXA/zOzinCneDvwP0Az8NNwvYSfPRm4HvgEMAn4LnCnmVWOoXy9wIeBRuBc4E/N7IJwvUeE5f3PsEyLgJXh5/4FOAX4vbBMXwTyY/yZLAVuCbd5I5ADriD4mbwReCfwybAMdcC9wN3ATOAY4D533wI8AFxUsN5LgJvdPTPGckiZURDI4eo/3X2ru28EfgM85u5PuXsauA04KVzu/cDP3f1X4Y7sX4Bqgh3t6UAS+Hd3z7j7LcDygm38CfBdd3/M3XPufgOQDj83Knd/wN2fcfe8uz9NEEZvC2d/CLjX3W8Kt9vu7ivNLAZ8DPisu28Mt/lwWKexeMTdbw+32e/uT7j7o+6edfdXCIJsqAzvAba4+zfdfcDdu939sXDeDQQ7f8wsDnyAICwlohQEcrjaWvC6f4T3teHrmcD6oRnungc2AC3hvI2+98iK6wteHwn8edi00mFmHcCs8HOjMrPTzOz+sEmlE7ic4MiccB3rRvjYZIKmqZHmjcWGYWU41szuMrMtYXPR18ZQBoA7gAVmdhTBWVenuz9+kGWSMqAgkIluE8EOHQAzM4Kd4EZgM9ASThtyRMHrDcA/untjwVfK3W8aw3Z/BNwJzHL3BuBqYGg7G4CjR/jMDmBgH/N6gVRBPeIEzUqFhg8V/F/A88Bcd68naDrbXxlw9wHgJwRnLpeis4HIUxDIRPcT4Fwze2fY2fnnBM07DwOPAFngM2aWMLP3AksKPvs94PLw6N7MrCbsBK4bw3brgJ3uPmBmS4APFsy7ETjTzC4KtzvJzBaFZyvXA/9qZjPNLG5mbwz7JF4AqsLtJ4GvAPvrq6gDuoAeM5sP/GnBvLuA6Wb2OTOrNLM6MzutYP4PgI8C5wM/HEN9pYwpCGRCc/c1BO3d/0lwxH0ecJ67D7r7IPBegh3eLoL+hJ8VfHYFQT/Bt8P5a8Nlx+KTwN+ZWTfw1wSBNLTeV4FzCEJpJ0FH8Ynh7M8DzxD0VewEvgHE3L0zXOe1BGczvcBeVxGN4PMEAdRNEGo/LihDN0Gzz3nAFuBF4O0F839L0En9ZNi/IBFmejCNSDSZ2a+BH7n7taUui5SWgkAkgszsVOBXBH0c3aUuj5SWmoZEIsbMbiC4x+BzCgEBnRGIiESezghERCJuwg1cNXnyZJ89e3apiyEiMqE88cQTO9x9+L0pwAQMgtmzZ7NixYpSF0NEZEIxs/X7mqemIRGRiFMQiIhEnIJARCTiJlwfwUgymQxtbW0MDAyUuihFV1VVRWtrK8mkniEiIuOjLIKgra2Nuro6Zs+ezd4DTZYXd6e9vZ22tjbmzJlT6uKISJkoi6ahgYEBJk2aVNYhAGBmTJo0KRJnPiJy6JRFEABlHwJDolJPETl0yiYI9ivTD12bIJ8tdUlERA4r0QmC7CD0bIXsWB8PO3YdHR1cddVVB/y5c845h46OjnEvj4jIgYhOECQqgu+HMAhyudyon1u2bBmNjY3jXh4RkQNRFlcNjUk8fOpfbnDcV33llVeybt06Fi1aRDKZpLa2lhkzZrBy5UpWrVrFBRdcwIYNGxgYGOCzn/0sl112GbBnuIyenh7OPvts3vzmN/Pwww/T0tLCHXfcQXV19biXVURkuLILgr/9f8+xalPXyDMHeyHWAYmXD2idC2bW8zfnLdzn/K9//es8++yzrFy5kgceeIBzzz2XZ599dvclntdffz3Nzc309/dz6qmn8r73vY9JkybttY4XX3yRm266ie9973tcdNFF3HrrrVxyySUHVE4RkYNRdkEwKovBIXj+wpIlS/a6zv8//uM/uO222wDYsGEDL7744muCYM6cOSxatAiAU045hVdeeaXo5RQRgTIMgtGO3OlYDwNdMP0NRS1DTU3N7tcPPPAA9957L4888gipVIozzjhjxPsAKisrd7+Ox+P09/cXtYwiIkOi01kMQT9BPgv50TtxD1RdXR3d3SM/8a+zs5OmpiZSqRTPP/88jz766LhuW0Tk9Sq7M4JRJQo6jGPj1xE7adIk3vSmN3H88cdTXV3NtGnTds8766yzuPrqqznhhBOYN28ep59++rhtV0RkPEy4ZxYvXrzYhz+YZvXq1Rx33HH7//BgH+xYA01zoLqxOAU8BMZcXxGRkJk94e6LR5oXraahoXsJcuN/L4GIyEQVrSCIJcDiRbmpTERkoipqEJjZWWa2xszWmtmVoyx3qpnlzOzCYpYHCPoJFAQiIrsVLQjMLA58BzgbWAB8wMwW7GO5bwD3FKsse0lUFuXuYhGRiaqYZwRLgLXu/pK7DwI3A0tHWO7PgFuBbUUsyx7xMAg8f0g2JyJyuCtmELQAGwret4XTdjOzFuAPgKtHW5GZXWZmK8xsxfbt219fqXYPPqezAhERKG4QjPQEleHXqv478CV3H/UOL3e/xt0Xu/viKVOmvL5SFXHwubGqra0t2bZFRIYr5g1lbcCsgvetwKZhyywGbg6fujUZOMfMsu5+e9FKNXRTmTqMRUSA4gbBcmCumc0BNgIXAx8sXMDdd4/MZmbfB+4qaghAeAlpbFzvJfjSl77EkUceySc/+UkAvvrVr2JmPPjgg+zatYtMJsM//MM/sHTpSF0kIiKlVbQgcPesmX2a4GqgOHC9uz9nZpeH80ftFzhov7gStjwz+jKZPjCDxBiHmZj+Bjj76/ucffHFF/O5z31udxD85Cc/4e677+aKK66gvr6eHTt2cPrpp3P++efrmcMictgp6lhD7r4MWDZs2ogB4O4fLWZZ9mI2rlcNnXTSSWzbto1Nmzaxfft2mpqamDFjBldccQUPPvggsViMjRs3snXrVqZPnz5u2xURGQ/lN+jcKEfuu3VthJ7tMOPEIBTGwYUXXsgtt9zCli1buPjii7nxxhvZvn07TzzxBMlkktmzZ484/LSISKlFa4iJIfFKwCGXGbdVXnzxxdx8883ccsstXHjhhXR2djJ16lSSyST3338/69evH7dtiYiMp/I7IxiL3cNRp/fcV/A6LVy4kO7ublpaWpgxYwYf+tCHOO+881i8eDGLFi1i/vz547IdEZHxFs0giA/dVJaGyrpxW+0zz+zppJ48eTKPPPLIiMv19PSM2zZFRF6viDYNVQCmMYdERIhqEJhBPKlhJkREKKMgOOAnrcUrJ+QDaibaE+VE5PBXFkFQVVVFe3v7ge0kExUTrmnI3Wlvb6eqqqrURRGRMlIWncWtra20tbVxQCOTDnTBQAfsjAVDTkwQVVVVtLa2lroYIlJGyiIIkskkc+bM2f+ChZ67He74CFz+EExfWJRyiYhMBBPnUHi8Nc0Ovu98uaTFEBEpNQXBrldKWQoRkZKLbhBUN0JVo4JARCIvukEA0DxHQSAikRftIGiarSAQkchTEHS8CvlRH5ksIlLWFAT5DHQNf5SyiEh0KAhAzUMiEmkKAlAQiEikRTsI6lvB4goCEYm0aAdBPAGNsxQEIhJp0Q4C0CWkIhJ5CgIFgYhEnIKgaTb07YB0d6lLIiJSEgoCXTkkIhGnIFAQiEjEKQgaZgXfOzeWthwiIiWiIEhNgkQVdLWVuiQiIiWhIDCD+hboVBCISDQpCAAaWtQ0JCKRpSCAYKiJLgWBiESTggCCM4LuzZDLlrokIiKHnIIAoKEVPB+EgYhIxCgIIGgaAjUPiUgkKQggaBoCXTkkIpGkIIDg8lFQEIhIJCkIAKrqobJBTUMiEkkKgiG6l0BEIqqoQWBmZ5nZGjNba2ZXjjB/qZk9bWYrzWyFmb25mOUZVUMrdG4o2eZFREqlaEFgZnHgO8DZwALgA2a2YNhi9wEnuvsi4GPAtcUqz37Vt6hpSEQiqZhnBEuAte7+krsPAjcDSwsXcPced/fwbQ3glEpDC/S1Q6a/ZEUQESmFYgZBC1DY1tIWTtuLmf2BmT0P/JzgrOA1zOyysOloxfbt24tS2D33EmwqzvpFRA5TxQwCG2Haa4743f02d58PXAD8/Ugrcvdr3H2xuy+eMmXK+JZySEMYBOonEJGIKWYQtAGzCt63Avs83Hb3B4GjzWxyEcu0b7tvKlM/gYhESzGDYDkw18zmmFkFcDFwZ+ECZnaMmVn4+mSgAmgvYpn2beimMnUYi0jEJIq1YnfPmtmngXuAOHC9uz9nZpeH868G3gd82MwyQD/w/oLO40MrUQk1U9U0JCKRU7QgAHD3ZcCyYdOuLnj9DeAbxSzDAdFNZSISQbqzuJDuJRCRCFIQFGqYFQw8V6LWKRGRUlAQFGpogcEeGOgsdUlERA4ZBUEhXTkkIhGkICi0+6YyBYGIRIeCoFD9zOC7zghEJEIUBIVSk4Lv/TtLWw4RkUNIQVAoWQ2JaujfVeqSiIgcMgqC4VLN0KcgEJHoUBAMV92kpiERiRQFwXDVTdCnIBCR6FAQDJdqVh+BiESKgmC46mY1DYlIpCgIhqtuCs4INN6QiESEgmC4VDPks5DuKnVJREQOCQXBcNXNwXf1E4hIRCgIhkuFQaArh0QkIhQEw1U3Bd/VYSwiEaEgGG6oaUh3F4tIRCgIhkupj0BEokVBMFxVY/BdTUMiEhEKguHiCahsUGexiESGgmAkKQ08JyLRoSAYSbXGGxKR6FAQjCTVrKYhEYkMBcFI9EwCEYmQMQWBmX3WzOotcJ2ZPWlm7y524UqmWk8pE5HoGOsZwcfcvQt4NzAF+CPg60UrVamlmiHdCblsqUsiIlJ0Yw0CC7+fA/y3u/+uYFr5Gbq7eKCjpMUQETkUxhoET5jZLwmC4B4zqwPyxStWiQ2NN6QOYxGJgMQYl/s4sAh4yd37zKyZoHmoPKU08JyIRMdYzwjeCKxx9w4zuwT4CtBZvGKVmJ5JICIRMtYg+C+gz8xOBL4IrAd+ULRSlZqeSSAiETLWIMi6uwNLgW+5+7eAuuIVq8T0TAIRiZCx9hF0m9mXgUuBt5hZHEgWr1glVlkPsYTOCEQkEsZ6RvB+IE1wP8EWoAX4v0UrVamZhXcXq49ARMrfmIIg3PnfCDSY2XuAAXcv3z4CCAee0xmBiJS/sQ4xcRHwOPCHwEXAY2Z24Rg+d5aZrTGztWZ25QjzP2RmT4dfD4ed0YeH6iY1DYlIJIy1j+AvgVPdfRuAmU0B7gVu2dcHwn6E7wDvAtqA5WZ2p7uvKljsZeBt7r7LzM4GrgFOO/BqFEGqGTpeLXUpRESKbqx9BLGhEAi1j+GzS4C17v6Suw8CNxNcdbSbuz/s7kMN8Y8CrWMsT/HpmQQiEhFjPSO428zuAW4K378fWLafz7QAGwretzH60f7HgV+MNMPMLgMuAzjiiCPGUt7XL6WmIRGJhjEFgbt/wczeB7yJYLC5a9z9tv18bKRB6XzEBc3eThAEb97H9q8haDZi8eLFI65j3FU3QbYfMv2QrD4kmxQRKYWxnhHg7rcCtx7AutuAWQXvW4FNwxcysxOAa4Gz3b39ANZfXIXDTCgIRKSMjRoEZtbNyEfxBri714/y8eXAXDObA2wELgY+OGz9RwA/Ay519xcOpOBFVzjMRP3M0pZFRKSIRg0Cdz/oYSTcPWtmnwbuAeLA9e7+nJldHs6/GvhrYBJwlZlBMJTF4oPd5rjafUagfgIRKW9jbho6GO6+jGGdymEADL3+Y+CPi1mGg6ZnEohIROjh9fuS0lDUIhINCoJ92T0CqYJARMqbgmBfElVgMRjsLXVJRESKSkGwL2ZQUQuZvlKXRESkqBQEo0mmYLCn1KUQESkqBcFoKmpgUGcEIlLeFASjqahRH4GIlD0FwWgqatQ0JCJlT0EwmooadRaLSNlTEIwmmVLTkIiUPQXBaCpq1VksImVPQTCaCl0+KiLlT0EwGl01JCIRoCAYTbIGcmnIZUtdEhGRolEQjKaiJvie0VmBiJQvBcFohoJAHcYiUsYUBKPZHQQ6IxCR8qUgGI2ahkQkAhQEo0mmgu86IxCRMqYgGE1FbfBdQSAiZUxBMJoKnRGISPlTEIxGncUiEgEKgtEMNQ1pBFIRKWMKgtHs7izWeEMiUr4UBKNJVgOmG8pEpKwpCEZjpoHnRKTsKQj2R4+rFJEypyDYn2RKncUiUtYUBPtTUaumIREpawqC/VEfgYiUOQXB/lToAfYiUt4UBPtTUaM+AhEpawqC/UnqqiERKW8Kgv1RH4GIlDkFwf5UpHRnsYiUNQXB/lTUQrYf8rlSl0REpCgUBPuz+3GVOisQkfJU1CAws7PMbI2ZrTWzK0eYP9/MHjGztJl9vphlOWh6XKWIlLlEsVZsZnHgO8C7gDZguZnd6e6rChbbCXwGuKBY5Xjd9LhKESlzxTwjWAKsdfeX3H0QuBlYWriAu29z9+VApojleH30uEoRKXPFDIIWYEPB+7Zw2sSix1WKSJkrZhDYCNP8oFZkdpmZrTCzFdu3b3+dxTpAyaHOYgWBiJSnYgZBGzCr4H0rsOlgVuTu17j7YndfPGXKlIMqzI6eNP/2qxfI5Q8wi3RGICJlrphBsByYa2ZzzKwCuBi4s4jbG9XD69r51n0v8qPH1h/YB3cHgS4fFZHyVLQgcPcs8GngHmA18BN3f87MLjezywHMbLqZtQH/B/iKmbWZWX0xynPeCTN40zGT+Od71rCte2DsH9wdBBpvSETKU1HvI3D3Ze5+rLsf7e7/GE672t2vDl9vcfdWd69398bwdVcxymJm/P3S40ln8nzt56vH/kE1DYlImYvUncVHTanlE287ittXbuLhtTvG9qFEdfBddxaLSJmKVBAAfOrtx3BEc4qv3PEs6ewYxg+KxcKhqHVGICLlKXJBUJWM83dLF/LS9l7+6vZncR/DVUR6SpmIlLHIBQHAGfOm8mfvOIafrGjjuode3v8H9EwCESljkQwCgCvOPJazFk7na8tWc/+abaMvnNTjKkWkfEU2CGIx41/ffyLzp9fzmR89xZot3fteuGKUx1W2r4Oug7pPTkTksBDZIABIVSS49iOLSVXGufS6x9iwcx9H/aM1Df30o7DsC0Uro4hIsUU6CABmNlbzg4+dRjqb59LrHmN7d/q1C1XU7PvO4l3rgy8RkQkq8kEAMG96Hdd/9FS2dqX5yPWP0zUwbFTsfTUNpXsg3QndahoSkYlLQRA65cgm/uuSk1mztZuv/+L5vWcmUyN3FndvDr73tUPmAIatEBE5jCgICpwxbyqXnn4kNz3+Ks9u7NwzY199BIWdxEOhICIywSgIhrniXcfSnKrgq3c+t+dms4rw8tF8fu+FC3f+unJIRCYoBcEwDdVJvnjWPFas38XtKzcGE4cGnhvePKQzAhEpAwqCEfzhKbM4sbWBf1r2PD3p7L5HIO3eDPHK4HXXxkNbSBGRcaIgGEEsZvzt0uPZ1p0OHmSzr8dVdm2C5jlQUaemIRGZsBQE+7BoViNHT6nhkXXt+z4j6NoEdTOgfqaCQEQmLAXBKJbMmcSKV3aRS6SCCcNvKuveHIRA/QwFgYhMWAqCUZw2p5nudJb1Q/eSFd5UlstCz9YwCFrUWSwiE5aCYBSnzmkG4Jlt4Z3GhU1DvdvA80HTUN0M6N4C+TE86EZE5DCjIBhFS2M1LY3VPLk5DILCy0e7wjOA+pnBl+egZz/DWYuIHIYUBPuxZE4zj7aFw0cUNg0NjS801FkM6icQkQlJQbAfS+Y009Yb/pgKO4uHdvpDZwSgwedEZEJKlLoAh7slc5rpJ7xprLCPoGsTxJKQmgzYnmkiIhOMzgj246jJNTTXVtEXq9v7iL97c9AsFItBahLEK3R3sYhMSAqC/TAzTp3dzFPMg1d+u2dG16bg/gEIwqBu+p4OZBGRCURBMAanzm7m1+n5sHMddLYFE4fOCIbUt6hpSEQmJAXBGCyZ08zD+YXBm5d/A+7B0X99y56F6maos1hEJiQFwRgcN6Oerrq57PRaHr//dl7euAkyvazYVcXHvr+c7//25T3jDQ09w0BEZIJQEIxBPGbc9um3sLX5VFo7lvOJq+4C4IZn0jy8bgff/OULpFPTITsA/btKXFoRkQOjIBijqfVVHPfGc5lp7Xz5uHYAvnTR2/nhx0+jO53l8faqYEH1E4jIBKMgOBBz3gbA29O/BqD1yGM45cgmjptRz8/Who+xVBCIyASjIDgQk+dC7XRoWx68r5uBmXHp6Ufy2I7wjEAdxnKo5HNw95dh1R2lLokcjP6OUpdgNwXBgTCDOW8NXqcmQSK443jpopn0V04mj5X+jCCfg5U/gg3Lx2FdecgMvP71SHH85pvw6FXw0z+CNb8odWnkQPzux/CN2fDEDa+d1731kF90oiA4UENBUDdz96SaygRLT5nNDm9gYGdb8Evs3QG97WNbZ6YfnrkF7v4LWP/w3n8EHa8GO/Ytz+6Z3r0VfvlXwR/S/7wXXn00mL71ObjuXXD7nwbfl30B0t2jb/uVh+B774B/XQCPXBWUxR1evBeueSv8Uwvc+RnYtX7PZ3q2BdtMFwzCl03D0z+FW/8Ynr01CBEIntvw8Lfha61w7buCy2/Hmzs8/3P4+Z/DmrshNzRa7EAw/b6/h41P7P2ZwV5Ye+/Yf0eHm/WPwAP/BAsugBknwk8/uvcNj3L46t4Kv/giWCz4m13/8J55j14N35wHP77ktQ/CKiLzCXa54+LFi33FihWlK8Cu9fCtE2Duu+FDP909ee22bvq+/RaOi28kEY9h2fBIum4GTH8DNM0OfvEYxOKQqAq+ujcFO86BzmC+52HqAph3drDTbHt8z7brZkLLycEOLDcIx54FGx6Hvh0w8yTY8gxUNcC7/xE2r4THvhvc6zD/3CAQBjqDs5jGI6BxFqy9D9Ysg/rWoHzrHwqavppmw4ZHofFImPOWYAfvOTjq7dD+Iux6JShPLAmti2HKPFh9V1COZE3wbOdpb4DTPgErroNNTwX9KzteDOp71BlBGbathm3PB69PuCj4GhrAL58Lfh5me+qfy8C6XwfhOGNR8HPt2hj8p1p7L8QSkM8GZ2utS4KQGywIwlmnw4nvD0Js9V1BOeMVwc508cdg0tF7wjY1CeKH6VBcfTvxq99C1hL85h0/Y97kClpue2/wTIzT/zS42bGzLfj9nfYJmHpcqUs8vrLp4Oq8uumlLsmBc4cfX4K/+CueedePWPDYF0mkO+FPfg0rroff/jvMPDn4PzNzEXzg5nGrp5k94e6LR5ynIDgI331bsBN++5f3mnztt7/G9K0PsIXJxBpncURjktnZl5nW9wLV/VvCoekcy2exXBrzPPl4JVtbfp/V08/nlar5HNf+K+a33UJT53P0Ny8gu+APSMw9k43PP4a/cA+TO37Hc9VL+M20S0k3zKGvp5Pjt9zG27qX8UrVfJ6a/3nmzpnNlLpK6nc8yRGP/BVVPW1YdQNW1YBn+vCODcTyGfotxeOtH6H/lE/QOqWZms2PMPWJfyPZtYH18z/O6pb3ks4nmJXoYP7aa6nf+CCx6Qth1mnQNCfoK3n5f4MzkbnvhlM/DrPfCs/dBvf/I+x6GWqmwNnfgIXvDS6vXX4dPPRvQeBNWxiEyOanw8CzYAc82AvZfqisD452Zy4Kzj5W3QH9O3f/vD2WAAxPVNJ1+hfpXvAh4q8+SO3zt1K1bSXpI96CL7iAyiMXU/HsT7DHvxuEWFUDLPwDmPv7QbD87ua9AwOCkJ4yD6YuhLppQcAlq4PnV1fWBetITYKGWVAzee/AGk/dW2DljeSe+Rm92RibvQnr3szszDreN/i3PONHEY8ZH16Q4MvbPk9F13qomQoNLUHQZgfg6HcEf68WNgBUNQR1m3xsUKfRZAeDwKyoK04wZgZgy9PBQUp1U/DVvQVeeiD42+rdAdMWwPQTgt/JSw8ER9DZ/uBv4/gLYeEFwcHEYW5n7yCr772BNz31ef4590GuyryHo2wTd1T+NYkYVOf7WH/0B8m+++scteu32K1/HPw8zrgSjnnnnoOkg6QgGG/uI/7HH8zmWf7KTh5au4Pfrt3B85u7Gczl97maODkMJzvCILD19NJFzV7TzODYqXWYQVd/hu6BLA2pJNPrq5hSV8nGjn5Wb+4ik3vt77S2MsExU2tp29VHe88Ax1T1UNfQxNPb82TzY/8baG2qZv70elqbqmnb1ceL23rYuKuPlqYUc6fWcuSkGroHMmzv7GX6rid4KXE02cpGKhMx+gZzdPVn6OwbpKmmgrnT6pg7tZYp9VVMGWzj6C2/oC7TTjJVR1WqjmR6J7HNK4lvexa3OFtmvIOnGs7kqYEWbMvvmNL1LLH8IN/NvoftNI1a7njMSCXgDcmN9NYdxeTGemY0VnH8zAZObangqPYHsXRXsLB7EBjbVsHWVdDXDvnMvleeqILq5uBMzyx83wRVjUFoxJPB2UosXvDLjAWhUlEHiYrgCLd3B/TtJAd0pp3erg5m7nqcOHmW5+fR55XMiO1karyX3876E3qP/zCzJ9fwy+e28KPHXyU9OMiSI+o57diZvPmYyZzQnKNi5ffh8e8Fj1UdzsIBE/O54MvzQVnjFbgZNtC598OYKuuhuhFqpwVfNVOCUKlqgKp6qKiFZAoqUsFRe7oH0l3Bz7J9bXBGaEYuNYW+RCPWvZnUzueIjfCzzRNje/0C+iqnMal3LXV9r2I4maZjiM99B7G6GbD6zuDIGYIz75knBWeJqclBeSrrgp+7xcK6Ngdlrpmyu39vL/v4f33Q+nbS88xdbFn1W9btHGRdR46LYvezIz6FW0/6PqcfM42Xd/TSv/qXfHzT33BV5jy+nbsAMI6bUc8Vxw9w5jOfJ9bxSrC+KcfBGz8FJ196UMVREJSIu7Ozd5DNnQPs7B0kk8szmA12vDEzYgYViRiTaiuDI/iqBP2ZHL3pYIe5rTvN1q4BOvoGWTCznlOObKahOjnqNtPZHC9s6aGzP0PenVze2dTZz4tbe1izpZummiRLF7VwxrwpVCbipLM51mzpZnPnnk7hZNxoqK6gMZUkGYuxtXuAzZ0DbNjZx/Nbulm9uYuNu/o5ojnFMdNqaW2spq2jn7Vbe1i/s5f6qiTTG6qYWleJOwxkcwxk8qQq4jRUJ6mrSrKjJ83abT2sb+9lfzmUJIvhDBLUfWpdJfOm1zFvWh1HTEqRiMWIxyAei1GRiFERN8DoG8zSPZClJ52lfzDHQCZH72CWbV1pNncO0Larj66BLAAN1Ukm1VSQiBuJWIy8O9m8k83licWM6lie2liGqVVZWqozzKjK0Owd1AxspnZgM6lcD5VxpyJuVHiaxGAniXQniWxvcAboWcxzgAX/PEci20cynwYgQ5LOeCPdVsdAJkfMg8eerkguZvWMC5g8eyGnzm7m5COaqK6Iv+ZntKt3kBsfW8+vVm3l6Y2duAfhN6upmmMmV3NEdZpYDAwjld1Fc9/LTO1/ibpsO3lLQCxBLu/0DwwwMDBALpcjlmqkun4ydXV1VGR7SWa6qMx00JjvoC7bTlW6nUSme8QdeaGsVbAl2corzKQvk6cu28Fk62QndTyVn8tT+WPY7g3UWy+N9NJLFY/lj9vrQCjFADUMsJ3goOLoKbUsmFnPGxs7OCm9nOaOZ0m1P0Ny1zqM/e/TPJbEkyny8argd5PpC5pzK+uw+pZgQMnK+qDpMF4RBkS4Xhtq2q0Mwt3z4Hmy2Qw9vf109/WRb3+Z1q4niZOny6uJG1QzSL66ifhHbsemv2HvAuWy9GRh3bYenm7r4IePvsqard1MSiU5f8Yufs+eZmHfCnzB+bSc+an91m8kJQsCMzsL+BYQB651968Pm2/h/HOAPuCj7v7kaOucSEEg+5fO5ujsz9A/GARgZ3+Gnb2D7OxNk87mScSMRDxGfXWSoybXMHtyDbWV49NE4e68vKOXFa/s4qkNHfSks2RzeTK5PDEzkvEY8ZiRd2cwm2cwl6ejL8P27jTbu9O7z/aScSOb9wO+0MMMpqYSTKsxPFFNPB6jMhHjDS0NLJ7dzOLZTUyuHeHIdT86+gZ5eF07qzZ18dKOHl7a3suuvkHc2R26lYkgNM0gl3eyOScRN2Y1pThiUoq6qgQvbOlm9eZutnQN7C5vzIzcXsntVJKhnj6qLU0NA1STZpAEPVTT69X0JZuY3phiZmM1rU0pWpuqaW2qZnJtJamKODWVCaqTcVIVcVIVCRLxYBt5dzJZpz+Toz+To70nzbrtPazd1sOarT08t7GT9t7BvepeQYY6+qizPmrpJ4YTN6euAprooZkgyJL5oJxVDJIlTj+VDJCkjn5a4jtpsV2k6CdBloRn2H2eYEaCHBVkqWCQOHlyxMhj5DxGhjiDJNnldayqeyOZuedy3Mlv5YRZjZjZmM863J2H17Xzo8df5YUt3WzY1cdAJs+n3n40X/j9+Qf8NxEUvQRBYGZx4AXgXUAbsBz4gLuvKljmHODPCILgNOBb7n7aaOtVEMjhwN3Jh0fdEOxMu/ozdPRnGMjkwjOTGMl4jGTcSCZiwU405wzm8jhOc6qCRPzwv3BvIJMjHjMSYV07w7PV9p5BKhJGVTJOZSIOOIPZ4Cy0uiJGbWWSmso4tZWJYCc4ztydrV1BOPSms0FgDOZ2z8879KazdA0EzajA7jPx+uokTTUVNFYnybvTN5ijN52lN52jJ52hJx2spzIRhDMGuVxwljgYntmns8GBQCoZp7oiTmMqyZzJNcyZXMNRU2rH7YBlqK7be9LEzA7q4ABGD4JiXhaxBFjr7i+FhbgZWAqsKlhmKfADD9LoUTNrNLMZ7q6B/eWwZmbEC/Zt8ZjRVFNBU01F6QpVJFXJvZuiGlMVNKYqYFqJChQyM6Y3VDG9oaq0BTkEzIypdcWrZzEPR1qADQXv28JpB7oMZnaZma0wsxXbt28f94KKiERZMYNgpHPB4e1QY1kGd7/G3Re7++IpU6aMS+FERCRQzCBoA2YVvG8Fho+/MJZlRESkiIoZBMuBuWY2x8wqgIuBO4ctcyfwYQucDnSqf0BE5NAqWmexu2fN7NPAPQSXj17v7s+Z2eXh/KuBZQRXDK0luHz0j4pVHhERGVlRB1Nx92UEO/vCaVcXvHbg4O6OEBGRcXH4X8QsIiJFpSAQEYm4CTfWkJltB9bvd8GRTQZ2jGNxJooo1juKdYZo1juKdYYDr/eR7j7i9fcTLgheDzNbsa9brMtZFOsdxTpDNOsdxTrD+NZbTUMiIhGnIBARibioBcE1pS5AiUSx3lGsM0Sz3lGsM4xjvSPVRyAiIq8VtTMCEREZRkEgIhJxkQkCMzvLzNaY2Vozu7LU5SkGM5tlZveb2Woze87MPhtObzazX5nZi+H30Z/0PgGZWdzMnjKzu8L3Uahzo5ndYmbPh7/zN0ak3leEf9/PmtlNZlZVbvU2s+vNbJuZPVswbZ91NLMvh/u2NWb2+we6vUgEQfjYzO8AZwMLgA+Y2YLSlqoossCfu/txwOnAp8J6Xgnc5+5zgfvC9+Xms8DqgvdRqPO3gLvdfT5wIkH9y7reZtYCfAZY7O7HEwxoeTHlV+/vA2cNmzZiHcP/4xcDC8PPXBXu88YsEkFAwWMz3X0QGHpsZllx983u/mT4uptgx9BCUNcbwsVuAC4oSQGLxMxagXOBawsml3ud64G3AtcBuPugu3dQ5vUOJYBqM0sAKYJnmJRVvd39QWDnsMn7quNS4GZ3T7v7ywSjOS85kO1FJQjG9EjMcmJms4GTgMeAaUPPeQi/Ty1h0Yrh34EvAvmCaeVe56OA7cB/h01i15pZDWVeb3ffCPwL8CqwmeAZJr+kzOsd2lcdX/f+LSpBMKZHYpYLM6sFbgU+5+5dpS5PMZnZe4Bt7v5EqctyiCWAk4H/cveTgF4mfnPIfoXt4kuBOcBMoMbMLiltqUrude/fohIEkXkkppklCULgRnf/WTh5q5nNCOfPALaVqnxF8CbgfDN7haDJ7x1m9kPKu84Q/E23uftj4ftbCIKh3Ot9JvCyu2939wzwM+D3KP96w77r+Lr3b1EJgrE8NnPCMzMjaDNe7e7/WjDrTuAj4euPAHcc6rIVi7t/2d1b3X02we/11+5+CWVcZwB33wJsMLN54aR3Aqso83oTNAmdbmap8O/9nQR9YeVeb9h3He8ELjazSjObA8wFHj+gNbt7JL4IHon5ArAO+MtSl6dIdXwzwSnh08DK8OscYBLBVQYvht+bS13WItX/DOCu8HXZ1xlYBKwIf9+3A00RqfffAs8DzwL/A1SWW72Bmwj6QDIER/wfH62OwF+G+7Y1wNkHuj0NMSEiEnFRaRoSEZF9UBCIiEScgkBEJOIUBCIiEacgEBGJOAWByCFkZmcMjZAqcrhQEIiIRJyCQGQEZnaJmT1uZivN7Lvh8w56zOybZvakmd1nZlPCZReZ2aNm9rSZ3TY0TryZHWNm95rZ78LPHB2uvrbgOQI3hnfIipSMgkBkGDM7Dng/8CZ3XwTkgA8BNcCT7n4y8L/A34Qf+QHwJXc/AXimYPqNwHfc/USC8XA2h9NPAj5H8GyMowjGSxIpmUSpCyByGHoncAqwPDxYryYY4CsP/Dhc5ofAz8ysAWh09/8Np98A/NTM6oAWd78NwN0HAML1Pe7ubeH7lcBs4KGi10pkHxQEIq9lwA3u/uW9Jpr91bDlRhufZbTmnnTB6xz6fyglpqYhkde6D7jQzKbC7mfFHknw/+XCcJkPAg+5eyewy8zeEk6/FPhfD54D0WZmF4TrqDSz1KGshMhY6UhEZBh3X2VmXwF+aWYxghEgP0Xw8JeFZvYE0EnQjwDBkMBXhzv6l4A/CqdfCnzXzP4uXMcfHsJqiIyZRh8VGSMz63H32lKXQ2S8qWlIRCTidEYgIhJxOiMQEYk4BYGISMQpCEREIk5BICIScQoCEZGI+/9meK319Yg/xwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "target = 'SMA 50'\n",
    "\n",
    "columns = columns_4\n",
    "num_features = len(columns)\n",
    "crypto = cryptos[0]\n",
    "execute_test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EMA 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading... ETH\n",
      "Extracting columns columns for ETH\n",
      "Proccessing and arranging columns for LSTM model\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EMA_200_19</th>\n",
       "      <th>ADX_19</th>\n",
       "      <th>EMA_200_18</th>\n",
       "      <th>ADX_18</th>\n",
       "      <th>EMA_200_17</th>\n",
       "      <th>ADX_17</th>\n",
       "      <th>EMA_200_16</th>\n",
       "      <th>ADX_16</th>\n",
       "      <th>EMA_200_15</th>\n",
       "      <th>ADX_15</th>\n",
       "      <th>...</th>\n",
       "      <th>ADX_4</th>\n",
       "      <th>EMA_200_3</th>\n",
       "      <th>ADX_3</th>\n",
       "      <th>EMA_200_2</th>\n",
       "      <th>ADX_2</th>\n",
       "      <th>EMA_200_1</th>\n",
       "      <th>ADX_1</th>\n",
       "      <th>EMA_200_0</th>\n",
       "      <th>ADX_0</th>\n",
       "      <th>EMA_200</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>775.993770</td>\n",
       "      <td>41.418230</td>\n",
       "      <td>776.782688</td>\n",
       "      <td>36.212628</td>\n",
       "      <td>778.347338</td>\n",
       "      <td>24.312204</td>\n",
       "      <td>779.955822</td>\n",
       "      <td>21.025032</td>\n",
       "      <td>781.740341</td>\n",
       "      <td>21.223914</td>\n",
       "      <td>...</td>\n",
       "      <td>28.656861</td>\n",
       "      <td>827.149747</td>\n",
       "      <td>27.861915</td>\n",
       "      <td>828.809949</td>\n",
       "      <td>27.314258</td>\n",
       "      <td>830.836715</td>\n",
       "      <td>26.829022</td>\n",
       "      <td>834.039833</td>\n",
       "      <td>26.295579</td>\n",
       "      <td>859.418186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>776.782688</td>\n",
       "      <td>36.212628</td>\n",
       "      <td>778.347338</td>\n",
       "      <td>24.312204</td>\n",
       "      <td>779.955822</td>\n",
       "      <td>21.025032</td>\n",
       "      <td>781.740341</td>\n",
       "      <td>21.223914</td>\n",
       "      <td>783.952975</td>\n",
       "      <td>22.305116</td>\n",
       "      <td>...</td>\n",
       "      <td>27.861915</td>\n",
       "      <td>828.809949</td>\n",
       "      <td>27.314258</td>\n",
       "      <td>830.836715</td>\n",
       "      <td>26.829022</td>\n",
       "      <td>834.039833</td>\n",
       "      <td>26.295579</td>\n",
       "      <td>836.178740</td>\n",
       "      <td>25.001883</td>\n",
       "      <td>859.335915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>778.347338</td>\n",
       "      <td>24.312204</td>\n",
       "      <td>779.955822</td>\n",
       "      <td>21.025032</td>\n",
       "      <td>781.740341</td>\n",
       "      <td>21.223914</td>\n",
       "      <td>783.952975</td>\n",
       "      <td>22.305116</td>\n",
       "      <td>787.327472</td>\n",
       "      <td>23.246794</td>\n",
       "      <td>...</td>\n",
       "      <td>27.314258</td>\n",
       "      <td>830.836715</td>\n",
       "      <td>26.829022</td>\n",
       "      <td>834.039833</td>\n",
       "      <td>26.295579</td>\n",
       "      <td>836.178740</td>\n",
       "      <td>25.001883</td>\n",
       "      <td>837.739150</td>\n",
       "      <td>24.131656</td>\n",
       "      <td>858.834961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>779.955822</td>\n",
       "      <td>21.025032</td>\n",
       "      <td>781.740341</td>\n",
       "      <td>21.223914</td>\n",
       "      <td>783.952975</td>\n",
       "      <td>22.305116</td>\n",
       "      <td>787.327472</td>\n",
       "      <td>23.246794</td>\n",
       "      <td>790.768791</td>\n",
       "      <td>25.900560</td>\n",
       "      <td>...</td>\n",
       "      <td>26.829022</td>\n",
       "      <td>834.039833</td>\n",
       "      <td>26.295579</td>\n",
       "      <td>836.178740</td>\n",
       "      <td>25.001883</td>\n",
       "      <td>837.739150</td>\n",
       "      <td>24.131656</td>\n",
       "      <td>839.154681</td>\n",
       "      <td>23.956457</td>\n",
       "      <td>858.912822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>781.740341</td>\n",
       "      <td>21.223914</td>\n",
       "      <td>783.952975</td>\n",
       "      <td>22.305116</td>\n",
       "      <td>787.327472</td>\n",
       "      <td>23.246794</td>\n",
       "      <td>790.768791</td>\n",
       "      <td>25.900560</td>\n",
       "      <td>795.746216</td>\n",
       "      <td>26.950869</td>\n",
       "      <td>...</td>\n",
       "      <td>26.295579</td>\n",
       "      <td>836.178740</td>\n",
       "      <td>25.001883</td>\n",
       "      <td>837.739150</td>\n",
       "      <td>24.131656</td>\n",
       "      <td>839.154681</td>\n",
       "      <td>23.956457</td>\n",
       "      <td>841.362097</td>\n",
       "      <td>23.763680</td>\n",
       "      <td>858.740257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1573</th>\n",
       "      <td>3170.179794</td>\n",
       "      <td>19.071649</td>\n",
       "      <td>3178.405866</td>\n",
       "      <td>19.441324</td>\n",
       "      <td>3189.513867</td>\n",
       "      <td>19.895549</td>\n",
       "      <td>3201.679600</td>\n",
       "      <td>20.260773</td>\n",
       "      <td>3212.193335</td>\n",
       "      <td>19.858133</td>\n",
       "      <td>...</td>\n",
       "      <td>17.630929</td>\n",
       "      <td>3339.640830</td>\n",
       "      <td>16.807307</td>\n",
       "      <td>3347.378235</td>\n",
       "      <td>16.765313</td>\n",
       "      <td>3355.826611</td>\n",
       "      <td>17.981035</td>\n",
       "      <td>3365.694903</td>\n",
       "      <td>19.049911</td>\n",
       "      <td>3485.692671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1574</th>\n",
       "      <td>3178.405866</td>\n",
       "      <td>19.441324</td>\n",
       "      <td>3189.513867</td>\n",
       "      <td>19.895549</td>\n",
       "      <td>3201.679600</td>\n",
       "      <td>20.260773</td>\n",
       "      <td>3212.193335</td>\n",
       "      <td>19.858133</td>\n",
       "      <td>3220.887630</td>\n",
       "      <td>19.464946</td>\n",
       "      <td>...</td>\n",
       "      <td>16.807307</td>\n",
       "      <td>3347.378235</td>\n",
       "      <td>16.765313</td>\n",
       "      <td>3355.826611</td>\n",
       "      <td>17.981035</td>\n",
       "      <td>3365.694903</td>\n",
       "      <td>19.049911</td>\n",
       "      <td>3375.055153</td>\n",
       "      <td>19.747824</td>\n",
       "      <td>3491.180605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1575</th>\n",
       "      <td>3189.513867</td>\n",
       "      <td>19.895549</td>\n",
       "      <td>3201.679600</td>\n",
       "      <td>20.260773</td>\n",
       "      <td>3212.193335</td>\n",
       "      <td>19.858133</td>\n",
       "      <td>3220.887630</td>\n",
       "      <td>19.464946</td>\n",
       "      <td>3232.017505</td>\n",
       "      <td>19.925177</td>\n",
       "      <td>...</td>\n",
       "      <td>16.765313</td>\n",
       "      <td>3355.826611</td>\n",
       "      <td>17.981035</td>\n",
       "      <td>3365.694903</td>\n",
       "      <td>19.049911</td>\n",
       "      <td>3375.055153</td>\n",
       "      <td>19.747824</td>\n",
       "      <td>3385.620873</td>\n",
       "      <td>20.202159</td>\n",
       "      <td>3494.181295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1576</th>\n",
       "      <td>3201.679600</td>\n",
       "      <td>20.260773</td>\n",
       "      <td>3212.193335</td>\n",
       "      <td>19.858133</td>\n",
       "      <td>3220.887630</td>\n",
       "      <td>19.464946</td>\n",
       "      <td>3232.017505</td>\n",
       "      <td>19.925177</td>\n",
       "      <td>3242.339320</td>\n",
       "      <td>19.969782</td>\n",
       "      <td>...</td>\n",
       "      <td>17.981035</td>\n",
       "      <td>3365.694903</td>\n",
       "      <td>19.049911</td>\n",
       "      <td>3375.055153</td>\n",
       "      <td>19.747824</td>\n",
       "      <td>3385.620873</td>\n",
       "      <td>20.202159</td>\n",
       "      <td>3392.785242</td>\n",
       "      <td>20.614088</td>\n",
       "      <td>3495.534616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1577</th>\n",
       "      <td>3212.193335</td>\n",
       "      <td>19.858133</td>\n",
       "      <td>3220.887630</td>\n",
       "      <td>19.464946</td>\n",
       "      <td>3232.017505</td>\n",
       "      <td>19.925177</td>\n",
       "      <td>3242.339320</td>\n",
       "      <td>19.969782</td>\n",
       "      <td>3255.100621</td>\n",
       "      <td>19.934622</td>\n",
       "      <td>...</td>\n",
       "      <td>19.049911</td>\n",
       "      <td>3375.055153</td>\n",
       "      <td>19.747824</td>\n",
       "      <td>3385.620873</td>\n",
       "      <td>20.202159</td>\n",
       "      <td>3392.785242</td>\n",
       "      <td>20.614088</td>\n",
       "      <td>3397.811657</td>\n",
       "      <td>21.222026</td>\n",
       "      <td>3497.661336</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1421 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       EMA_200_19     ADX_19   EMA_200_18     ADX_18   EMA_200_17     ADX_17  \\\n",
       "157    775.993770  41.418230   776.782688  36.212628   778.347338  24.312204   \n",
       "158    776.782688  36.212628   778.347338  24.312204   779.955822  21.025032   \n",
       "159    778.347338  24.312204   779.955822  21.025032   781.740341  21.223914   \n",
       "160    779.955822  21.025032   781.740341  21.223914   783.952975  22.305116   \n",
       "161    781.740341  21.223914   783.952975  22.305116   787.327472  23.246794   \n",
       "...           ...        ...          ...        ...          ...        ...   \n",
       "1573  3170.179794  19.071649  3178.405866  19.441324  3189.513867  19.895549   \n",
       "1574  3178.405866  19.441324  3189.513867  19.895549  3201.679600  20.260773   \n",
       "1575  3189.513867  19.895549  3201.679600  20.260773  3212.193335  19.858133   \n",
       "1576  3201.679600  20.260773  3212.193335  19.858133  3220.887630  19.464946   \n",
       "1577  3212.193335  19.858133  3220.887630  19.464946  3232.017505  19.925177   \n",
       "\n",
       "       EMA_200_16     ADX_16   EMA_200_15     ADX_15  ...      ADX_4  \\\n",
       "157    779.955822  21.025032   781.740341  21.223914  ...  28.656861   \n",
       "158    781.740341  21.223914   783.952975  22.305116  ...  27.861915   \n",
       "159    783.952975  22.305116   787.327472  23.246794  ...  27.314258   \n",
       "160    787.327472  23.246794   790.768791  25.900560  ...  26.829022   \n",
       "161    790.768791  25.900560   795.746216  26.950869  ...  26.295579   \n",
       "...           ...        ...          ...        ...  ...        ...   \n",
       "1573  3201.679600  20.260773  3212.193335  19.858133  ...  17.630929   \n",
       "1574  3212.193335  19.858133  3220.887630  19.464946  ...  16.807307   \n",
       "1575  3220.887630  19.464946  3232.017505  19.925177  ...  16.765313   \n",
       "1576  3232.017505  19.925177  3242.339320  19.969782  ...  17.981035   \n",
       "1577  3242.339320  19.969782  3255.100621  19.934622  ...  19.049911   \n",
       "\n",
       "        EMA_200_3      ADX_3    EMA_200_2      ADX_2    EMA_200_1      ADX_1  \\\n",
       "157    827.149747  27.861915   828.809949  27.314258   830.836715  26.829022   \n",
       "158    828.809949  27.314258   830.836715  26.829022   834.039833  26.295579   \n",
       "159    830.836715  26.829022   834.039833  26.295579   836.178740  25.001883   \n",
       "160    834.039833  26.295579   836.178740  25.001883   837.739150  24.131656   \n",
       "161    836.178740  25.001883   837.739150  24.131656   839.154681  23.956457   \n",
       "...           ...        ...          ...        ...          ...        ...   \n",
       "1573  3339.640830  16.807307  3347.378235  16.765313  3355.826611  17.981035   \n",
       "1574  3347.378235  16.765313  3355.826611  17.981035  3365.694903  19.049911   \n",
       "1575  3355.826611  17.981035  3365.694903  19.049911  3375.055153  19.747824   \n",
       "1576  3365.694903  19.049911  3375.055153  19.747824  3385.620873  20.202159   \n",
       "1577  3375.055153  19.747824  3385.620873  20.202159  3392.785242  20.614088   \n",
       "\n",
       "        EMA_200_0      ADX_0      EMA_200  \n",
       "157    834.039833  26.295579   859.418186  \n",
       "158    836.178740  25.001883   859.335915  \n",
       "159    837.739150  24.131656   858.834961  \n",
       "160    839.154681  23.956457   858.912822  \n",
       "161    841.362097  23.763680   858.740257  \n",
       "...           ...        ...          ...  \n",
       "1573  3365.694903  19.049911  3485.692671  \n",
       "1574  3375.055153  19.747824  3491.180605  \n",
       "1575  3385.620873  20.202159  3494.181295  \n",
       "1576  3392.785242  20.614088  3495.534616  \n",
       "1577  3397.811657  21.222026  3497.661336  \n",
       "\n",
       "[1421 rows x 41 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EMA_200_19</th>\n",
       "      <th>ADX_19</th>\n",
       "      <th>EMA_200_18</th>\n",
       "      <th>ADX_18</th>\n",
       "      <th>EMA_200_17</th>\n",
       "      <th>ADX_17</th>\n",
       "      <th>EMA_200_16</th>\n",
       "      <th>ADX_16</th>\n",
       "      <th>EMA_200_15</th>\n",
       "      <th>ADX_15</th>\n",
       "      <th>...</th>\n",
       "      <th>ADX_4</th>\n",
       "      <th>EMA_200_3</th>\n",
       "      <th>ADX_3</th>\n",
       "      <th>EMA_200_2</th>\n",
       "      <th>ADX_2</th>\n",
       "      <th>EMA_200_1</th>\n",
       "      <th>ADX_1</th>\n",
       "      <th>EMA_200_0</th>\n",
       "      <th>ADX_0</th>\n",
       "      <th>EMA_200</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1578</th>\n",
       "      <td>3220.88763</td>\n",
       "      <td>19.464946</td>\n",
       "      <td>3232.017505</td>\n",
       "      <td>19.925177</td>\n",
       "      <td>3242.33932</td>\n",
       "      <td>19.969782</td>\n",
       "      <td>3255.100621</td>\n",
       "      <td>19.934622</td>\n",
       "      <td>3262.922505</td>\n",
       "      <td>19.004087</td>\n",
       "      <td>...</td>\n",
       "      <td>19.747824</td>\n",
       "      <td>3385.620873</td>\n",
       "      <td>20.202159</td>\n",
       "      <td>3392.785242</td>\n",
       "      <td>20.614088</td>\n",
       "      <td>3397.811657</td>\n",
       "      <td>21.222026</td>\n",
       "      <td>3404.692835</td>\n",
       "      <td>22.210426</td>\n",
       "      <td>3499.927989</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      EMA_200_19     ADX_19   EMA_200_18     ADX_18  EMA_200_17     ADX_17  \\\n",
       "1578  3220.88763  19.464946  3232.017505  19.925177  3242.33932  19.969782   \n",
       "\n",
       "       EMA_200_16     ADX_16   EMA_200_15     ADX_15  ...      ADX_4  \\\n",
       "1578  3255.100621  19.934622  3262.922505  19.004087  ...  19.747824   \n",
       "\n",
       "        EMA_200_3      ADX_3    EMA_200_2      ADX_2    EMA_200_1      ADX_1  \\\n",
       "1578  3385.620873  20.202159  3392.785242  20.614088  3397.811657  21.222026   \n",
       "\n",
       "        EMA_200_0      ADX_0      EMA_200  \n",
       "1578  3404.692835  22.210426  3499.927989  \n",
       "\n",
       "[1 rows x 41 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (1421, 1, 40) (1421, 1)\n",
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_56 (LSTM)               (None, 1, 25)             6600      \n",
      "_________________________________________________________________\n",
      "lstm_57 (LSTM)               (None, 1, 25)             5100      \n",
      "_________________________________________________________________\n",
      "dropout_45 (Dropout)         (None, 1, 25)             0         \n",
      "_________________________________________________________________\n",
      "lstm_58 (LSTM)               (None, 1, 25)             5100      \n",
      "_________________________________________________________________\n",
      "dropout_46 (Dropout)         (None, 1, 25)             0         \n",
      "_________________________________________________________________\n",
      "lstm_59 (LSTM)               (None, 1, 25)             5100      \n",
      "_________________________________________________________________\n",
      "dropout_47 (Dropout)         (None, 1, 25)             0         \n",
      "_________________________________________________________________\n",
      "lstm_60 (LSTM)               (None, 25)                5100      \n",
      "_________________________________________________________________\n",
      "dropout_48 (Dropout)         (None, 25)                0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 1)                 26        \n",
      "=================================================================\n",
      "Total params: 27,026\n",
      "Trainable params: 27,026\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Y shape (1421, 1)\n",
      "Train on 1421 samples, validate on 285 samples\n",
      "Epoch 1/100\n",
      " - 10s - loss: 0.0863 - mse: 0.0863 - val_loss: 0.3922 - val_mse: 0.3922\n",
      "Epoch 2/100\n",
      " - 0s - loss: 0.0756 - mse: 0.0756 - val_loss: 0.3438 - val_mse: 0.3438\n",
      "Epoch 3/100\n",
      " - 0s - loss: 0.0671 - mse: 0.0671 - val_loss: 0.2916 - val_mse: 0.2916\n",
      "Epoch 4/100\n",
      " - 0s - loss: 0.0603 - mse: 0.0603 - val_loss: 0.2307 - val_mse: 0.2307\n",
      "Epoch 5/100\n",
      " - 0s - loss: 0.0499 - mse: 0.0499 - val_loss: 0.1437 - val_mse: 0.1437\n",
      "Epoch 6/100\n",
      " - 0s - loss: 0.0258 - mse: 0.0258 - val_loss: 0.0216 - val_mse: 0.0216\n",
      "Epoch 7/100\n",
      " - 0s - loss: 0.0207 - mse: 0.0207 - val_loss: 0.0069 - val_mse: 0.0069\n",
      "Epoch 8/100\n",
      " - 0s - loss: 0.0249 - mse: 0.0249 - val_loss: 0.0653 - val_mse: 0.0653\n",
      "Epoch 9/100\n",
      " - 1s - loss: 0.0101 - mse: 0.0101 - val_loss: 0.0069 - val_mse: 0.0069\n",
      "Epoch 10/100\n",
      " - 1s - loss: 0.0089 - mse: 0.0089 - val_loss: 0.0091 - val_mse: 0.0091\n",
      "Epoch 11/100\n",
      " - 1s - loss: 0.0090 - mse: 0.0090 - val_loss: 0.0067 - val_mse: 0.0067\n",
      "Epoch 12/100\n",
      " - 1s - loss: 0.0078 - mse: 0.0078 - val_loss: 0.0083 - val_mse: 0.0083\n",
      "Epoch 13/100\n",
      " - 0s - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0065 - val_mse: 0.0065\n",
      "Epoch 14/100\n",
      " - 0s - loss: 0.0089 - mse: 0.0089 - val_loss: 0.0089 - val_mse: 0.0089\n",
      "Epoch 15/100\n",
      " - 0s - loss: 0.0121 - mse: 0.0121 - val_loss: 0.0068 - val_mse: 0.0068\n",
      "Epoch 16/100\n",
      " - 0s - loss: 0.0107 - mse: 0.0107 - val_loss: 0.0121 - val_mse: 0.0121\n",
      "Epoch 17/100\n",
      " - 0s - loss: 0.0115 - mse: 0.0115 - val_loss: 0.0082 - val_mse: 0.0082\n",
      "Epoch 18/100\n",
      " - 1s - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0109 - val_mse: 0.0109\n",
      "Epoch 19/100\n",
      " - 1s - loss: 0.0108 - mse: 0.0108 - val_loss: 0.0061 - val_mse: 0.0061\n",
      "Epoch 20/100\n",
      " - 0s - loss: 0.0086 - mse: 0.0086 - val_loss: 0.0101 - val_mse: 0.0101\n",
      "Epoch 21/100\n",
      " - 1s - loss: 0.0105 - mse: 0.0105 - val_loss: 0.0072 - val_mse: 0.0072\n",
      "Epoch 22/100\n",
      " - 0s - loss: 0.0100 - mse: 0.0100 - val_loss: 0.0129 - val_mse: 0.0129\n",
      "Epoch 23/100\n",
      " - 0s - loss: 0.0089 - mse: 0.0089 - val_loss: 0.0069 - val_mse: 0.0069\n",
      "Epoch 24/100\n",
      " - 0s - loss: 0.0070 - mse: 0.0070 - val_loss: 0.0081 - val_mse: 0.0081\n",
      "Epoch 25/100\n",
      " - 0s - loss: 0.0088 - mse: 0.0088 - val_loss: 0.0063 - val_mse: 0.0063\n",
      "Epoch 26/100\n",
      " - 0s - loss: 0.0061 - mse: 0.0061 - val_loss: 0.0067 - val_mse: 0.0067\n",
      "Epoch 27/100\n",
      " - 0s - loss: 0.0067 - mse: 0.0067 - val_loss: 0.0055 - val_mse: 0.0055\n",
      "Epoch 28/100\n",
      " - 0s - loss: 0.0049 - mse: 0.0049 - val_loss: 0.0046 - val_mse: 0.0046\n",
      "Epoch 29/100\n",
      " - 1s - loss: 0.0049 - mse: 0.0049 - val_loss: 0.0044 - val_mse: 0.0044\n",
      "Epoch 30/100\n",
      " - 0s - loss: 0.0056 - mse: 0.0056 - val_loss: 0.0042 - val_mse: 0.0042\n",
      "Epoch 31/100\n",
      " - 0s - loss: 0.0055 - mse: 0.0055 - val_loss: 0.0040 - val_mse: 0.0040\n",
      "Epoch 32/100\n",
      " - 0s - loss: 0.0055 - mse: 0.0055 - val_loss: 0.0040 - val_mse: 0.0040\n",
      "Epoch 33/100\n",
      " - 1s - loss: 0.0053 - mse: 0.0053 - val_loss: 0.0043 - val_mse: 0.0043\n",
      "Epoch 34/100\n",
      " - 0s - loss: 0.0057 - mse: 0.0057 - val_loss: 0.0040 - val_mse: 0.0040\n",
      "Epoch 35/100\n",
      " - 0s - loss: 0.0051 - mse: 0.0051 - val_loss: 0.0039 - val_mse: 0.0039\n",
      "Epoch 36/100\n",
      " - 0s - loss: 0.0061 - mse: 0.0061 - val_loss: 0.0046 - val_mse: 0.0046\n",
      "Epoch 37/100\n",
      " - 0s - loss: 0.0056 - mse: 0.0056 - val_loss: 0.0048 - val_mse: 0.0048\n",
      "Epoch 38/100\n",
      " - 0s - loss: 0.0059 - mse: 0.0059 - val_loss: 0.0054 - val_mse: 0.0054\n",
      "Epoch 39/100\n",
      " - 0s - loss: 0.0057 - mse: 0.0057 - val_loss: 0.0041 - val_mse: 0.0041\n",
      "Epoch 40/100\n",
      " - 0s - loss: 0.0063 - mse: 0.0063 - val_loss: 0.0047 - val_mse: 0.0047\n",
      "Epoch 41/100\n",
      " - 0s - loss: 0.0062 - mse: 0.0062 - val_loss: 0.0066 - val_mse: 0.0066\n",
      "Epoch 42/100\n",
      " - 0s - loss: 0.0075 - mse: 0.0075 - val_loss: 0.0057 - val_mse: 0.0057\n",
      "Epoch 43/100\n",
      " - 0s - loss: 0.0060 - mse: 0.0060 - val_loss: 0.0054 - val_mse: 0.0054\n",
      "Epoch 44/100\n",
      " - 0s - loss: 0.0068 - mse: 0.0068 - val_loss: 0.0052 - val_mse: 0.0052\n",
      "Epoch 45/100\n",
      " - 0s - loss: 0.0059 - mse: 0.0059 - val_loss: 0.0067 - val_mse: 0.0067\n",
      "Epoch 46/100\n",
      " - 0s - loss: 0.0049 - mse: 0.0049 - val_loss: 0.0057 - val_mse: 0.0057\n",
      "Epoch 47/100\n",
      " - 0s - loss: 0.0046 - mse: 0.0046 - val_loss: 0.0044 - val_mse: 0.0044\n",
      "Epoch 48/100\n",
      " - 0s - loss: 0.0054 - mse: 0.0054 - val_loss: 0.0042 - val_mse: 0.0042\n",
      "Epoch 49/100\n",
      " - 0s - loss: 0.0043 - mse: 0.0043 - val_loss: 0.0037 - val_mse: 0.0037\n",
      "Epoch 50/100\n",
      " - 0s - loss: 0.0051 - mse: 0.0051 - val_loss: 0.0044 - val_mse: 0.0044\n",
      "Epoch 51/100\n",
      " - 0s - loss: 0.0050 - mse: 0.0050 - val_loss: 0.0037 - val_mse: 0.0037\n",
      "Epoch 52/100\n",
      " - 0s - loss: 0.0053 - mse: 0.0053 - val_loss: 0.0037 - val_mse: 0.0037\n",
      "Epoch 53/100\n",
      " - 0s - loss: 0.0052 - mse: 0.0052 - val_loss: 0.0047 - val_mse: 0.0047\n",
      "Epoch 54/100\n",
      " - 0s - loss: 0.0051 - mse: 0.0051 - val_loss: 0.0040 - val_mse: 0.0040\n",
      "Epoch 55/100\n",
      " - 0s - loss: 0.0054 - mse: 0.0054 - val_loss: 0.0052 - val_mse: 0.0052\n",
      "Epoch 56/100\n",
      " - 0s - loss: 0.0051 - mse: 0.0051 - val_loss: 0.0045 - val_mse: 0.0045\n",
      "Epoch 57/100\n",
      " - 0s - loss: 0.0052 - mse: 0.0052 - val_loss: 0.0052 - val_mse: 0.0052\n",
      "Epoch 58/100\n",
      " - 0s - loss: 0.0050 - mse: 0.0050 - val_loss: 0.0053 - val_mse: 0.0053\n",
      "Epoch 59/100\n",
      " - 1s - loss: 0.0043 - mse: 0.0043 - val_loss: 0.0036 - val_mse: 0.0036\n",
      "Epoch 60/100\n",
      " - 0s - loss: 0.0040 - mse: 0.0040 - val_loss: 0.0040 - val_mse: 0.0040\n",
      "Epoch 61/100\n",
      " - 1s - loss: 0.0040 - mse: 0.0040 - val_loss: 0.0034 - val_mse: 0.0034\n",
      "Epoch 62/100\n",
      " - 0s - loss: 0.0042 - mse: 0.0042 - val_loss: 0.0039 - val_mse: 0.0039\n",
      "Epoch 63/100\n",
      " - 1s - loss: 0.0044 - mse: 0.0044 - val_loss: 0.0037 - val_mse: 0.0037\n",
      "Epoch 64/100\n",
      " - 0s - loss: 0.0041 - mse: 0.0041 - val_loss: 0.0040 - val_mse: 0.0040\n",
      "Epoch 65/100\n",
      " - 0s - loss: 0.0038 - mse: 0.0038 - val_loss: 0.0030 - val_mse: 0.0030\n",
      "Epoch 66/100\n",
      " - 0s - loss: 0.0046 - mse: 0.0046 - val_loss: 0.0031 - val_mse: 0.0031\n",
      "Epoch 67/100\n",
      " - 0s - loss: 0.0038 - mse: 0.0038 - val_loss: 0.0030 - val_mse: 0.0030\n",
      "Epoch 68/100\n",
      " - 1s - loss: 0.0044 - mse: 0.0044 - val_loss: 0.0038 - val_mse: 0.0038\n",
      "Epoch 69/100\n",
      " - 1s - loss: 0.0037 - mse: 0.0037 - val_loss: 0.0027 - val_mse: 0.0027\n",
      "Epoch 70/100\n",
      " - 0s - loss: 0.0043 - mse: 0.0043 - val_loss: 0.0036 - val_mse: 0.0036\n",
      "Epoch 71/100\n",
      " - 0s - loss: 0.0035 - mse: 0.0035 - val_loss: 0.0029 - val_mse: 0.0029\n",
      "Epoch 72/100\n",
      " - 0s - loss: 0.0036 - mse: 0.0036 - val_loss: 0.0028 - val_mse: 0.0028\n",
      "Epoch 73/100\n",
      " - 0s - loss: 0.0040 - mse: 0.0040 - val_loss: 0.0031 - val_mse: 0.0031\n",
      "Epoch 74/100\n",
      " - 0s - loss: 0.0047 - mse: 0.0047 - val_loss: 0.0035 - val_mse: 0.0035\n",
      "Epoch 75/100\n",
      " - 0s - loss: 0.0039 - mse: 0.0039 - val_loss: 0.0032 - val_mse: 0.0032\n",
      "Epoch 76/100\n",
      " - 1s - loss: 0.0038 - mse: 0.0038 - val_loss: 0.0035 - val_mse: 0.0035\n",
      "Epoch 77/100\n",
      " - 0s - loss: 0.0041 - mse: 0.0041 - val_loss: 0.0033 - val_mse: 0.0033\n",
      "Epoch 78/100\n",
      " - 0s - loss: 0.0050 - mse: 0.0050 - val_loss: 0.0039 - val_mse: 0.0039\n",
      "Epoch 79/100\n",
      " - 0s - loss: 0.0053 - mse: 0.0053 - val_loss: 0.0041 - val_mse: 0.0041\n",
      "Epoch 80/100\n",
      " - 0s - loss: 0.0050 - mse: 0.0050 - val_loss: 0.0041 - val_mse: 0.0041\n",
      "Epoch 81/100\n",
      " - 0s - loss: 0.0048 - mse: 0.0048 - val_loss: 0.0034 - val_mse: 0.0034\n",
      "Epoch 82/100\n",
      " - 0s - loss: 0.0054 - mse: 0.0054 - val_loss: 0.0043 - val_mse: 0.0043\n",
      "Epoch 83/100\n",
      " - 0s - loss: 0.0049 - mse: 0.0049 - val_loss: 0.0040 - val_mse: 0.0040\n",
      "Epoch 84/100\n",
      " - 0s - loss: 0.0054 - mse: 0.0054 - val_loss: 0.0042 - val_mse: 0.0042\n",
      "Epoch 85/100\n",
      " - 0s - loss: 0.0053 - mse: 0.0053 - val_loss: 0.0049 - val_mse: 0.0049\n",
      "Epoch 86/100\n",
      " - 0s - loss: 0.0054 - mse: 0.0054 - val_loss: 0.0040 - val_mse: 0.0040\n",
      "Epoch 87/100\n",
      " - 0s - loss: 0.0049 - mse: 0.0049 - val_loss: 0.0051 - val_mse: 0.0051\n",
      "Epoch 88/100\n",
      " - 0s - loss: 0.0050 - mse: 0.0050 - val_loss: 0.0039 - val_mse: 0.0039\n",
      "Epoch 89/100\n",
      " - 0s - loss: 0.0042 - mse: 0.0042 - val_loss: 0.0039 - val_mse: 0.0039\n",
      "Epoch 90/100\n",
      " - 0s - loss: 0.0041 - mse: 0.0041 - val_loss: 0.0036 - val_mse: 0.0036\n",
      "Epoch 91/100\n",
      " - 0s - loss: 0.0038 - mse: 0.0038 - val_loss: 0.0029 - val_mse: 0.0029\n",
      "Epoch 92/100\n",
      " - 0s - loss: 0.0035 - mse: 0.0035 - val_loss: 0.0028 - val_mse: 0.0028\n",
      "Epoch 93/100\n",
      " - 0s - loss: 0.0037 - mse: 0.0037 - val_loss: 0.0027 - val_mse: 0.0027\n",
      "Epoch 94/100\n",
      " - 0s - loss: 0.0035 - mse: 0.0035 - val_loss: 0.0031 - val_mse: 0.0031\n",
      "Epoch 95/100\n",
      " - 0s - loss: 0.0031 - mse: 0.0031 - val_loss: 0.0026 - val_mse: 0.0026\n",
      "Epoch 96/100\n",
      " - 0s - loss: 0.0031 - mse: 0.0031 - val_loss: 0.0025 - val_mse: 0.0025\n",
      "Epoch 97/100\n",
      " - 0s - loss: 0.0038 - mse: 0.0038 - val_loss: 0.0023 - val_mse: 0.0023\n",
      "Epoch 98/100\n",
      " - 0s - loss: 0.0035 - mse: 0.0035 - val_loss: 0.0028 - val_mse: 0.0028\n",
      "Epoch 99/100\n",
      " - 0s - loss: 0.0036 - mse: 0.0036 - val_loss: 0.0026 - val_mse: 0.0026\n",
      "Epoch 100/100\n",
      " - 0s - loss: 0.0040 - mse: 0.0040 - val_loss: 0.0028 - val_mse: 0.0028\n",
      "real [[3499.92798938]]\n",
      "Test RMSE: 162.457\n",
      "Diff [[162.45654891]]\n",
      "% Diff [[4.64171118]] %\n",
      "Predictions [[3337.47144046]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "target = 'EMA_200'\n",
    "\n",
    "columns = columns_5\n",
    "num_features = len(columns)\n",
    "crypto = cryptos[0]\n",
    "execute_test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SMA 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading... ETH\n",
      "Extracting columns columns for ETH\n",
      "Proccessing and arranging columns for LSTM model\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SMA 200_19</th>\n",
       "      <th>ADX_19</th>\n",
       "      <th>SMA 200_18</th>\n",
       "      <th>ADX_18</th>\n",
       "      <th>SMA 200_17</th>\n",
       "      <th>ADX_17</th>\n",
       "      <th>SMA 200_16</th>\n",
       "      <th>ADX_16</th>\n",
       "      <th>SMA 200_15</th>\n",
       "      <th>ADX_15</th>\n",
       "      <th>...</th>\n",
       "      <th>ADX_4</th>\n",
       "      <th>SMA 200_3</th>\n",
       "      <th>ADX_3</th>\n",
       "      <th>SMA 200_2</th>\n",
       "      <th>ADX_2</th>\n",
       "      <th>SMA 200_1</th>\n",
       "      <th>ADX_1</th>\n",
       "      <th>SMA 200_0</th>\n",
       "      <th>ADX_0</th>\n",
       "      <th>SMA 200</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>342</th>\n",
       "      <td>710.05045</td>\n",
       "      <td>35.636123</td>\n",
       "      <td>708.48280</td>\n",
       "      <td>34.690646</td>\n",
       "      <td>706.92065</td>\n",
       "      <td>33.990806</td>\n",
       "      <td>705.40345</td>\n",
       "      <td>32.739224</td>\n",
       "      <td>703.84995</td>\n",
       "      <td>31.248367</td>\n",
       "      <td>...</td>\n",
       "      <td>26.199775</td>\n",
       "      <td>688.11095</td>\n",
       "      <td>24.683538</td>\n",
       "      <td>685.72815</td>\n",
       "      <td>23.265035</td>\n",
       "      <td>683.27840</td>\n",
       "      <td>21.832497</td>\n",
       "      <td>680.87830</td>\n",
       "      <td>20.764010</td>\n",
       "      <td>608.53340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>708.48280</td>\n",
       "      <td>34.690646</td>\n",
       "      <td>706.92065</td>\n",
       "      <td>33.990806</td>\n",
       "      <td>705.40345</td>\n",
       "      <td>32.739224</td>\n",
       "      <td>703.84995</td>\n",
       "      <td>31.248367</td>\n",
       "      <td>702.83250</td>\n",
       "      <td>30.423749</td>\n",
       "      <td>...</td>\n",
       "      <td>24.683538</td>\n",
       "      <td>685.72815</td>\n",
       "      <td>23.265035</td>\n",
       "      <td>683.27840</td>\n",
       "      <td>21.832497</td>\n",
       "      <td>680.87830</td>\n",
       "      <td>20.764010</td>\n",
       "      <td>678.21825</td>\n",
       "      <td>19.452398</td>\n",
       "      <td>604.67030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>706.92065</td>\n",
       "      <td>33.990806</td>\n",
       "      <td>705.40345</td>\n",
       "      <td>32.739224</td>\n",
       "      <td>703.84995</td>\n",
       "      <td>31.248367</td>\n",
       "      <td>702.83250</td>\n",
       "      <td>30.423749</td>\n",
       "      <td>701.85575</td>\n",
       "      <td>30.761095</td>\n",
       "      <td>...</td>\n",
       "      <td>23.265035</td>\n",
       "      <td>683.27840</td>\n",
       "      <td>21.832497</td>\n",
       "      <td>680.87830</td>\n",
       "      <td>20.764010</td>\n",
       "      <td>678.21825</td>\n",
       "      <td>19.452398</td>\n",
       "      <td>674.91600</td>\n",
       "      <td>18.283855</td>\n",
       "      <td>600.48095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345</th>\n",
       "      <td>705.40345</td>\n",
       "      <td>32.739224</td>\n",
       "      <td>703.84995</td>\n",
       "      <td>31.248367</td>\n",
       "      <td>702.83250</td>\n",
       "      <td>30.423749</td>\n",
       "      <td>701.85575</td>\n",
       "      <td>30.761095</td>\n",
       "      <td>700.72145</td>\n",
       "      <td>31.166891</td>\n",
       "      <td>...</td>\n",
       "      <td>21.832497</td>\n",
       "      <td>680.87830</td>\n",
       "      <td>20.764010</td>\n",
       "      <td>678.21825</td>\n",
       "      <td>19.452398</td>\n",
       "      <td>674.91600</td>\n",
       "      <td>18.283855</td>\n",
       "      <td>671.60055</td>\n",
       "      <td>17.020782</td>\n",
       "      <td>595.65700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>703.84995</td>\n",
       "      <td>31.248367</td>\n",
       "      <td>702.83250</td>\n",
       "      <td>30.423749</td>\n",
       "      <td>701.85575</td>\n",
       "      <td>30.761095</td>\n",
       "      <td>700.72145</td>\n",
       "      <td>31.166891</td>\n",
       "      <td>699.30900</td>\n",
       "      <td>31.711802</td>\n",
       "      <td>...</td>\n",
       "      <td>20.764010</td>\n",
       "      <td>678.21825</td>\n",
       "      <td>19.452398</td>\n",
       "      <td>674.91600</td>\n",
       "      <td>18.283855</td>\n",
       "      <td>671.60055</td>\n",
       "      <td>17.020782</td>\n",
       "      <td>667.49200</td>\n",
       "      <td>15.987591</td>\n",
       "      <td>591.35950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1573</th>\n",
       "      <td>3111.99135</td>\n",
       "      <td>19.071649</td>\n",
       "      <td>3117.22805</td>\n",
       "      <td>19.441324</td>\n",
       "      <td>3121.54665</td>\n",
       "      <td>19.895549</td>\n",
       "      <td>3127.41245</td>\n",
       "      <td>20.260773</td>\n",
       "      <td>3131.08270</td>\n",
       "      <td>19.858133</td>\n",
       "      <td>...</td>\n",
       "      <td>17.630929</td>\n",
       "      <td>3166.00945</td>\n",
       "      <td>16.807307</td>\n",
       "      <td>3169.72035</td>\n",
       "      <td>16.765313</td>\n",
       "      <td>3178.50795</td>\n",
       "      <td>17.981035</td>\n",
       "      <td>3186.40280</td>\n",
       "      <td>19.049911</td>\n",
       "      <td>3331.78195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1574</th>\n",
       "      <td>3117.22805</td>\n",
       "      <td>19.441324</td>\n",
       "      <td>3121.54665</td>\n",
       "      <td>19.895549</td>\n",
       "      <td>3127.41245</td>\n",
       "      <td>20.260773</td>\n",
       "      <td>3131.08270</td>\n",
       "      <td>19.858133</td>\n",
       "      <td>3134.06390</td>\n",
       "      <td>19.464946</td>\n",
       "      <td>...</td>\n",
       "      <td>16.807307</td>\n",
       "      <td>3169.72035</td>\n",
       "      <td>16.765313</td>\n",
       "      <td>3178.50795</td>\n",
       "      <td>17.981035</td>\n",
       "      <td>3186.40280</td>\n",
       "      <td>19.049911</td>\n",
       "      <td>3195.77990</td>\n",
       "      <td>19.747824</td>\n",
       "      <td>3339.61265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1575</th>\n",
       "      <td>3121.54665</td>\n",
       "      <td>19.895549</td>\n",
       "      <td>3127.41245</td>\n",
       "      <td>20.260773</td>\n",
       "      <td>3131.08270</td>\n",
       "      <td>19.858133</td>\n",
       "      <td>3134.06390</td>\n",
       "      <td>19.464946</td>\n",
       "      <td>3138.36345</td>\n",
       "      <td>19.925177</td>\n",
       "      <td>...</td>\n",
       "      <td>16.765313</td>\n",
       "      <td>3178.50795</td>\n",
       "      <td>17.981035</td>\n",
       "      <td>3186.40280</td>\n",
       "      <td>19.049911</td>\n",
       "      <td>3195.77990</td>\n",
       "      <td>19.747824</td>\n",
       "      <td>3206.49010</td>\n",
       "      <td>20.202159</td>\n",
       "      <td>3346.80635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1576</th>\n",
       "      <td>3127.41245</td>\n",
       "      <td>20.260773</td>\n",
       "      <td>3131.08270</td>\n",
       "      <td>19.858133</td>\n",
       "      <td>3134.06390</td>\n",
       "      <td>19.464946</td>\n",
       "      <td>3138.36345</td>\n",
       "      <td>19.925177</td>\n",
       "      <td>3140.15895</td>\n",
       "      <td>19.969782</td>\n",
       "      <td>...</td>\n",
       "      <td>17.981035</td>\n",
       "      <td>3186.40280</td>\n",
       "      <td>19.049911</td>\n",
       "      <td>3195.77990</td>\n",
       "      <td>19.747824</td>\n",
       "      <td>3206.49010</td>\n",
       "      <td>20.202159</td>\n",
       "      <td>3216.53635</td>\n",
       "      <td>20.614088</td>\n",
       "      <td>3353.10360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1577</th>\n",
       "      <td>3131.08270</td>\n",
       "      <td>19.858133</td>\n",
       "      <td>3134.06390</td>\n",
       "      <td>19.464946</td>\n",
       "      <td>3138.36345</td>\n",
       "      <td>19.925177</td>\n",
       "      <td>3140.15895</td>\n",
       "      <td>19.969782</td>\n",
       "      <td>3143.16345</td>\n",
       "      <td>19.934622</td>\n",
       "      <td>...</td>\n",
       "      <td>19.049911</td>\n",
       "      <td>3195.77990</td>\n",
       "      <td>19.747824</td>\n",
       "      <td>3206.49010</td>\n",
       "      <td>20.202159</td>\n",
       "      <td>3216.53635</td>\n",
       "      <td>20.614088</td>\n",
       "      <td>3222.78390</td>\n",
       "      <td>21.222026</td>\n",
       "      <td>3359.10330</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1236 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      SMA 200_19     ADX_19  SMA 200_18     ADX_18  SMA 200_17     ADX_17  \\\n",
       "342    710.05045  35.636123   708.48280  34.690646   706.92065  33.990806   \n",
       "343    708.48280  34.690646   706.92065  33.990806   705.40345  32.739224   \n",
       "344    706.92065  33.990806   705.40345  32.739224   703.84995  31.248367   \n",
       "345    705.40345  32.739224   703.84995  31.248367   702.83250  30.423749   \n",
       "346    703.84995  31.248367   702.83250  30.423749   701.85575  30.761095   \n",
       "...          ...        ...         ...        ...         ...        ...   \n",
       "1573  3111.99135  19.071649  3117.22805  19.441324  3121.54665  19.895549   \n",
       "1574  3117.22805  19.441324  3121.54665  19.895549  3127.41245  20.260773   \n",
       "1575  3121.54665  19.895549  3127.41245  20.260773  3131.08270  19.858133   \n",
       "1576  3127.41245  20.260773  3131.08270  19.858133  3134.06390  19.464946   \n",
       "1577  3131.08270  19.858133  3134.06390  19.464946  3138.36345  19.925177   \n",
       "\n",
       "      SMA 200_16     ADX_16  SMA 200_15     ADX_15  ...      ADX_4  \\\n",
       "342    705.40345  32.739224   703.84995  31.248367  ...  26.199775   \n",
       "343    703.84995  31.248367   702.83250  30.423749  ...  24.683538   \n",
       "344    702.83250  30.423749   701.85575  30.761095  ...  23.265035   \n",
       "345    701.85575  30.761095   700.72145  31.166891  ...  21.832497   \n",
       "346    700.72145  31.166891   699.30900  31.711802  ...  20.764010   \n",
       "...          ...        ...         ...        ...  ...        ...   \n",
       "1573  3127.41245  20.260773  3131.08270  19.858133  ...  17.630929   \n",
       "1574  3131.08270  19.858133  3134.06390  19.464946  ...  16.807307   \n",
       "1575  3134.06390  19.464946  3138.36345  19.925177  ...  16.765313   \n",
       "1576  3138.36345  19.925177  3140.15895  19.969782  ...  17.981035   \n",
       "1577  3140.15895  19.969782  3143.16345  19.934622  ...  19.049911   \n",
       "\n",
       "       SMA 200_3      ADX_3   SMA 200_2      ADX_2   SMA 200_1      ADX_1  \\\n",
       "342    688.11095  24.683538   685.72815  23.265035   683.27840  21.832497   \n",
       "343    685.72815  23.265035   683.27840  21.832497   680.87830  20.764010   \n",
       "344    683.27840  21.832497   680.87830  20.764010   678.21825  19.452398   \n",
       "345    680.87830  20.764010   678.21825  19.452398   674.91600  18.283855   \n",
       "346    678.21825  19.452398   674.91600  18.283855   671.60055  17.020782   \n",
       "...          ...        ...         ...        ...         ...        ...   \n",
       "1573  3166.00945  16.807307  3169.72035  16.765313  3178.50795  17.981035   \n",
       "1574  3169.72035  16.765313  3178.50795  17.981035  3186.40280  19.049911   \n",
       "1575  3178.50795  17.981035  3186.40280  19.049911  3195.77990  19.747824   \n",
       "1576  3186.40280  19.049911  3195.77990  19.747824  3206.49010  20.202159   \n",
       "1577  3195.77990  19.747824  3206.49010  20.202159  3216.53635  20.614088   \n",
       "\n",
       "       SMA 200_0      ADX_0     SMA 200  \n",
       "342    680.87830  20.764010   608.53340  \n",
       "343    678.21825  19.452398   604.67030  \n",
       "344    674.91600  18.283855   600.48095  \n",
       "345    671.60055  17.020782   595.65700  \n",
       "346    667.49200  15.987591   591.35950  \n",
       "...          ...        ...         ...  \n",
       "1573  3186.40280  19.049911  3331.78195  \n",
       "1574  3195.77990  19.747824  3339.61265  \n",
       "1575  3206.49010  20.202159  3346.80635  \n",
       "1576  3216.53635  20.614088  3353.10360  \n",
       "1577  3222.78390  21.222026  3359.10330  \n",
       "\n",
       "[1236 rows x 41 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SMA 200_19</th>\n",
       "      <th>ADX_19</th>\n",
       "      <th>SMA 200_18</th>\n",
       "      <th>ADX_18</th>\n",
       "      <th>SMA 200_17</th>\n",
       "      <th>ADX_17</th>\n",
       "      <th>SMA 200_16</th>\n",
       "      <th>ADX_16</th>\n",
       "      <th>SMA 200_15</th>\n",
       "      <th>ADX_15</th>\n",
       "      <th>...</th>\n",
       "      <th>ADX_4</th>\n",
       "      <th>SMA 200_3</th>\n",
       "      <th>ADX_3</th>\n",
       "      <th>SMA 200_2</th>\n",
       "      <th>ADX_2</th>\n",
       "      <th>SMA 200_1</th>\n",
       "      <th>ADX_1</th>\n",
       "      <th>SMA 200_0</th>\n",
       "      <th>ADX_0</th>\n",
       "      <th>SMA 200</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1578</th>\n",
       "      <td>3134.0639</td>\n",
       "      <td>19.464946</td>\n",
       "      <td>3138.36345</td>\n",
       "      <td>19.925177</td>\n",
       "      <td>3140.15895</td>\n",
       "      <td>19.969782</td>\n",
       "      <td>3143.16345</td>\n",
       "      <td>19.934622</td>\n",
       "      <td>3143.64005</td>\n",
       "      <td>19.004087</td>\n",
       "      <td>...</td>\n",
       "      <td>19.747824</td>\n",
       "      <td>3206.4901</td>\n",
       "      <td>20.202159</td>\n",
       "      <td>3216.53635</td>\n",
       "      <td>20.614088</td>\n",
       "      <td>3222.7839</td>\n",
       "      <td>21.222026</td>\n",
       "      <td>3229.7052</td>\n",
       "      <td>22.210426</td>\n",
       "      <td>3364.82675</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      SMA 200_19     ADX_19  SMA 200_18     ADX_18  SMA 200_17     ADX_17  \\\n",
       "1578   3134.0639  19.464946  3138.36345  19.925177  3140.15895  19.969782   \n",
       "\n",
       "      SMA 200_16     ADX_16  SMA 200_15     ADX_15  ...      ADX_4  SMA 200_3  \\\n",
       "1578  3143.16345  19.934622  3143.64005  19.004087  ...  19.747824  3206.4901   \n",
       "\n",
       "          ADX_3   SMA 200_2      ADX_2  SMA 200_1      ADX_1  SMA 200_0  \\\n",
       "1578  20.202159  3216.53635  20.614088  3222.7839  21.222026  3229.7052   \n",
       "\n",
       "          ADX_0     SMA 200  \n",
       "1578  22.210426  3364.82675  \n",
       "\n",
       "[1 rows x 41 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (1236, 1, 40) (1236, 1)\n",
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_61 (LSTM)               (None, 1, 25)             6600      \n",
      "_________________________________________________________________\n",
      "lstm_62 (LSTM)               (None, 1, 25)             5100      \n",
      "_________________________________________________________________\n",
      "dropout_49 (Dropout)         (None, 1, 25)             0         \n",
      "_________________________________________________________________\n",
      "lstm_63 (LSTM)               (None, 1, 25)             5100      \n",
      "_________________________________________________________________\n",
      "dropout_50 (Dropout)         (None, 1, 25)             0         \n",
      "_________________________________________________________________\n",
      "lstm_64 (LSTM)               (None, 1, 25)             5100      \n",
      "_________________________________________________________________\n",
      "dropout_51 (Dropout)         (None, 1, 25)             0         \n",
      "_________________________________________________________________\n",
      "lstm_65 (LSTM)               (None, 25)                5100      \n",
      "_________________________________________________________________\n",
      "dropout_52 (Dropout)         (None, 25)                0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 1)                 26        \n",
      "=================================================================\n",
      "Total params: 27,026\n",
      "Trainable params: 27,026\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Y shape (1236, 1)\n",
      "Train on 1236 samples, validate on 248 samples\n",
      "Epoch 1/100\n",
      " - 10s - loss: 0.1013 - mse: 0.1013 - val_loss: 0.4742 - val_mse: 0.4742\n",
      "Epoch 2/100\n",
      " - 0s - loss: 0.0916 - mse: 0.0916 - val_loss: 0.4300 - val_mse: 0.4300\n",
      "Epoch 3/100\n",
      " - 0s - loss: 0.0831 - mse: 0.0831 - val_loss: 0.3803 - val_mse: 0.3803\n",
      "Epoch 4/100\n",
      " - 0s - loss: 0.0757 - mse: 0.0757 - val_loss: 0.3219 - val_mse: 0.3219\n",
      "Epoch 5/100\n",
      " - 0s - loss: 0.0675 - mse: 0.0675 - val_loss: 0.2457 - val_mse: 0.2457\n",
      "Epoch 6/100\n",
      " - 0s - loss: 0.0513 - mse: 0.0513 - val_loss: 0.1242 - val_mse: 0.1242\n",
      "Epoch 7/100\n",
      " - 0s - loss: 0.0220 - mse: 0.0220 - val_loss: 0.0060 - val_mse: 0.0060\n",
      "Epoch 8/100\n",
      " - 0s - loss: 0.0192 - mse: 0.0192 - val_loss: 0.0082 - val_mse: 0.0082\n",
      "Epoch 9/100\n",
      " - 0s - loss: 0.0223 - mse: 0.0223 - val_loss: 0.0522 - val_mse: 0.0522\n",
      "Epoch 10/100\n",
      " - 0s - loss: 0.0102 - mse: 0.0102 - val_loss: 0.0074 - val_mse: 0.0074\n",
      "Epoch 11/100\n",
      " - 0s - loss: 0.0079 - mse: 0.0079 - val_loss: 0.0083 - val_mse: 0.0083\n",
      "Epoch 12/100\n",
      " - 1s - loss: 0.0089 - mse: 0.0089 - val_loss: 0.0058 - val_mse: 0.0058\n",
      "Epoch 13/100\n",
      " - 1s - loss: 0.0075 - mse: 0.0075 - val_loss: 0.0064 - val_mse: 0.0064\n",
      "Epoch 14/100\n",
      " - 0s - loss: 0.0071 - mse: 0.0071 - val_loss: 0.0046 - val_mse: 0.0046\n",
      "Epoch 15/100\n",
      " - 0s - loss: 0.0069 - mse: 0.0069 - val_loss: 0.0046 - val_mse: 0.0046\n",
      "Epoch 16/100\n",
      " - 0s - loss: 0.0064 - mse: 0.0064 - val_loss: 0.0044 - val_mse: 0.0044\n",
      "Epoch 17/100\n",
      " - 0s - loss: 0.0064 - mse: 0.0064 - val_loss: 0.0047 - val_mse: 0.0047\n",
      "Epoch 18/100\n",
      " - 0s - loss: 0.0063 - mse: 0.0063 - val_loss: 0.0039 - val_mse: 0.0039\n",
      "Epoch 19/100\n",
      " - 0s - loss: 0.0062 - mse: 0.0062 - val_loss: 0.0039 - val_mse: 0.0039\n",
      "Epoch 20/100\n",
      " - 0s - loss: 0.0061 - mse: 0.0061 - val_loss: 0.0038 - val_mse: 0.0038\n",
      "Epoch 21/100\n",
      " - 0s - loss: 0.0065 - mse: 0.0065 - val_loss: 0.0035 - val_mse: 0.0035\n",
      "Epoch 22/100\n",
      " - 0s - loss: 0.0063 - mse: 0.0063 - val_loss: 0.0050 - val_mse: 0.0050\n",
      "Epoch 23/100\n",
      " - 0s - loss: 0.0076 - mse: 0.0076 - val_loss: 0.0037 - val_mse: 0.0037\n",
      "Epoch 24/100\n",
      " - 0s - loss: 0.0074 - mse: 0.0074 - val_loss: 0.0064 - val_mse: 0.0064\n",
      "Epoch 25/100\n",
      " - 0s - loss: 0.0077 - mse: 0.0077 - val_loss: 0.0056 - val_mse: 0.0056\n",
      "Epoch 26/100\n",
      " - 0s - loss: 0.0062 - mse: 0.0062 - val_loss: 0.0035 - val_mse: 0.0035\n",
      "Epoch 27/100\n",
      " - 0s - loss: 0.0070 - mse: 0.0070 - val_loss: 0.0043 - val_mse: 0.0043\n",
      "Epoch 28/100\n",
      " - 0s - loss: 0.0069 - mse: 0.0069 - val_loss: 0.0060 - val_mse: 0.0060\n",
      "Epoch 29/100\n",
      " - 0s - loss: 0.0077 - mse: 0.0077 - val_loss: 0.0054 - val_mse: 0.0054\n",
      "Epoch 30/100\n",
      " - 0s - loss: 0.0062 - mse: 0.0062 - val_loss: 0.0053 - val_mse: 0.0053\n",
      "Epoch 31/100\n",
      " - 0s - loss: 0.0057 - mse: 0.0057 - val_loss: 0.0047 - val_mse: 0.0047\n",
      "Epoch 32/100\n",
      " - 0s - loss: 0.0042 - mse: 0.0042 - val_loss: 0.0032 - val_mse: 0.0032\n",
      "Epoch 33/100\n",
      " - 0s - loss: 0.0047 - mse: 0.0047 - val_loss: 0.0029 - val_mse: 0.0029\n",
      "Epoch 34/100\n",
      " - 0s - loss: 0.0047 - mse: 0.0047 - val_loss: 0.0024 - val_mse: 0.0024\n",
      "Epoch 35/100\n",
      " - 0s - loss: 0.0051 - mse: 0.0051 - val_loss: 0.0030 - val_mse: 0.0030\n",
      "Epoch 36/100\n",
      " - 0s - loss: 0.0047 - mse: 0.0047 - val_loss: 0.0035 - val_mse: 0.0035\n",
      "Epoch 37/100\n",
      " - 0s - loss: 0.0052 - mse: 0.0052 - val_loss: 0.0028 - val_mse: 0.0028\n",
      "Epoch 38/100\n",
      " - 0s - loss: 0.0063 - mse: 0.0063 - val_loss: 0.0045 - val_mse: 0.0045\n",
      "Epoch 39/100\n",
      " - 0s - loss: 0.0055 - mse: 0.0055 - val_loss: 0.0042 - val_mse: 0.0042\n",
      "Epoch 40/100\n",
      " - 0s - loss: 0.0047 - mse: 0.0047 - val_loss: 0.0026 - val_mse: 0.0026\n",
      "Epoch 41/100\n",
      " - 0s - loss: 0.0044 - mse: 0.0044 - val_loss: 0.0026 - val_mse: 0.0026\n",
      "Epoch 42/100\n",
      " - 0s - loss: 0.0036 - mse: 0.0036 - val_loss: 0.0024 - val_mse: 0.0024\n",
      "Epoch 43/100\n",
      " - 0s - loss: 0.0037 - mse: 0.0037 - val_loss: 0.0024 - val_mse: 0.0024\n",
      "Epoch 44/100\n",
      " - 0s - loss: 0.0045 - mse: 0.0045 - val_loss: 0.0021 - val_mse: 0.0021\n",
      "Epoch 45/100\n",
      " - 0s - loss: 0.0043 - mse: 0.0043 - val_loss: 0.0038 - val_mse: 0.0038\n",
      "Epoch 46/100\n",
      " - 0s - loss: 0.0045 - mse: 0.0045 - val_loss: 0.0023 - val_mse: 0.0023\n",
      "Epoch 47/100\n",
      " - 0s - loss: 0.0047 - mse: 0.0047 - val_loss: 0.0025 - val_mse: 0.0025\n",
      "Epoch 48/100\n",
      " - 0s - loss: 0.0057 - mse: 0.0057 - val_loss: 0.0034 - val_mse: 0.0034\n",
      "Epoch 49/100\n",
      " - 0s - loss: 0.0059 - mse: 0.0059 - val_loss: 0.0043 - val_mse: 0.0043\n",
      "Epoch 50/100\n",
      " - 0s - loss: 0.0063 - mse: 0.0063 - val_loss: 0.0053 - val_mse: 0.0053\n",
      "Epoch 51/100\n",
      " - 0s - loss: 0.0057 - mse: 0.0057 - val_loss: 0.0045 - val_mse: 0.0045\n",
      "Epoch 52/100\n",
      " - 0s - loss: 0.0059 - mse: 0.0059 - val_loss: 0.0065 - val_mse: 0.0065\n",
      "Epoch 53/100\n",
      " - 1s - loss: 0.0053 - mse: 0.0053 - val_loss: 0.0042 - val_mse: 0.0042\n",
      "Epoch 54/100\n",
      " - 1s - loss: 0.0043 - mse: 0.0043 - val_loss: 0.0030 - val_mse: 0.0030\n",
      "Epoch 55/100\n",
      " - 1s - loss: 0.0048 - mse: 0.0048 - val_loss: 0.0032 - val_mse: 0.0032\n",
      "Epoch 56/100\n",
      " - 1s - loss: 0.0048 - mse: 0.0048 - val_loss: 0.0030 - val_mse: 0.0030\n",
      "Epoch 57/100\n",
      " - 1s - loss: 0.0042 - mse: 0.0042 - val_loss: 0.0040 - val_mse: 0.0040\n",
      "Epoch 58/100\n",
      " - 1s - loss: 0.0034 - mse: 0.0034 - val_loss: 0.0024 - val_mse: 0.0024\n",
      "Epoch 59/100\n",
      " - 1s - loss: 0.0041 - mse: 0.0041 - val_loss: 0.0024 - val_mse: 0.0024\n",
      "Epoch 60/100\n",
      " - 1s - loss: 0.0036 - mse: 0.0036 - val_loss: 0.0021 - val_mse: 0.0021\n",
      "Epoch 61/100\n",
      " - 1s - loss: 0.0041 - mse: 0.0041 - val_loss: 0.0024 - val_mse: 0.0024\n",
      "Epoch 62/100\n",
      " - 1s - loss: 0.0039 - mse: 0.0039 - val_loss: 0.0024 - val_mse: 0.0024\n",
      "Epoch 63/100\n",
      " - 1s - loss: 0.0044 - mse: 0.0044 - val_loss: 0.0036 - val_mse: 0.0036\n",
      "Epoch 64/100\n",
      " - 1s - loss: 0.0040 - mse: 0.0040 - val_loss: 0.0023 - val_mse: 0.0023\n",
      "Epoch 65/100\n",
      " - 1s - loss: 0.0037 - mse: 0.0037 - val_loss: 0.0032 - val_mse: 0.0032\n",
      "Epoch 66/100\n",
      " - 1s - loss: 0.0041 - mse: 0.0041 - val_loss: 0.0026 - val_mse: 0.0026\n",
      "Epoch 67/100\n",
      " - 0s - loss: 0.0045 - mse: 0.0045 - val_loss: 0.0032 - val_mse: 0.0032\n",
      "Epoch 68/100\n",
      " - 1s - loss: 0.0051 - mse: 0.0051 - val_loss: 0.0033 - val_mse: 0.0033\n",
      "Epoch 69/100\n",
      " - 0s - loss: 0.0054 - mse: 0.0054 - val_loss: 0.0040 - val_mse: 0.0040\n",
      "Epoch 70/100\n",
      " - 1s - loss: 0.0047 - mse: 0.0047 - val_loss: 0.0032 - val_mse: 0.0032\n",
      "Epoch 71/100\n",
      " - 0s - loss: 0.0043 - mse: 0.0043 - val_loss: 0.0037 - val_mse: 0.0037\n",
      "Epoch 72/100\n",
      " - 0s - loss: 0.0046 - mse: 0.0046 - val_loss: 0.0029 - val_mse: 0.0029\n",
      "Epoch 73/100\n",
      " - 0s - loss: 0.0042 - mse: 0.0042 - val_loss: 0.0031 - val_mse: 0.0031\n",
      "Epoch 74/100\n",
      " - 0s - loss: 0.0037 - mse: 0.0037 - val_loss: 0.0024 - val_mse: 0.0024\n",
      "Epoch 75/100\n",
      " - 0s - loss: 0.0037 - mse: 0.0037 - val_loss: 0.0031 - val_mse: 0.0031\n",
      "Epoch 76/100\n",
      " - 0s - loss: 0.0034 - mse: 0.0034 - val_loss: 0.0022 - val_mse: 0.0022\n",
      "Epoch 77/100\n",
      " - 0s - loss: 0.0036 - mse: 0.0036 - val_loss: 0.0027 - val_mse: 0.0027\n",
      "Epoch 78/100\n",
      " - 0s - loss: 0.0042 - mse: 0.0042 - val_loss: 0.0024 - val_mse: 0.0024\n",
      "Epoch 79/100\n",
      " - 0s - loss: 0.0041 - mse: 0.0041 - val_loss: 0.0025 - val_mse: 0.0025\n",
      "Epoch 80/100\n",
      " - 0s - loss: 0.0049 - mse: 0.0049 - val_loss: 0.0034 - val_mse: 0.0034\n",
      "Epoch 81/100\n",
      " - 0s - loss: 0.0048 - mse: 0.0048 - val_loss: 0.0035 - val_mse: 0.0035\n",
      "Epoch 82/100\n",
      " - 0s - loss: 0.0047 - mse: 0.0047 - val_loss: 0.0030 - val_mse: 0.0030\n",
      "Epoch 83/100\n",
      " - 0s - loss: 0.0044 - mse: 0.0044 - val_loss: 0.0039 - val_mse: 0.0039\n",
      "real [[3364.82675]]\n",
      "Test RMSE: 228.052\n",
      "Diff [[228.05229394]]\n",
      "% Diff [[6.7775345]] %\n",
      "Predictions [[3136.77445606]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "target = 'SMA 200'\n",
    "\n",
    "columns = columns_6\n",
    "num_features = len(columns)\n",
    "crypto = crypto\n",
    "execute_test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tras analizar los resultados obtenidos observamos ligeras mejores cuando el valor del precio esta suavizado (menos outliers). Entre SMA y EMA parece que EMA se comporta ligeramente mejor. No es algo determinante pero seguiremos usando EMA porque cambia de forma mas rapida y de acuerda al valor real de las tendencias porque tiene mas en cuenta los ultimos precios a la hora de calcularse\n",
    "\n",
    "Además hemos visto dificultades en la red para predecir el valor de la métrica ADX. De ahora en adelante analizaremos RSI en vez de ADX pero es posible que si no conseguimos buenas predicciones usemos solo el valor del precio, sus diferencias o la operación mas adecuada (se comenta más adelante estos dos nuevos métodos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Antes de seguir probaremos dos metodos mas:\n",
    "- Uso de la diferencia de precio\n",
    "- Uso de la operación mas conveniente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_7 = ['RSI', 'close_diff_5']\n",
    "columns_8 = ['RSI', 'close_diff_10']\n",
    "columns_9 = ['RSI', 'close_diff_20']\n",
    "columns_11 = ['op_buy', 'op_sell', 'op_hold'] # Usar softmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dado que actualmente tenemos puesto el parametro de dias de prediccion a 20, usaremos la columna con un calculo de diferencia de precio de 20 dias -> columns_9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading... ETH\n",
      "Extracting columns columns for ETH\n",
      "Proccessing and arranging columns for LSTM model\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RSI_19</th>\n",
       "      <th>close_diff_20_19</th>\n",
       "      <th>RSI_18</th>\n",
       "      <th>close_diff_20_18</th>\n",
       "      <th>RSI_17</th>\n",
       "      <th>close_diff_20_17</th>\n",
       "      <th>RSI_16</th>\n",
       "      <th>close_diff_20_16</th>\n",
       "      <th>RSI_15</th>\n",
       "      <th>close_diff_20_15</th>\n",
       "      <th>...</th>\n",
       "      <th>close_diff_20_4</th>\n",
       "      <th>RSI_3</th>\n",
       "      <th>close_diff_20_3</th>\n",
       "      <th>RSI_2</th>\n",
       "      <th>close_diff_20_2</th>\n",
       "      <th>RSI_1</th>\n",
       "      <th>close_diff_20_1</th>\n",
       "      <th>RSI_0</th>\n",
       "      <th>close_diff_20_0</th>\n",
       "      <th>close_diff_20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>80.914056</td>\n",
       "      <td>339.09</td>\n",
       "      <td>81.309636</td>\n",
       "      <td>335.18</td>\n",
       "      <td>86.146268</td>\n",
       "      <td>500.79</td>\n",
       "      <td>79.935566</td>\n",
       "      <td>464.59</td>\n",
       "      <td>67.133485</td>\n",
       "      <td>502.96</td>\n",
       "      <td>...</td>\n",
       "      <td>137.72</td>\n",
       "      <td>47.319361</td>\n",
       "      <td>45.97</td>\n",
       "      <td>51.974254</td>\n",
       "      <td>121.00</td>\n",
       "      <td>51.702144</td>\n",
       "      <td>97.22</td>\n",
       "      <td>51.347368</td>\n",
       "      <td>46.92</td>\n",
       "      <td>-126.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>81.309636</td>\n",
       "      <td>335.18</td>\n",
       "      <td>86.146268</td>\n",
       "      <td>500.79</td>\n",
       "      <td>79.935566</td>\n",
       "      <td>464.59</td>\n",
       "      <td>67.133485</td>\n",
       "      <td>502.96</td>\n",
       "      <td>72.227956</td>\n",
       "      <td>613.53</td>\n",
       "      <td>...</td>\n",
       "      <td>45.97</td>\n",
       "      <td>51.974254</td>\n",
       "      <td>121.00</td>\n",
       "      <td>51.702144</td>\n",
       "      <td>97.22</td>\n",
       "      <td>51.347368</td>\n",
       "      <td>46.92</td>\n",
       "      <td>55.424951</td>\n",
       "      <td>-4.10</td>\n",
       "      <td>-180.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>86.146268</td>\n",
       "      <td>500.79</td>\n",
       "      <td>79.935566</td>\n",
       "      <td>464.59</td>\n",
       "      <td>67.133485</td>\n",
       "      <td>502.96</td>\n",
       "      <td>72.227956</td>\n",
       "      <td>613.53</td>\n",
       "      <td>76.756435</td>\n",
       "      <td>730.02</td>\n",
       "      <td>...</td>\n",
       "      <td>121.00</td>\n",
       "      <td>51.702144</td>\n",
       "      <td>97.22</td>\n",
       "      <td>51.347368</td>\n",
       "      <td>46.92</td>\n",
       "      <td>55.424951</td>\n",
       "      <td>-4.10</td>\n",
       "      <td>62.115254</td>\n",
       "      <td>118.78</td>\n",
       "      <td>-281.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>79.935566</td>\n",
       "      <td>464.59</td>\n",
       "      <td>67.133485</td>\n",
       "      <td>502.96</td>\n",
       "      <td>72.227956</td>\n",
       "      <td>613.53</td>\n",
       "      <td>76.756435</td>\n",
       "      <td>730.02</td>\n",
       "      <td>72.845019</td>\n",
       "      <td>632.05</td>\n",
       "      <td>...</td>\n",
       "      <td>97.22</td>\n",
       "      <td>51.347368</td>\n",
       "      <td>46.92</td>\n",
       "      <td>55.424951</td>\n",
       "      <td>-4.10</td>\n",
       "      <td>62.115254</td>\n",
       "      <td>118.78</td>\n",
       "      <td>56.928602</td>\n",
       "      <td>-113.99</td>\n",
       "      <td>-266.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>67.133485</td>\n",
       "      <td>502.96</td>\n",
       "      <td>72.227956</td>\n",
       "      <td>613.53</td>\n",
       "      <td>76.756435</td>\n",
       "      <td>730.02</td>\n",
       "      <td>72.845019</td>\n",
       "      <td>632.05</td>\n",
       "      <td>66.121951</td>\n",
       "      <td>521.00</td>\n",
       "      <td>...</td>\n",
       "      <td>46.92</td>\n",
       "      <td>55.424951</td>\n",
       "      <td>-4.10</td>\n",
       "      <td>62.115254</td>\n",
       "      <td>118.78</td>\n",
       "      <td>56.928602</td>\n",
       "      <td>-113.99</td>\n",
       "      <td>51.296643</td>\n",
       "      <td>-161.50</td>\n",
       "      <td>-147.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1573</th>\n",
       "      <td>47.095555</td>\n",
       "      <td>1.78</td>\n",
       "      <td>39.023233</td>\n",
       "      <td>-421.99</td>\n",
       "      <td>48.716109</td>\n",
       "      <td>-27.92</td>\n",
       "      <td>51.957920</td>\n",
       "      <td>124.96</td>\n",
       "      <td>47.702403</td>\n",
       "      <td>-61.12</td>\n",
       "      <td>...</td>\n",
       "      <td>-154.25</td>\n",
       "      <td>46.826530</td>\n",
       "      <td>-428.55</td>\n",
       "      <td>44.735958</td>\n",
       "      <td>-509.25</td>\n",
       "      <td>46.793026</td>\n",
       "      <td>-367.34</td>\n",
       "      <td>50.574650</td>\n",
       "      <td>137.83</td>\n",
       "      <td>-284.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1574</th>\n",
       "      <td>39.023233</td>\n",
       "      <td>-421.99</td>\n",
       "      <td>48.716109</td>\n",
       "      <td>-27.92</td>\n",
       "      <td>51.957920</td>\n",
       "      <td>124.96</td>\n",
       "      <td>47.702403</td>\n",
       "      <td>-61.12</td>\n",
       "      <td>43.413283</td>\n",
       "      <td>-503.92</td>\n",
       "      <td>...</td>\n",
       "      <td>-428.55</td>\n",
       "      <td>44.735958</td>\n",
       "      <td>-509.25</td>\n",
       "      <td>46.793026</td>\n",
       "      <td>-367.34</td>\n",
       "      <td>50.574650</td>\n",
       "      <td>137.83</td>\n",
       "      <td>49.541304</td>\n",
       "      <td>18.60</td>\n",
       "      <td>-269.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1575</th>\n",
       "      <td>48.716109</td>\n",
       "      <td>-27.92</td>\n",
       "      <td>51.957920</td>\n",
       "      <td>124.96</td>\n",
       "      <td>47.702403</td>\n",
       "      <td>-61.12</td>\n",
       "      <td>43.413283</td>\n",
       "      <td>-503.92</td>\n",
       "      <td>50.467423</td>\n",
       "      <td>-263.91</td>\n",
       "      <td>...</td>\n",
       "      <td>-509.25</td>\n",
       "      <td>46.793026</td>\n",
       "      <td>-367.34</td>\n",
       "      <td>50.574650</td>\n",
       "      <td>137.83</td>\n",
       "      <td>49.541304</td>\n",
       "      <td>18.60</td>\n",
       "      <td>52.829940</td>\n",
       "      <td>440.01</td>\n",
       "      <td>-644.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1576</th>\n",
       "      <td>51.957920</td>\n",
       "      <td>124.96</td>\n",
       "      <td>47.702403</td>\n",
       "      <td>-61.12</td>\n",
       "      <td>43.413283</td>\n",
       "      <td>-503.92</td>\n",
       "      <td>50.467423</td>\n",
       "      <td>-263.91</td>\n",
       "      <td>48.661227</td>\n",
       "      <td>-262.96</td>\n",
       "      <td>...</td>\n",
       "      <td>-367.34</td>\n",
       "      <td>50.574650</td>\n",
       "      <td>137.83</td>\n",
       "      <td>49.541304</td>\n",
       "      <td>18.60</td>\n",
       "      <td>52.829940</td>\n",
       "      <td>440.01</td>\n",
       "      <td>44.841174</td>\n",
       "      <td>-189.12</td>\n",
       "      <td>-475.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1577</th>\n",
       "      <td>47.702403</td>\n",
       "      <td>-61.12</td>\n",
       "      <td>43.413283</td>\n",
       "      <td>-503.92</td>\n",
       "      <td>50.467423</td>\n",
       "      <td>-263.91</td>\n",
       "      <td>48.661227</td>\n",
       "      <td>-262.96</td>\n",
       "      <td>54.986266</td>\n",
       "      <td>50.61</td>\n",
       "      <td>...</td>\n",
       "      <td>137.83</td>\n",
       "      <td>49.541304</td>\n",
       "      <td>18.60</td>\n",
       "      <td>52.829940</td>\n",
       "      <td>440.01</td>\n",
       "      <td>44.841174</td>\n",
       "      <td>-189.12</td>\n",
       "      <td>40.686916</td>\n",
       "      <td>-514.23</td>\n",
       "      <td>-188.67</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1415 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         RSI_19  close_diff_20_19     RSI_18  close_diff_20_18     RSI_17  \\\n",
       "163   80.914056            339.09  81.309636            335.18  86.146268   \n",
       "164   81.309636            335.18  86.146268            500.79  79.935566   \n",
       "165   86.146268            500.79  79.935566            464.59  67.133485   \n",
       "166   79.935566            464.59  67.133485            502.96  72.227956   \n",
       "167   67.133485            502.96  72.227956            613.53  76.756435   \n",
       "...         ...               ...        ...               ...        ...   \n",
       "1573  47.095555              1.78  39.023233           -421.99  48.716109   \n",
       "1574  39.023233           -421.99  48.716109            -27.92  51.957920   \n",
       "1575  48.716109            -27.92  51.957920            124.96  47.702403   \n",
       "1576  51.957920            124.96  47.702403            -61.12  43.413283   \n",
       "1577  47.702403            -61.12  43.413283           -503.92  50.467423   \n",
       "\n",
       "      close_diff_20_17     RSI_16  close_diff_20_16     RSI_15  \\\n",
       "163             500.79  79.935566            464.59  67.133485   \n",
       "164             464.59  67.133485            502.96  72.227956   \n",
       "165             502.96  72.227956            613.53  76.756435   \n",
       "166             613.53  76.756435            730.02  72.845019   \n",
       "167             730.02  72.845019            632.05  66.121951   \n",
       "...                ...        ...               ...        ...   \n",
       "1573            -27.92  51.957920            124.96  47.702403   \n",
       "1574            124.96  47.702403            -61.12  43.413283   \n",
       "1575            -61.12  43.413283           -503.92  50.467423   \n",
       "1576           -503.92  50.467423           -263.91  48.661227   \n",
       "1577           -263.91  48.661227           -262.96  54.986266   \n",
       "\n",
       "      close_diff_20_15  ...  close_diff_20_4      RSI_3  close_diff_20_3  \\\n",
       "163             502.96  ...           137.72  47.319361            45.97   \n",
       "164             613.53  ...            45.97  51.974254           121.00   \n",
       "165             730.02  ...           121.00  51.702144            97.22   \n",
       "166             632.05  ...            97.22  51.347368            46.92   \n",
       "167             521.00  ...            46.92  55.424951            -4.10   \n",
       "...                ...  ...              ...        ...              ...   \n",
       "1573            -61.12  ...          -154.25  46.826530          -428.55   \n",
       "1574           -503.92  ...          -428.55  44.735958          -509.25   \n",
       "1575           -263.91  ...          -509.25  46.793026          -367.34   \n",
       "1576           -262.96  ...          -367.34  50.574650           137.83   \n",
       "1577             50.61  ...           137.83  49.541304            18.60   \n",
       "\n",
       "          RSI_2  close_diff_20_2      RSI_1  close_diff_20_1      RSI_0  \\\n",
       "163   51.974254           121.00  51.702144            97.22  51.347368   \n",
       "164   51.702144            97.22  51.347368            46.92  55.424951   \n",
       "165   51.347368            46.92  55.424951            -4.10  62.115254   \n",
       "166   55.424951            -4.10  62.115254           118.78  56.928602   \n",
       "167   62.115254           118.78  56.928602          -113.99  51.296643   \n",
       "...         ...              ...        ...              ...        ...   \n",
       "1573  44.735958          -509.25  46.793026          -367.34  50.574650   \n",
       "1574  46.793026          -367.34  50.574650           137.83  49.541304   \n",
       "1575  50.574650           137.83  49.541304            18.60  52.829940   \n",
       "1576  49.541304            18.60  52.829940           440.01  44.841174   \n",
       "1577  52.829940           440.01  44.841174          -189.12  40.686916   \n",
       "\n",
       "      close_diff_20_0  close_diff_20  \n",
       "163             46.92        -126.48  \n",
       "164             -4.10        -180.32  \n",
       "165            118.78        -281.97  \n",
       "166           -113.99        -266.01  \n",
       "167           -161.50        -147.39  \n",
       "...               ...            ...  \n",
       "1573           137.83        -284.03  \n",
       "1574            18.60        -269.17  \n",
       "1575           440.01        -644.16  \n",
       "1576          -189.12        -475.45  \n",
       "1577          -514.23        -188.67  \n",
       "\n",
       "[1415 rows x 41 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RSI_19</th>\n",
       "      <th>close_diff_20_19</th>\n",
       "      <th>RSI_18</th>\n",
       "      <th>close_diff_20_18</th>\n",
       "      <th>RSI_17</th>\n",
       "      <th>close_diff_20_17</th>\n",
       "      <th>RSI_16</th>\n",
       "      <th>close_diff_20_16</th>\n",
       "      <th>RSI_15</th>\n",
       "      <th>close_diff_20_15</th>\n",
       "      <th>...</th>\n",
       "      <th>close_diff_20_4</th>\n",
       "      <th>RSI_3</th>\n",
       "      <th>close_diff_20_3</th>\n",
       "      <th>RSI_2</th>\n",
       "      <th>close_diff_20_2</th>\n",
       "      <th>RSI_1</th>\n",
       "      <th>close_diff_20_1</th>\n",
       "      <th>RSI_0</th>\n",
       "      <th>close_diff_20_0</th>\n",
       "      <th>close_diff_20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1578</th>\n",
       "      <td>43.413283</td>\n",
       "      <td>-503.92</td>\n",
       "      <td>50.467423</td>\n",
       "      <td>-263.91</td>\n",
       "      <td>48.661227</td>\n",
       "      <td>-262.96</td>\n",
       "      <td>54.986266</td>\n",
       "      <td>50.61</td>\n",
       "      <td>43.948042</td>\n",
       "      <td>-476.8</td>\n",
       "      <td>...</td>\n",
       "      <td>18.6</td>\n",
       "      <td>52.82994</td>\n",
       "      <td>440.01</td>\n",
       "      <td>44.841174</td>\n",
       "      <td>-189.12</td>\n",
       "      <td>40.686916</td>\n",
       "      <td>-514.23</td>\n",
       "      <td>45.681743</td>\n",
       "      <td>-168.94</td>\n",
       "      <td>-363.91</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         RSI_19  close_diff_20_19     RSI_18  close_diff_20_18     RSI_17  \\\n",
       "1578  43.413283           -503.92  50.467423           -263.91  48.661227   \n",
       "\n",
       "      close_diff_20_17     RSI_16  close_diff_20_16     RSI_15  \\\n",
       "1578           -262.96  54.986266             50.61  43.948042   \n",
       "\n",
       "      close_diff_20_15  ...  close_diff_20_4     RSI_3  close_diff_20_3  \\\n",
       "1578            -476.8  ...             18.6  52.82994           440.01   \n",
       "\n",
       "          RSI_2  close_diff_20_2      RSI_1  close_diff_20_1      RSI_0  \\\n",
       "1578  44.841174          -189.12  40.686916          -514.23  45.681743   \n",
       "\n",
       "      close_diff_20_0  close_diff_20  \n",
       "1578          -168.94        -363.91  \n",
       "\n",
       "[1 rows x 41 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (1415, 1, 40) (1415, 1)\n",
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_66 (LSTM)               (None, 1, 25)             6600      \n",
      "_________________________________________________________________\n",
      "lstm_67 (LSTM)               (None, 1, 25)             5100      \n",
      "_________________________________________________________________\n",
      "dropout_53 (Dropout)         (None, 1, 25)             0         \n",
      "_________________________________________________________________\n",
      "lstm_68 (LSTM)               (None, 1, 25)             5100      \n",
      "_________________________________________________________________\n",
      "dropout_54 (Dropout)         (None, 1, 25)             0         \n",
      "_________________________________________________________________\n",
      "lstm_69 (LSTM)               (None, 1, 25)             5100      \n",
      "_________________________________________________________________\n",
      "dropout_55 (Dropout)         (None, 1, 25)             0         \n",
      "_________________________________________________________________\n",
      "lstm_70 (LSTM)               (None, 25)                5100      \n",
      "_________________________________________________________________\n",
      "dropout_56 (Dropout)         (None, 25)                0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 1)                 26        \n",
      "=================================================================\n",
      "Total params: 27,026\n",
      "Trainable params: 27,026\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Y shape (1415, 1)\n",
      "Train on 1415 samples, validate on 283 samples\n",
      "Epoch 1/100\n",
      " - 12s - loss: 0.2080 - mse: 0.2080 - val_loss: 0.2174 - val_mse: 0.2174\n",
      "Epoch 2/100\n",
      " - 0s - loss: 0.1016 - mse: 0.1016 - val_loss: 0.0456 - val_mse: 0.0456\n",
      "Epoch 3/100\n",
      " - 0s - loss: 0.0191 - mse: 0.0191 - val_loss: 0.0394 - val_mse: 0.0394\n",
      "Epoch 4/100\n",
      " - 0s - loss: 0.0147 - mse: 0.0147 - val_loss: 0.0349 - val_mse: 0.0349\n",
      "Epoch 5/100\n",
      " - 0s - loss: 0.0132 - mse: 0.0132 - val_loss: 0.0349 - val_mse: 0.0349\n",
      "Epoch 6/100\n",
      " - 0s - loss: 0.0144 - mse: 0.0144 - val_loss: 0.0350 - val_mse: 0.0350\n",
      "Epoch 7/100\n",
      " - 0s - loss: 0.0133 - mse: 0.0133 - val_loss: 0.0343 - val_mse: 0.0343\n",
      "Epoch 8/100\n",
      " - 1s - loss: 0.0135 - mse: 0.0135 - val_loss: 0.0344 - val_mse: 0.0344\n",
      "Epoch 9/100\n",
      " - 1s - loss: 0.0127 - mse: 0.0127 - val_loss: 0.0343 - val_mse: 0.0343\n",
      "Epoch 10/100\n",
      " - 1s - loss: 0.0121 - mse: 0.0121 - val_loss: 0.0342 - val_mse: 0.0342\n",
      "Epoch 11/100\n",
      " - 1s - loss: 0.0124 - mse: 0.0124 - val_loss: 0.0344 - val_mse: 0.0344\n",
      "Epoch 12/100\n",
      " - 1s - loss: 0.0125 - mse: 0.0125 - val_loss: 0.0342 - val_mse: 0.0342\n",
      "Epoch 13/100\n",
      " - 1s - loss: 0.0119 - mse: 0.0119 - val_loss: 0.0341 - val_mse: 0.0341\n",
      "Epoch 14/100\n",
      " - 1s - loss: 0.0124 - mse: 0.0124 - val_loss: 0.0344 - val_mse: 0.0344\n",
      "Epoch 15/100\n",
      " - 1s - loss: 0.0118 - mse: 0.0118 - val_loss: 0.0340 - val_mse: 0.0340\n",
      "Epoch 16/100\n",
      " - 1s - loss: 0.0119 - mse: 0.0119 - val_loss: 0.0339 - val_mse: 0.0339\n",
      "Epoch 17/100\n",
      " - 1s - loss: 0.0110 - mse: 0.0110 - val_loss: 0.0338 - val_mse: 0.0338\n",
      "Epoch 18/100\n",
      " - 0s - loss: 0.0113 - mse: 0.0113 - val_loss: 0.0338 - val_mse: 0.0338\n",
      "Epoch 19/100\n",
      " - 0s - loss: 0.0115 - mse: 0.0115 - val_loss: 0.0340 - val_mse: 0.0340\n",
      "Epoch 20/100\n",
      " - 0s - loss: 0.0105 - mse: 0.0105 - val_loss: 0.0338 - val_mse: 0.0338\n",
      "Epoch 21/100\n",
      " - 0s - loss: 0.0114 - mse: 0.0114 - val_loss: 0.0338 - val_mse: 0.0338\n",
      "Epoch 22/100\n",
      " - 0s - loss: 0.0111 - mse: 0.0111 - val_loss: 0.0339 - val_mse: 0.0339\n",
      "Epoch 23/100\n",
      " - 0s - loss: 0.0107 - mse: 0.0107 - val_loss: 0.0338 - val_mse: 0.0338\n",
      "Epoch 24/100\n",
      " - 0s - loss: 0.0110 - mse: 0.0110 - val_loss: 0.0339 - val_mse: 0.0339\n",
      "Epoch 25/100\n",
      " - 0s - loss: 0.0107 - mse: 0.0107 - val_loss: 0.0337 - val_mse: 0.0337\n",
      "Epoch 26/100\n",
      " - 0s - loss: 0.0113 - mse: 0.0113 - val_loss: 0.0339 - val_mse: 0.0339\n",
      "Epoch 27/100\n",
      " - 0s - loss: 0.0108 - mse: 0.0108 - val_loss: 0.0339 - val_mse: 0.0339\n",
      "Epoch 28/100\n",
      " - 1s - loss: 0.0098 - mse: 0.0098 - val_loss: 0.0338 - val_mse: 0.0338\n",
      "Epoch 29/100\n",
      " - 0s - loss: 0.0102 - mse: 0.0102 - val_loss: 0.0336 - val_mse: 0.0336\n",
      "Epoch 30/100\n",
      " - 0s - loss: 0.0102 - mse: 0.0102 - val_loss: 0.0338 - val_mse: 0.0338\n",
      "Epoch 31/100\n",
      " - 0s - loss: 0.0104 - mse: 0.0104 - val_loss: 0.0338 - val_mse: 0.0338\n",
      "Epoch 32/100\n",
      " - 0s - loss: 0.0104 - mse: 0.0104 - val_loss: 0.0338 - val_mse: 0.0338\n",
      "Epoch 33/100\n",
      " - 1s - loss: 0.0100 - mse: 0.0100 - val_loss: 0.0337 - val_mse: 0.0337\n",
      "Epoch 34/100\n",
      " - 1s - loss: 0.0101 - mse: 0.0101 - val_loss: 0.0337 - val_mse: 0.0337\n",
      "Epoch 35/100\n",
      " - 0s - loss: 0.0100 - mse: 0.0100 - val_loss: 0.0337 - val_mse: 0.0337\n",
      "Epoch 36/100\n",
      " - 0s - loss: 0.0100 - mse: 0.0100 - val_loss: 0.0339 - val_mse: 0.0339\n",
      "Epoch 37/100\n",
      " - 0s - loss: 0.0099 - mse: 0.0099 - val_loss: 0.0336 - val_mse: 0.0336\n",
      "Epoch 38/100\n",
      " - 0s - loss: 0.0101 - mse: 0.0101 - val_loss: 0.0338 - val_mse: 0.0338\n",
      "Epoch 39/100\n",
      " - 0s - loss: 0.0101 - mse: 0.0101 - val_loss: 0.0337 - val_mse: 0.0337\n",
      "Epoch 40/100\n",
      " - 0s - loss: 0.0097 - mse: 0.0097 - val_loss: 0.0337 - val_mse: 0.0337\n",
      "Epoch 41/100\n",
      " - 0s - loss: 0.0101 - mse: 0.0101 - val_loss: 0.0338 - val_mse: 0.0338\n",
      "Epoch 42/100\n",
      " - 0s - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0335 - val_mse: 0.0335\n",
      "Epoch 43/100\n",
      " - 0s - loss: 0.0102 - mse: 0.0102 - val_loss: 0.0337 - val_mse: 0.0337\n",
      "Epoch 44/100\n",
      " - 0s - loss: 0.0099 - mse: 0.0099 - val_loss: 0.0339 - val_mse: 0.0339\n",
      "Epoch 45/100\n",
      " - 1s - loss: 0.0099 - mse: 0.0099 - val_loss: 0.0337 - val_mse: 0.0337\n",
      "Epoch 46/100\n",
      " - 1s - loss: 0.0099 - mse: 0.0099 - val_loss: 0.0337 - val_mse: 0.0337\n",
      "Epoch 47/100\n",
      " - 0s - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0339 - val_mse: 0.0339\n",
      "Epoch 48/100\n",
      " - 0s - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0335 - val_mse: 0.0335\n",
      "Epoch 49/100\n",
      " - 0s - loss: 0.0097 - mse: 0.0097 - val_loss: 0.0337 - val_mse: 0.0337\n",
      "Epoch 50/100\n",
      " - 0s - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0336 - val_mse: 0.0336\n",
      "Epoch 51/100\n",
      " - 0s - loss: 0.0097 - mse: 0.0097 - val_loss: 0.0339 - val_mse: 0.0339\n",
      "Epoch 52/100\n",
      " - 0s - loss: 0.0094 - mse: 0.0094 - val_loss: 0.0338 - val_mse: 0.0338\n",
      "Epoch 53/100\n",
      " - 0s - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0335 - val_mse: 0.0335\n",
      "Epoch 54/100\n",
      " - 0s - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0337 - val_mse: 0.0337\n",
      "Epoch 55/100\n",
      " - 0s - loss: 0.0097 - mse: 0.0097 - val_loss: 0.0337 - val_mse: 0.0337\n",
      "Epoch 56/100\n",
      " - 0s - loss: 0.0099 - mse: 0.0099 - val_loss: 0.0337 - val_mse: 0.0337\n",
      "Epoch 57/100\n",
      " - 1s - loss: 0.0093 - mse: 0.0093 - val_loss: 0.0337 - val_mse: 0.0337\n",
      "Epoch 58/100\n",
      " - 0s - loss: 0.0094 - mse: 0.0094 - val_loss: 0.0337 - val_mse: 0.0337\n",
      "Epoch 59/100\n",
      " - 0s - loss: 0.0094 - mse: 0.0094 - val_loss: 0.0338 - val_mse: 0.0338\n",
      "Epoch 60/100\n",
      " - 0s - loss: 0.0092 - mse: 0.0092 - val_loss: 0.0336 - val_mse: 0.0336\n",
      "Epoch 61/100\n",
      " - 0s - loss: 0.0093 - mse: 0.0093 - val_loss: 0.0338 - val_mse: 0.0338\n",
      "Epoch 62/100\n",
      " - 0s - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0336 - val_mse: 0.0336\n",
      "Epoch 63/100\n",
      " - 0s - loss: 0.0093 - mse: 0.0093 - val_loss: 0.0339 - val_mse: 0.0339\n",
      "Epoch 64/100\n",
      " - 0s - loss: 0.0092 - mse: 0.0092 - val_loss: 0.0336 - val_mse: 0.0336\n",
      "Epoch 65/100\n",
      " - 0s - loss: 0.0092 - mse: 0.0092 - val_loss: 0.0337 - val_mse: 0.0337\n",
      "Epoch 66/100\n",
      " - 0s - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0337 - val_mse: 0.0337\n",
      "Epoch 67/100\n",
      " - 0s - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0338 - val_mse: 0.0338\n",
      "Epoch 68/100\n",
      " - 1s - loss: 0.0094 - mse: 0.0094 - val_loss: 0.0339 - val_mse: 0.0339\n",
      "Epoch 69/100\n",
      " - 1s - loss: 0.0093 - mse: 0.0093 - val_loss: 0.0337 - val_mse: 0.0337\n",
      "Epoch 70/100\n",
      " - 0s - loss: 0.0094 - mse: 0.0094 - val_loss: 0.0338 - val_mse: 0.0338\n",
      "Epoch 71/100\n",
      " - 0s - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0338 - val_mse: 0.0338\n",
      "Epoch 72/100\n",
      " - 0s - loss: 0.0091 - mse: 0.0091 - val_loss: 0.0337 - val_mse: 0.0337\n",
      "Epoch 73/100\n",
      " - 0s - loss: 0.0091 - mse: 0.0091 - val_loss: 0.0336 - val_mse: 0.0336\n",
      "Epoch 74/100\n",
      " - 1s - loss: 0.0094 - mse: 0.0094 - val_loss: 0.0337 - val_mse: 0.0337\n",
      "Epoch 75/100\n",
      " - 0s - loss: 0.0091 - mse: 0.0091 - val_loss: 0.0336 - val_mse: 0.0336\n",
      "Epoch 76/100\n",
      " - 0s - loss: 0.0093 - mse: 0.0093 - val_loss: 0.0337 - val_mse: 0.0337\n",
      "Epoch 77/100\n",
      " - 0s - loss: 0.0092 - mse: 0.0092 - val_loss: 0.0337 - val_mse: 0.0337\n",
      "Epoch 78/100\n",
      " - 0s - loss: 0.0092 - mse: 0.0092 - val_loss: 0.0337 - val_mse: 0.0337\n",
      "Epoch 79/100\n",
      " - 0s - loss: 0.0089 - mse: 0.0089 - val_loss: 0.0337 - val_mse: 0.0337\n",
      "Epoch 80/100\n",
      " - 1s - loss: 0.0092 - mse: 0.0092 - val_loss: 0.0337 - val_mse: 0.0337\n",
      "Epoch 81/100\n",
      " - 1s - loss: 0.0091 - mse: 0.0091 - val_loss: 0.0337 - val_mse: 0.0337\n",
      "Epoch 82/100\n",
      " - 1s - loss: 0.0091 - mse: 0.0091 - val_loss: 0.0335 - val_mse: 0.0335\n",
      "Epoch 83/100\n",
      " - 1s - loss: 0.0092 - mse: 0.0092 - val_loss: 0.0337 - val_mse: 0.0337\n",
      "Epoch 84/100\n",
      " - 1s - loss: 0.0092 - mse: 0.0092 - val_loss: 0.0336 - val_mse: 0.0336\n",
      "Epoch 85/100\n",
      " - 0s - loss: 0.0088 - mse: 0.0088 - val_loss: 0.0335 - val_mse: 0.0335\n",
      "Epoch 86/100\n",
      " - 0s - loss: 0.0089 - mse: 0.0089 - val_loss: 0.0337 - val_mse: 0.0337\n",
      "Epoch 87/100\n",
      " - 0s - loss: 0.0092 - mse: 0.0092 - val_loss: 0.0338 - val_mse: 0.0338\n",
      "Epoch 88/100\n",
      " - 0s - loss: 0.0091 - mse: 0.0091 - val_loss: 0.0336 - val_mse: 0.0336\n",
      "Epoch 89/100\n",
      " - 0s - loss: 0.0089 - mse: 0.0089 - val_loss: 0.0337 - val_mse: 0.0337\n",
      "Epoch 90/100\n",
      " - 0s - loss: 0.0089 - mse: 0.0089 - val_loss: 0.0337 - val_mse: 0.0337\n",
      "Epoch 91/100\n",
      " - 0s - loss: 0.0089 - mse: 0.0089 - val_loss: 0.0336 - val_mse: 0.0336\n",
      "Epoch 92/100\n",
      " - 0s - loss: 0.0090 - mse: 0.0090 - val_loss: 0.0335 - val_mse: 0.0335\n",
      "Epoch 93/100\n",
      " - 0s - loss: 0.0092 - mse: 0.0092 - val_loss: 0.0337 - val_mse: 0.0337\n",
      "Epoch 94/100\n",
      " - 0s - loss: 0.0090 - mse: 0.0090 - val_loss: 0.0336 - val_mse: 0.0336\n",
      "Epoch 95/100\n",
      " - 0s - loss: 0.0091 - mse: 0.0091 - val_loss: 0.0335 - val_mse: 0.0335\n",
      "Epoch 96/100\n",
      " - 0s - loss: 0.0092 - mse: 0.0092 - val_loss: 0.0336 - val_mse: 0.0336\n",
      "Epoch 97/100\n",
      " - 1s - loss: 0.0088 - mse: 0.0088 - val_loss: 0.0334 - val_mse: 0.0334\n",
      "Epoch 98/100\n",
      " - 1s - loss: 0.0092 - mse: 0.0092 - val_loss: 0.0335 - val_mse: 0.0335\n",
      "Epoch 99/100\n",
      " - 0s - loss: 0.0091 - mse: 0.0091 - val_loss: 0.0335 - val_mse: 0.0335\n",
      "Epoch 100/100\n",
      " - 1s - loss: 0.0090 - mse: 0.0090 - val_loss: 0.0335 - val_mse: 0.0335\n",
      "real [[-363.91]]\n",
      "Test RMSE: 413.151\n",
      "Diff [[-413.15065333]]\n",
      "% Diff [[113.53099759]] %\n",
      "Predictions [[49.24065333]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAArOElEQVR4nO3de7xcZX3v8c9vXWZmX3PZCUlIgARBBSwXDYiVtl5bwCKcajX10rscq1bx1Yt46mltjz0ve07tq7VVKVqqVoQqiqIHwWpF24JKglEBQSIXE0KSnctO9nWuv/PHs2bvyWZ2mB0ymWTP9/16zWvvPev2PDOz13c9z7NmLXN3REREZos6XQARETk2KSBERKQpBYSIiDSlgBARkaYUECIi0pQCQkREmlJAiABm9nEze1+L8z5qZi9rd5lEOk0BISIiTSkgRBYQM0s6XQZZOBQQctzIunb+yMx+YGbjZvZPZrbCzL5iZqNm9jUzW9Iw/yvN7D4zGzGzO8zsjIZp55nZPdly/woUZm3rl81sc7bsnWZ2dotlfIWZfc/MDpjZVjN776zpF2XrG8mm/2b2fI+ZfcDMHjOz/Wb2n9lzLzKzbU1eh5dlv7/XzG4ys0+Z2QHgN83sAjO7K9vGE2b2D2aWa1j+LDP7NzPba2Y7zex/mNlKM5sws6GG+Z5nZsNmlrZSd1l4FBByvHkV8HLgmcBlwFeA/wEsI3ye3w5gZs8EbgCuApYDtwJfMrNctrP8AvAvwFLgs9l6yZZ9LnAd8N+BIeAfgVvMLN9C+caBXwcWA68Afs/MrsjWe3JW3r/PynQusDlb7q+B5wE/m5Xpj4Fai6/J5cBN2TavB6rAOwmvyQuAlwJvycowAHwNuA04ETgN+Lq77wDuAF7TsN43ADe6e7nFcsgCo4CQ483fu/tOd38c+A/gO+7+PXcvAjcD52XzvRb4f+7+b9kO7q+BHsIO+EIgBf7W3cvufhNwd8M23gT8o7t/x92r7v4JoJgtd0jufoe7/9Dda+7+A0JI/UI2+fXA19z9hmy7e9x9s5lFwG8D73D3x7Nt3pnVqRV3ufsXsm1Ouvsmd/+2u1fc/VFCwNXL8MvADnf/gLtPufuou38nm/YJQihgZjHwa4QQlS6lgJDjzc6G3yeb/N2f/X4i8Fh9grvXgK3A6mza437wlSofa/j9FOAPsi6aETMbAU7KljskM3u+mX0j65rZD7yZcCRPto6fNFlsGaGLq9m0VmydVYZnmtmXzWxH1u30v1soA8AXgTPN7FRCK22/u3/3MMskC4ACQhaq7YQdPQBmZoSd4+PAE8Dq7Lm6kxt+3wr8pbsvbnj0uvsNLWz308AtwEnuvgi4BqhvZyvwjCbL7Aam5pg2DvQ21CMmdE81mn1J5o8ADwCnu/sgoQvuqcqAu08BnyG0dN6IWg9dTwEhC9VngFeY2UuzQdY/IHQT3QncBVSAt5tZYma/AlzQsOxHgTdnrQEzs75s8Hmghe0OAHvdfcrMLgBe1zDteuBlZvaabLtDZnZu1rq5DvgbMzvRzGIze0E25vFjoJBtPwXeAzzVWMgAcAAYM7NnA7/XMO3LwEozu8rM8mY2YGbPb5j+SeA3gVcCn2qhvrKAKSBkQXL3Bwn96X9POEK/DLjM3UvuXgJ+hbAj3EcYr/h8w7IbCeMQ/5BN35LN24q3AH9hZqPAnxKCqr7enwKXEsJqL2GA+pxs8h8CPySMhewF/gqI3H1/ts6PEVo/48BBZzU18YeEYBolhN2/NpRhlNB9dBmwA3gIeHHD9P8iDI7fk41fSBcz3TBIRBqZ2b8Dn3b3j3W6LNJZCggRmWZm5wP/RhhDGe10eaSz1MUkIgCY2ScI35G4SuEgoBaEiIjMQS0IERFpakFd2GvZsmW+du3aThdDROS4sWnTpt3uPvu7NcACC4i1a9eycePGThdDROS4YWaPzTVNXUwiItKUAkJERJpSQIiISFMLagyimXK5zLZt25iamup0UdqqUCiwZs0a0lT3dhGRI2PBB8S2bdsYGBhg7dq1HHzxzoXD3dmzZw/btm1j3bp1nS6OiCwQC76LaWpqiqGhoQUbDgBmxtDQ0IJvJYnI0bXgAwJY0OFQ1w11FJGjqysC4imN7oCpA50uhYjIMUUBATC2E4rtuTbZyMgIH/7wh+e93KWXXsrIyMiRL5CISIsUEEC4G2N7Llo4V0BUq9VDLnfrrbeyePHitpRJRKQVC/4sppaYQZuuanv11Vfzk5/8hHPPPZc0Tenv72fVqlVs3ryZ+++/nyuuuIKtW7cyNTXFO97xDq688kpg5rIhY2NjXHLJJVx00UXceeedrF69mi9+8Yv09PS0pbwiInVdFRB//qX7uH97k7GG0jhEeyB5qjs5PtmZJw7yZ5edNef097///dx7771s3ryZO+64g1e84hXce++906ejXnfddSxdupTJyUnOP/98XvWqVzE0NHTQOh566CFuuOEGPvrRj/Ka17yGz33uc7zhDW+Yd1lFROajqwLi0I7OfTEuuOCCg76r8MEPfpCbb74ZgK1bt/LQQw89KSDWrVvHueeeC8Dznvc8Hn300aNSVhHpbl0VEHMe6e+8D3J9sGRt28vQ19c3/fsdd9zB1772Ne666y56e3t50Yte1PS7DPl8fvr3OI6ZnJxsezlFRDRIDUD7xiAGBgYYHW1+htT+/ftZsmQJvb29PPDAA3z7299uSxlERA5HV7Ug5mTtO4tpaGiIF77whTznOc+hp6eHFStWTE+7+OKLueaaazj77LN51rOexYUXXtiWMoiIHI4FdU/q9evX++wbBv3oRz/ijDPOOORypSfux+Ic6QmntbN4bddKXUVEGpnZJndf32yaupiASg2qtVqniyEickxRQEBbu5hERI5XCghCNJgCQkTkIAoIoJ1nMYmIHK8UEEC4FpOIiDRqa0CY2cVm9qCZbTGzq5tMf72Z/SB73Glm57S67JHkGoMQEXmStgWEmcXAh4BLgDOBXzOzM2fN9gjwC+5+NvC/gGvnseyRLC12jHQx9ff3d7oIIiJAe1sQFwBb3P1hdy8BNwKXN87g7ne6+77sz28Da1pd9sg7NgJCRORY0c5vUq8Gtjb8vQ14/iHm/x3gK/Nd1syuBK4EOPnkkw+vpNa+FsS73vUuTjnlFN7ylrcA8N73vhcz41vf+hb79u2jXC7zvve9j8svb3P+iYjMUzsDotnIb9O9sJm9mBAQF813WXe/lqxrav369Yfey3/latjxwyc93VOaxKhC7jC6d1b+DFzy/jknb9iwgauuumo6ID7zmc9w22238c53vpPBwUF2797NhRdeyCtf+UrdV1pEjintDIhtwEkNf68Bts+eyczOBj4GXOLue+az7BFjYG3qYTrvvPPYtWsX27dvZ3h4mCVLlrBq1Sre+c538q1vfYsoinj88cfZuXMnK1eubE8hREQOQzsD4m7gdDNbBzwObABe1ziDmZ0MfB54o7v/eD7LHpY5jvQndz5CoXqA5MRzmk5/ul796ldz0003sWPHDjZs2MD111/P8PAwmzZtIk1T1q5d2/Qy3yIindS2gHD3ipm9DbgdiIHr3P0+M3tzNv0a4E+BIeDDWfdKxd3Xz7Vsu8qKWVu/CbFhwwbe9KY3sXv3br75zW/ymc98hhNOOIE0TfnGN77BY4891sati4gcnrZe7tvdbwVunfXcNQ2//y7wu60u2z7tPc31rLPOYnR0lNWrV7Nq1Spe//rXc9lll7F+/XrOPfdcnv3sZ7dt2yIih0v3g4CjcrG+H/5wZnB82bJl3HXXXU3nGxsba2s5RERapUttAGBEBgvp3hgiIk+XAgKmTy+tKSBERKZ1RUA8ZcsgCwg/jm8apNaPiBxpCz4gCoUCe/bsOfQOtB4Qx+lO1t3Zs2cPhUKh00URkQVkwQ9Sr1mzhm3btjE8PDznPKXx/eTK+6nseYAkOT5fkkKhwJo1a556RhGRFh2fe8N5SNOUdevWHXKeH9z8Ac74/l/w8G/cw6nrnnGUSiYicmxb8F1MrYiTHADlUqnDJREROXYoIIA4DQFRKhc7XBIRkWOHAgKIkxRQC0JEpJECAkjqAVEpd7gkIiLHDgUEM11MFbUgRESmKSCApB4QGoMQEZmmgADS6YBQC0JEpE4BASS5EBBVjUGIiExTQABpmgegqhaEiMg0BQSQZi2IiloQIiLTFBBAmn2TulZRC0JEpE4BAUTZ9yA0BiEiMkMBARCFgKgpIEREpikgAOIsIKrqYhIRqVNAAEThqueuFoSIyDQFBDS0ICodLoiIyLFDAQHTLQidxSQiMkMBAdMBQU1dTCIidQoImO5i8qoCQkSkTgEB06e5ooAQEZmmgIDpFgQ1DVKLiNQpIACimBqG6ywmEZFpCohMjRhTC0JEZJoCIlOzBNNZTCIi0xQQmWqkgBARaaSAyIQWhLqYRETqFBAZtwTzCu7e6aKIiBwTFBCZWpQQe5VKTQEhIgIKiBmWkFiVUqXW6ZKIiBwTFBAZjxJSqhQVECIigAJimkcJCVWKlWqniyIickxoa0CY2cVm9qCZbTGzq5tMf7aZ3WVmRTP7w1nTHjWzH5rZZjPb2M5yAhCnJFQoltWCEBEBSNq1YjOLgQ8BLwe2AXeb2S3ufn/DbHuBtwNXzLGaF7v77naVsZFHqbqYREQatLMFcQGwxd0fdvcScCNweeMM7r7L3e8GOv4NNYsTYjRILSJS186AWA1sbfh7W/Zcqxz4qpltMrMr55rJzK40s41mtnF4ePgwiwpECalpDEJEpK6dAWFNnpvPlwxe6O7PBS4B3mpmP99sJne/1t3Xu/v65cuXH045AbA4zQap1YIQEYH2BsQ24KSGv9cA21td2N23Zz93ATcTuqzaZiYg1IIQEYH2BsTdwOlmts7McsAG4JZWFjSzPjMbqP8O/CJwb9tKSgiIlKrOYhIRybTtLCZ3r5jZ24DbgRi4zt3vM7M3Z9OvMbOVwEZgEKiZ2VXAmcAy4GYzq5fx0+5+W7vKCmBJOM21VFVAiIhAGwMCwN1vBW6d9dw1Db/vIHQ9zXYAOKedZZstinOhi0ktCBERQN+knhbF+ia1iEgjBUQmSnIkprOYRETqFBCZONE3qUVEGikgMlGS0/cgREQaKCAy06e5agxCRARQQMyIEhLT1VxFROoUEHVRQkJNXUwiIhkFRF39UhvlSqdLIiJyTFBA1EUpAJVKx688LiJyTFBA1MXhS+XVcqnDBREROTYoIOrUghAROYgCoi4OAVEtFztcEBGRY4MCoi6KAbUgRETqFBB1WRdTVQEhIgIoIGZkXUxe0SC1iAgoIGaoBSEichAFRF12mqtXFRAiIqCAmJG1IGrqYhIRARQQM6LQgqhVdKkNERFQQMyodzHVyrh7hwsjItJ5Coi6rIsp8SrlqgJCREQBUZed5ppYRTcNEhFBATEja0HovtQiIkFLAWFm7zCzQQv+yczuMbNfbHfhjqpsDEL3pRYRCVptQfy2ux8AfhFYDvwW8P62laoTshZETJWSAkJEpOWAsOznpcA/u/v3G55bGLLTXEMXk8YgRERaDYhNZvZVQkDcbmYDwMI6zK4PUlOlWF5YVRMRORxJi/P9DnAu8LC7T5jZUkI308JRb0FYRWMQIiK03oJ4AfCgu4+Y2RuA9wD721esDmhsQaiLSUSk5YD4CDBhZucAfww8BnyybaXqhGgmIDRILSLSekBUPFx/4nLg79z974CB9hWrA3Saq4jIQVodgxg1s3cDbwR+zsxiIG1fsTogagwIdTGJiLTagngtUCR8H2IHsBr4v20rVSc0fpNaZzGJiLQWEFkoXA8sMrNfBqbcfWGNQRw0SK2AEBFp9VIbrwG+C/wq8BrgO2b26nYW7KiLYhwjsYoGqUVEaH0M4k+A8919F4CZLQe+BtzUroJ1RJySVjQGISICrY9BRPVwyOyZx7LHjygloaYuJhERWm9B3GZmtwM3ZH+/Fri1PUXqHIsS8pHGIEREoPVB6j8CrgXOBs4BrnX3dz3VcmZ2sZk9aGZbzOzqJtOfbWZ3mVnRzP5wPsu2RZyQj2oUy+piEhFptQWBu38O+Fyr82fflfgQ8HJgG3C3md3i7vc3zLYXeDtwxWEse+RFKXlTF5OICDxFC8LMRs3sQJPHqJkdeIp1XwBscfeH3b0E3Ej4JvY0d9/l7ncD5fku2xZxSj6qMqUWhIjIoVsQ7v50LqexGtja8Pc24PlHelkzuxK4EuDkk0+efykbRaGLaVIBISLS1jORmt1QyI/0su5+rbuvd/f1y5cvb7lwTcUpuajGpL5JLSLS1oDYBpzU8PcaYPtRWPbwRQk5qzJVUgtCRKSdAXE3cLqZrTOzHLABuOUoLHv4ooScqYtJRATmcRbTfLl7xczeBtwOxMB17n6fmb05m36Nma0ENgKDQM3MrgLOdPcDzZZtV1mnxSmpVRUQIiK0MSAA3P1WZn2hzt2vafh9B6H7qKVl2y5KSSkxqS4mEZEFeLmMpyNrQeg0VxERBcTBooQUdTGJiIAC4mBRQpIFRLjDqohI91JANIpTEqq4o8ttiEjXU0A0ihJiKgAahxCRrqeAaBSnxB6CQeMQItLtFBCNonS6BTGhU11FpMspIBrFCVG9BaGAEJEup4BoFCXErjEIERFQQBwsSomygNAYhIh0OwVEozjFallAqItJRLqcAqJRlMwEhFoQItLlFBCN4hSrhbufagxCRLqdAqJRlGJeBVxdTCLS9RQQjaJw9fNwPSZdakNEupsColHcGBBqQYhId1NANIpSAAZSjUGIiCggGsX1gNAYhIiIAqJRNgbRn7q6mESk6ykgGmUtiN5EASEiooBolLUg+lKYUheTiHQ5BUSjbJC6P3Fd7ltEup4ColF2mmtvXFMXk4h0PQVEo2hmDEKnuYpIt1NANNIgtYjINAVEo6ihi0ljECLS5RQQjbKAKMS63LeIiAKiUdbF1JPUNAYhIl1PAdEoG6TuiWqUq065qiu6ikj3UkA0yk5zLUQhGNSKEJFupoBolLUgCnEICI1DiEg3U0A0ysYg8vUWREldTCLSvRQQjabPYnJALQgR6W4KiEZZQOQtBIMCQkS6mQKiUdbFlLNsDEJflhORLqaAaBTVxyBCMOgsJhHpZgqIRtlprvUWhC75LSLdTAHRKGtBpBqDEBFRQBwkVkCIiNS1NSDM7GIze9DMtpjZ1U2mm5l9MJv+AzN7bsO0R83sh2a22cw2trOc07KzmFKyMQh1MYlIF0vatWIzi4EPAS8HtgF3m9kt7n5/w2yXAKdnj+cDH8l+1r3Y3Xe3q4xPEsWAkaAWhIhIO1sQFwBb3P1hdy8BNwKXz5rncuCTHnwbWGxmq9pYpqcWp8ReIY1NASEiXa2dAbEa2Nrw97bsuVbnceCrZrbJzK6cayNmdqWZbTSzjcPDw0+/1FEKtQqFNNb3IESkq7UzIKzJcz6PeV7o7s8ldEO91cx+vtlG3P1ad1/v7uuXL19++KWtixOolulJY30PQkS6WjsDYhtwUsPfa4Dtrc7j7vWfu4CbCV1W7Ze1IHpysbqYRKSrtTMg7gZON7N1ZpYDNgC3zJrnFuDXs7OZLgT2u/sTZtZnZgMAZtYH/CJwbxvLOiNKoFqkR11MItLl2nYWk7tXzOxtwO1ADFzn7veZ2Zuz6dcAtwKXAluACeC3ssVXADebWb2Mn3b329pV1oOsOBN+fDuLe/4bk+X8UdmkiMixqG0BAeDutxJCoPG5axp+d+CtTZZ7GDinnWWb04veDf/0cq6IvsTnktd2pAgiIscCfZN6tpMugGdewivHPktU3N/p0oiIdIwCopmXvIeCT3D5+Gc7XRIRkY5RQDSz8jlsXvRSfqX0JRjd2enSiIh0hAJiDt888U0kVOAbf9npooiIdIQCYg6TA6fwydolcM8n4MGvdLo4IiJHnQJiDoU05v2l1+Arfwa+8BY48ESniyQiclQpIObQk8aUSCle/jGoTMHNV0JNX5wTke7R1u9BHM960pCdE4OnUrjkr+CW34cbXweDJ4JFISwqU1CehLQXVp0Nq86FodPALAsTD9/MjuLsZxpuSmQRVIpQnoBqCZI8pH3ZtFmXp6pVYXIf5Pog7Tnqr4OIdC8FxBx6cjGQ3RPivDfCjnvhvpvh8U3gtbCTT3rCTntqP3z/009/o1ESgiDXP7PeiT1hewCFRTCwCnqWQn4A8v2QFEJZoiT8rKsUYWoEigegVoPeJTPLmQEW1lschdJYmD8phO0mBahVoFoGr4YALAyGECuNhfVOZd8RidKw7bgegLlQh8Ki8KiWQh0m9oR1xrnwMINqBWrlUO5cX9hOkg+hWKsQAjYLVfcQlJN7oTgGvUuhbzn0LIbyVChXeSKsu14Pi0I9zbIwnwo/c31h2b7lYRvF0fCYHMnqNhIuGTn9GueZvq5ktZzNfyC8fgMrs/dkCZTGw7RKdtCQ6wvlmdgL47vCTzyUy+KwTP8J0DsUXqd6OeotVbMwXxRN38wKr4Xp09Pi8FoVR8PrAtC3LKwzKcy8ZpUi5AfDe5Lkw3MTe8NyvUPQvyK8ptVSOOgpT4TteDV8frw683elBNViWGecC69RbiCUrf4+1Cozr3+chrIkBUgL2ftcCGWvFMM2vTbz2cgud0N5Kvz0WvYgO9jKDrjq74nZzOe1/tpESXgk+YM/08XR8D6ZhXKkPRDnwzrjNKvDBJTHs9dhKryfXss+D4PZusoz25t+r6KZRxTP7B+SfPb52hf+b5J8+B/PD8wcQNYPOuvrjdPwmub7w/tcLYVHrdrwetTC58k9rPOZv/T090GzKCDmUEizgChlH7hL/094zGV0B2zfDCOPzXxIIPuHrn94y2Gn6NXwhiY9kOTCP1x5PHxwSxPhZ3k8fBj7T4DeZeHv0R1wYHv4kI3thD0PhWU926F6w8Vy41zYeRYWAQa7t4SddGlsZj6Lsn/uLGgqk+GfojKV7fRzYZ7SeBY0lbDD7lmSrZfw3Oz6lcZCmRrlF83UdXqHkIWLe/NlZrMohFyuN+zMiwcOnh7nw7qfdNHgBlGShc8c0l4oLA7veXEs28as9eX6w3sD4X14qnJDeC17h0Id6p+Jib2tLdsKi8N76cDsL3haHN7f8vjBz6d9IcQm9x76NZleTxZsST484lzYwZfGstedLAR6sx24z9S1vrM/Hlk8E0LHqr4T4I8eOuKrVUDMoScLiJYv+T2wEp51cRtL1GHuM0c2s7vBms1bGgs78SQfAiW73/eh118KO5z60R9k4ZPtfPKD4Wi6rjwVjvaTQthpx8nMesqTMy2v+hFW2hOO1sqTML47HNVbFNY7fXSda17vuvoRbF2tCuPDIbRz/TOtuvpReKUYjszzg026D2uh/OO7Q/nqR6j1enjDDrZWOfgo1X3mqD5KshZTtv5K1mqrTIVt5wbC61athMArT4bn612WtdpMS6PeAkzy4WCgfjRs0aHf90opzBMfYpdSq4UyVaZmWij1oLEovM7VYqhrUsim5We2X3+9669HeIPCaxElBx9w1LLWaaUUtlWezI7K+0P98PD5qXfz1g9yLAoHIGnWpZv2zLRg62FYX1eUznweG9+v+ntWr2elGN7bniXh/a2WwnqKY6GM9VZhFM+0mKulML00GtYb52bqN91SyXoCzMJybaCAmMNBXUwSPoSzd56Hmjc/EB7zWn92ZHqQHNDbfJm0AOnKFtfTuFwPLD4pPFoq1yHqHcVZN9OsciT50II7lCgKO+repc23awY8xU63mSQHg01uzBgnzbcVRdA3FB6Hq5XPRpTtfHO9QJNytOKpDjSmtVCe+X4+06yL7OlKC6HL9jigs5jm0NPYxSQi0oUUEHOYHoNQC0JEupQCYg71LibddlREupUCYg7qYhKRbqeAmEOvBqlFpMspIOZQH4OYUAtCRLqUAmIO+STCTGMQItK9FBBzMDN60lhjECLStRQQh9CTxhqDEJGupYA4hIICQkS6mALiEHpyMRNFBYSIdCcFxCGcuWqQf39wF/dt3//UM4uILDAKiEP4s8vOZElvyu/f8D3Gi8fwpX5FRNpAAXEIQ/15/va15/HI7nH+9Iv3dbo4IiJHlQLiKbzgGUP8/ktO53P3bOPj//UI1drBN4+ZKlcZmSh1qHQiIu2j+0G04O0vOY2Nj+7lvV+6n4/f+Si/fdE61g718aXvb+e2e3cwVqpw/tqlvOJnVvH8U5dSLNcYK1Yw4GfWLGKg0J6beYiItJO5H+L2jMeZ9evX+8aNG9uy7kq1xu337eSj//Ewm7eOADCQT/il56zkxEUFbrtvBz/eOfak5SKD56xexPlrl3LWiYM8e+Ugpy7v48BUmeHRInvHS0yWqhQrNSq1GqsX9/LMFf0s7s1RqdZ4fGSSn+6dYGlfjtNO6CefxE/ahojI4TKzTe6+vuk0BcT8uDvf2zrC3rESF52+bPqaTQBbdo1y3/YD9OcT+vMJU5UaGx/dy3ce2cvmrSOUKrWWt7O0L8foVJlydeb9SSLjtBP6GexJqdWcmjsnLe3lotOW8XOnL+eEgTwjk2X2jIXg2T9Z5sBUhf58zAuesYxFPTMtma17J3h49ziDhYTFvTmW9uYY7Emwp7qdKDBerPDI7nGW9edZMZhvaRkROTYpII4BlWqNR/eM86MnRnlszziLelKW9ecZ6s/Tm4vJJxFRZPx07wQP7Rzl4eFxFvfmOHVZHycP9TI8WuRHTxzggR2jjBcrxJFhBg/uGGP3WLgZfGRQm+PtjCPjeacsYc3iHr7zyF4eH5l80jx9uZjVS3pY1p9n30SZ3WNF9k+WWdyTsnwgz6KelK37Jti6d/KgZU5d3s/5a5fy0jNO4Py1S8klEZOlKk/sn2SiVKXmTrXmFCs1xosVxooViuUa5VqNas0pJDEnLe3l5KFelvbmmCpXmSxXw7Q0nn59ag617PMarpUVgsndGS9V2TdeCneGjCNyccSinpQomgmvWs3ZPVZkoJBO3+8DoFyt8ZPhMSpVZ8VggaG+3EHLiSxkCogFzN15YMco/7VlN/snywz15Rjqz7OkN8einpTBnoRdo0XueHAX//7AMLsOTHH+2qW84BlDnLFqkPFShf1ZGDw+Msnj+ybZPVZkSW9uOhT2T4busH0TJVYv6eVZK/pZt6yfveNFfjI8zkO7Rrn70X2UKjX6cjFJHLF/stzWeseR0Z9PKKQRIxNlik1aZ2lsrBgssGKwwL6JEtv2TVKq1DCD1Yt7OHV5PyMTJR7YMXpQ6y6JjL58QhobSXZT+kqtRqlSI40jlg/kWdafZ0lfjkISkU8jIjNGpyqMTpWZLFcpJDE9uZhcElEs15goVShVayzuzXFCtrwZVKtOpRYCNPysMVmuMlGqMlmqMjpVYWQytAYX9aQ8c8UAz1wxwOKelKlylalKjZo7uTgil0Tkk4hCGlNIY2IzipVaNl9Y31S5Sqnq9OVi+gsJfbmENI5IYyONI+LISCLDgV2jU2wfmWLXgSnMjHy2/rCdULdCGraXT2LK1ZkDgLFihclSlfFShb5cwilDfaxd1ssJA3kgHNwUyzX2jBfZPVZkqlxjcU/K4t4cffmYiVKViVI4kEjj8Brn4nAQFRnEUcRQX45l/Xl6cjGlSljXnrESNXciMyIzkqxeSWRUa85kObwGlZpnrXDozyesXPTkA4NSpcbe8RJ7xotMlKrTr21PdtDSl08OOlBpJhwYVRmbqnBgqsJEqUI+qb/2MdWaM1WpUSxXKVedSnbQNFhIWbW4MN2lPFGqsG1fOOAqpOH1L2SvST4NB1BpfHjnHCkgpO0mShXu3LKHb/54GDNYuajAqkUF+vMpkUGU7WD68gl92Y69/o87VqywdW8YaxmZLNGbhp1rZMZUtrMsVmphPZHhHrY3NlVhslxlSW+Oof4ci3tz4FCu1SiWawyPFXliZJKdB4os7k05eWkvq5f0MDJR5ifDYzw8PM5AIeE5qxdx1omD5JOIXaNFduyfYrxYoVxzqlXH8WwnGlGq1tg9WmR4rBiCqRzKVnWnP58wmLVOpsrV6bGlQhrRmwuBMzJRZtdokbFZ36uJIwsPs+n5e3IxA4WExT0pgz0pe8dL/HjnKDsPFI/qeztQSDCgWKlRqtZodZeRTyJ6czHjpeq8ulfnq5BGTJWf/vrTOBwYlCs1yjVvqcyRQRJF0+9fzUPXb60WPodPZ/dqBicM5KlUnT3jhz5Tcll/jo3veflhbmfugNBZTHJE9OYSXnbmCl525op5LzvUn+eUob42lOrYVb+MfJLtWOYzjrN/osx4qZK1FELrpVQNLZzpFkPWRVc/0sxnLZreXGhZTJSrjBcrIQirTrlao1wNrZFKNRxZLx/Ic+LiAr25md2Eu1Ou+vT26tuaLFfJxTMHAP35hDg7Gq/WnCf2T/Lo7gn2TpSoH5SmcdYKGAjdrCMTZfaNlxgvVenLxfRmR+jlaqhXKWst1Tx02e4ZL7F7rMjesRIDhZRlAzmG+vIkDTvqSi3Up1StkcZGIQmtqzSOiAwwGJ2qsGP/FNv3TzJZCvVIk4jeNGZpf1hnb9ZKmaqEA5aJYoXxrJVXycYDqzWfPhjCCOvJHv2FhMGsxVaq1hibqjBarJBENv3+pHFEEoeDhH0TpekWfRIba5b0ctLSXvrzMcXyzPtcqoaDoSRuT5eoAkKkAxpPbpivRb0pi3oPPnV6vuurn0gxX2ZGLjFySQT51paJo7CDW7Ok95DzrVrUM+/ySHvpi3IiItKUAkJERJpSQIiISFNtDQgzu9jMHjSzLWZ2dZPpZmYfzKb/wMye2+qyIiLSXm0LCDOLgQ8BlwBnAr9mZmfOmu0S4PTscSXwkXksKyIibdTOFsQFwBZ3f9jdS8CNwOWz5rkc+KQH3wYWm9mqFpcVEZE2amdArAa2Nvy9LXuulXlaWRYAM7vSzDaa2cbh4eGnXWgREQnaGRDNvrkx+3uFc83TyrLhSfdr3X29u69fvnz5PIsoIiJzaecX5bYBJzX8vQbY3uI8uRaWfZJNmzbtNrPHDqu0sAzYfZjLHq+6sc7QnfXuxjpDd9Z7vnU+Za4J7QyIu4HTzWwd8DiwAXjdrHluAd5mZjcCzwf2u/sTZjbcwrJP4u6H3YQws41zXY9koerGOkN31rsb6wzdWe8jWee2BYS7V8zsbcDtQAxc5+73mdmbs+nXALcClwJbgAngtw61bLvKKiIiT9bWazG5+62EEGh87pqG3x14a6vLiojI0aNvUs+4ttMF6IBurDN0Z727sc7QnfU+YnVeUPeDEBGRI0ctCBERaUoBISIiTXV9QHTLRQHN7CQz+4aZ/cjM7jOzd2TPLzWzfzOzh7KfSzpd1iPNzGIz+56ZfTn7uxvqvNjMbjKzB7L3/AULvd5m9s7ss32vmd1gZoWFWGczu87MdpnZvQ3PzVlPM3t3tn970Mx+aT7b6uqA6LKLAlaAP3D3M4ALgbdmdb0a+Lq7nw58Pft7oXkH8KOGv7uhzn8H3ObuzwbOIdR/wdbbzFYDbwfWu/tzCKfHb2Bh1vnjwMWznmtaz+x/fANwVrbMh7P9Xku6OiDooosCuvsT7n5P9vsoYYexmlDfT2SzfQK4oiMFbBMzWwO8AvhYw9MLvc6DwM8D/wTg7iV3H2GB15tw2n6PmSVAL+HqCwuuzu7+LWDvrKfnquflwI3uXnT3RwjfObug1W11e0C0fFHAhcTM1gLnAd8BVrj7ExBCBDihg0Vrh78F/hioNTy30Ot8KjAM/HPWtfYxM+tjAdfb3R8H/hr4KfAE4aoMX2UB13mWuer5tPZx3R4QLV8UcKEws37gc8BV7n6g0+VpJzP7ZWCXu2/qdFmOsgR4LvARdz8PGGdhdK3MKetzvxxYB5wI9JnZGzpbqmPC09rHdXtAtHJBwQXDzFJCOFzv7p/Pnt6Z3YOD7OeuTpWvDV4IvNLMHiV0H77EzD7Fwq4zhM/1Nnf/Tvb3TYTAWMj1fhnwiLsPu3sZ+DzwsyzsOjeaq55Pax/X7QExfUFBM8sRBnNu6XCZ2sLMjNAn/SN3/5uGSbcAv5H9/hvAF4922drF3d/t7mvcfS3hvf13d38DC7jOAO6+A9hqZs/KnnopcD8Lu94/BS40s97ss/5SwjjbQq5zo7nqeQuwwczy2cVPTwe+2/Ja3b2rH4SLBf4Y+AnwJ50uTxvreRGhafkDYHP2uBQYIpz18FD2c2mny9qm+r8I+HL2+4KvM3AusDF7v78ALFno9Qb+HHgAuBf4FyC/EOsM3EAYZykTWgi/c6h6An+S7d8eBC6Zz7Z0qQ0REWmq27uYRERkDgoIERFpSgEhIiJNKSBERKQpBYSIiDSlgBA5BpjZi+pXmxU5ViggRESkKQWEyDyY2RvM7LtmttnM/jG718SYmX3AzO4xs6+b2fJs3nPN7Ntm9gMzu7l+jX4zO83MvmZm38+WeUa2+v6Gezhcn30jWKRjFBAiLTKzM4DXAi9093OBKvB6oA+4x92fC3wT+LNskU8C73L3s4EfNjx/PfAhdz+HcL2gJ7LnzwOuItyb5FTCtaREOibpdAFEjiMvBZ4H3J0d3PcQLopWA/41m+dTwOfNbBGw2N2/mT3/CeCzZjYArHb3mwHcfQogW9933X1b9vdmYC3wn22vlcgcFBAirTPgE+7+7oOeNPufs+Y71PVrDtVtVGz4vYr+P6XD1MUk0rqvA682sxNg+j7ApxD+j16dzfM64D/dfT+wz8x+Lnv+jcA3PdyDY5uZXZGtI29mvUezEiKt0hGKSIvc/X4zew/wVTOLCFfTfCvhhjxnmdkmYD9hnALCZZevyQLgYeC3suffCPyjmf1Fto5fPYrVEGmZruYq8jSZ2Zi793e6HCJHmrqYRESkKbUgRESkKbUgRESkKQWEiIg0pYAQEZGmFBAiItKUAkJERJr6/8Wptw8RyWOKAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "target = 'close_diff_20'\n",
    "\n",
    "columns = columns_9\n",
    "num_features = len(columns)\n",
    "\n",
    "crypto = crypto\n",
    "execute_test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este metodo ofrece resultados aceptables en comparación con el calculo del precio como valor y por tanto usaremos este en vez del precio final como prediccion dado que si calculamos el precio final luego debemos calcular cuanto mas sube o baja con respecto al dia actual. Este método ya nos da directamente ese valor\n",
    "\n",
    "Como podemos ver la precision de prediccion no es demasiado acertada para las metricas y por tanto evitaremos su uso en nuestro modelo final\n",
    "\n",
    "La precision de este metodo mejorará al usar menos dias de predicción. De todas formas trataremos de mejorar la red con 20 dias en adelante antes de bajar a 10 o 5 dias. Además es posible que no exista una relación temparal tal como para el precio. Por eso podemos encontrar dificultades en el modelo para generar buenos resultados.\n",
    "\n",
    "En adelante usaremos la combinacion de precio con diferencia de precio. Si al modelo le costara mucho predecir la diferencia de precio usaremos solo el precio."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para calcular la operacion mas adecuada debemos cambiar la red para aceptar una activación softmax\n",
    "\n",
    "Vamos a buscar ejemplos donde se realiza una venta o compra en la fila de test para poner mas aprueba al modelo (debido a que la mayoria son hold).\n",
    "\n",
    "Debemos añadir un class weight en el modelo. Por eso analizamos el peso de cada clase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading... ETH\n",
      "Extracting columns columns for ETH\n",
      "Proccessing and arranging columns for LSTM model\n",
      "224\n",
      "221\n",
      "991\n"
     ]
    }
   ],
   "source": [
    "columns = columns_11\n",
    "\n",
    "target = None\n",
    "\n",
    "activation = 'softmax'\n",
    "loss = 'categorical_crossentropy'\n",
    "metrics = ['categorical_crossentropy', 'accuracy']\n",
    "\n",
    "crypto = 'ETH'\n",
    "\n",
    "sim = DLSimulator(crypto, prev_periods, pred_periods, columns, target,\n",
    "    norm_strat, model_sel, layers, neurons, batch_size, epochs, \n",
    "    activation, loss, metrics, optimizer, initial_learning_rate, callbacks)\n",
    "\n",
    "df = sim.get_df()\n",
    "\n",
    "print(len(df[(df['op_buy_0']==1)]))\n",
    "print(len(df[(df['op_sell_0']==1)]))\n",
    "print(len(df[(df['op_hold_0']==1)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Añadiremos al modelo un x4 para las clases sell y buy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The index [-7, -9, -15, -19] provide examples with buy and sell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading... ETH\n",
      "Extracting columns columns for ETH\n",
      "Proccessing and arranging columns for LSTM model\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>op_buy_19</th>\n",
       "      <th>op_sell_19</th>\n",
       "      <th>op_hold_19</th>\n",
       "      <th>op_buy_18</th>\n",
       "      <th>op_sell_18</th>\n",
       "      <th>op_hold_18</th>\n",
       "      <th>op_buy_17</th>\n",
       "      <th>op_sell_17</th>\n",
       "      <th>op_hold_17</th>\n",
       "      <th>op_buy_16</th>\n",
       "      <th>...</th>\n",
       "      <th>op_hold_2</th>\n",
       "      <th>op_buy_1</th>\n",
       "      <th>op_sell_1</th>\n",
       "      <th>op_hold_1</th>\n",
       "      <th>op_buy_0</th>\n",
       "      <th>op_sell_0</th>\n",
       "      <th>op_hold_0</th>\n",
       "      <th>op_buy</th>\n",
       "      <th>op_sell</th>\n",
       "      <th>op_hold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1567</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1568</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1569</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1570</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1571</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1429 rows × 63 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      op_buy_19  op_sell_19  op_hold_19  op_buy_18  op_sell_18  op_hold_18  \\\n",
       "143         0.0         0.0         1.0        0.0         1.0         0.0   \n",
       "144         0.0         1.0         0.0        0.0         0.0         1.0   \n",
       "145         0.0         0.0         1.0        0.0         0.0         1.0   \n",
       "146         0.0         0.0         1.0        1.0         0.0         0.0   \n",
       "147         1.0         0.0         0.0        0.0         0.0         1.0   \n",
       "...         ...         ...         ...        ...         ...         ...   \n",
       "1567        0.0         1.0         0.0        0.0         0.0         1.0   \n",
       "1568        0.0         0.0         1.0        0.0         0.0         1.0   \n",
       "1569        0.0         0.0         1.0        0.0         0.0         1.0   \n",
       "1570        0.0         0.0         1.0        0.0         0.0         1.0   \n",
       "1571        0.0         0.0         1.0        0.0         0.0         1.0   \n",
       "\n",
       "      op_buy_17  op_sell_17  op_hold_17  op_buy_16  ...  op_hold_2  op_buy_1  \\\n",
       "143         0.0         0.0         1.0        0.0  ...        1.0       0.0   \n",
       "144         0.0         0.0         1.0        1.0  ...        1.0       0.0   \n",
       "145         1.0         0.0         0.0        0.0  ...        1.0       0.0   \n",
       "146         0.0         0.0         1.0        0.0  ...        1.0       0.0   \n",
       "147         0.0         0.0         1.0        0.0  ...        1.0       0.0   \n",
       "...         ...         ...         ...        ...  ...        ...       ...   \n",
       "1567        0.0         0.0         1.0        0.0  ...        1.0       0.0   \n",
       "1568        0.0         0.0         1.0        0.0  ...        1.0       0.0   \n",
       "1569        0.0         0.0         1.0        0.0  ...        0.0       0.0   \n",
       "1570        0.0         0.0         1.0        0.0  ...        1.0       0.0   \n",
       "1571        0.0         1.0         0.0        1.0  ...        1.0       0.0   \n",
       "\n",
       "      op_sell_1  op_hold_1  op_buy_0  op_sell_0  op_hold_0  op_buy  op_sell  \\\n",
       "143         0.0        1.0         0          0          1     1.0      0.0   \n",
       "144         0.0        1.0         0          0          1     0.0      0.0   \n",
       "145         0.0        1.0         0          0          1     0.0      1.0   \n",
       "146         0.0        1.0         0          1          0     0.0      0.0   \n",
       "147         1.0        0.0         0          0          1     0.0      0.0   \n",
       "...         ...        ...       ...        ...        ...     ...      ...   \n",
       "1567        0.0        1.0         0          1          0     0.0      0.0   \n",
       "1568        1.0        0.0         0          0          1     0.0      0.0   \n",
       "1569        0.0        1.0         0          0          1     0.0      0.0   \n",
       "1570        0.0        1.0         0          0          1     0.0      1.0   \n",
       "1571        0.0        1.0         1          0          0     0.0      0.0   \n",
       "\n",
       "      op_hold  \n",
       "143       0.0  \n",
       "144       1.0  \n",
       "145       0.0  \n",
       "146       1.0  \n",
       "147       1.0  \n",
       "...       ...  \n",
       "1567      1.0  \n",
       "1568      1.0  \n",
       "1569      1.0  \n",
       "1570      0.0  \n",
       "1571      1.0  \n",
       "\n",
       "[1429 rows x 63 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>op_buy_19</th>\n",
       "      <th>op_sell_19</th>\n",
       "      <th>op_hold_19</th>\n",
       "      <th>op_buy_18</th>\n",
       "      <th>op_sell_18</th>\n",
       "      <th>op_hold_18</th>\n",
       "      <th>op_buy_17</th>\n",
       "      <th>op_sell_17</th>\n",
       "      <th>op_hold_17</th>\n",
       "      <th>op_buy_16</th>\n",
       "      <th>...</th>\n",
       "      <th>op_hold_2</th>\n",
       "      <th>op_buy_1</th>\n",
       "      <th>op_sell_1</th>\n",
       "      <th>op_hold_1</th>\n",
       "      <th>op_buy_0</th>\n",
       "      <th>op_sell_0</th>\n",
       "      <th>op_hold_0</th>\n",
       "      <th>op_buy</th>\n",
       "      <th>op_sell</th>\n",
       "      <th>op_hold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1572</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 63 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      op_buy_19  op_sell_19  op_hold_19  op_buy_18  op_sell_18  op_hold_18  \\\n",
       "1572        0.0         0.0         1.0        0.0         1.0         0.0   \n",
       "\n",
       "      op_buy_17  op_sell_17  op_hold_17  op_buy_16  ...  op_hold_2  op_buy_1  \\\n",
       "1572        1.0         0.0         0.0        0.0  ...        1.0       1.0   \n",
       "\n",
       "      op_sell_1  op_hold_1  op_buy_0  op_sell_0  op_hold_0  op_buy  op_sell  \\\n",
       "1572        0.0        0.0         0          0          1     0.0      1.0   \n",
       "\n",
       "      op_hold  \n",
       "1572      0.0  \n",
       "\n",
       "[1 rows x 63 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (1429, 20, 3) (1429, 3)\n",
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_71 (LSTM)               (None, 20, 25)            2900      \n",
      "_________________________________________________________________\n",
      "lstm_72 (LSTM)               (None, 20, 25)            5100      \n",
      "_________________________________________________________________\n",
      "dropout_57 (Dropout)         (None, 20, 25)            0         \n",
      "_________________________________________________________________\n",
      "lstm_73 (LSTM)               (None, 20, 25)            5100      \n",
      "_________________________________________________________________\n",
      "dropout_58 (Dropout)         (None, 20, 25)            0         \n",
      "_________________________________________________________________\n",
      "lstm_74 (LSTM)               (None, 20, 25)            5100      \n",
      "_________________________________________________________________\n",
      "dropout_59 (Dropout)         (None, 20, 25)            0         \n",
      "_________________________________________________________________\n",
      "lstm_75 (LSTM)               (None, 25)                5100      \n",
      "_________________________________________________________________\n",
      "dropout_60 (Dropout)         (None, 25)                0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 3)                 78        \n",
      "=================================================================\n",
      "Total params: 23,378\n",
      "Trainable params: 23,378\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Y shape (1429, 3)\n",
      "Train on 1429 samples, validate on 286 samples\n",
      "Epoch 1/100\n",
      " - 13s - loss: 2.1230 - categorical_crossentropy: 1.0915 - accuracy: 0.3625 - val_loss: 1.0728 - val_categorical_crossentropy: 1.0728 - val_accuracy: 0.6783\n",
      "Epoch 2/100\n",
      " - 4s - loss: 2.1187 - categorical_crossentropy: 1.0684 - accuracy: 0.6900 - val_loss: 1.0644 - val_categorical_crossentropy: 1.0644 - val_accuracy: 0.6783\n",
      "Epoch 3/100\n",
      " - 5s - loss: 2.1182 - categorical_crossentropy: 1.0689 - accuracy: 0.6914 - val_loss: 1.0670 - val_categorical_crossentropy: 1.0670 - val_accuracy: 0.6783\n",
      "Epoch 4/100\n",
      " - 5s - loss: 2.1196 - categorical_crossentropy: 1.0643 - accuracy: 0.6900 - val_loss: 1.0614 - val_categorical_crossentropy: 1.0614 - val_accuracy: 0.6783\n",
      "Epoch 5/100\n",
      " - 5s - loss: 2.1195 - categorical_crossentropy: 1.0633 - accuracy: 0.6900 - val_loss: 1.0623 - val_categorical_crossentropy: 1.0623 - val_accuracy: 0.6783\n",
      "Epoch 6/100\n",
      " - 5s - loss: 2.1181 - categorical_crossentropy: 1.0636 - accuracy: 0.6900 - val_loss: 1.0645 - val_categorical_crossentropy: 1.0645 - val_accuracy: 0.6783\n",
      "Epoch 7/100\n",
      " - 4s - loss: 2.1160 - categorical_crossentropy: 1.0622 - accuracy: 0.6900 - val_loss: 1.0573 - val_categorical_crossentropy: 1.0573 - val_accuracy: 0.6783\n",
      "Epoch 8/100\n",
      " - 5s - loss: 2.1196 - categorical_crossentropy: 1.0579 - accuracy: 0.6886 - val_loss: 1.0614 - val_categorical_crossentropy: 1.0614 - val_accuracy: 0.6783\n",
      "Epoch 9/100\n",
      " - 5s - loss: 2.1194 - categorical_crossentropy: 1.0637 - accuracy: 0.6893 - val_loss: 1.0632 - val_categorical_crossentropy: 1.0632 - val_accuracy: 0.6783\n",
      "Epoch 10/100\n",
      " - 5s - loss: 2.1197 - categorical_crossentropy: 1.0648 - accuracy: 0.6865 - val_loss: 1.0673 - val_categorical_crossentropy: 1.0673 - val_accuracy: 0.6783\n",
      "Epoch 11/100\n",
      " - 5s - loss: 2.1178 - categorical_crossentropy: 1.0715 - accuracy: 0.6893 - val_loss: 1.0695 - val_categorical_crossentropy: 1.0695 - val_accuracy: 0.6783\n",
      "Epoch 12/100\n",
      " - 5s - loss: 2.1188 - categorical_crossentropy: 1.0627 - accuracy: 0.6872 - val_loss: 1.0567 - val_categorical_crossentropy: 1.0567 - val_accuracy: 0.6783\n",
      "Epoch 13/100\n",
      " - 5s - loss: 2.1181 - categorical_crossentropy: 1.0596 - accuracy: 0.6886 - val_loss: 1.0615 - val_categorical_crossentropy: 1.0615 - val_accuracy: 0.6783\n",
      "Epoch 14/100\n",
      " - 5s - loss: 2.1179 - categorical_crossentropy: 1.0626 - accuracy: 0.6865 - val_loss: 1.0580 - val_categorical_crossentropy: 1.0580 - val_accuracy: 0.6783\n",
      "Epoch 15/100\n",
      " - 6s - loss: 2.1203 - categorical_crossentropy: 1.0620 - accuracy: 0.6851 - val_loss: 1.0653 - val_categorical_crossentropy: 1.0653 - val_accuracy: 0.6783\n",
      "Epoch 16/100\n",
      " - 9s - loss: 2.1184 - categorical_crossentropy: 1.0675 - accuracy: 0.6893 - val_loss: 1.0671 - val_categorical_crossentropy: 1.0671 - val_accuracy: 0.6783\n",
      "Epoch 17/100\n",
      " - 7s - loss: 2.1181 - categorical_crossentropy: 1.0680 - accuracy: 0.6893 - val_loss: 1.0676 - val_categorical_crossentropy: 1.0676 - val_accuracy: 0.6783\n",
      "Epoch 18/100\n",
      " - 5s - loss: 2.1179 - categorical_crossentropy: 1.0648 - accuracy: 0.6886 - val_loss: 1.0614 - val_categorical_crossentropy: 1.0614 - val_accuracy: 0.6783\n",
      "Epoch 19/100\n",
      " - 5s - loss: 2.1200 - categorical_crossentropy: 1.0629 - accuracy: 0.6914 - val_loss: 1.0646 - val_categorical_crossentropy: 1.0646 - val_accuracy: 0.6783\n",
      "Epoch 20/100\n",
      " - 5s - loss: 2.1184 - categorical_crossentropy: 1.0675 - accuracy: 0.6900 - val_loss: 1.0697 - val_categorical_crossentropy: 1.0697 - val_accuracy: 0.6783\n",
      "Epoch 21/100\n",
      " - 5s - loss: 2.1175 - categorical_crossentropy: 1.0690 - accuracy: 0.6907 - val_loss: 1.0651 - val_categorical_crossentropy: 1.0651 - val_accuracy: 0.6783\n",
      "Epoch 22/100\n",
      " - 5s - loss: 2.1185 - categorical_crossentropy: 1.0631 - accuracy: 0.6886 - val_loss: 1.0586 - val_categorical_crossentropy: 1.0586 - val_accuracy: 0.6783\n",
      "Epoch 23/100\n",
      " - 5s - loss: 2.1190 - categorical_crossentropy: 1.0595 - accuracy: 0.6907 - val_loss: 1.0607 - val_categorical_crossentropy: 1.0607 - val_accuracy: 0.6783\n",
      "Epoch 24/100\n",
      " - 5s - loss: 2.1185 - categorical_crossentropy: 1.0612 - accuracy: 0.6900 - val_loss: 1.0635 - val_categorical_crossentropy: 1.0635 - val_accuracy: 0.6783\n",
      "Epoch 25/100\n",
      " - 5s - loss: 2.1176 - categorical_crossentropy: 1.0661 - accuracy: 0.6809 - val_loss: 1.0646 - val_categorical_crossentropy: 1.0646 - val_accuracy: 0.6783\n",
      "Epoch 26/100\n",
      " - 5s - loss: 2.1208 - categorical_crossentropy: 1.0654 - accuracy: 0.6760 - val_loss: 1.0641 - val_categorical_crossentropy: 1.0641 - val_accuracy: 0.6783\n",
      "Epoch 27/100\n",
      " - 5s - loss: 2.1181 - categorical_crossentropy: 1.0657 - accuracy: 0.6900 - val_loss: 1.0659 - val_categorical_crossentropy: 1.0659 - val_accuracy: 0.6783\n",
      "Epoch 28/100\n",
      " - 5s - loss: 2.1187 - categorical_crossentropy: 1.0669 - accuracy: 0.6886 - val_loss: 1.0655 - val_categorical_crossentropy: 1.0655 - val_accuracy: 0.6783\n",
      "Epoch 29/100\n",
      " - 5s - loss: 2.1189 - categorical_crossentropy: 1.0653 - accuracy: 0.6900 - val_loss: 1.0650 - val_categorical_crossentropy: 1.0650 - val_accuracy: 0.6783\n",
      "Epoch 30/100\n",
      " - 5s - loss: 2.1180 - categorical_crossentropy: 1.0649 - accuracy: 0.6872 - val_loss: 1.0640 - val_categorical_crossentropy: 1.0640 - val_accuracy: 0.6783\n",
      "Epoch 31/100\n",
      " - 6s - loss: 2.1201 - categorical_crossentropy: 1.0620 - accuracy: 0.6900 - val_loss: 1.0618 - val_categorical_crossentropy: 1.0618 - val_accuracy: 0.6783\n",
      "Epoch 32/100\n",
      " - 5s - loss: 2.1174 - categorical_crossentropy: 1.0629 - accuracy: 0.6900 - val_loss: 1.0626 - val_categorical_crossentropy: 1.0626 - val_accuracy: 0.6783\n",
      "real [[0. 1. 0.]]\n",
      "Test RMSE: 0.485\n",
      "Diff [[-0.32473758  0.68504483 -0.36030719]]\n",
      "% Diff [[       -inf 68.50448251        -inf]] %\n",
      "Predictions [[0.32473758 0.31495517 0.36030719]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../dl_solutions/dlsolutions.py:311: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  print('% Diff', 100*((inv_y - inv_preds)/inv_y), '%')\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAgZElEQVR4nO3de5hddX3v8fdnX+aWTC4kAUJCSLSCFg+GEpGKPU0frQUpYitFKNpiW2mr5xR4esF62kKt7WNb7VNbT0VUDthSWspFrKdipUegFlATGgUBxSqQAUImCUlmkrntvb/nj/XbMzuTmcmQZM+emfV5Pc961n2v31pr799nXfZeWxGBmZnlV6HVBTAzs9ZyEJiZ5ZyDwMws5xwEZmY55yAwM8s5B4GZWc45CCxXJN0o6UPTnPYpSW9qdpnMWs1BYGaWcw4CszlIUqnVZbD5w0Fgs066JPPbkr4laZ+kz0g6TtIXJfVJukfS0obp3yrp25J2S7pX0qsaxp0u6eE03z8CHeOW9dOStqR5H5B02jTLeJ6k/5S0V9JWSdeOG/+G9Hq70/jL0vBOSR+V9LSkPZK+moZtlNQzwXZ4U+q+VtJtkv5O0l7gMklnSnowLeN5SR+X1NYw/6mSvixpl6QXJH1A0vGS9kta1jDdGZJ6JZWns+42/zgIbLZ6O/CTwMnA+cAXgQ8Ay8net78BIOlk4BbgSmAF8C/AP0tqS5Xi54C/BY4B/im9LmneHwFuAH4VWAZ8Evi8pPZplG8f8AvAEuA84NclvS297ppU3r9OZVoPbEnzfQQ4A3h9KtPvALVpbpMLgNvSMm8GqsBVZNvkR4E3Au9NZegG7gHuBk4Afgj4t4jYBtwLXNTwuu8E/iEiRqZZDptnHAQ2W/11RLwQEc8C/w58LSL+MyKGgDuB09N07wD+b0R8OVVkHwE6ySras4Ay8JcRMRIRtwHfaFjGe4BPRsTXIqIaETcBQ2m+KUXEvRHxSETUIuJbZGH042n0pcA9EXFLWu7OiNgiqQD8EnBFRDyblvlAWqfpeDAiPpeWORARmyPioYioRMRTZEFWL8NPA9si4qMRMRgRfRHxtTTuJrLKH0lF4BKysLScchDYbPVCQ/fABP0LU/cJwNP1ERFRA7YCq9K4Z+PAJys+3dB9EvCb6dLKbkm7gRPTfFOS9DpJX0mXVPYAv0Z2ZE56jf+aYLblZJemJho3HVvHleFkSV+QtC1dLvqTaZQB4C7ghyW9jOysa09EfP0wy2TzgIPA5rrnyCp0ACSJrBJ8FngeWJWG1a1p6N4K/HFELGlouiLilmks9++BzwMnRsRi4DqgvpytwMsnmGcHMDjJuH1AV8N6FMkuKzUa/6jgTwBPAK+IiEVkl84OVQYiYhC4lezM5V34bCD3HAQ2190KnCfpjelm52+SXd55AHgQqAC/Iakk6WeBMxvm/RTwa+noXpIWpJvA3dNYbjewKyIGJZ0J/HzDuJuBN0m6KC13maT16WzlBuAvJJ0gqSjpR9M9ie8CHWn5ZeD3gEPdq+gG9gL9kl4J/HrDuC8Ax0u6UlK7pG5Jr2sY/1ngMuCtwN9NY31tHnMQ2JwWEd8hu97912RH3OcD50fEcEQMAz9LVuG9SHY/4Y6GeTeR3Sf4eBr/vTTtdLwX+KCkPuAPyAKp/rrPAG8hC6VdZDeKX5NG/xbwCNm9il3AnwKFiNiTXvPTZGcz+4ADvkU0gd8iC6A+slD7x4Yy9JFd9jkf2AY8CfxEw/j/ILtJ/XC6v2A5Jv8xjVk+Sfp/wN9HxKdbXRZrLQeBWQ5Jei3wZbJ7HH2tLo+1li8NmeWMpJvIfmNwpUPAwGcEZma55zMCM7Ocm3MPrlq+fHmsXbu21cUwM5tTNm/evCMixv82BZiDQbB27Vo2bdrU6mKYmc0pkp6ebJwvDZmZ5ZyDwMws5xwEZmY5N+fuEUxkZGSEnp4eBgcHW12Upuvo6GD16tWUy/4PETM7OuZFEPT09NDd3c3atWs58EGT80tEsHPnTnp6eli3bl2ri2Nm88S8uDQ0ODjIsmXL5nUIAEhi2bJluTjzMbOZMy+CAJj3IVCXl/U0s5kzLy4NTcfgSJXd+0coFUWpkDXFQoFSURQLouAK1mxOqVRr7BuqogIsaCtRLPgzfLhyFQTb+ya/pFJsCIdiQaN/81TPB6We0eFkfxcVAbv3vMhdt93Kpe9+DxHZ8FpE6o6x/5Ua9z791Usv5CN/8xkWLV4yuiyRHfXXuwuj3akt2L1/hD//0hN0tZXoKBfpLBfpbCvQWS7R2Zb1Fwuwd6DCnoERdu8fZs9Ahd0Dw+zZP5INS8MHR2pjy25cTr0caVyQrXDjuo2uY8TotiiXREepSGdbkY5SkfZygc5ykY5ykY7U3V4uUq0FlWqNkdSuVIPh1K7UaoxUg1oEUrZfCqrvH43uq0JqN26v+jqM354AlVqN/cNV9g9V2T9SZWC4wr6hKgMjVfYPV7Jxw1UKgvZSVt56u6NhHerDioUCBaV9lJZT7y8UDtx+47cr44ZHwMBIlcFUloGRGgPDFQZGqgwMp2akSqUWtJeKtJcKtJcKtJUKtJeLtBcLtJcLaXiRcjEd6BQ0dvBTLIxuw3p3tZZt70o1GGnY9pVqjUotGKnWqNaCai2opX1djay7Vsv2US2CWi17r0uimNa/oLGDrKx7bNjogVhBFItj+7Zx+EitRt9ghb7BCnsHRugbHBnrHxxh/3D1gM9TR7nAwvYSC9pLdLWVWNheZEHqX9BWRCiVPajVgmp6D9fGrV8tvZ/r/TR+ntM8QNqujdu4kLbt2PaOYGw/jtQYHB57vw2O1Eb3b0GwsCMra3cq88J60zHWv+GkpbzuZcsmrccOV26CYElXG4s7y+mNnzXV9GYf669/KLLKsV5/jz2XLw6oEAEKgh07X+Rvb/gUl1z2HiQoSpQQtVqVUqk0vv4fnfdvb/3cAUPrlWnjG7Faq6Xh9coX9g9X+MS9W6m9xOcFdreXWNxVZnFnmSVdZV55/CI6ysW0jjG2nFSOxuUyLpgaK7/GSnikGgymCm1gpErfYIXevqE0LHvjD1Wq2TYqFiinD1C5JMrpDK1UKKSKTNmHNe2fWqq0apFV6tVqVilluytGy8z49Rj94GZB1NVWpKu9RFe5yMrFZTrb0rC2El1tRQJGyzs0UmWoUsv6K9mw3ftHGKrUGirCA0Ox3l+vSA7arnHg+yhS4HWksnWWi3S0FeksFzi2u2M0SLvaihQLYqhSY6hSZbhSS901hitV+ocq7OzPxlVqMRqq1VpWyTdW+pWGN0+9Ai4XD97+5YbwKDRU8IUDQi8FHwVqkS1nOC2vHhzVWgqRVOlWIytf/fNYrdVSO0bbxYJY1FGiu6NMd0eJ7o4Sxy3qSN3l0XZE0D9UYd9Qhf6hrJLNuivs7B/mmZ372TdcIYLR9cjaUChkwVVMBxSj65Te0EqfcY12a/SAbnCkRqVWpZLCslIbC9D6NgdG92n9IG1Fdzud5a7RfdpRLlAL6B+s0D9coX8wK/8z+/Y3rFeFkWrw3o0vdxAcKSmldfHovu41V36IrU//gAvf/AbK5TILFy5k5cqVbNmyhccee4y3ve1tbN26lcHBQa644gouv/xyYOxxGf39/Zx77rm84Q1v4IEHHmDVqlXcdddddHZ2Trweezr5rz95CyPVGD1SHD1yTJXwSLWWKvwsABd1lCgV580tITtC9Uq5XpHb7DdUqTYclB5d8y4I/vCfv81jz+09qq/5wycs4przT510/Ic//GEeffRRtmzZwr333st5553Ho48+OvoVzxtuuIFjjjmGgYEBXvva1/L2t7+dZcsOTPUnn3ySW265hU996lNcdNFF3H777bzzne+cdJmSaCuJtlKBxfg3BfbS1A+KbO5oP9pHsA3mXRDMBmeeeeYB3/P/q7/6K+68804Atm7dypNPPnlQEKxbt47169cDcMYZZ/DUU0/NVHHNLOfmXRBMdeQ+UxYsWDDafe+993LPPffw4IMP0tXVxcaNGyf8HUB7e/tod7FYZGBgYEbKambmi8ZHQXd3N319E//j3549e1i6dCldXV088cQTPPTQQzNcOjOzqc27M4JWWLZsGWeffTavfvWr6ezs5Ljjjhsdd84553Dddddx2mmnccopp3DWWWe1sKRmZgebc/9ZvGHDhhj/xzSPP/44r3rVq1pUopmXt/U1syMnaXNEbJhonC8NmZnlnIPAzCznHARmZjnnIDAzyzkHgZlZzjkIzMxyzkHQAgsXLmx1EczMRjkIzMxyzr8sPgquvvpqTjrpJN773vcCcO211yKJ+++/nxdffJGRkRE+9KEPccEFF7S4pGZmB5t/QfDF98O2R47uax7/3+DcD086+uKLL+bKK68cDYJbb72Vu+++m6uuuopFixaxY8cOzjrrLN761rf6P4fNbNaZf0HQAqeffjrbt2/nueeeo7e3l6VLl7Jy5Uquuuoq7r//fgqFAs8++ywvvPACxx9/fKuLa2Z2gKYFgaQTgc8CxwM14PqI+Ni4aQR8DHgLsB+4LCIePqIFT3Hk3kwXXnght912G9u2bePiiy/m5ptvpre3l82bN1Mul1m7du2Ej582M2u1Zp4RVIDfjIiHJXUDmyV9OSIea5jmXOAVqXkd8InUnnMuvvhi3vOe97Bjxw7uu+8+br31Vo499ljK5TJf+cpXePrpp1tdRDOzCTUtCCLieeD51N0n6XFgFdAYBBcAn43sEagPSVoiaWWad0459dRT6evrY9WqVaxcuZJLL72U888/nw0bNrB+/Xpe+cpXtrqIZmYTmpF7BJLWAqcDXxs3ahWwtaG/Jw07IAgkXQ5cDrBmzZqmlfNIPfLI2E3q5cuX8+CDD044XX9//0wVyczskJr+OwJJC4HbgSsjYvy/yk/0FZqD/iAhIq6PiA0RsWHFihXNKKaZWW41NQgklclC4OaIuGOCSXqAExv6VwPPNbNMZmZ2oKYFQfpG0GeAxyPiLyaZ7PPALyhzFrDncO8PzLV/WjtceVlPM5s5zbxHcDbwLuARSVvSsA8AawAi4jrgX8i+Ovo9sq+PvvtwFtTR0cHOnTtZtmzZvP7BVkSwc+dOOjo6Wl0UM5tHmvmtoa8y8T2AxmkCeN+RLmv16tX09PTQ29t7pC8163V0dLB69epWF8PM5pF58cvicrnMunXrWl0MM7M5yU8fNTPLOQeBmVnOOQjMzHLOQWBmlnMOAjOznHMQmJnlnIPAzCznHARmZjnnIDAzyzkHgZlZzjkIzMxyzkFgZpZzDgIzs5xzEJiZ5ZyDwMws5xwEZmY55yAwM8s5B4GZWc45CMzMcs5BYGaWcw4CM7OccxCYmeWcg8DMLOccBGZmOecgMDPLOQeBmVnOOQjMzHKuaUEg6QZJ2yU9Osn4xZL+WdI3JX1b0rubVRYzM5tcM88IbgTOmWL8+4DHIuI1wEbgo5LamlgeMzObQNOCICLuB3ZNNQnQLUnAwjRtpVnlMTOzibXyHsHHgVcBzwGPAFdERG2iCSVdLmmTpE29vb0zWUYzs3mvlUHwU8AW4ARgPfBxSYsmmjAiro+IDRGxYcWKFTNXQjOzHGhlELwbuCMy3wN+ALyyheUxM8ulVgbBM8AbASQdB5wCfL+F5TEzy6VSs15Y0i1k3wZaLqkHuAYoA0TEdcAfATdKegQQcHVE7GhWeczMbGJNC4KIuOQQ458D3tys5ZuZ2fT4l8VmZjnnIDAzyzkHgZlZzjkIzMxyzkFgZpZzDgIzs5xzEJiZ5ZyDwMws5xwEZmY55yAwM8s5B4GZWc45CMzMcs5BYGaWcw4CM7OccxCYmeWcg8DMLOccBGZmOecgMDPLOQeBmVnOOQjMzHLOQWBmlnMOAjOznHMQmJnlnIPAzCznHARmZjnnIDAzyzkHgZlZzk0rCCRdIWmRMp+R9LCkNze7cGZm1nzTPSP4pYjYC7wZWAG8G/jwVDNIukHSdkmPTjHNRklbJH1b0n3TLrWZmR010w0CpfZbgP8TEd9sGDaZG4FzJn1BaQnwN8BbI+JU4OemWRYzMzuKphsEmyX9K1kQfElSN1CbaoaIuB/YNcUkPw/cERHPpOm3T7MsZmZ2FE03CH4ZeD/w2ojYD5TJLg8diZOBpZLulbRZ0i9MNqGkyyVtkrSpt7f3CBdrZmaNphsEPwp8JyJ2S3on8HvAniNcdgk4AzgP+Cng9yWdPNGEEXF9RGyIiA0rVqw4wsWamVmj6QbBJ4D9kl4D/A7wNPDZI1x2D3B3ROyLiB3A/cBrjvA1zczsJZpuEFQiIoALgI9FxMeA7iNc9l3Aj0kqSeoCXgc8foSvaWZmL1FpmtP1Sfpd4F1klXeR7D7BpCTdAmwElkvqAa6pzxMR10XE45LuBr5FduP50xEx6VdNzcysOaYbBO8g+5bPL0XENklrgD+faoaIuORQLxoRf36o1zEzs+aa1qWhiNgG3AwslvTTwGBEHOk9AjMzmwWm+4iJi4Cvk/3o6yLga5IubGbBzMxsZkz30tD/IvsNwXYASSuAe4DbmlUwMzObGdP91lBh3C9/d76Eec3MbBab7hnB3ZK+BNyS+t8B/EtzimRmZjNpWkEQEb8t6e3A2WQPm7s+Iu5sasnMzGxGTPeMgIi4Hbi9iWUxM7MWmDIIJPUBMdEoICJiUVNKZWZmM2bKIIiII32MhJmZzXL+5o+ZWc45CMzMcs5BYGaWcw4CM7OccxCYmeWcg8DMLOccBGZmOecgMDPLOQeBmVnOOQjMzHLOQWBmlnMOAjOznHMQmJnlnIPAzCznHARmZjnnIDAzyzkHgZlZzjkIzMxyzkFgZpZzTQsCSTdI2i7p0UNM91pJVUkXNqssZmY2uWaeEdwInDPVBJKKwJ8CX2piOczMbApNC4KIuB/YdYjJ/idwO7C9WeUwM7OptewegaRVwM8A101j2sslbZK0qbe3t/mFMzPLkVbeLP5L4OqIqB5qwoi4PiI2RMSGFStWNL9kZmY5UmrhsjcA/yAJYDnwFkmViPhcC8tkZpY7LQuCiFhX75Z0I/AFh4CZ2cxrWhBIugXYCCyX1ANcA5QBIuKQ9wXMzGxmNC0IIuKSlzDtZc0qh5mZTc2/LDYzyzkHgZlZzjkIzMxyzkFgZpZzDgIzs5xzEJiZ5ZyDwMws5xwEZmY55yAwM8s5B4GZWc45CMzMcs5BYGaWcw4CM7OccxCYmeWcg8DMLOccBGZmOecgMDPLOQeBmVnOOQjMzHLOQWBmlnMOAjOznHMQmJnlnIPAzCznHARmZjnnIDAzyzkHgZlZzjkIzMxyzkFgZpZzTQsCSTdI2i7p0UnGXyrpW6l5QNJrmlUWMzObXDPPCG4Ezpli/A+AH4+I04A/Aq5vYlnMzGwSpWa9cETcL2ntFOMfaOh9CFjdrLKYmdnkZss9gl8GvjjZSEmXS9okaVNvb+8MFsvMbP5reRBI+gmyILh6smki4vqI2BARG1asWDFzhTMzy4GmXRqaDkmnAZ8Gzo2Ina0si5lZXrXsjEDSGuAO4F0R8d1WlcPMLO+adkYg6RZgI7BcUg9wDVAGiIjrgD8AlgF/IwmgEhEbmlUeMzObWDO/NXTJIcb/CvArzVq+mZlNT8tvFpuZWWs5CMzMcs5BYGaWcw4CM7OccxCYmeWcg8DMLOccBGZmOecgMDPLOQeBmVnOOQjMzHLOQWBmlnMOAjOznHMQmJnlnIPAzCznHARmZjnnIDAzyzkHgZlZzrX0z+tn1H99Be5+Pyw/OWtWnALLX5F1ty1odenmr1oVRvbD8P6sPbIfKkPZdm9f2OrSzS+VYdi3HfpeyPoXLIcFK6Ctq7XlslkvP0FQ6oBjXgYvfBue+AJEbWzc4hNTKJwCK06G7pVZhTXUD8P7YLg/a8b3F0rZtItOOLDdvRK6lkHhME+4ajWoDKTKcx+MDIxVpNVhWLQKlp4E5c6js22mEgHVERjaC/t3TtDsOrB/qD9V/PtSpT848esWSrByPZz0ejjpbFhzFnQuaf76TKRWhT09sOv78OJTMLg7C6uRgaxdGRxrRurdQ1CrQFSz91IttUe7Uz+C7uNh8eqG5sSx7vbuyctVGYbBPdm2H9yTNQO7soq+f1tqp6ZvWzZuIm0Lx0JhwbEN3Stg8aqsPEvWQOdSyP4/vDmqFRjuy97L1eFs+1VHoDaSjasOp+6RtG1roCKokJVLhQObQhpXHck+LyON+6m+7xqGw8HzHtDUl1EcN00xG1coHjiuUM7axXLWXSylYaU0rASl9uxzWl6QtdsWZPPMMoqIVpfhJdmwYUNs2rTpyF6kMpR96Hd8F3q/m7V3fAd2PJlVXhMpdWQ7sW1h1rQvzF6nb1v2QWTcdiyUUziszOatVbM3dy29yUf76x+GdOQ8MpC9eaej+wQ4Zh0sXQtL16Xu1O5cmoXVaEW9a+KKfGjv5JVeffj4dWtU7spCr+sY6Dwmq9jaFmTD27qyD0BbV+pPw1WA57fA0w/As5uzCgDBca+GtWdn4bDm9bBwRbaMkQHo3w77escqvv7UvW97VrF0LM6CpGMxdCxJ3ePalSHY9QN48QfZ/t+V2rufyfbLeMX2bN+VUrvc0F3qGKsYGiuMQqGhu5jt175tWdDsfTYLiEYdS7KKuOuYbH8N7h2r+CcLUYBiGyw8Lmu6jz+wvfC4rOKqb7N9O7LtVO/u3w77dxx4MATZ+3rJmqyph8OSNdmBR9TG3p/1M7vR7oGx4B/qh6G+dOC0d6x/qG/67+ujTtn+UiGFdUNoj98GM6HYln0ORj8jndn7pbFOaKwjomH4634dfuJ3D2uxkjZHxIYJx+UyCCZTq2Uf1n3bU4W/YKxdLE8+X7WSjsqeh73PHdyujqSjhFLWnqwpd6ama6zyLHeNHUmUO7Pp9vRkR66jldoPsiPERioeXOmMjitklXbXMuhYlCq5zlTJdY4dxTT2t3enCr+xOebIz0pGBqBnUxYKT/8HbP36WIWxaFWqRPZOPG/n0qzSK3dl0wzszo7ma5VDL7etG45Zm50lLl2XtetBumB5FgKHe0Y3mcZQ2LM1tVOzf2e2jTsWQfuiFGiLoH1xQ/eibJ27jz/yo/daLTuD2NOTBeGerVl7d739DAztmeaLaex92t6dHSS1L0oHBQvTsIam3NVwFF0++Ii63i9lZ6SNlfYBTarQC+WGoO44+P1cLE+9rRqXMXpmN9mZXhp30IFcOqupH+jVu+sHU+PP7OtNvT8i1QPFhjqhOK6/BC/bCKece1i73EGQB8P7YffTY+GwrzerLLqWjVX69cq7Y8nRr+SOlsowPP/NLBS2P5aVdeGxqTkuu5xRb5faDp4/Ijs6Hdw9Fgz1dqE0VvEvWN7cyyDzwcDuLCD2PpdVSPXLG+MPTkod3pZzgIPAzCznpgqCWXpYaGZmM8VBYGaWcw4CM7OccxCYmeWcg8DMLOccBGZmOecgMDPLOQeBmVnOzbkflEnqBZ4+zNmXAzuOYnFaZT6sh9dhdvA6zA4zsQ4nRcSKiUbMuSA4EpI2TfbLurlkPqyH12F28DrMDq1eB18aMjPLOQeBmVnO5S0Irm91AY6S+bAeXofZweswO7R0HXJ1j8DMzA6WtzMCMzMbx0FgZpZzuQkCSedI+o6k70l6f6vLczgkPSXpEUlbJM2Jf+eRdIOk7ZIebRh2jKQvS3oytZe2soyHMsk6XCvp2bQvtkh6SyvLeCiSTpT0FUmPS/q2pCvS8DmzL6ZYhzmzLyR1SPq6pG+mdfjDNLyl+yEX9wgkFYHvAj8J9ADfAC6JiMdaWrCXSNJTwIaImDM/npH034F+4LMR8eo07M+AXRHx4RTKSyPi6laWcyqTrMO1QH9EfKSVZZsuSSuBlRHxsKRuYDPwNuAy5si+mGIdLmKO7AtJAhZERL+kMvBV4ArgZ2nhfsjLGcGZwPci4vsRMQz8A3BBi8uUCxFxP7Br3OALgJtS901kH+ZZa5J1mFMi4vmIeDh19wGPA6uYQ/tiinWYMyLTn3rLqQlavB/yEgSrgK0N/T3MsTdQEsC/Stos6fJWF+YIHBcRz0P24QaObXF5Dtf/kPStdOlo1l5SGU/SWuB04GvM0X0xbh1gDu0LSUVJW4DtwJcjouX7IS9BoAmGzcVrYmdHxI8A5wLvS5csrDU+AbwcWA88D3y0paWZJkkLgduBKyNib6vLczgmWIc5tS8iohoR64HVwJmSXt3iIuUmCHqAExv6VwPPtagshy0inkvt7cCdZJe85qIX0vXe+nXf7S0uz0sWES+kD3QN+BRzYF+ka9K3AzdHxB1p8JzaFxOtw1zcFwARsRu4FziHFu+HvATBN4BXSFonqQ24GPh8i8v0kkhakG6QIWkB8Gbg0annmrU+D/xi6v5F4K4WluWw1D+0yc8wy/dFukn5GeDxiPiLhlFzZl9Mtg5zaV9IWiFpSeruBN4EPEGL90MuvjUEkL5S9pdAEbghIv64tSV6aSS9jOwsAKAE/P1cWAdJtwAbyR6z+wJwDfA54FZgDfAM8HMRMWtvxk6yDhvJLkUE8BTwq/VrvLORpDcA/w48AtTS4A+QXWOfE/tiinW4hDmyLySdRnYzuEh2IH5rRHxQ0jJauB9yEwRmZjaxvFwaMjOzSTgIzMxyzkFgZpZzDgIzs5xzEJiZ5ZyDwGwGSdoo6QutLodZIweBmVnOOQjMJiDpnem58VskfTI9KKxf0kclPSzp3yStSNOul/RQeujZnfWHnkn6IUn3pGfPPyzp5enlF0q6TdITkm5Ov5g1axkHgdk4kl4FvIPsIX/rgSpwKbAAeDg9+O8+sl8YA3wWuDoiTiP71Wt9+M3A/46I1wCvJ3sgGmRPzbwS+GHgZcDZTV4lsymVWl0As1nojcAZwDfSwXon2UPAasA/pmn+DrhD0mJgSUTcl4bfBPxTei7Uqoi4EyAiBgHS6309InpS/xZgLdkflJi1hIPA7GACboqI3z1goPT746ab6vksU13uGWroruLPobWYLw2ZHezfgAslHQuj/yd7Etnn5cI0zc8DX42IPcCLkn4sDX8XcF96Tn6PpLel12iX1DWTK2E2XT4SMRsnIh6T9Htk/wZXAEaA9wH7gFMlbQb2kN1HgOyxwdeliv77wLvT8HcBn5T0wfQaPzeDq2E2bX76qNk0SeqPiIWtLofZ0eZLQ2ZmOeczAjOznPMZgZlZzjkIzMxyzkFgZpZzDgIzs5xzEJiZ5dz/B1N1wArbFnCqAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading... ETH\n",
      "Extracting columns columns for ETH\n",
      "Proccessing and arranging columns for LSTM model\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>op_buy_19</th>\n",
       "      <th>op_sell_19</th>\n",
       "      <th>op_hold_19</th>\n",
       "      <th>op_buy_18</th>\n",
       "      <th>op_sell_18</th>\n",
       "      <th>op_hold_18</th>\n",
       "      <th>op_buy_17</th>\n",
       "      <th>op_sell_17</th>\n",
       "      <th>op_hold_17</th>\n",
       "      <th>op_buy_16</th>\n",
       "      <th>...</th>\n",
       "      <th>op_hold_2</th>\n",
       "      <th>op_buy_1</th>\n",
       "      <th>op_sell_1</th>\n",
       "      <th>op_hold_1</th>\n",
       "      <th>op_buy_0</th>\n",
       "      <th>op_sell_0</th>\n",
       "      <th>op_hold_0</th>\n",
       "      <th>op_buy</th>\n",
       "      <th>op_sell</th>\n",
       "      <th>op_hold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1565</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1566</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1567</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1568</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1569</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1427 rows × 63 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      op_buy_19  op_sell_19  op_hold_19  op_buy_18  op_sell_18  op_hold_18  \\\n",
       "143         0.0         0.0         1.0        0.0         1.0         0.0   \n",
       "144         0.0         1.0         0.0        0.0         0.0         1.0   \n",
       "145         0.0         0.0         1.0        0.0         0.0         1.0   \n",
       "146         0.0         0.0         1.0        1.0         0.0         0.0   \n",
       "147         1.0         0.0         0.0        0.0         0.0         1.0   \n",
       "...         ...         ...         ...        ...         ...         ...   \n",
       "1565        0.0         0.0         1.0        0.0         0.0         1.0   \n",
       "1566        0.0         0.0         1.0        0.0         1.0         0.0   \n",
       "1567        0.0         1.0         0.0        0.0         0.0         1.0   \n",
       "1568        0.0         0.0         1.0        0.0         0.0         1.0   \n",
       "1569        0.0         0.0         1.0        0.0         0.0         1.0   \n",
       "\n",
       "      op_buy_17  op_sell_17  op_hold_17  op_buy_16  ...  op_hold_2  op_buy_1  \\\n",
       "143         0.0         0.0         1.0        0.0  ...        1.0       0.0   \n",
       "144         0.0         0.0         1.0        1.0  ...        1.0       0.0   \n",
       "145         1.0         0.0         0.0        0.0  ...        1.0       0.0   \n",
       "146         0.0         0.0         1.0        0.0  ...        1.0       0.0   \n",
       "147         0.0         0.0         1.0        0.0  ...        1.0       0.0   \n",
       "...         ...         ...         ...        ...  ...        ...       ...   \n",
       "1565        0.0         1.0         0.0        0.0  ...        0.0       0.0   \n",
       "1566        0.0         0.0         1.0        0.0  ...        1.0       0.0   \n",
       "1567        0.0         0.0         1.0        0.0  ...        1.0       0.0   \n",
       "1568        0.0         0.0         1.0        0.0  ...        1.0       0.0   \n",
       "1569        0.0         0.0         1.0        0.0  ...        0.0       0.0   \n",
       "\n",
       "      op_sell_1  op_hold_1  op_buy_0  op_sell_0  op_hold_0  op_buy  op_sell  \\\n",
       "143         0.0        1.0         0          0          1     1.0      0.0   \n",
       "144         0.0        1.0         0          0          1     0.0      0.0   \n",
       "145         0.0        1.0         0          0          1     0.0      1.0   \n",
       "146         0.0        1.0         0          1          0     0.0      0.0   \n",
       "147         1.0        0.0         0          0          1     0.0      0.0   \n",
       "...         ...        ...       ...        ...        ...     ...      ...   \n",
       "1565        0.0        1.0         0          0          1     0.0      0.0   \n",
       "1566        0.0        1.0         0          0          1     0.0      0.0   \n",
       "1567        0.0        1.0         0          1          0     0.0      0.0   \n",
       "1568        1.0        0.0         0          0          1     0.0      0.0   \n",
       "1569        0.0        1.0         0          0          1     0.0      0.0   \n",
       "\n",
       "      op_hold  \n",
       "143       0.0  \n",
       "144       1.0  \n",
       "145       0.0  \n",
       "146       1.0  \n",
       "147       1.0  \n",
       "...       ...  \n",
       "1565      1.0  \n",
       "1566      1.0  \n",
       "1567      1.0  \n",
       "1568      1.0  \n",
       "1569      1.0  \n",
       "\n",
       "[1427 rows x 63 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>op_buy_19</th>\n",
       "      <th>op_sell_19</th>\n",
       "      <th>op_hold_19</th>\n",
       "      <th>op_buy_18</th>\n",
       "      <th>op_sell_18</th>\n",
       "      <th>op_hold_18</th>\n",
       "      <th>op_buy_17</th>\n",
       "      <th>op_sell_17</th>\n",
       "      <th>op_hold_17</th>\n",
       "      <th>op_buy_16</th>\n",
       "      <th>...</th>\n",
       "      <th>op_hold_2</th>\n",
       "      <th>op_buy_1</th>\n",
       "      <th>op_sell_1</th>\n",
       "      <th>op_hold_1</th>\n",
       "      <th>op_buy_0</th>\n",
       "      <th>op_sell_0</th>\n",
       "      <th>op_hold_0</th>\n",
       "      <th>op_buy</th>\n",
       "      <th>op_sell</th>\n",
       "      <th>op_hold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1570</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 63 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      op_buy_19  op_sell_19  op_hold_19  op_buy_18  op_sell_18  op_hold_18  \\\n",
       "1570        0.0         0.0         1.0        0.0         0.0         1.0   \n",
       "\n",
       "      op_buy_17  op_sell_17  op_hold_17  op_buy_16  ...  op_hold_2  op_buy_1  \\\n",
       "1570        0.0         0.0         1.0        0.0  ...        1.0       0.0   \n",
       "\n",
       "      op_sell_1  op_hold_1  op_buy_0  op_sell_0  op_hold_0  op_buy  op_sell  \\\n",
       "1570        0.0        1.0         0          0          1     0.0      1.0   \n",
       "\n",
       "      op_hold  \n",
       "1570      0.0  \n",
       "\n",
       "[1 rows x 63 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (1427, 20, 3) (1427, 3)\n",
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_76 (LSTM)               (None, 20, 25)            2900      \n",
      "_________________________________________________________________\n",
      "lstm_77 (LSTM)               (None, 20, 25)            5100      \n",
      "_________________________________________________________________\n",
      "dropout_61 (Dropout)         (None, 20, 25)            0         \n",
      "_________________________________________________________________\n",
      "lstm_78 (LSTM)               (None, 20, 25)            5100      \n",
      "_________________________________________________________________\n",
      "dropout_62 (Dropout)         (None, 20, 25)            0         \n",
      "_________________________________________________________________\n",
      "lstm_79 (LSTM)               (None, 20, 25)            5100      \n",
      "_________________________________________________________________\n",
      "dropout_63 (Dropout)         (None, 20, 25)            0         \n",
      "_________________________________________________________________\n",
      "lstm_80 (LSTM)               (None, 25)                5100      \n",
      "_________________________________________________________________\n",
      "dropout_64 (Dropout)         (None, 25)                0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 3)                 78        \n",
      "=================================================================\n",
      "Total params: 23,378\n",
      "Trainable params: 23,378\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Y shape (1427, 3)\n",
      "Train on 1427 samples, validate on 286 samples\n",
      "Epoch 1/100\n",
      " - 13s - loss: 2.1211 - categorical_crossentropy: 1.0732 - accuracy: 0.4765 - val_loss: 1.0527 - val_categorical_crossentropy: 1.0527 - val_accuracy: 0.6748\n",
      "Epoch 2/100\n",
      " - 4s - loss: 2.1178 - categorical_crossentropy: 1.0661 - accuracy: 0.6826 - val_loss: 1.0674 - val_categorical_crossentropy: 1.0674 - val_accuracy: 0.6748\n",
      "Epoch 3/100\n",
      " - 5s - loss: 2.1185 - categorical_crossentropy: 1.0662 - accuracy: 0.6741 - val_loss: 1.0591 - val_categorical_crossentropy: 1.0591 - val_accuracy: 0.6748\n",
      "Epoch 4/100\n",
      " - 5s - loss: 2.1179 - categorical_crossentropy: 1.0584 - accuracy: 0.6854 - val_loss: 1.0611 - val_categorical_crossentropy: 1.0611 - val_accuracy: 0.6748\n",
      "Epoch 5/100\n",
      " - 5s - loss: 2.1177 - categorical_crossentropy: 1.0678 - accuracy: 0.6762 - val_loss: 1.0609 - val_categorical_crossentropy: 1.0609 - val_accuracy: 0.6748\n",
      "Epoch 6/100\n",
      " - 4s - loss: 2.1183 - categorical_crossentropy: 1.0626 - accuracy: 0.6896 - val_loss: 1.0625 - val_categorical_crossentropy: 1.0625 - val_accuracy: 0.6748\n",
      "Epoch 7/100\n",
      " - 4s - loss: 2.1181 - categorical_crossentropy: 1.0642 - accuracy: 0.6819 - val_loss: 1.0601 - val_categorical_crossentropy: 1.0601 - val_accuracy: 0.6748\n",
      "Epoch 8/100\n",
      " - 4s - loss: 2.1171 - categorical_crossentropy: 1.0595 - accuracy: 0.6889 - val_loss: 1.0585 - val_categorical_crossentropy: 1.0585 - val_accuracy: 0.6748\n",
      "Epoch 9/100\n",
      " - 4s - loss: 2.1161 - categorical_crossentropy: 1.0555 - accuracy: 0.6896 - val_loss: 1.0508 - val_categorical_crossentropy: 1.0508 - val_accuracy: 0.6748\n",
      "Epoch 10/100\n",
      " - 4s - loss: 2.1179 - categorical_crossentropy: 1.0561 - accuracy: 0.6790 - val_loss: 1.0655 - val_categorical_crossentropy: 1.0655 - val_accuracy: 0.6748\n",
      "Epoch 11/100\n",
      " - 4s - loss: 2.1161 - categorical_crossentropy: 1.0702 - accuracy: 0.6454 - val_loss: 1.0679 - val_categorical_crossentropy: 1.0679 - val_accuracy: 0.6748\n",
      "Epoch 12/100\n",
      " - 6s - loss: 2.1197 - categorical_crossentropy: 1.0694 - accuracy: 0.6377 - val_loss: 1.0646 - val_categorical_crossentropy: 1.0646 - val_accuracy: 0.6748\n",
      "Epoch 13/100\n",
      " - 6s - loss: 2.1195 - categorical_crossentropy: 1.0632 - accuracy: 0.6861 - val_loss: 1.0680 - val_categorical_crossentropy: 1.0680 - val_accuracy: 0.6748\n",
      "Epoch 14/100\n",
      " - 5s - loss: 2.1188 - categorical_crossentropy: 1.0718 - accuracy: 0.6868 - val_loss: 1.0689 - val_categorical_crossentropy: 1.0689 - val_accuracy: 0.6748\n",
      "Epoch 15/100\n",
      " - 5s - loss: 2.1168 - categorical_crossentropy: 1.0634 - accuracy: 0.6903 - val_loss: 1.0593 - val_categorical_crossentropy: 1.0593 - val_accuracy: 0.6748\n",
      "Epoch 16/100\n",
      " - 5s - loss: 2.1167 - categorical_crossentropy: 1.0571 - accuracy: 0.6903 - val_loss: 1.0553 - val_categorical_crossentropy: 1.0553 - val_accuracy: 0.6748\n",
      "Epoch 17/100\n",
      " - 5s - loss: 2.1185 - categorical_crossentropy: 1.0620 - accuracy: 0.6896 - val_loss: 1.0665 - val_categorical_crossentropy: 1.0665 - val_accuracy: 0.6748\n",
      "Epoch 18/100\n",
      " - 6s - loss: 2.1186 - categorical_crossentropy: 1.0687 - accuracy: 0.6903 - val_loss: 1.0659 - val_categorical_crossentropy: 1.0659 - val_accuracy: 0.6748\n",
      "Epoch 19/100\n",
      " - 6s - loss: 2.1183 - categorical_crossentropy: 1.0690 - accuracy: 0.6882 - val_loss: 1.0655 - val_categorical_crossentropy: 1.0655 - val_accuracy: 0.6748\n",
      "Epoch 20/100\n",
      " - 8s - loss: 2.1174 - categorical_crossentropy: 1.0640 - accuracy: 0.6896 - val_loss: 1.0598 - val_categorical_crossentropy: 1.0598 - val_accuracy: 0.6748\n",
      "Epoch 21/100\n",
      " - 5s - loss: 2.1177 - categorical_crossentropy: 1.0618 - accuracy: 0.6903 - val_loss: 1.0609 - val_categorical_crossentropy: 1.0609 - val_accuracy: 0.6748\n",
      "Epoch 22/100\n",
      " - 4s - loss: 2.1173 - categorical_crossentropy: 1.0644 - accuracy: 0.6903 - val_loss: 1.0674 - val_categorical_crossentropy: 1.0674 - val_accuracy: 0.6748\n",
      "Epoch 23/100\n",
      " - 5s - loss: 2.1166 - categorical_crossentropy: 1.0651 - accuracy: 0.6854 - val_loss: 1.0601 - val_categorical_crossentropy: 1.0601 - val_accuracy: 0.6748\n",
      "Epoch 24/100\n",
      " - 5s - loss: 2.1171 - categorical_crossentropy: 1.0593 - accuracy: 0.6896 - val_loss: 1.0574 - val_categorical_crossentropy: 1.0574 - val_accuracy: 0.6748\n",
      "Epoch 25/100\n",
      " - 5s - loss: 2.1174 - categorical_crossentropy: 1.0559 - accuracy: 0.6854 - val_loss: 1.0573 - val_categorical_crossentropy: 1.0573 - val_accuracy: 0.6748\n",
      "Epoch 26/100\n",
      " - 5s - loss: 2.1183 - categorical_crossentropy: 1.0663 - accuracy: 0.6748 - val_loss: 1.0619 - val_categorical_crossentropy: 1.0619 - val_accuracy: 0.6748\n",
      "Epoch 27/100\n",
      " - 5s - loss: 2.1177 - categorical_crossentropy: 1.0614 - accuracy: 0.6762 - val_loss: 1.0612 - val_categorical_crossentropy: 1.0612 - val_accuracy: 0.6748\n",
      "Epoch 28/100\n",
      " - 5s - loss: 2.1196 - categorical_crossentropy: 1.0683 - accuracy: 0.6819 - val_loss: 1.0680 - val_categorical_crossentropy: 1.0680 - val_accuracy: 0.6748\n",
      "Epoch 29/100\n",
      " - 5s - loss: 2.1167 - categorical_crossentropy: 1.0638 - accuracy: 0.6903 - val_loss: 1.0563 - val_categorical_crossentropy: 1.0563 - val_accuracy: 0.6748\n",
      "Epoch 30/100\n",
      " - 5s - loss: 2.1181 - categorical_crossentropy: 1.0576 - accuracy: 0.6903 - val_loss: 1.0624 - val_categorical_crossentropy: 1.0624 - val_accuracy: 0.6748\n",
      "Epoch 31/100\n",
      " - 5s - loss: 2.1176 - categorical_crossentropy: 1.0710 - accuracy: 0.6706 - val_loss: 1.0715 - val_categorical_crossentropy: 1.0715 - val_accuracy: 0.6748\n",
      "Epoch 32/100\n",
      " - 5s - loss: 2.1180 - categorical_crossentropy: 1.0648 - accuracy: 0.6804 - val_loss: 1.0599 - val_categorical_crossentropy: 1.0599 - val_accuracy: 0.6748\n",
      "Epoch 33/100\n",
      " - 5s - loss: 2.1177 - categorical_crossentropy: 1.0640 - accuracy: 0.6896 - val_loss: 1.0636 - val_categorical_crossentropy: 1.0636 - val_accuracy: 0.6748\n",
      "Epoch 34/100\n",
      " - 5s - loss: 2.1173 - categorical_crossentropy: 1.0647 - accuracy: 0.6896 - val_loss: 1.0619 - val_categorical_crossentropy: 1.0619 - val_accuracy: 0.6748\n",
      "real [[0. 1. 0.]]\n",
      "Test RMSE: 0.488\n",
      "Diff [[-0.32404155  0.68935561 -0.36531413]]\n",
      "% Diff [[       -inf 68.93556118        -inf]] %\n",
      "Predictions [[0.32404155 0.31064439 0.36531413]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../dl_solutions/dlsolutions.py:311: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  print('% Diff', 100*((inv_y - inv_preds)/inv_y), '%')\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading... ETH\n",
      "Extracting columns columns for ETH\n",
      "Proccessing and arranging columns for LSTM model\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>op_buy_19</th>\n",
       "      <th>op_sell_19</th>\n",
       "      <th>op_hold_19</th>\n",
       "      <th>op_buy_18</th>\n",
       "      <th>op_sell_18</th>\n",
       "      <th>op_hold_18</th>\n",
       "      <th>op_buy_17</th>\n",
       "      <th>op_sell_17</th>\n",
       "      <th>op_hold_17</th>\n",
       "      <th>op_buy_16</th>\n",
       "      <th>...</th>\n",
       "      <th>op_hold_2</th>\n",
       "      <th>op_buy_1</th>\n",
       "      <th>op_sell_1</th>\n",
       "      <th>op_hold_1</th>\n",
       "      <th>op_buy_0</th>\n",
       "      <th>op_sell_0</th>\n",
       "      <th>op_hold_0</th>\n",
       "      <th>op_buy</th>\n",
       "      <th>op_sell</th>\n",
       "      <th>op_hold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1559</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1560</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1561</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1562</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1563</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1421 rows × 63 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      op_buy_19  op_sell_19  op_hold_19  op_buy_18  op_sell_18  op_hold_18  \\\n",
       "143         0.0         0.0         1.0        0.0         1.0         0.0   \n",
       "144         0.0         1.0         0.0        0.0         0.0         1.0   \n",
       "145         0.0         0.0         1.0        0.0         0.0         1.0   \n",
       "146         0.0         0.0         1.0        1.0         0.0         0.0   \n",
       "147         1.0         0.0         0.0        0.0         0.0         1.0   \n",
       "...         ...         ...         ...        ...         ...         ...   \n",
       "1559        0.0         0.0         1.0        0.0         0.0         1.0   \n",
       "1560        0.0         0.0         1.0        1.0         0.0         0.0   \n",
       "1561        1.0         0.0         0.0        0.0         0.0         1.0   \n",
       "1562        0.0         0.0         1.0        0.0         0.0         1.0   \n",
       "1563        0.0         0.0         1.0        0.0         1.0         0.0   \n",
       "\n",
       "      op_buy_17  op_sell_17  op_hold_17  op_buy_16  ...  op_hold_2  op_buy_1  \\\n",
       "143         0.0         0.0         1.0        0.0  ...        1.0       0.0   \n",
       "144         0.0         0.0         1.0        1.0  ...        1.0       0.0   \n",
       "145         1.0         0.0         0.0        0.0  ...        1.0       0.0   \n",
       "146         0.0         0.0         1.0        0.0  ...        1.0       0.0   \n",
       "147         0.0         0.0         1.0        0.0  ...        1.0       0.0   \n",
       "...         ...         ...         ...        ...  ...        ...       ...   \n",
       "1559        1.0         0.0         0.0        0.0  ...        0.0       0.0   \n",
       "1560        0.0         0.0         1.0        0.0  ...        1.0       1.0   \n",
       "1561        0.0         0.0         1.0        0.0  ...        0.0       0.0   \n",
       "1562        0.0         1.0         0.0        0.0  ...        1.0       1.0   \n",
       "1563        0.0         0.0         1.0        0.0  ...        0.0       0.0   \n",
       "\n",
       "      op_sell_1  op_hold_1  op_buy_0  op_sell_0  op_hold_0  op_buy  op_sell  \\\n",
       "143         0.0        1.0         0          0          1     1.0      0.0   \n",
       "144         0.0        1.0         0          0          1     0.0      0.0   \n",
       "145         0.0        1.0         0          0          1     0.0      1.0   \n",
       "146         0.0        1.0         0          1          0     0.0      0.0   \n",
       "147         1.0        0.0         0          0          1     0.0      0.0   \n",
       "...         ...        ...       ...        ...        ...     ...      ...   \n",
       "1559        0.0        1.0         1          0          0     0.0      1.0   \n",
       "1560        0.0        0.0         0          0          1     1.0      0.0   \n",
       "1561        0.0        1.0         1          0          0     0.0      0.0   \n",
       "1562        0.0        0.0         0          1          0     0.0      0.0   \n",
       "1563        1.0        0.0         1          0          0     0.0      0.0   \n",
       "\n",
       "      op_hold  \n",
       "143       0.0  \n",
       "144       1.0  \n",
       "145       0.0  \n",
       "146       1.0  \n",
       "147       1.0  \n",
       "...       ...  \n",
       "1559      0.0  \n",
       "1560      0.0  \n",
       "1561      1.0  \n",
       "1562      1.0  \n",
       "1563      1.0  \n",
       "\n",
       "[1421 rows x 63 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>op_buy_19</th>\n",
       "      <th>op_sell_19</th>\n",
       "      <th>op_hold_19</th>\n",
       "      <th>op_buy_18</th>\n",
       "      <th>op_sell_18</th>\n",
       "      <th>op_hold_18</th>\n",
       "      <th>op_buy_17</th>\n",
       "      <th>op_sell_17</th>\n",
       "      <th>op_hold_17</th>\n",
       "      <th>op_buy_16</th>\n",
       "      <th>...</th>\n",
       "      <th>op_hold_2</th>\n",
       "      <th>op_buy_1</th>\n",
       "      <th>op_sell_1</th>\n",
       "      <th>op_hold_1</th>\n",
       "      <th>op_buy_0</th>\n",
       "      <th>op_sell_0</th>\n",
       "      <th>op_hold_0</th>\n",
       "      <th>op_buy</th>\n",
       "      <th>op_sell</th>\n",
       "      <th>op_hold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1564</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 63 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      op_buy_19  op_sell_19  op_hold_19  op_buy_18  op_sell_18  op_hold_18  \\\n",
       "1564        0.0         1.0         0.0        0.0         0.0         1.0   \n",
       "\n",
       "      op_buy_17  op_sell_17  op_hold_17  op_buy_16  ...  op_hold_2  op_buy_1  \\\n",
       "1564        0.0         0.0         1.0        0.0  ...        0.0       1.0   \n",
       "\n",
       "      op_sell_1  op_hold_1  op_buy_0  op_sell_0  op_hold_0  op_buy  op_sell  \\\n",
       "1564        0.0        0.0         0          0          1     1.0      0.0   \n",
       "\n",
       "      op_hold  \n",
       "1564      0.0  \n",
       "\n",
       "[1 rows x 63 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (1421, 20, 3) (1421, 3)\n",
      "Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_81 (LSTM)               (None, 20, 25)            2900      \n",
      "_________________________________________________________________\n",
      "lstm_82 (LSTM)               (None, 20, 25)            5100      \n",
      "_________________________________________________________________\n",
      "dropout_65 (Dropout)         (None, 20, 25)            0         \n",
      "_________________________________________________________________\n",
      "lstm_83 (LSTM)               (None, 20, 25)            5100      \n",
      "_________________________________________________________________\n",
      "dropout_66 (Dropout)         (None, 20, 25)            0         \n",
      "_________________________________________________________________\n",
      "lstm_84 (LSTM)               (None, 20, 25)            5100      \n",
      "_________________________________________________________________\n",
      "dropout_67 (Dropout)         (None, 20, 25)            0         \n",
      "_________________________________________________________________\n",
      "lstm_85 (LSTM)               (None, 25)                5100      \n",
      "_________________________________________________________________\n",
      "dropout_68 (Dropout)         (None, 25)                0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 3)                 78        \n",
      "=================================================================\n",
      "Total params: 23,378\n",
      "Trainable params: 23,378\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Y shape (1421, 3)\n",
      "Train on 1421 samples, validate on 285 samples\n",
      "Epoch 1/100\n",
      " - 13s - loss: 2.1221 - categorical_crossentropy: 1.0743 - accuracy: 0.4940 - val_loss: 1.0501 - val_categorical_crossentropy: 1.0501 - val_accuracy: 0.6737\n",
      "Epoch 2/100\n",
      " - 5s - loss: 2.1211 - categorical_crossentropy: 1.0691 - accuracy: 0.6847 - val_loss: 1.0687 - val_categorical_crossentropy: 1.0687 - val_accuracy: 0.6737\n",
      "Epoch 3/100\n",
      " - 5s - loss: 2.1218 - categorical_crossentropy: 1.0759 - accuracy: 0.6742 - val_loss: 1.0711 - val_categorical_crossentropy: 1.0711 - val_accuracy: 0.6737\n",
      "Epoch 4/100\n",
      " - 5s - loss: 2.1209 - categorical_crossentropy: 1.0773 - accuracy: 0.6826 - val_loss: 1.0707 - val_categorical_crossentropy: 1.0707 - val_accuracy: 0.6737\n",
      "Epoch 5/100\n",
      " - 5s - loss: 2.1208 - categorical_crossentropy: 1.0726 - accuracy: 0.6897 - val_loss: 1.0693 - val_categorical_crossentropy: 1.0693 - val_accuracy: 0.6737\n",
      "Epoch 6/100\n",
      " - 5s - loss: 2.1208 - categorical_crossentropy: 1.0727 - accuracy: 0.6897 - val_loss: 1.0699 - val_categorical_crossentropy: 1.0699 - val_accuracy: 0.6737\n",
      "Epoch 7/100\n",
      " - 5s - loss: 2.1197 - categorical_crossentropy: 1.0703 - accuracy: 0.6890 - val_loss: 1.0649 - val_categorical_crossentropy: 1.0649 - val_accuracy: 0.6737\n",
      "Epoch 8/100\n",
      " - 5s - loss: 2.1201 - categorical_crossentropy: 1.0663 - accuracy: 0.6897 - val_loss: 1.0636 - val_categorical_crossentropy: 1.0636 - val_accuracy: 0.6737\n",
      "Epoch 9/100\n",
      " - 4s - loss: 2.1205 - categorical_crossentropy: 1.0669 - accuracy: 0.6897 - val_loss: 1.0674 - val_categorical_crossentropy: 1.0674 - val_accuracy: 0.6737\n",
      "Epoch 10/100\n",
      " - 5s - loss: 2.1201 - categorical_crossentropy: 1.0729 - accuracy: 0.6897 - val_loss: 1.0719 - val_categorical_crossentropy: 1.0719 - val_accuracy: 0.6737\n",
      "Epoch 11/100\n",
      " - 5s - loss: 2.1194 - categorical_crossentropy: 1.0693 - accuracy: 0.6897 - val_loss: 1.0650 - val_categorical_crossentropy: 1.0650 - val_accuracy: 0.6737\n",
      "Epoch 12/100\n",
      " - 5s - loss: 2.1185 - categorical_crossentropy: 1.0651 - accuracy: 0.6897 - val_loss: 1.0642 - val_categorical_crossentropy: 1.0642 - val_accuracy: 0.6737\n",
      "Epoch 13/100\n",
      " - 6s - loss: 2.1227 - categorical_crossentropy: 1.0703 - accuracy: 0.6524 - val_loss: 1.0658 - val_categorical_crossentropy: 1.0658 - val_accuracy: 0.6737\n",
      "Epoch 14/100\n",
      " - 5s - loss: 2.1192 - categorical_crossentropy: 1.0672 - accuracy: 0.6897 - val_loss: 1.0645 - val_categorical_crossentropy: 1.0645 - val_accuracy: 0.6737\n",
      "Epoch 15/100\n",
      " - 5s - loss: 2.1193 - categorical_crossentropy: 1.0664 - accuracy: 0.6904 - val_loss: 1.0658 - val_categorical_crossentropy: 1.0658 - val_accuracy: 0.6737\n",
      "Epoch 16/100\n",
      " - 5s - loss: 2.1183 - categorical_crossentropy: 1.0672 - accuracy: 0.6882 - val_loss: 1.0655 - val_categorical_crossentropy: 1.0655 - val_accuracy: 0.6737\n",
      "Epoch 17/100\n",
      " - 5s - loss: 2.1214 - categorical_crossentropy: 1.0709 - accuracy: 0.6826 - val_loss: 1.0714 - val_categorical_crossentropy: 1.0714 - val_accuracy: 0.6737\n",
      "Epoch 18/100\n",
      " - 4s - loss: 2.1202 - categorical_crossentropy: 1.0721 - accuracy: 0.6897 - val_loss: 1.0692 - val_categorical_crossentropy: 1.0692 - val_accuracy: 0.6737\n",
      "Epoch 19/100\n",
      " - 5s - loss: 2.1210 - categorical_crossentropy: 1.0719 - accuracy: 0.6897 - val_loss: 1.0720 - val_categorical_crossentropy: 1.0720 - val_accuracy: 0.6737\n",
      "Epoch 20/100\n",
      " - 7s - loss: 2.1200 - categorical_crossentropy: 1.0722 - accuracy: 0.6897 - val_loss: 1.0686 - val_categorical_crossentropy: 1.0686 - val_accuracy: 0.6737\n",
      "Epoch 21/100\n",
      " - 8s - loss: 2.1203 - categorical_crossentropy: 1.0708 - accuracy: 0.6897 - val_loss: 1.0676 - val_categorical_crossentropy: 1.0676 - val_accuracy: 0.6737\n",
      "Epoch 22/100\n",
      " - 7s - loss: 2.1200 - categorical_crossentropy: 1.0677 - accuracy: 0.6897 - val_loss: 1.0674 - val_categorical_crossentropy: 1.0674 - val_accuracy: 0.6737\n",
      "Epoch 23/100\n",
      " - 5s - loss: 2.1186 - categorical_crossentropy: 1.0663 - accuracy: 0.6897 - val_loss: 1.0641 - val_categorical_crossentropy: 1.0641 - val_accuracy: 0.6737\n",
      "Epoch 24/100\n",
      " - 6s - loss: 2.1208 - categorical_crossentropy: 1.0653 - accuracy: 0.6897 - val_loss: 1.0643 - val_categorical_crossentropy: 1.0643 - val_accuracy: 0.6737\n",
      "Epoch 25/100\n",
      " - 5s - loss: 2.1194 - categorical_crossentropy: 1.0670 - accuracy: 0.6897 - val_loss: 1.0680 - val_categorical_crossentropy: 1.0680 - val_accuracy: 0.6737\n",
      "Epoch 26/100\n",
      " - 5s - loss: 2.1197 - categorical_crossentropy: 1.0684 - accuracy: 0.6897 - val_loss: 1.0671 - val_categorical_crossentropy: 1.0671 - val_accuracy: 0.6737\n",
      "Epoch 27/100\n",
      " - 5s - loss: 2.1203 - categorical_crossentropy: 1.0677 - accuracy: 0.6897 - val_loss: 1.0672 - val_categorical_crossentropy: 1.0672 - val_accuracy: 0.6737\n",
      "Epoch 28/100\n",
      " - 5s - loss: 2.1207 - categorical_crossentropy: 1.0692 - accuracy: 0.6897 - val_loss: 1.0702 - val_categorical_crossentropy: 1.0702 - val_accuracy: 0.6737\n",
      "Epoch 29/100\n",
      " - 5s - loss: 2.1187 - categorical_crossentropy: 1.0696 - accuracy: 0.6897 - val_loss: 1.0678 - val_categorical_crossentropy: 1.0678 - val_accuracy: 0.6737\n",
      "Epoch 30/100\n",
      " - 5s - loss: 2.1195 - categorical_crossentropy: 1.0669 - accuracy: 0.6897 - val_loss: 1.0661 - val_categorical_crossentropy: 1.0661 - val_accuracy: 0.6737\n",
      "Epoch 31/100\n",
      " - 6s - loss: 2.1192 - categorical_crossentropy: 1.0685 - accuracy: 0.6861 - val_loss: 1.0684 - val_categorical_crossentropy: 1.0684 - val_accuracy: 0.6737\n",
      "Epoch 32/100\n",
      " - 6s - loss: 2.1186 - categorical_crossentropy: 1.0670 - accuracy: 0.6868 - val_loss: 1.0654 - val_categorical_crossentropy: 1.0654 - val_accuracy: 0.6737\n",
      "Epoch 33/100\n",
      " - 5s - loss: 2.1212 - categorical_crossentropy: 1.0694 - accuracy: 0.6826 - val_loss: 1.0632 - val_categorical_crossentropy: 1.0632 - val_accuracy: 0.6737\n",
      "Epoch 34/100\n",
      " - 5s - loss: 2.1202 - categorical_crossentropy: 1.0660 - accuracy: 0.6897 - val_loss: 1.0658 - val_categorical_crossentropy: 1.0658 - val_accuracy: 0.6737\n",
      "Epoch 35/100\n",
      " - 6s - loss: 2.1189 - categorical_crossentropy: 1.0653 - accuracy: 0.6897 - val_loss: 1.0643 - val_categorical_crossentropy: 1.0643 - val_accuracy: 0.6737\n",
      "Epoch 36/100\n",
      " - 5s - loss: 2.1209 - categorical_crossentropy: 1.0681 - accuracy: 0.6897 - val_loss: 1.0689 - val_categorical_crossentropy: 1.0689 - val_accuracy: 0.6737\n",
      "Epoch 37/100\n",
      " - 6s - loss: 2.1196 - categorical_crossentropy: 1.0711 - accuracy: 0.6897 - val_loss: 1.0713 - val_categorical_crossentropy: 1.0713 - val_accuracy: 0.6737\n",
      "Epoch 38/100\n",
      " - 6s - loss: 2.1199 - categorical_crossentropy: 1.0721 - accuracy: 0.6897 - val_loss: 1.0704 - val_categorical_crossentropy: 1.0704 - val_accuracy: 0.6737\n",
      "Epoch 39/100\n",
      " - 6s - loss: 2.1195 - categorical_crossentropy: 1.0698 - accuracy: 0.6897 - val_loss: 1.0675 - val_categorical_crossentropy: 1.0675 - val_accuracy: 0.6737\n",
      "Epoch 40/100\n",
      " - 6s - loss: 2.1201 - categorical_crossentropy: 1.0665 - accuracy: 0.6897 - val_loss: 1.0648 - val_categorical_crossentropy: 1.0648 - val_accuracy: 0.6737\n",
      "Epoch 41/100\n",
      " - 5s - loss: 2.1192 - categorical_crossentropy: 1.0660 - accuracy: 0.6897 - val_loss: 1.0659 - val_categorical_crossentropy: 1.0659 - val_accuracy: 0.6737\n",
      "real [[1. 0. 0.]]\n",
      "Test RMSE: 0.481\n",
      "Diff [[ 0.68004659 -0.31399435 -0.36605227]]\n",
      "% Diff [[68.00465882        -inf        -inf]] %\n",
      "Predictions [[0.31995341 0.31399435 0.36605227]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../dl_solutions/dlsolutions.py:311: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  print('% Diff', 100*((inv_y - inv_preds)/inv_y), '%')\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading... ETH\n",
      "Extracting columns columns for ETH\n",
      "Proccessing and arranging columns for LSTM model\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>op_buy_19</th>\n",
       "      <th>op_sell_19</th>\n",
       "      <th>op_hold_19</th>\n",
       "      <th>op_buy_18</th>\n",
       "      <th>op_sell_18</th>\n",
       "      <th>op_hold_18</th>\n",
       "      <th>op_buy_17</th>\n",
       "      <th>op_sell_17</th>\n",
       "      <th>op_hold_17</th>\n",
       "      <th>op_buy_16</th>\n",
       "      <th>...</th>\n",
       "      <th>op_hold_2</th>\n",
       "      <th>op_buy_1</th>\n",
       "      <th>op_sell_1</th>\n",
       "      <th>op_hold_1</th>\n",
       "      <th>op_buy_0</th>\n",
       "      <th>op_sell_0</th>\n",
       "      <th>op_hold_0</th>\n",
       "      <th>op_buy</th>\n",
       "      <th>op_sell</th>\n",
       "      <th>op_hold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1555</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1556</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1557</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1558</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1559</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1417 rows × 63 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      op_buy_19  op_sell_19  op_hold_19  op_buy_18  op_sell_18  op_hold_18  \\\n",
       "143         0.0         0.0         1.0        0.0         1.0         0.0   \n",
       "144         0.0         1.0         0.0        0.0         0.0         1.0   \n",
       "145         0.0         0.0         1.0        0.0         0.0         1.0   \n",
       "146         0.0         0.0         1.0        1.0         0.0         0.0   \n",
       "147         1.0         0.0         0.0        0.0         0.0         1.0   \n",
       "...         ...         ...         ...        ...         ...         ...   \n",
       "1555        0.0         0.0         1.0        1.0         0.0         0.0   \n",
       "1556        1.0         0.0         0.0        0.0         0.0         1.0   \n",
       "1557        0.0         0.0         1.0        0.0         0.0         1.0   \n",
       "1558        0.0         0.0         1.0        0.0         0.0         1.0   \n",
       "1559        0.0         0.0         1.0        0.0         0.0         1.0   \n",
       "\n",
       "      op_buy_17  op_sell_17  op_hold_17  op_buy_16  ...  op_hold_2  op_buy_1  \\\n",
       "143         0.0         0.0         1.0        0.0  ...        1.0       0.0   \n",
       "144         0.0         0.0         1.0        1.0  ...        1.0       0.0   \n",
       "145         1.0         0.0         0.0        0.0  ...        1.0       0.0   \n",
       "146         0.0         0.0         1.0        0.0  ...        1.0       0.0   \n",
       "147         0.0         0.0         1.0        0.0  ...        1.0       0.0   \n",
       "...         ...         ...         ...        ...  ...        ...       ...   \n",
       "1555        0.0         0.0         1.0        0.0  ...        1.0       0.0   \n",
       "1556        0.0         0.0         1.0        0.0  ...        0.0       1.0   \n",
       "1557        0.0         0.0         1.0        0.0  ...        0.0       0.0   \n",
       "1558        0.0         0.0         1.0        1.0  ...        1.0       0.0   \n",
       "1559        1.0         0.0         0.0        0.0  ...        0.0       0.0   \n",
       "\n",
       "      op_sell_1  op_hold_1  op_buy_0  op_sell_0  op_hold_0  op_buy  op_sell  \\\n",
       "143         0.0        1.0         0          0          1     1.0      0.0   \n",
       "144         0.0        1.0         0          0          1     0.0      0.0   \n",
       "145         0.0        1.0         0          0          1     0.0      1.0   \n",
       "146         0.0        1.0         0          1          0     0.0      0.0   \n",
       "147         1.0        0.0         0          0          1     0.0      0.0   \n",
       "...         ...        ...       ...        ...        ...     ...      ...   \n",
       "1555        1.0        0.0         1          0          0     0.0      1.0   \n",
       "1556        0.0        0.0         0          0          1     0.0      0.0   \n",
       "1557        0.0        1.0         0          1          0     1.0      0.0   \n",
       "1558        1.0        0.0         0          0          1     0.0      0.0   \n",
       "1559        0.0        1.0         1          0          0     0.0      1.0   \n",
       "\n",
       "      op_hold  \n",
       "143       0.0  \n",
       "144       1.0  \n",
       "145       0.0  \n",
       "146       1.0  \n",
       "147       1.0  \n",
       "...       ...  \n",
       "1555      0.0  \n",
       "1556      1.0  \n",
       "1557      0.0  \n",
       "1558      1.0  \n",
       "1559      0.0  \n",
       "\n",
       "[1417 rows x 63 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>op_buy_19</th>\n",
       "      <th>op_sell_19</th>\n",
       "      <th>op_hold_19</th>\n",
       "      <th>op_buy_18</th>\n",
       "      <th>op_sell_18</th>\n",
       "      <th>op_hold_18</th>\n",
       "      <th>op_buy_17</th>\n",
       "      <th>op_sell_17</th>\n",
       "      <th>op_hold_17</th>\n",
       "      <th>op_buy_16</th>\n",
       "      <th>...</th>\n",
       "      <th>op_hold_2</th>\n",
       "      <th>op_buy_1</th>\n",
       "      <th>op_sell_1</th>\n",
       "      <th>op_hold_1</th>\n",
       "      <th>op_buy_0</th>\n",
       "      <th>op_sell_0</th>\n",
       "      <th>op_hold_0</th>\n",
       "      <th>op_buy</th>\n",
       "      <th>op_sell</th>\n",
       "      <th>op_hold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1560</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 63 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      op_buy_19  op_sell_19  op_hold_19  op_buy_18  op_sell_18  op_hold_18  \\\n",
       "1560        0.0         0.0         1.0        1.0         0.0         0.0   \n",
       "\n",
       "      op_buy_17  op_sell_17  op_hold_17  op_buy_16  ...  op_hold_2  op_buy_1  \\\n",
       "1560        0.0         0.0         1.0        0.0  ...        1.0       1.0   \n",
       "\n",
       "      op_sell_1  op_hold_1  op_buy_0  op_sell_0  op_hold_0  op_buy  op_sell  \\\n",
       "1560        0.0        0.0         0          0          1     1.0      0.0   \n",
       "\n",
       "      op_hold  \n",
       "1560      0.0  \n",
       "\n",
       "[1 rows x 63 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (1417, 20, 3) (1417, 3)\n",
      "Model: \"sequential_18\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_86 (LSTM)               (None, 20, 25)            2900      \n",
      "_________________________________________________________________\n",
      "lstm_87 (LSTM)               (None, 20, 25)            5100      \n",
      "_________________________________________________________________\n",
      "dropout_69 (Dropout)         (None, 20, 25)            0         \n",
      "_________________________________________________________________\n",
      "lstm_88 (LSTM)               (None, 20, 25)            5100      \n",
      "_________________________________________________________________\n",
      "dropout_70 (Dropout)         (None, 20, 25)            0         \n",
      "_________________________________________________________________\n",
      "lstm_89 (LSTM)               (None, 20, 25)            5100      \n",
      "_________________________________________________________________\n",
      "dropout_71 (Dropout)         (None, 20, 25)            0         \n",
      "_________________________________________________________________\n",
      "lstm_90 (LSTM)               (None, 25)                5100      \n",
      "_________________________________________________________________\n",
      "dropout_72 (Dropout)         (None, 25)                0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 3)                 78        \n",
      "=================================================================\n",
      "Total params: 23,378\n",
      "Trainable params: 23,378\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Y shape (1417, 3)\n",
      "Train on 1417 samples, validate on 284 samples\n",
      "Epoch 1/100\n",
      " - 14s - loss: 2.1237 - categorical_crossentropy: 1.0779 - accuracy: 0.5116 - val_loss: 1.0606 - val_categorical_crossentropy: 1.0606 - val_accuracy: 0.6725\n",
      "Epoch 2/100\n",
      " - 4s - loss: 2.1214 - categorical_crossentropy: 1.0739 - accuracy: 0.6789 - val_loss: 1.0674 - val_categorical_crossentropy: 1.0674 - val_accuracy: 0.6725\n",
      "Epoch 3/100\n",
      " - 5s - loss: 2.1195 - categorical_crossentropy: 1.0656 - accuracy: 0.6867 - val_loss: 1.0567 - val_categorical_crossentropy: 1.0567 - val_accuracy: 0.6725\n",
      "Epoch 4/100\n",
      " - 5s - loss: 2.1194 - categorical_crossentropy: 1.0637 - accuracy: 0.6853 - val_loss: 1.0636 - val_categorical_crossentropy: 1.0636 - val_accuracy: 0.6725\n",
      "Epoch 5/100\n",
      " - 5s - loss: 2.1200 - categorical_crossentropy: 1.0687 - accuracy: 0.6711 - val_loss: 1.0656 - val_categorical_crossentropy: 1.0656 - val_accuracy: 0.6725\n",
      "Epoch 6/100\n",
      " - 5s - loss: 2.1204 - categorical_crossentropy: 1.0617 - accuracy: 0.6556 - val_loss: 1.0641 - val_categorical_crossentropy: 1.0641 - val_accuracy: 0.6725\n",
      "Epoch 7/100\n",
      " - 5s - loss: 2.1235 - categorical_crossentropy: 1.0823 - accuracy: 0.6133 - val_loss: 1.0810 - val_categorical_crossentropy: 1.0810 - val_accuracy: 0.6725\n",
      "Epoch 8/100\n",
      " - 5s - loss: 2.1201 - categorical_crossentropy: 1.0804 - accuracy: 0.6591 - val_loss: 1.0735 - val_categorical_crossentropy: 1.0735 - val_accuracy: 0.6725\n",
      "Epoch 9/100\n",
      " - 5s - loss: 2.1214 - categorical_crossentropy: 1.0730 - accuracy: 0.6775 - val_loss: 1.0691 - val_categorical_crossentropy: 1.0691 - val_accuracy: 0.6725\n",
      "Epoch 10/100\n",
      " - 4s - loss: 2.1205 - categorical_crossentropy: 1.0693 - accuracy: 0.6860 - val_loss: 1.0669 - val_categorical_crossentropy: 1.0669 - val_accuracy: 0.6725\n",
      "Epoch 11/100\n",
      " - 5s - loss: 2.1204 - categorical_crossentropy: 1.0708 - accuracy: 0.6754 - val_loss: 1.0697 - val_categorical_crossentropy: 1.0697 - val_accuracy: 0.6725\n",
      "Epoch 12/100\n",
      " - 4s - loss: 2.1212 - categorical_crossentropy: 1.0683 - accuracy: 0.6782 - val_loss: 1.0657 - val_categorical_crossentropy: 1.0657 - val_accuracy: 0.6725\n",
      "Epoch 13/100\n",
      " - 5s - loss: 2.1214 - categorical_crossentropy: 1.0699 - accuracy: 0.6817 - val_loss: 1.0714 - val_categorical_crossentropy: 1.0714 - val_accuracy: 0.6725\n",
      "Epoch 14/100\n",
      " - 5s - loss: 2.1217 - categorical_crossentropy: 1.0753 - accuracy: 0.6831 - val_loss: 1.0741 - val_categorical_crossentropy: 1.0741 - val_accuracy: 0.6725\n",
      "Epoch 15/100\n",
      " - 5s - loss: 2.1213 - categorical_crossentropy: 1.0750 - accuracy: 0.6860 - val_loss: 1.0740 - val_categorical_crossentropy: 1.0740 - val_accuracy: 0.6725\n",
      "Epoch 16/100\n",
      " - 4s - loss: 2.1221 - categorical_crossentropy: 1.0792 - accuracy: 0.6895 - val_loss: 1.0781 - val_categorical_crossentropy: 1.0781 - val_accuracy: 0.6725\n",
      "Epoch 17/100\n",
      " - 5s - loss: 2.1205 - categorical_crossentropy: 1.0789 - accuracy: 0.6895 - val_loss: 1.0767 - val_categorical_crossentropy: 1.0767 - val_accuracy: 0.6725\n",
      "Epoch 18/100\n",
      " - 4s - loss: 2.1207 - categorical_crossentropy: 1.0769 - accuracy: 0.6881 - val_loss: 1.0745 - val_categorical_crossentropy: 1.0745 - val_accuracy: 0.6725\n",
      "Epoch 19/100\n",
      " - 5s - loss: 2.1207 - categorical_crossentropy: 1.0760 - accuracy: 0.6881 - val_loss: 1.0759 - val_categorical_crossentropy: 1.0759 - val_accuracy: 0.6725\n",
      "Epoch 20/100\n",
      " - 5s - loss: 2.1205 - categorical_crossentropy: 1.0781 - accuracy: 0.6838 - val_loss: 1.0754 - val_categorical_crossentropy: 1.0754 - val_accuracy: 0.6725\n",
      "Epoch 21/100\n",
      " - 5s - loss: 2.1205 - categorical_crossentropy: 1.0734 - accuracy: 0.6867 - val_loss: 1.0674 - val_categorical_crossentropy: 1.0674 - val_accuracy: 0.6725\n",
      "Epoch 22/100\n",
      " - 5s - loss: 2.1212 - categorical_crossentropy: 1.0689 - accuracy: 0.6888 - val_loss: 1.0680 - val_categorical_crossentropy: 1.0680 - val_accuracy: 0.6725\n",
      "Epoch 23/100\n",
      " - 5s - loss: 2.1203 - categorical_crossentropy: 1.0688 - accuracy: 0.6888 - val_loss: 1.0682 - val_categorical_crossentropy: 1.0682 - val_accuracy: 0.6725\n",
      "Epoch 24/100\n",
      " - 5s - loss: 2.1209 - categorical_crossentropy: 1.0711 - accuracy: 0.6888 - val_loss: 1.0713 - val_categorical_crossentropy: 1.0713 - val_accuracy: 0.6725\n",
      "Epoch 25/100\n",
      " - 5s - loss: 2.1211 - categorical_crossentropy: 1.0728 - accuracy: 0.6895 - val_loss: 1.0720 - val_categorical_crossentropy: 1.0720 - val_accuracy: 0.6725\n",
      "Epoch 26/100\n",
      " - 5s - loss: 2.1213 - categorical_crossentropy: 1.0746 - accuracy: 0.6888 - val_loss: 1.0735 - val_categorical_crossentropy: 1.0735 - val_accuracy: 0.6725\n",
      "Epoch 27/100\n",
      " - 5s - loss: 2.1200 - categorical_crossentropy: 1.0750 - accuracy: 0.6888 - val_loss: 1.0746 - val_categorical_crossentropy: 1.0746 - val_accuracy: 0.6725\n",
      "Epoch 28/100\n",
      " - 5s - loss: 2.1203 - categorical_crossentropy: 1.0753 - accuracy: 0.6895 - val_loss: 1.0724 - val_categorical_crossentropy: 1.0724 - val_accuracy: 0.6725\n",
      "Epoch 29/100\n",
      " - 5s - loss: 2.1198 - categorical_crossentropy: 1.0703 - accuracy: 0.6895 - val_loss: 1.0687 - val_categorical_crossentropy: 1.0687 - val_accuracy: 0.6725\n",
      "real [[1. 0. 0.]]\n",
      "Test RMSE: 0.477\n",
      "Diff [[ 0.67462528 -0.31170809 -0.36291718]]\n",
      "% Diff [[67.46252775        -inf        -inf]] %\n",
      "Predictions [[0.32537472 0.31170809 0.36291718]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../dl_solutions/dlsolutions.py:311: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  print('% Diff', 100*((inv_y - inv_preds)/inv_y), '%')\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "split_indexes = [-7, -9, -15, -19]\n",
    "\n",
    "for split_index in split_indexes:\n",
    "    execute_test(split_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En los cuatro casos el modelo no ha acertado. Consideraremos esta opción para nuestro modelo final una vez optimizado sobre el precio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejemplo con target none"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El siguiente análisis se centrará en los hiperparametros y modelado de la red (layers, epochs, batch size, dropout). Antes de comenzar inicializaremos los parametros que dejaremos fijos durante esta etapa de analisis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### PERIODS ####\n",
    "prev_periods = 20\n",
    "pred_periods = 20\n",
    "\n",
    "#LSTM\n",
    "model_sel = 0 \n",
    "\n",
    "# Cryptos\n",
    "cryptos = ['ETH', 'ADA', 'BTC', 'LNK', 'LTC']\n",
    "\n",
    "#### NORM AND FEATURES CONFIGURATION ####\n",
    "target = None\n",
    "norm_strat = 2\n",
    "\n",
    "#### COLUMNS ####\n",
    "columns_11 = ['op_buy', 'op_sell', 'op_hold'] # Usar softmax\n",
    "columns_12 = ['close', 'close_diff_20']\n",
    "\n",
    "\n",
    "#### Hyper params ####\n",
    "\n",
    "#activations = ['relu', 'sigmoid', 'softmax']\n",
    "#losses = ['mse', 'binary_crossentropy', 'categorical_crossentropy']\n",
    "#metrics_opt = ['mse', 'accuracy']\n",
    "activation = 'relu'\n",
    "loss = 'mse'\n",
    "metrics = ['mse']\n",
    "optimizer = 'adam'\n",
    "initial_learning_rate = 0.01\n",
    "callbacks = ['mc', 'es']\n",
    "batch_size = 64\n",
    "epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading... ETH\n",
      "Extracting columns columns for ETH\n",
      "Proccessing and arranging columns for LSTM model\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>close_19</th>\n",
       "      <th>ADX_19</th>\n",
       "      <th>close_18</th>\n",
       "      <th>ADX_18</th>\n",
       "      <th>close_17</th>\n",
       "      <th>ADX_17</th>\n",
       "      <th>close_16</th>\n",
       "      <th>ADX_16</th>\n",
       "      <th>close_15</th>\n",
       "      <th>ADX_15</th>\n",
       "      <th>...</th>\n",
       "      <th>close_3</th>\n",
       "      <th>ADX_3</th>\n",
       "      <th>close_2</th>\n",
       "      <th>ADX_2</th>\n",
       "      <th>close_1</th>\n",
       "      <th>ADX_1</th>\n",
       "      <th>close_0</th>\n",
       "      <th>ADX_0</th>\n",
       "      <th>close</th>\n",
       "      <th>ADX</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>754.99</td>\n",
       "      <td>41.418230</td>\n",
       "      <td>855.28</td>\n",
       "      <td>36.212628</td>\n",
       "      <td>934.03</td>\n",
       "      <td>24.312204</td>\n",
       "      <td>940.00</td>\n",
       "      <td>21.025032</td>\n",
       "      <td>959.30</td>\n",
       "      <td>21.223914</td>\n",
       "      <td>...</td>\n",
       "      <td>1000.00</td>\n",
       "      <td>27.861915</td>\n",
       "      <td>994.00</td>\n",
       "      <td>27.314258</td>\n",
       "      <td>1032.50</td>\n",
       "      <td>26.829022</td>\n",
       "      <td>1152.75</td>\n",
       "      <td>26.295579</td>\n",
       "      <td>877.00</td>\n",
       "      <td>24.441875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>855.28</td>\n",
       "      <td>36.212628</td>\n",
       "      <td>934.03</td>\n",
       "      <td>24.312204</td>\n",
       "      <td>940.00</td>\n",
       "      <td>21.025032</td>\n",
       "      <td>959.30</td>\n",
       "      <td>21.223914</td>\n",
       "      <td>1004.11</td>\n",
       "      <td>22.305116</td>\n",
       "      <td>...</td>\n",
       "      <td>994.00</td>\n",
       "      <td>27.314258</td>\n",
       "      <td>1032.50</td>\n",
       "      <td>26.829022</td>\n",
       "      <td>1152.75</td>\n",
       "      <td>26.295579</td>\n",
       "      <td>1049.00</td>\n",
       "      <td>25.001883</td>\n",
       "      <td>851.15</td>\n",
       "      <td>24.385214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>934.03</td>\n",
       "      <td>24.312204</td>\n",
       "      <td>940.00</td>\n",
       "      <td>21.025032</td>\n",
       "      <td>959.30</td>\n",
       "      <td>21.223914</td>\n",
       "      <td>1004.11</td>\n",
       "      <td>22.305116</td>\n",
       "      <td>1123.09</td>\n",
       "      <td>23.246794</td>\n",
       "      <td>...</td>\n",
       "      <td>1032.50</td>\n",
       "      <td>26.829022</td>\n",
       "      <td>1152.75</td>\n",
       "      <td>26.295579</td>\n",
       "      <td>1049.00</td>\n",
       "      <td>25.001883</td>\n",
       "      <td>993.00</td>\n",
       "      <td>24.131656</td>\n",
       "      <td>808.99</td>\n",
       "      <td>24.078679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>940.00</td>\n",
       "      <td>21.025032</td>\n",
       "      <td>959.30</td>\n",
       "      <td>21.223914</td>\n",
       "      <td>1004.11</td>\n",
       "      <td>22.305116</td>\n",
       "      <td>1123.09</td>\n",
       "      <td>23.246794</td>\n",
       "      <td>1133.18</td>\n",
       "      <td>25.900560</td>\n",
       "      <td>...</td>\n",
       "      <td>1152.75</td>\n",
       "      <td>26.295579</td>\n",
       "      <td>1049.00</td>\n",
       "      <td>25.001883</td>\n",
       "      <td>993.00</td>\n",
       "      <td>24.131656</td>\n",
       "      <td>980.00</td>\n",
       "      <td>23.956457</td>\n",
       "      <td>866.66</td>\n",
       "      <td>23.976865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>959.30</td>\n",
       "      <td>21.223914</td>\n",
       "      <td>1004.11</td>\n",
       "      <td>22.305116</td>\n",
       "      <td>1123.09</td>\n",
       "      <td>23.246794</td>\n",
       "      <td>1133.18</td>\n",
       "      <td>25.900560</td>\n",
       "      <td>1291.00</td>\n",
       "      <td>26.950869</td>\n",
       "      <td>...</td>\n",
       "      <td>1049.00</td>\n",
       "      <td>25.001883</td>\n",
       "      <td>993.00</td>\n",
       "      <td>24.131656</td>\n",
       "      <td>980.00</td>\n",
       "      <td>23.956457</td>\n",
       "      <td>1061.00</td>\n",
       "      <td>23.763680</td>\n",
       "      <td>841.57</td>\n",
       "      <td>23.677467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1573</th>\n",
       "      <td>4287.80</td>\n",
       "      <td>19.071649</td>\n",
       "      <td>3996.90</td>\n",
       "      <td>19.441324</td>\n",
       "      <td>4294.76</td>\n",
       "      <td>19.895549</td>\n",
       "      <td>4412.17</td>\n",
       "      <td>20.260773</td>\n",
       "      <td>4258.31</td>\n",
       "      <td>19.858133</td>\n",
       "      <td>...</td>\n",
       "      <td>4215.73</td>\n",
       "      <td>16.807307</td>\n",
       "      <td>4117.25</td>\n",
       "      <td>16.765313</td>\n",
       "      <td>4196.44</td>\n",
       "      <td>17.981035</td>\n",
       "      <td>4347.59</td>\n",
       "      <td>19.049911</td>\n",
       "      <td>4063.56</td>\n",
       "      <td>28.514337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1574</th>\n",
       "      <td>3996.90</td>\n",
       "      <td>19.441324</td>\n",
       "      <td>4294.76</td>\n",
       "      <td>19.895549</td>\n",
       "      <td>4412.17</td>\n",
       "      <td>20.260773</td>\n",
       "      <td>4258.31</td>\n",
       "      <td>19.858133</td>\n",
       "      <td>4085.97</td>\n",
       "      <td>19.464946</td>\n",
       "      <td>...</td>\n",
       "      <td>4117.25</td>\n",
       "      <td>16.765313</td>\n",
       "      <td>4196.44</td>\n",
       "      <td>17.981035</td>\n",
       "      <td>4347.59</td>\n",
       "      <td>19.049911</td>\n",
       "      <td>4306.40</td>\n",
       "      <td>19.747824</td>\n",
       "      <td>4037.23</td>\n",
       "      <td>28.403375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1575</th>\n",
       "      <td>4294.76</td>\n",
       "      <td>19.895549</td>\n",
       "      <td>4412.17</td>\n",
       "      <td>20.260773</td>\n",
       "      <td>4258.31</td>\n",
       "      <td>19.858133</td>\n",
       "      <td>4085.97</td>\n",
       "      <td>19.464946</td>\n",
       "      <td>4339.44</td>\n",
       "      <td>19.925177</td>\n",
       "      <td>...</td>\n",
       "      <td>4196.44</td>\n",
       "      <td>17.981035</td>\n",
       "      <td>4347.59</td>\n",
       "      <td>19.049911</td>\n",
       "      <td>4306.40</td>\n",
       "      <td>19.747824</td>\n",
       "      <td>4436.91</td>\n",
       "      <td>20.202159</td>\n",
       "      <td>3792.75</td>\n",
       "      <td>28.223716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1576</th>\n",
       "      <td>4412.17</td>\n",
       "      <td>20.260773</td>\n",
       "      <td>4258.31</td>\n",
       "      <td>19.858133</td>\n",
       "      <td>4085.97</td>\n",
       "      <td>19.464946</td>\n",
       "      <td>4339.44</td>\n",
       "      <td>19.925177</td>\n",
       "      <td>4269.36</td>\n",
       "      <td>19.969782</td>\n",
       "      <td>...</td>\n",
       "      <td>4347.59</td>\n",
       "      <td>19.049911</td>\n",
       "      <td>4306.40</td>\n",
       "      <td>19.747824</td>\n",
       "      <td>4436.91</td>\n",
       "      <td>20.202159</td>\n",
       "      <td>4105.64</td>\n",
       "      <td>20.614088</td>\n",
       "      <td>3630.19</td>\n",
       "      <td>29.015362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1577</th>\n",
       "      <td>4258.31</td>\n",
       "      <td>19.858133</td>\n",
       "      <td>4085.97</td>\n",
       "      <td>19.464946</td>\n",
       "      <td>4339.44</td>\n",
       "      <td>19.925177</td>\n",
       "      <td>4269.36</td>\n",
       "      <td>19.969782</td>\n",
       "      <td>4524.85</td>\n",
       "      <td>19.934622</td>\n",
       "      <td>...</td>\n",
       "      <td>4306.40</td>\n",
       "      <td>19.747824</td>\n",
       "      <td>4436.91</td>\n",
       "      <td>20.202159</td>\n",
       "      <td>4105.64</td>\n",
       "      <td>20.614088</td>\n",
       "      <td>3897.94</td>\n",
       "      <td>21.222026</td>\n",
       "      <td>3709.27</td>\n",
       "      <td>30.170528</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1421 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      close_19     ADX_19  close_18     ADX_18  close_17     ADX_17  close_16  \\\n",
       "157     754.99  41.418230    855.28  36.212628    934.03  24.312204    940.00   \n",
       "158     855.28  36.212628    934.03  24.312204    940.00  21.025032    959.30   \n",
       "159     934.03  24.312204    940.00  21.025032    959.30  21.223914   1004.11   \n",
       "160     940.00  21.025032    959.30  21.223914   1004.11  22.305116   1123.09   \n",
       "161     959.30  21.223914   1004.11  22.305116   1123.09  23.246794   1133.18   \n",
       "...        ...        ...       ...        ...       ...        ...       ...   \n",
       "1573   4287.80  19.071649   3996.90  19.441324   4294.76  19.895549   4412.17   \n",
       "1574   3996.90  19.441324   4294.76  19.895549   4412.17  20.260773   4258.31   \n",
       "1575   4294.76  19.895549   4412.17  20.260773   4258.31  19.858133   4085.97   \n",
       "1576   4412.17  20.260773   4258.31  19.858133   4085.97  19.464946   4339.44   \n",
       "1577   4258.31  19.858133   4085.97  19.464946   4339.44  19.925177   4269.36   \n",
       "\n",
       "         ADX_16  close_15     ADX_15  ...  close_3      ADX_3  close_2  \\\n",
       "157   21.025032    959.30  21.223914  ...  1000.00  27.861915   994.00   \n",
       "158   21.223914   1004.11  22.305116  ...   994.00  27.314258  1032.50   \n",
       "159   22.305116   1123.09  23.246794  ...  1032.50  26.829022  1152.75   \n",
       "160   23.246794   1133.18  25.900560  ...  1152.75  26.295579  1049.00   \n",
       "161   25.900560   1291.00  26.950869  ...  1049.00  25.001883   993.00   \n",
       "...         ...       ...        ...  ...      ...        ...      ...   \n",
       "1573  20.260773   4258.31  19.858133  ...  4215.73  16.807307  4117.25   \n",
       "1574  19.858133   4085.97  19.464946  ...  4117.25  16.765313  4196.44   \n",
       "1575  19.464946   4339.44  19.925177  ...  4196.44  17.981035  4347.59   \n",
       "1576  19.925177   4269.36  19.969782  ...  4347.59  19.049911  4306.40   \n",
       "1577  19.969782   4524.85  19.934622  ...  4306.40  19.747824  4436.91   \n",
       "\n",
       "          ADX_2  close_1      ADX_1  close_0      ADX_0    close        ADX  \n",
       "157   27.314258  1032.50  26.829022  1152.75  26.295579   877.00  24.441875  \n",
       "158   26.829022  1152.75  26.295579  1049.00  25.001883   851.15  24.385214  \n",
       "159   26.295579  1049.00  25.001883   993.00  24.131656   808.99  24.078679  \n",
       "160   25.001883   993.00  24.131656   980.00  23.956457   866.66  23.976865  \n",
       "161   24.131656   980.00  23.956457  1061.00  23.763680   841.57  23.677467  \n",
       "...         ...      ...        ...      ...        ...      ...        ...  \n",
       "1573  16.765313  4196.44  17.981035  4347.59  19.049911  4063.56  28.514337  \n",
       "1574  17.981035  4347.59  19.049911  4306.40  19.747824  4037.23  28.403375  \n",
       "1575  19.049911  4306.40  19.747824  4436.91  20.202159  3792.75  28.223716  \n",
       "1576  19.747824  4436.91  20.202159  4105.64  20.614088  3630.19  29.015362  \n",
       "1577  20.202159  4105.64  20.614088  3897.94  21.222026  3709.27  30.170528  \n",
       "\n",
       "[1421 rows x 42 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>close_19</th>\n",
       "      <th>ADX_19</th>\n",
       "      <th>close_18</th>\n",
       "      <th>ADX_18</th>\n",
       "      <th>close_17</th>\n",
       "      <th>ADX_17</th>\n",
       "      <th>close_16</th>\n",
       "      <th>ADX_16</th>\n",
       "      <th>close_15</th>\n",
       "      <th>ADX_15</th>\n",
       "      <th>...</th>\n",
       "      <th>close_3</th>\n",
       "      <th>ADX_3</th>\n",
       "      <th>close_2</th>\n",
       "      <th>ADX_2</th>\n",
       "      <th>close_1</th>\n",
       "      <th>ADX_1</th>\n",
       "      <th>close_0</th>\n",
       "      <th>ADX_0</th>\n",
       "      <th>close</th>\n",
       "      <th>ADX</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1578</th>\n",
       "      <td>4085.97</td>\n",
       "      <td>19.464946</td>\n",
       "      <td>4339.44</td>\n",
       "      <td>19.925177</td>\n",
       "      <td>4269.36</td>\n",
       "      <td>19.969782</td>\n",
       "      <td>4524.85</td>\n",
       "      <td>19.934622</td>\n",
       "      <td>4041.2</td>\n",
       "      <td>19.004087</td>\n",
       "      <td>...</td>\n",
       "      <td>4436.91</td>\n",
       "      <td>20.202159</td>\n",
       "      <td>4105.64</td>\n",
       "      <td>20.614088</td>\n",
       "      <td>3897.94</td>\n",
       "      <td>21.222026</td>\n",
       "      <td>4089.37</td>\n",
       "      <td>22.210426</td>\n",
       "      <td>3725.46</td>\n",
       "      <td>31.29229</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      close_19     ADX_19  close_18     ADX_18  close_17     ADX_17  close_16  \\\n",
       "1578   4085.97  19.464946   4339.44  19.925177   4269.36  19.969782   4524.85   \n",
       "\n",
       "         ADX_16  close_15     ADX_15  ...  close_3      ADX_3  close_2  \\\n",
       "1578  19.934622    4041.2  19.004087  ...  4436.91  20.202159  4105.64   \n",
       "\n",
       "          ADX_2  close_1      ADX_1  close_0      ADX_0    close       ADX  \n",
       "1578  20.614088  3897.94  21.222026  4089.37  22.210426  3725.46  31.29229  \n",
       "\n",
       "[1 rows x 42 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (1421, 20, 2) (1421, 2)\n",
      "Model: \"sequential_20\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_96 (LSTM)               (None, 20, 25)            2800      \n",
      "_________________________________________________________________\n",
      "lstm_97 (LSTM)               (None, 20, 25)            5100      \n",
      "_________________________________________________________________\n",
      "dropout_77 (Dropout)         (None, 20, 25)            0         \n",
      "_________________________________________________________________\n",
      "lstm_98 (LSTM)               (None, 20, 25)            5100      \n",
      "_________________________________________________________________\n",
      "dropout_78 (Dropout)         (None, 20, 25)            0         \n",
      "_________________________________________________________________\n",
      "lstm_99 (LSTM)               (None, 20, 25)            5100      \n",
      "_________________________________________________________________\n",
      "dropout_79 (Dropout)         (None, 20, 25)            0         \n",
      "_________________________________________________________________\n",
      "lstm_100 (LSTM)              (None, 25)                5100      \n",
      "_________________________________________________________________\n",
      "dropout_80 (Dropout)         (None, 25)                0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 2)                 52        \n",
      "=================================================================\n",
      "Total params: 23,252\n",
      "Trainable params: 23,252\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Y shape (1421, 2)\n",
      "Train on 1421 samples, validate on 285 samples\n",
      "Epoch 1/100\n",
      " - 16s - loss: 0.0931 - mse: 0.0931 - val_loss: 0.2364 - val_mse: 0.2364\n",
      "Epoch 2/100\n",
      " - 4s - loss: 0.0603 - mse: 0.0603 - val_loss: 0.1189 - val_mse: 0.1189\n",
      "Epoch 3/100\n",
      " - 6s - loss: 0.0664 - mse: 0.0664 - val_loss: 0.1071 - val_mse: 0.1071\n",
      "Epoch 4/100\n",
      " - 14s - loss: 0.0479 - mse: 0.0479 - val_loss: 0.0467 - val_mse: 0.0467\n",
      "Epoch 5/100\n",
      " - 7s - loss: 0.0366 - mse: 0.0366 - val_loss: 0.0236 - val_mse: 0.0236\n",
      "Epoch 6/100\n",
      " - 6s - loss: 0.0381 - mse: 0.0381 - val_loss: 0.0417 - val_mse: 0.0417\n",
      "Epoch 7/100\n",
      " - 5s - loss: 0.0312 - mse: 0.0312 - val_loss: 0.0209 - val_mse: 0.0209\n",
      "Epoch 8/100\n",
      " - 5s - loss: 0.0298 - mse: 0.0298 - val_loss: 0.0219 - val_mse: 0.0219\n",
      "Epoch 9/100\n",
      " - 5s - loss: 0.0328 - mse: 0.0328 - val_loss: 0.0228 - val_mse: 0.0228\n",
      "Epoch 10/100\n",
      " - 5s - loss: 0.0377 - mse: 0.0377 - val_loss: 0.0344 - val_mse: 0.0344\n",
      "Epoch 11/100\n",
      " - 5s - loss: 0.0508 - mse: 0.0508 - val_loss: 0.0882 - val_mse: 0.0882\n",
      "Epoch 12/100\n",
      " - 5s - loss: 0.0322 - mse: 0.0322 - val_loss: 0.0215 - val_mse: 0.0215\n",
      "Epoch 13/100\n",
      " - 5s - loss: 0.0318 - mse: 0.0318 - val_loss: 0.0204 - val_mse: 0.0204\n",
      "Epoch 14/100\n",
      " - 5s - loss: 0.0310 - mse: 0.0310 - val_loss: 0.0233 - val_mse: 0.0233\n",
      "Epoch 15/100\n",
      " - 6s - loss: 0.0309 - mse: 0.0309 - val_loss: 0.0205 - val_mse: 0.0205\n",
      "Epoch 16/100\n",
      " - 6s - loss: 0.0294 - mse: 0.0294 - val_loss: 0.0232 - val_mse: 0.0232\n",
      "Epoch 17/100\n",
      " - 5s - loss: 0.0298 - mse: 0.0298 - val_loss: 0.0202 - val_mse: 0.0202\n",
      "Epoch 18/100\n",
      " - 5s - loss: 0.0298 - mse: 0.0298 - val_loss: 0.0227 - val_mse: 0.0227\n",
      "Epoch 19/100\n",
      " - 5s - loss: 0.0297 - mse: 0.0297 - val_loss: 0.0199 - val_mse: 0.0199\n",
      "Epoch 20/100\n",
      " - 5s - loss: 0.0297 - mse: 0.0297 - val_loss: 0.0240 - val_mse: 0.0240\n",
      "Epoch 21/100\n",
      " - 5s - loss: 0.0290 - mse: 0.0290 - val_loss: 0.0202 - val_mse: 0.0202\n",
      "Epoch 22/100\n",
      " - 5s - loss: 0.0285 - mse: 0.0285 - val_loss: 0.0210 - val_mse: 0.0210\n",
      "Epoch 23/100\n",
      " - 5s - loss: 0.0283 - mse: 0.0283 - val_loss: 0.0198 - val_mse: 0.0198\n",
      "Epoch 24/100\n",
      " - 6s - loss: 0.0278 - mse: 0.0278 - val_loss: 0.0202 - val_mse: 0.0202\n",
      "Epoch 25/100\n",
      " - 5s - loss: 0.0280 - mse: 0.0280 - val_loss: 0.0197 - val_mse: 0.0197\n",
      "Epoch 26/100\n",
      " - 5s - loss: 0.0270 - mse: 0.0270 - val_loss: 0.0197 - val_mse: 0.0197\n",
      "Epoch 27/100\n",
      " - 5s - loss: 0.0276 - mse: 0.0276 - val_loss: 0.0194 - val_mse: 0.0194\n",
      "Epoch 28/100\n",
      " - 5s - loss: 0.0274 - mse: 0.0274 - val_loss: 0.0196 - val_mse: 0.0196\n",
      "Epoch 29/100\n",
      " - 5s - loss: 0.0271 - mse: 0.0271 - val_loss: 0.0192 - val_mse: 0.0192\n",
      "Epoch 30/100\n",
      " - 5s - loss: 0.0268 - mse: 0.0268 - val_loss: 0.0195 - val_mse: 0.0195\n",
      "Epoch 31/100\n",
      " - 5s - loss: 0.0273 - mse: 0.0273 - val_loss: 0.0190 - val_mse: 0.0190\n",
      "Epoch 32/100\n",
      " - 5s - loss: 0.0271 - mse: 0.0271 - val_loss: 0.0190 - val_mse: 0.0190\n",
      "Epoch 33/100\n",
      " - 4s - loss: 0.0272 - mse: 0.0272 - val_loss: 0.0190 - val_mse: 0.0190\n",
      "Epoch 34/100\n",
      " - 4s - loss: 0.0270 - mse: 0.0270 - val_loss: 0.0189 - val_mse: 0.0189\n",
      "Epoch 35/100\n",
      " - 4s - loss: 0.0266 - mse: 0.0266 - val_loss: 0.0185 - val_mse: 0.0185\n",
      "Epoch 36/100\n",
      " - 5s - loss: 0.0269 - mse: 0.0269 - val_loss: 0.0187 - val_mse: 0.0187\n",
      "Epoch 37/100\n",
      " - 5s - loss: 0.0267 - mse: 0.0267 - val_loss: 0.0184 - val_mse: 0.0184\n",
      "Epoch 38/100\n",
      " - 4s - loss: 0.0265 - mse: 0.0265 - val_loss: 0.0182 - val_mse: 0.0182\n",
      "Epoch 39/100\n",
      " - 5s - loss: 0.0269 - mse: 0.0269 - val_loss: 0.0181 - val_mse: 0.0181\n",
      "Epoch 40/100\n",
      " - 4s - loss: 0.0270 - mse: 0.0270 - val_loss: 0.0184 - val_mse: 0.0184\n",
      "Epoch 41/100\n",
      " - 4s - loss: 0.0278 - mse: 0.0278 - val_loss: 0.0186 - val_mse: 0.0186\n",
      "Epoch 42/100\n",
      " - 5s - loss: 0.0295 - mse: 0.0295 - val_loss: 0.0234 - val_mse: 0.0234\n",
      "Epoch 43/100\n",
      " - 5s - loss: 0.0302 - mse: 0.0302 - val_loss: 0.0186 - val_mse: 0.0186\n",
      "Epoch 44/100\n",
      " - 5s - loss: 0.0319 - mse: 0.0319 - val_loss: 0.0337 - val_mse: 0.0337\n",
      "Epoch 45/100\n",
      " - 5s - loss: 0.0283 - mse: 0.0283 - val_loss: 0.0196 - val_mse: 0.0196\n",
      "Epoch 46/100\n",
      " - 5s - loss: 0.0263 - mse: 0.0263 - val_loss: 0.0195 - val_mse: 0.0195\n",
      "Epoch 47/100\n",
      " - 7s - loss: 0.0271 - mse: 0.0271 - val_loss: 0.0181 - val_mse: 0.0181\n",
      "Epoch 48/100\n",
      " - 5s - loss: 0.0265 - mse: 0.0265 - val_loss: 0.0184 - val_mse: 0.0184\n",
      "Epoch 49/100\n",
      " - 4s - loss: 0.0272 - mse: 0.0272 - val_loss: 0.0178 - val_mse: 0.0178\n",
      "Epoch 50/100\n",
      " - 5s - loss: 0.0265 - mse: 0.0265 - val_loss: 0.0192 - val_mse: 0.0192\n",
      "Epoch 51/100\n",
      " - 5s - loss: 0.0278 - mse: 0.0278 - val_loss: 0.0178 - val_mse: 0.0178\n",
      "Epoch 52/100\n",
      " - 4s - loss: 0.0271 - mse: 0.0271 - val_loss: 0.0197 - val_mse: 0.0197\n",
      "Epoch 53/100\n",
      " - 5s - loss: 0.0272 - mse: 0.0272 - val_loss: 0.0177 - val_mse: 0.0177\n",
      "Epoch 54/100\n",
      " - 4s - loss: 0.0273 - mse: 0.0273 - val_loss: 0.0213 - val_mse: 0.0213\n",
      "Epoch 55/100\n",
      " - 4s - loss: 0.0274 - mse: 0.0274 - val_loss: 0.0178 - val_mse: 0.0178\n",
      "Epoch 56/100\n",
      " - 4s - loss: 0.0260 - mse: 0.0260 - val_loss: 0.0201 - val_mse: 0.0201\n",
      "Epoch 57/100\n",
      " - 4s - loss: 0.0259 - mse: 0.0259 - val_loss: 0.0177 - val_mse: 0.0177\n",
      "Epoch 58/100\n",
      " - 4s - loss: 0.0255 - mse: 0.0255 - val_loss: 0.0183 - val_mse: 0.0183\n",
      "Epoch 59/100\n",
      " - 5s - loss: 0.0260 - mse: 0.0260 - val_loss: 0.0173 - val_mse: 0.0173\n",
      "Epoch 60/100\n",
      " - 5s - loss: 0.0258 - mse: 0.0258 - val_loss: 0.0188 - val_mse: 0.0188\n",
      "Epoch 61/100\n",
      " - 5s - loss: 0.0261 - mse: 0.0261 - val_loss: 0.0172 - val_mse: 0.0172\n",
      "Epoch 62/100\n",
      " - 5s - loss: 0.0260 - mse: 0.0260 - val_loss: 0.0190 - val_mse: 0.0190\n",
      "Epoch 63/100\n",
      " - 4s - loss: 0.0256 - mse: 0.0256 - val_loss: 0.0172 - val_mse: 0.0172\n",
      "Epoch 64/100\n",
      " - 5s - loss: 0.0259 - mse: 0.0259 - val_loss: 0.0188 - val_mse: 0.0188\n",
      "Epoch 65/100\n",
      " - 4s - loss: 0.0260 - mse: 0.0260 - val_loss: 0.0170 - val_mse: 0.0170\n",
      "Epoch 66/100\n",
      " - 4s - loss: 0.0257 - mse: 0.0257 - val_loss: 0.0183 - val_mse: 0.0183\n",
      "Epoch 67/100\n",
      " - 4s - loss: 0.0253 - mse: 0.0253 - val_loss: 0.0170 - val_mse: 0.0170\n",
      "Epoch 68/100\n",
      " - 4s - loss: 0.0249 - mse: 0.0249 - val_loss: 0.0170 - val_mse: 0.0170\n",
      "Epoch 69/100\n",
      " - 4s - loss: 0.0252 - mse: 0.0252 - val_loss: 0.0165 - val_mse: 0.0165\n",
      "Epoch 70/100\n",
      " - 4s - loss: 0.0247 - mse: 0.0247 - val_loss: 0.0167 - val_mse: 0.0167\n",
      "Epoch 71/100\n",
      " - 4s - loss: 0.0247 - mse: 0.0247 - val_loss: 0.0163 - val_mse: 0.0163\n",
      "Epoch 72/100\n",
      " - 5s - loss: 0.0245 - mse: 0.0245 - val_loss: 0.0171 - val_mse: 0.0171\n",
      "Epoch 73/100\n",
      " - 6s - loss: 0.0246 - mse: 0.0246 - val_loss: 0.0166 - val_mse: 0.0166\n",
      "Epoch 74/100\n",
      " - 5s - loss: 0.0250 - mse: 0.0250 - val_loss: 0.0178 - val_mse: 0.0178\n",
      "Epoch 75/100\n",
      " - 5s - loss: 0.0248 - mse: 0.0248 - val_loss: 0.0166 - val_mse: 0.0166\n",
      "Epoch 76/100\n",
      " - 5s - loss: 0.0253 - mse: 0.0253 - val_loss: 0.0183 - val_mse: 0.0183\n",
      "Epoch 77/100\n",
      " - 4s - loss: 0.0258 - mse: 0.0258 - val_loss: 0.0166 - val_mse: 0.0166\n",
      "Epoch 78/100\n",
      " - 4s - loss: 0.0252 - mse: 0.0252 - val_loss: 0.0192 - val_mse: 0.0192\n",
      "Epoch 79/100\n",
      " - 4s - loss: 0.0251 - mse: 0.0251 - val_loss: 0.0168 - val_mse: 0.0168\n",
      "Epoch 80/100\n",
      " - 4s - loss: 0.0246 - mse: 0.0246 - val_loss: 0.0182 - val_mse: 0.0182\n",
      "Epoch 81/100\n",
      " - 7s - loss: 0.0246 - mse: 0.0246 - val_loss: 0.0165 - val_mse: 0.0165\n",
      "Epoch 82/100\n",
      " - 5s - loss: 0.0241 - mse: 0.0241 - val_loss: 0.0169 - val_mse: 0.0169\n",
      "Epoch 83/100\n",
      " - 4s - loss: 0.0243 - mse: 0.0243 - val_loss: 0.0161 - val_mse: 0.0161\n",
      "Epoch 84/100\n",
      " - 5s - loss: 0.0233 - mse: 0.0233 - val_loss: 0.0163 - val_mse: 0.0163\n",
      "Epoch 85/100\n",
      " - 5s - loss: 0.0244 - mse: 0.0244 - val_loss: 0.0161 - val_mse: 0.0161\n",
      "Epoch 86/100\n",
      " - 5s - loss: 0.0238 - mse: 0.0238 - val_loss: 0.0162 - val_mse: 0.0162\n",
      "Epoch 87/100\n",
      " - 6s - loss: 0.0234 - mse: 0.0234 - val_loss: 0.0159 - val_mse: 0.0159\n",
      "Epoch 88/100\n",
      " - 5s - loss: 0.0238 - mse: 0.0238 - val_loss: 0.0159 - val_mse: 0.0159\n",
      "Epoch 89/100\n",
      " - 5s - loss: 0.0237 - mse: 0.0237 - val_loss: 0.0159 - val_mse: 0.0159\n",
      "Epoch 90/100\n",
      " - 4s - loss: 0.0232 - mse: 0.0232 - val_loss: 0.0159 - val_mse: 0.0159\n",
      "Epoch 91/100\n",
      " - 4s - loss: 0.0239 - mse: 0.0239 - val_loss: 0.0159 - val_mse: 0.0159\n",
      "Epoch 92/100\n",
      " - 5s - loss: 0.0230 - mse: 0.0230 - val_loss: 0.0160 - val_mse: 0.0160\n",
      "Epoch 93/100\n",
      " - 5s - loss: 0.0233 - mse: 0.0233 - val_loss: 0.0159 - val_mse: 0.0159\n",
      "Epoch 94/100\n",
      " - 33s - loss: 0.0234 - mse: 0.0234 - val_loss: 0.0159 - val_mse: 0.0159\n",
      "Epoch 95/100\n",
      " - 53s - loss: 0.0237 - mse: 0.0237 - val_loss: 0.0158 - val_mse: 0.0158\n",
      "Epoch 96/100\n",
      " - 71s - loss: 0.0246 - mse: 0.0246 - val_loss: 0.0166 - val_mse: 0.0166\n",
      "Epoch 97/100\n",
      " - 74s - loss: 0.0248 - mse: 0.0248 - val_loss: 0.0165 - val_mse: 0.0165\n",
      "Epoch 98/100\n",
      " - 108s - loss: 0.0253 - mse: 0.0253 - val_loss: 0.0188 - val_mse: 0.0188\n",
      "Epoch 99/100\n",
      " - 76s - loss: 0.0248 - mse: 0.0248 - val_loss: 0.0171 - val_mse: 0.0171\n",
      "Epoch 100/100\n",
      " - 6s - loss: 0.0241 - mse: 0.0241 - val_loss: 0.0174 - val_mse: 0.0174\n",
      "real [[3725.46         31.29229011]]\n",
      "Test RMSE: 213.584\n",
      "Diff [[-301.99947233    5.73349518]]\n",
      "% Diff [[-8.10636733 18.32238918]] %\n",
      "Predictions [[4027.45947233   25.55879493]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "columns = columns_2\n",
    "num_features = len(columns)\n",
    "\n",
    "\n",
    "crypto = crypto\n",
    "execute_test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelado:\n",
    "\n",
    "Modelaremos la red en las capas LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modifcamos el numero de capas:\n",
    "\n",
    "- 1 Capas\n",
    "- 4 Capas\n",
    "- 10 Capas\n",
    "\n",
    "Y neuronas\n",
    "\n",
    "- 10 Nueronas\n",
    "- 50 Neuronas\n",
    "- 100 Neuronas\n",
    "- Gradual invertido"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trabajaremos sobre diferencia de precio de 20 dias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'close'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading... ETH\n",
      "Extracting columns columns for ETH\n",
      "Proccessing and arranging columns for LSTM model\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>close_19</th>\n",
       "      <th>close_diff_20_19</th>\n",
       "      <th>close_18</th>\n",
       "      <th>close_diff_20_18</th>\n",
       "      <th>close_17</th>\n",
       "      <th>close_diff_20_17</th>\n",
       "      <th>close_16</th>\n",
       "      <th>close_diff_20_16</th>\n",
       "      <th>close_15</th>\n",
       "      <th>close_diff_20_15</th>\n",
       "      <th>...</th>\n",
       "      <th>close_diff_20_4</th>\n",
       "      <th>close_3</th>\n",
       "      <th>close_diff_20_3</th>\n",
       "      <th>close_2</th>\n",
       "      <th>close_diff_20_2</th>\n",
       "      <th>close_1</th>\n",
       "      <th>close_diff_20_1</th>\n",
       "      <th>close_0</th>\n",
       "      <th>close_diff_20_0</th>\n",
       "      <th>close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>1123.09</td>\n",
       "      <td>339.09</td>\n",
       "      <td>1133.18</td>\n",
       "      <td>335.18</td>\n",
       "      <td>1291.00</td>\n",
       "      <td>500.79</td>\n",
       "      <td>1247.00</td>\n",
       "      <td>464.59</td>\n",
       "      <td>1138.93</td>\n",
       "      <td>502.96</td>\n",
       "      <td>...</td>\n",
       "      <td>137.72</td>\n",
       "      <td>980.00</td>\n",
       "      <td>45.97</td>\n",
       "      <td>1061.00</td>\n",
       "      <td>121.00</td>\n",
       "      <td>1056.52</td>\n",
       "      <td>97.22</td>\n",
       "      <td>1051.03</td>\n",
       "      <td>46.92</td>\n",
       "      <td>924.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>1133.18</td>\n",
       "      <td>335.18</td>\n",
       "      <td>1291.00</td>\n",
       "      <td>500.79</td>\n",
       "      <td>1247.00</td>\n",
       "      <td>464.59</td>\n",
       "      <td>1138.93</td>\n",
       "      <td>502.96</td>\n",
       "      <td>1253.87</td>\n",
       "      <td>613.53</td>\n",
       "      <td>...</td>\n",
       "      <td>45.97</td>\n",
       "      <td>1061.00</td>\n",
       "      <td>121.00</td>\n",
       "      <td>1056.52</td>\n",
       "      <td>97.22</td>\n",
       "      <td>1051.03</td>\n",
       "      <td>46.92</td>\n",
       "      <td>1118.99</td>\n",
       "      <td>-4.10</td>\n",
       "      <td>938.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>1291.00</td>\n",
       "      <td>500.79</td>\n",
       "      <td>1247.00</td>\n",
       "      <td>464.59</td>\n",
       "      <td>1138.93</td>\n",
       "      <td>502.96</td>\n",
       "      <td>1253.87</td>\n",
       "      <td>613.53</td>\n",
       "      <td>1388.02</td>\n",
       "      <td>730.02</td>\n",
       "      <td>...</td>\n",
       "      <td>121.00</td>\n",
       "      <td>1056.52</td>\n",
       "      <td>97.22</td>\n",
       "      <td>1051.03</td>\n",
       "      <td>46.92</td>\n",
       "      <td>1118.99</td>\n",
       "      <td>-4.10</td>\n",
       "      <td>1251.96</td>\n",
       "      <td>118.78</td>\n",
       "      <td>969.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>1247.00</td>\n",
       "      <td>464.59</td>\n",
       "      <td>1138.93</td>\n",
       "      <td>502.96</td>\n",
       "      <td>1253.87</td>\n",
       "      <td>613.53</td>\n",
       "      <td>1388.02</td>\n",
       "      <td>730.02</td>\n",
       "      <td>1347.00</td>\n",
       "      <td>632.05</td>\n",
       "      <td>...</td>\n",
       "      <td>97.22</td>\n",
       "      <td>1051.03</td>\n",
       "      <td>46.92</td>\n",
       "      <td>1118.99</td>\n",
       "      <td>-4.10</td>\n",
       "      <td>1251.96</td>\n",
       "      <td>118.78</td>\n",
       "      <td>1177.01</td>\n",
       "      <td>-113.99</td>\n",
       "      <td>911.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>1138.93</td>\n",
       "      <td>502.96</td>\n",
       "      <td>1253.87</td>\n",
       "      <td>613.53</td>\n",
       "      <td>1388.02</td>\n",
       "      <td>730.02</td>\n",
       "      <td>1347.00</td>\n",
       "      <td>632.05</td>\n",
       "      <td>1271.00</td>\n",
       "      <td>521.00</td>\n",
       "      <td>...</td>\n",
       "      <td>46.92</td>\n",
       "      <td>1118.99</td>\n",
       "      <td>-4.10</td>\n",
       "      <td>1251.96</td>\n",
       "      <td>118.78</td>\n",
       "      <td>1177.01</td>\n",
       "      <td>-113.99</td>\n",
       "      <td>1085.50</td>\n",
       "      <td>-161.50</td>\n",
       "      <td>938.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1573</th>\n",
       "      <td>4287.80</td>\n",
       "      <td>1.78</td>\n",
       "      <td>3996.90</td>\n",
       "      <td>-421.99</td>\n",
       "      <td>4294.76</td>\n",
       "      <td>-27.92</td>\n",
       "      <td>4412.17</td>\n",
       "      <td>124.96</td>\n",
       "      <td>4258.31</td>\n",
       "      <td>-61.12</td>\n",
       "      <td>...</td>\n",
       "      <td>-154.25</td>\n",
       "      <td>4215.73</td>\n",
       "      <td>-428.55</td>\n",
       "      <td>4117.25</td>\n",
       "      <td>-509.25</td>\n",
       "      <td>4196.44</td>\n",
       "      <td>-367.34</td>\n",
       "      <td>4347.59</td>\n",
       "      <td>137.83</td>\n",
       "      <td>4063.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1574</th>\n",
       "      <td>3996.90</td>\n",
       "      <td>-421.99</td>\n",
       "      <td>4294.76</td>\n",
       "      <td>-27.92</td>\n",
       "      <td>4412.17</td>\n",
       "      <td>124.96</td>\n",
       "      <td>4258.31</td>\n",
       "      <td>-61.12</td>\n",
       "      <td>4085.97</td>\n",
       "      <td>-503.92</td>\n",
       "      <td>...</td>\n",
       "      <td>-428.55</td>\n",
       "      <td>4117.25</td>\n",
       "      <td>-509.25</td>\n",
       "      <td>4196.44</td>\n",
       "      <td>-367.34</td>\n",
       "      <td>4347.59</td>\n",
       "      <td>137.83</td>\n",
       "      <td>4306.40</td>\n",
       "      <td>18.60</td>\n",
       "      <td>4037.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1575</th>\n",
       "      <td>4294.76</td>\n",
       "      <td>-27.92</td>\n",
       "      <td>4412.17</td>\n",
       "      <td>124.96</td>\n",
       "      <td>4258.31</td>\n",
       "      <td>-61.12</td>\n",
       "      <td>4085.97</td>\n",
       "      <td>-503.92</td>\n",
       "      <td>4339.44</td>\n",
       "      <td>-263.91</td>\n",
       "      <td>...</td>\n",
       "      <td>-509.25</td>\n",
       "      <td>4196.44</td>\n",
       "      <td>-367.34</td>\n",
       "      <td>4347.59</td>\n",
       "      <td>137.83</td>\n",
       "      <td>4306.40</td>\n",
       "      <td>18.60</td>\n",
       "      <td>4436.91</td>\n",
       "      <td>440.01</td>\n",
       "      <td>3792.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1576</th>\n",
       "      <td>4412.17</td>\n",
       "      <td>124.96</td>\n",
       "      <td>4258.31</td>\n",
       "      <td>-61.12</td>\n",
       "      <td>4085.97</td>\n",
       "      <td>-503.92</td>\n",
       "      <td>4339.44</td>\n",
       "      <td>-263.91</td>\n",
       "      <td>4269.36</td>\n",
       "      <td>-262.96</td>\n",
       "      <td>...</td>\n",
       "      <td>-367.34</td>\n",
       "      <td>4347.59</td>\n",
       "      <td>137.83</td>\n",
       "      <td>4306.40</td>\n",
       "      <td>18.60</td>\n",
       "      <td>4436.91</td>\n",
       "      <td>440.01</td>\n",
       "      <td>4105.64</td>\n",
       "      <td>-189.12</td>\n",
       "      <td>3630.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1577</th>\n",
       "      <td>4258.31</td>\n",
       "      <td>-61.12</td>\n",
       "      <td>4085.97</td>\n",
       "      <td>-503.92</td>\n",
       "      <td>4339.44</td>\n",
       "      <td>-263.91</td>\n",
       "      <td>4269.36</td>\n",
       "      <td>-262.96</td>\n",
       "      <td>4524.85</td>\n",
       "      <td>50.61</td>\n",
       "      <td>...</td>\n",
       "      <td>137.83</td>\n",
       "      <td>4306.40</td>\n",
       "      <td>18.60</td>\n",
       "      <td>4436.91</td>\n",
       "      <td>440.01</td>\n",
       "      <td>4105.64</td>\n",
       "      <td>-189.12</td>\n",
       "      <td>3897.94</td>\n",
       "      <td>-514.23</td>\n",
       "      <td>3709.27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1415 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      close_19  close_diff_20_19  close_18  close_diff_20_18  close_17  \\\n",
       "163    1123.09            339.09   1133.18            335.18   1291.00   \n",
       "164    1133.18            335.18   1291.00            500.79   1247.00   \n",
       "165    1291.00            500.79   1247.00            464.59   1138.93   \n",
       "166    1247.00            464.59   1138.93            502.96   1253.87   \n",
       "167    1138.93            502.96   1253.87            613.53   1388.02   \n",
       "...        ...               ...       ...               ...       ...   \n",
       "1573   4287.80              1.78   3996.90           -421.99   4294.76   \n",
       "1574   3996.90           -421.99   4294.76            -27.92   4412.17   \n",
       "1575   4294.76            -27.92   4412.17            124.96   4258.31   \n",
       "1576   4412.17            124.96   4258.31            -61.12   4085.97   \n",
       "1577   4258.31            -61.12   4085.97           -503.92   4339.44   \n",
       "\n",
       "      close_diff_20_17  close_16  close_diff_20_16  close_15  \\\n",
       "163             500.79   1247.00            464.59   1138.93   \n",
       "164             464.59   1138.93            502.96   1253.87   \n",
       "165             502.96   1253.87            613.53   1388.02   \n",
       "166             613.53   1388.02            730.02   1347.00   \n",
       "167             730.02   1347.00            632.05   1271.00   \n",
       "...                ...       ...               ...       ...   \n",
       "1573            -27.92   4412.17            124.96   4258.31   \n",
       "1574            124.96   4258.31            -61.12   4085.97   \n",
       "1575            -61.12   4085.97           -503.92   4339.44   \n",
       "1576           -503.92   4339.44           -263.91   4269.36   \n",
       "1577           -263.91   4269.36           -262.96   4524.85   \n",
       "\n",
       "      close_diff_20_15  ...  close_diff_20_4  close_3  close_diff_20_3  \\\n",
       "163             502.96  ...           137.72   980.00            45.97   \n",
       "164             613.53  ...            45.97  1061.00           121.00   \n",
       "165             730.02  ...           121.00  1056.52            97.22   \n",
       "166             632.05  ...            97.22  1051.03            46.92   \n",
       "167             521.00  ...            46.92  1118.99            -4.10   \n",
       "...                ...  ...              ...      ...              ...   \n",
       "1573            -61.12  ...          -154.25  4215.73          -428.55   \n",
       "1574           -503.92  ...          -428.55  4117.25          -509.25   \n",
       "1575           -263.91  ...          -509.25  4196.44          -367.34   \n",
       "1576           -262.96  ...          -367.34  4347.59           137.83   \n",
       "1577             50.61  ...           137.83  4306.40            18.60   \n",
       "\n",
       "      close_2  close_diff_20_2  close_1  close_diff_20_1  close_0  \\\n",
       "163   1061.00           121.00  1056.52            97.22  1051.03   \n",
       "164   1056.52            97.22  1051.03            46.92  1118.99   \n",
       "165   1051.03            46.92  1118.99            -4.10  1251.96   \n",
       "166   1118.99            -4.10  1251.96           118.78  1177.01   \n",
       "167   1251.96           118.78  1177.01          -113.99  1085.50   \n",
       "...       ...              ...      ...              ...      ...   \n",
       "1573  4117.25          -509.25  4196.44          -367.34  4347.59   \n",
       "1574  4196.44          -367.34  4347.59           137.83  4306.40   \n",
       "1575  4347.59           137.83  4306.40            18.60  4436.91   \n",
       "1576  4306.40            18.60  4436.91           440.01  4105.64   \n",
       "1577  4436.91           440.01  4105.64          -189.12  3897.94   \n",
       "\n",
       "      close_diff_20_0    close  \n",
       "163             46.92   924.55  \n",
       "164             -4.10   938.67  \n",
       "165            118.78   969.99  \n",
       "166           -113.99   911.00  \n",
       "167           -161.50   938.11  \n",
       "...               ...      ...  \n",
       "1573           137.83  4063.56  \n",
       "1574            18.60  4037.23  \n",
       "1575           440.01  3792.75  \n",
       "1576          -189.12  3630.19  \n",
       "1577          -514.23  3709.27  \n",
       "\n",
       "[1415 rows x 41 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>close_19</th>\n",
       "      <th>close_diff_20_19</th>\n",
       "      <th>close_18</th>\n",
       "      <th>close_diff_20_18</th>\n",
       "      <th>close_17</th>\n",
       "      <th>close_diff_20_17</th>\n",
       "      <th>close_16</th>\n",
       "      <th>close_diff_20_16</th>\n",
       "      <th>close_15</th>\n",
       "      <th>close_diff_20_15</th>\n",
       "      <th>...</th>\n",
       "      <th>close_diff_20_4</th>\n",
       "      <th>close_3</th>\n",
       "      <th>close_diff_20_3</th>\n",
       "      <th>close_2</th>\n",
       "      <th>close_diff_20_2</th>\n",
       "      <th>close_1</th>\n",
       "      <th>close_diff_20_1</th>\n",
       "      <th>close_0</th>\n",
       "      <th>close_diff_20_0</th>\n",
       "      <th>close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1578</th>\n",
       "      <td>4085.97</td>\n",
       "      <td>-503.92</td>\n",
       "      <td>4339.44</td>\n",
       "      <td>-263.91</td>\n",
       "      <td>4269.36</td>\n",
       "      <td>-262.96</td>\n",
       "      <td>4524.85</td>\n",
       "      <td>50.61</td>\n",
       "      <td>4041.2</td>\n",
       "      <td>-476.8</td>\n",
       "      <td>...</td>\n",
       "      <td>18.6</td>\n",
       "      <td>4436.91</td>\n",
       "      <td>440.01</td>\n",
       "      <td>4105.64</td>\n",
       "      <td>-189.12</td>\n",
       "      <td>3897.94</td>\n",
       "      <td>-514.23</td>\n",
       "      <td>4089.37</td>\n",
       "      <td>-168.94</td>\n",
       "      <td>3725.46</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      close_19  close_diff_20_19  close_18  close_diff_20_18  close_17  \\\n",
       "1578   4085.97           -503.92   4339.44           -263.91   4269.36   \n",
       "\n",
       "      close_diff_20_17  close_16  close_diff_20_16  close_15  \\\n",
       "1578           -262.96   4524.85             50.61    4041.2   \n",
       "\n",
       "      close_diff_20_15  ...  close_diff_20_4  close_3  close_diff_20_3  \\\n",
       "1578            -476.8  ...             18.6  4436.91           440.01   \n",
       "\n",
       "      close_2  close_diff_20_2  close_1  close_diff_20_1  close_0  \\\n",
       "1578  4105.64          -189.12  3897.94          -514.23  4089.37   \n",
       "\n",
       "      close_diff_20_0    close  \n",
       "1578          -168.94  3725.46  \n",
       "\n",
       "[1 rows x 41 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (1415, 1, 40) (1415, 1)\n",
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_16 (LSTM)               (None, 1, 25)             6600      \n",
      "_________________________________________________________________\n",
      "lstm_17 (LSTM)               (None, 25)                5100      \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 25)                0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 26        \n",
      "=================================================================\n",
      "Total params: 11,726\n",
      "Trainable params: 11,726\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Y shape (1415, 1)\n",
      "Train on 1415 samples, validate on 283 samples\n",
      "Epoch 1/100\n",
      " - 4s - loss: 0.0769 - mse: 0.0769 - val_loss: 0.3161 - val_mse: 0.3161\n",
      "Epoch 2/100\n",
      " - 0s - loss: 0.0481 - mse: 0.0481 - val_loss: 0.1756 - val_mse: 0.1756\n",
      "Epoch 3/100\n",
      " - 0s - loss: 0.0328 - mse: 0.0328 - val_loss: 0.0779 - val_mse: 0.0779\n",
      "Epoch 4/100\n",
      " - 0s - loss: 0.0210 - mse: 0.0210 - val_loss: 0.0307 - val_mse: 0.0307\n",
      "Epoch 5/100\n",
      " - 0s - loss: 0.0094 - mse: 0.0094 - val_loss: 0.0206 - val_mse: 0.0206\n",
      "Epoch 6/100\n",
      " - 0s - loss: 0.0061 - mse: 0.0061 - val_loss: 0.0195 - val_mse: 0.0195\n",
      "Epoch 7/100\n",
      " - 0s - loss: 0.0069 - mse: 0.0069 - val_loss: 0.0191 - val_mse: 0.0191\n",
      "Epoch 8/100\n",
      " - 0s - loss: 0.0066 - mse: 0.0066 - val_loss: 0.0187 - val_mse: 0.0187\n",
      "Epoch 9/100\n",
      " - 0s - loss: 0.0067 - mse: 0.0067 - val_loss: 0.0184 - val_mse: 0.0184\n",
      "Epoch 10/100\n",
      " - 0s - loss: 0.0064 - mse: 0.0064 - val_loss: 0.0178 - val_mse: 0.0178\n",
      "Epoch 11/100\n",
      " - 0s - loss: 0.0060 - mse: 0.0060 - val_loss: 0.0174 - val_mse: 0.0174\n",
      "Epoch 12/100\n",
      " - 0s - loss: 0.0065 - mse: 0.0065 - val_loss: 0.0171 - val_mse: 0.0171\n",
      "Epoch 13/100\n",
      " - 0s - loss: 0.0068 - mse: 0.0068 - val_loss: 0.0172 - val_mse: 0.0172\n",
      "Epoch 14/100\n",
      " - 0s - loss: 0.0069 - mse: 0.0069 - val_loss: 0.0166 - val_mse: 0.0166\n",
      "Epoch 15/100\n",
      " - 0s - loss: 0.0070 - mse: 0.0070 - val_loss: 0.0170 - val_mse: 0.0170\n",
      "Epoch 16/100\n",
      " - 0s - loss: 0.0071 - mse: 0.0071 - val_loss: 0.0166 - val_mse: 0.0166\n",
      "Epoch 17/100\n",
      " - 0s - loss: 0.0079 - mse: 0.0079 - val_loss: 0.0170 - val_mse: 0.0170\n",
      "Epoch 18/100\n",
      " - 0s - loss: 0.0097 - mse: 0.0097 - val_loss: 0.0182 - val_mse: 0.0182\n",
      "Epoch 19/100\n",
      " - 0s - loss: 0.0086 - mse: 0.0086 - val_loss: 0.0166 - val_mse: 0.0166\n",
      "Epoch 20/100\n",
      " - 0s - loss: 0.0119 - mse: 0.0119 - val_loss: 0.0228 - val_mse: 0.0228\n",
      "Epoch 21/100\n",
      " - 0s - loss: 0.0090 - mse: 0.0090 - val_loss: 0.0163 - val_mse: 0.0163\n",
      "Epoch 22/100\n",
      " - 1s - loss: 0.0128 - mse: 0.0128 - val_loss: 0.0258 - val_mse: 0.0258\n",
      "Epoch 23/100\n",
      " - 0s - loss: 0.0073 - mse: 0.0073 - val_loss: 0.0165 - val_mse: 0.0165\n",
      "Epoch 24/100\n",
      " - 0s - loss: 0.0097 - mse: 0.0097 - val_loss: 0.0206 - val_mse: 0.0206\n",
      "Epoch 25/100\n",
      " - 0s - loss: 0.0068 - mse: 0.0068 - val_loss: 0.0159 - val_mse: 0.0159\n",
      "Epoch 26/100\n",
      " - 0s - loss: 0.0079 - mse: 0.0079 - val_loss: 0.0185 - val_mse: 0.0185\n",
      "Epoch 27/100\n",
      " - 0s - loss: 0.0062 - mse: 0.0062 - val_loss: 0.0158 - val_mse: 0.0158\n",
      "Epoch 28/100\n",
      " - 0s - loss: 0.0072 - mse: 0.0072 - val_loss: 0.0173 - val_mse: 0.0173\n",
      "Epoch 29/100\n",
      " - 0s - loss: 0.0058 - mse: 0.0058 - val_loss: 0.0155 - val_mse: 0.0155\n",
      "Epoch 30/100\n",
      " - 0s - loss: 0.0065 - mse: 0.0065 - val_loss: 0.0165 - val_mse: 0.0165\n",
      "Epoch 31/100\n",
      " - 0s - loss: 0.0071 - mse: 0.0071 - val_loss: 0.0158 - val_mse: 0.0158\n",
      "Epoch 32/100\n",
      " - 0s - loss: 0.0069 - mse: 0.0069 - val_loss: 0.0172 - val_mse: 0.0172\n",
      "Epoch 33/100\n",
      " - 0s - loss: 0.0060 - mse: 0.0060 - val_loss: 0.0155 - val_mse: 0.0155\n",
      "Epoch 34/100\n",
      " - 0s - loss: 0.0073 - mse: 0.0073 - val_loss: 0.0186 - val_mse: 0.0186\n",
      "Epoch 35/100\n",
      " - 0s - loss: 0.0065 - mse: 0.0065 - val_loss: 0.0157 - val_mse: 0.0157\n",
      "Epoch 36/100\n",
      " - 0s - loss: 0.0067 - mse: 0.0067 - val_loss: 0.0161 - val_mse: 0.0161\n",
      "Epoch 37/100\n",
      " - 0s - loss: 0.0057 - mse: 0.0057 - val_loss: 0.0153 - val_mse: 0.0153\n",
      "Epoch 38/100\n",
      " - 0s - loss: 0.0064 - mse: 0.0064 - val_loss: 0.0163 - val_mse: 0.0163\n",
      "Epoch 39/100\n",
      " - 0s - loss: 0.0065 - mse: 0.0065 - val_loss: 0.0154 - val_mse: 0.0154\n",
      "Epoch 40/100\n",
      " - 0s - loss: 0.0066 - mse: 0.0066 - val_loss: 0.0170 - val_mse: 0.0170\n",
      "Epoch 41/100\n",
      " - 0s - loss: 0.0055 - mse: 0.0055 - val_loss: 0.0152 - val_mse: 0.0152\n",
      "Epoch 42/100\n",
      " - 0s - loss: 0.0065 - mse: 0.0065 - val_loss: 0.0161 - val_mse: 0.0161\n",
      "Epoch 43/100\n",
      " - 0s - loss: 0.0062 - mse: 0.0062 - val_loss: 0.0152 - val_mse: 0.0152\n",
      "Epoch 44/100\n",
      " - 0s - loss: 0.0064 - mse: 0.0064 - val_loss: 0.0167 - val_mse: 0.0167\n",
      "Epoch 45/100\n",
      " - 0s - loss: 0.0055 - mse: 0.0055 - val_loss: 0.0150 - val_mse: 0.0150\n",
      "Epoch 46/100\n",
      " - 0s - loss: 0.0066 - mse: 0.0066 - val_loss: 0.0155 - val_mse: 0.0155\n",
      "Epoch 47/100\n",
      " - 0s - loss: 0.0057 - mse: 0.0057 - val_loss: 0.0150 - val_mse: 0.0150\n",
      "Epoch 48/100\n",
      " - 0s - loss: 0.0059 - mse: 0.0059 - val_loss: 0.0153 - val_mse: 0.0153\n",
      "Epoch 49/100\n",
      " - 0s - loss: 0.0052 - mse: 0.0052 - val_loss: 0.0149 - val_mse: 0.0149\n",
      "Epoch 50/100\n",
      " - 0s - loss: 0.0058 - mse: 0.0058 - val_loss: 0.0152 - val_mse: 0.0152\n",
      "Epoch 51/100\n",
      " - 0s - loss: 0.0052 - mse: 0.0052 - val_loss: 0.0149 - val_mse: 0.0149\n",
      "Epoch 52/100\n",
      " - 0s - loss: 0.0056 - mse: 0.0056 - val_loss: 0.0152 - val_mse: 0.0152\n",
      "Epoch 53/100\n",
      " - 0s - loss: 0.0054 - mse: 0.0054 - val_loss: 0.0149 - val_mse: 0.0149\n",
      "Epoch 54/100\n",
      " - 0s - loss: 0.0061 - mse: 0.0061 - val_loss: 0.0155 - val_mse: 0.0155\n",
      "Epoch 55/100\n",
      " - 0s - loss: 0.0058 - mse: 0.0058 - val_loss: 0.0149 - val_mse: 0.0149\n",
      "Epoch 56/100\n",
      " - 0s - loss: 0.0066 - mse: 0.0066 - val_loss: 0.0155 - val_mse: 0.0155\n",
      "Epoch 57/100\n",
      " - 0s - loss: 0.0069 - mse: 0.0069 - val_loss: 0.0151 - val_mse: 0.0151\n",
      "Epoch 58/100\n",
      " - 0s - loss: 0.0100 - mse: 0.0100 - val_loss: 0.0185 - val_mse: 0.0185\n",
      "Epoch 59/100\n",
      " - 0s - loss: 0.0081 - mse: 0.0081 - val_loss: 0.0152 - val_mse: 0.0152\n",
      "Epoch 60/100\n",
      " - 0s - loss: 0.0119 - mse: 0.0119 - val_loss: 0.0230 - val_mse: 0.0230\n",
      "Epoch 61/100\n",
      " - 0s - loss: 0.0070 - mse: 0.0070 - val_loss: 0.0156 - val_mse: 0.0156\n",
      "Epoch 62/100\n",
      " - 0s - loss: 0.0093 - mse: 0.0093 - val_loss: 0.0198 - val_mse: 0.0198\n",
      "Epoch 63/100\n",
      " - 0s - loss: 0.0061 - mse: 0.0061 - val_loss: 0.0155 - val_mse: 0.0155\n",
      "Epoch 64/100\n",
      " - 0s - loss: 0.0070 - mse: 0.0070 - val_loss: 0.0173 - val_mse: 0.0173\n",
      "Epoch 65/100\n",
      " - 0s - loss: 0.0056 - mse: 0.0056 - val_loss: 0.0151 - val_mse: 0.0151\n",
      "Epoch 66/100\n",
      " - 0s - loss: 0.0063 - mse: 0.0063 - val_loss: 0.0162 - val_mse: 0.0162\n",
      "Epoch 67/100\n",
      " - 0s - loss: 0.0048 - mse: 0.0048 - val_loss: 0.0149 - val_mse: 0.0149\n",
      "Epoch 68/100\n",
      " - 0s - loss: 0.0055 - mse: 0.0055 - val_loss: 0.0152 - val_mse: 0.0152\n",
      "Epoch 69/100\n",
      " - 0s - loss: 0.0053 - mse: 0.0053 - val_loss: 0.0149 - val_mse: 0.0149\n",
      "Epoch 70/100\n",
      " - 0s - loss: 0.0051 - mse: 0.0051 - val_loss: 0.0150 - val_mse: 0.0150\n",
      "Epoch 71/100\n",
      " - 0s - loss: 0.0052 - mse: 0.0052 - val_loss: 0.0148 - val_mse: 0.0148\n",
      "Epoch 72/100\n",
      " - 0s - loss: 0.0049 - mse: 0.0049 - val_loss: 0.0148 - val_mse: 0.0148\n",
      "Epoch 73/100\n",
      " - 0s - loss: 0.0051 - mse: 0.0051 - val_loss: 0.0151 - val_mse: 0.0151\n",
      "Epoch 74/100\n",
      " - 0s - loss: 0.0052 - mse: 0.0052 - val_loss: 0.0149 - val_mse: 0.0149\n",
      "Epoch 75/100\n",
      " - 0s - loss: 0.0052 - mse: 0.0052 - val_loss: 0.0148 - val_mse: 0.0148\n",
      "Epoch 76/100\n",
      " - 0s - loss: 0.0053 - mse: 0.0053 - val_loss: 0.0149 - val_mse: 0.0149\n",
      "Epoch 77/100\n",
      " - 0s - loss: 0.0054 - mse: 0.0054 - val_loss: 0.0147 - val_mse: 0.0147\n",
      "Epoch 78/100\n",
      " - 0s - loss: 0.0053 - mse: 0.0053 - val_loss: 0.0151 - val_mse: 0.0151\n",
      "Epoch 79/100\n",
      " - 0s - loss: 0.0051 - mse: 0.0051 - val_loss: 0.0147 - val_mse: 0.0147\n",
      "Epoch 80/100\n",
      " - 0s - loss: 0.0050 - mse: 0.0050 - val_loss: 0.0147 - val_mse: 0.0147\n",
      "Epoch 81/100\n",
      " - 0s - loss: 0.0046 - mse: 0.0046 - val_loss: 0.0146 - val_mse: 0.0146\n",
      "Epoch 82/100\n",
      " - 0s - loss: 0.0047 - mse: 0.0047 - val_loss: 0.0148 - val_mse: 0.0148\n",
      "Epoch 83/100\n",
      " - 0s - loss: 0.0049 - mse: 0.0049 - val_loss: 0.0146 - val_mse: 0.0146\n",
      "Epoch 84/100\n",
      " - 0s - loss: 0.0046 - mse: 0.0046 - val_loss: 0.0146 - val_mse: 0.0146\n",
      "Epoch 85/100\n",
      " - 0s - loss: 0.0052 - mse: 0.0052 - val_loss: 0.0148 - val_mse: 0.0148\n",
      "Epoch 86/100\n",
      " - 0s - loss: 0.0055 - mse: 0.0055 - val_loss: 0.0146 - val_mse: 0.0146\n",
      "Epoch 87/100\n",
      " - 0s - loss: 0.0046 - mse: 0.0046 - val_loss: 0.0146 - val_mse: 0.0146\n",
      "Epoch 88/100\n",
      " - 0s - loss: 0.0049 - mse: 0.0049 - val_loss: 0.0145 - val_mse: 0.0145\n",
      "Epoch 89/100\n",
      " - 0s - loss: 0.0046 - mse: 0.0046 - val_loss: 0.0145 - val_mse: 0.0145\n",
      "Epoch 90/100\n",
      " - 0s - loss: 0.0049 - mse: 0.0049 - val_loss: 0.0145 - val_mse: 0.0145\n",
      "Epoch 91/100\n",
      " - 0s - loss: 0.0053 - mse: 0.0053 - val_loss: 0.0147 - val_mse: 0.0147\n",
      "Epoch 92/100\n",
      " - 0s - loss: 0.0057 - mse: 0.0057 - val_loss: 0.0147 - val_mse: 0.0147\n",
      "Epoch 93/100\n",
      " - 0s - loss: 0.0062 - mse: 0.0062 - val_loss: 0.0149 - val_mse: 0.0149\n",
      "Epoch 94/100\n",
      " - 0s - loss: 0.0070 - mse: 0.0070 - val_loss: 0.0151 - val_mse: 0.0151\n",
      "Epoch 95/100\n",
      " - 0s - loss: 0.0057 - mse: 0.0057 - val_loss: 0.0147 - val_mse: 0.0147\n",
      "Epoch 96/100\n",
      " - 0s - loss: 0.0069 - mse: 0.0069 - val_loss: 0.0160 - val_mse: 0.0160\n",
      "Epoch 97/100\n",
      " - 0s - loss: 0.0061 - mse: 0.0061 - val_loss: 0.0149 - val_mse: 0.0149\n",
      "Epoch 98/100\n",
      " - 0s - loss: 0.0060 - mse: 0.0060 - val_loss: 0.0151 - val_mse: 0.0151\n",
      "Epoch 99/100\n",
      " - 0s - loss: 0.0052 - mse: 0.0052 - val_loss: 0.0145 - val_mse: 0.0145\n",
      "Epoch 100/100\n",
      " - 0s - loss: 0.0061 - mse: 0.0061 - val_loss: 0.0152 - val_mse: 0.0152\n",
      "real [[3725.46]]\n",
      "Test RMSE: 251.118\n",
      "Diff [[-251.11754379]]\n",
      "% Diff [[-6.74057818]] %\n",
      "Predictions [[3976.57754379]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "layers = 1\n",
    "neurons = [25, 25]\n",
    "\n",
    "columns = columns_12\n",
    "num_features = len(columns)\n",
    "\n",
    "crypto = crypto\n",
    "execute_test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los resultados son incluso mejores para algunos sets que con la configuración inicial.\n",
    "\n",
    "Iremos subiendo capas y neuronas hasta que perdamos eficiencia en nuestros resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading... ETH\n",
      "Extracting columns columns for ETH\n",
      "Proccessing and arranging columns for LSTM model\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>close_19</th>\n",
       "      <th>close_diff_20_19</th>\n",
       "      <th>close_18</th>\n",
       "      <th>close_diff_20_18</th>\n",
       "      <th>close_17</th>\n",
       "      <th>close_diff_20_17</th>\n",
       "      <th>close_16</th>\n",
       "      <th>close_diff_20_16</th>\n",
       "      <th>close_15</th>\n",
       "      <th>close_diff_20_15</th>\n",
       "      <th>...</th>\n",
       "      <th>close_diff_20_4</th>\n",
       "      <th>close_3</th>\n",
       "      <th>close_diff_20_3</th>\n",
       "      <th>close_2</th>\n",
       "      <th>close_diff_20_2</th>\n",
       "      <th>close_1</th>\n",
       "      <th>close_diff_20_1</th>\n",
       "      <th>close_0</th>\n",
       "      <th>close_diff_20_0</th>\n",
       "      <th>close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>1123.09</td>\n",
       "      <td>339.09</td>\n",
       "      <td>1133.18</td>\n",
       "      <td>335.18</td>\n",
       "      <td>1291.00</td>\n",
       "      <td>500.79</td>\n",
       "      <td>1247.00</td>\n",
       "      <td>464.59</td>\n",
       "      <td>1138.93</td>\n",
       "      <td>502.96</td>\n",
       "      <td>...</td>\n",
       "      <td>137.72</td>\n",
       "      <td>980.00</td>\n",
       "      <td>45.97</td>\n",
       "      <td>1061.00</td>\n",
       "      <td>121.00</td>\n",
       "      <td>1056.52</td>\n",
       "      <td>97.22</td>\n",
       "      <td>1051.03</td>\n",
       "      <td>46.92</td>\n",
       "      <td>924.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>1133.18</td>\n",
       "      <td>335.18</td>\n",
       "      <td>1291.00</td>\n",
       "      <td>500.79</td>\n",
       "      <td>1247.00</td>\n",
       "      <td>464.59</td>\n",
       "      <td>1138.93</td>\n",
       "      <td>502.96</td>\n",
       "      <td>1253.87</td>\n",
       "      <td>613.53</td>\n",
       "      <td>...</td>\n",
       "      <td>45.97</td>\n",
       "      <td>1061.00</td>\n",
       "      <td>121.00</td>\n",
       "      <td>1056.52</td>\n",
       "      <td>97.22</td>\n",
       "      <td>1051.03</td>\n",
       "      <td>46.92</td>\n",
       "      <td>1118.99</td>\n",
       "      <td>-4.10</td>\n",
       "      <td>938.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>1291.00</td>\n",
       "      <td>500.79</td>\n",
       "      <td>1247.00</td>\n",
       "      <td>464.59</td>\n",
       "      <td>1138.93</td>\n",
       "      <td>502.96</td>\n",
       "      <td>1253.87</td>\n",
       "      <td>613.53</td>\n",
       "      <td>1388.02</td>\n",
       "      <td>730.02</td>\n",
       "      <td>...</td>\n",
       "      <td>121.00</td>\n",
       "      <td>1056.52</td>\n",
       "      <td>97.22</td>\n",
       "      <td>1051.03</td>\n",
       "      <td>46.92</td>\n",
       "      <td>1118.99</td>\n",
       "      <td>-4.10</td>\n",
       "      <td>1251.96</td>\n",
       "      <td>118.78</td>\n",
       "      <td>969.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>1247.00</td>\n",
       "      <td>464.59</td>\n",
       "      <td>1138.93</td>\n",
       "      <td>502.96</td>\n",
       "      <td>1253.87</td>\n",
       "      <td>613.53</td>\n",
       "      <td>1388.02</td>\n",
       "      <td>730.02</td>\n",
       "      <td>1347.00</td>\n",
       "      <td>632.05</td>\n",
       "      <td>...</td>\n",
       "      <td>97.22</td>\n",
       "      <td>1051.03</td>\n",
       "      <td>46.92</td>\n",
       "      <td>1118.99</td>\n",
       "      <td>-4.10</td>\n",
       "      <td>1251.96</td>\n",
       "      <td>118.78</td>\n",
       "      <td>1177.01</td>\n",
       "      <td>-113.99</td>\n",
       "      <td>911.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>1138.93</td>\n",
       "      <td>502.96</td>\n",
       "      <td>1253.87</td>\n",
       "      <td>613.53</td>\n",
       "      <td>1388.02</td>\n",
       "      <td>730.02</td>\n",
       "      <td>1347.00</td>\n",
       "      <td>632.05</td>\n",
       "      <td>1271.00</td>\n",
       "      <td>521.00</td>\n",
       "      <td>...</td>\n",
       "      <td>46.92</td>\n",
       "      <td>1118.99</td>\n",
       "      <td>-4.10</td>\n",
       "      <td>1251.96</td>\n",
       "      <td>118.78</td>\n",
       "      <td>1177.01</td>\n",
       "      <td>-113.99</td>\n",
       "      <td>1085.50</td>\n",
       "      <td>-161.50</td>\n",
       "      <td>938.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1573</th>\n",
       "      <td>4287.80</td>\n",
       "      <td>1.78</td>\n",
       "      <td>3996.90</td>\n",
       "      <td>-421.99</td>\n",
       "      <td>4294.76</td>\n",
       "      <td>-27.92</td>\n",
       "      <td>4412.17</td>\n",
       "      <td>124.96</td>\n",
       "      <td>4258.31</td>\n",
       "      <td>-61.12</td>\n",
       "      <td>...</td>\n",
       "      <td>-154.25</td>\n",
       "      <td>4215.73</td>\n",
       "      <td>-428.55</td>\n",
       "      <td>4117.25</td>\n",
       "      <td>-509.25</td>\n",
       "      <td>4196.44</td>\n",
       "      <td>-367.34</td>\n",
       "      <td>4347.59</td>\n",
       "      <td>137.83</td>\n",
       "      <td>4063.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1574</th>\n",
       "      <td>3996.90</td>\n",
       "      <td>-421.99</td>\n",
       "      <td>4294.76</td>\n",
       "      <td>-27.92</td>\n",
       "      <td>4412.17</td>\n",
       "      <td>124.96</td>\n",
       "      <td>4258.31</td>\n",
       "      <td>-61.12</td>\n",
       "      <td>4085.97</td>\n",
       "      <td>-503.92</td>\n",
       "      <td>...</td>\n",
       "      <td>-428.55</td>\n",
       "      <td>4117.25</td>\n",
       "      <td>-509.25</td>\n",
       "      <td>4196.44</td>\n",
       "      <td>-367.34</td>\n",
       "      <td>4347.59</td>\n",
       "      <td>137.83</td>\n",
       "      <td>4306.40</td>\n",
       "      <td>18.60</td>\n",
       "      <td>4037.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1575</th>\n",
       "      <td>4294.76</td>\n",
       "      <td>-27.92</td>\n",
       "      <td>4412.17</td>\n",
       "      <td>124.96</td>\n",
       "      <td>4258.31</td>\n",
       "      <td>-61.12</td>\n",
       "      <td>4085.97</td>\n",
       "      <td>-503.92</td>\n",
       "      <td>4339.44</td>\n",
       "      <td>-263.91</td>\n",
       "      <td>...</td>\n",
       "      <td>-509.25</td>\n",
       "      <td>4196.44</td>\n",
       "      <td>-367.34</td>\n",
       "      <td>4347.59</td>\n",
       "      <td>137.83</td>\n",
       "      <td>4306.40</td>\n",
       "      <td>18.60</td>\n",
       "      <td>4436.91</td>\n",
       "      <td>440.01</td>\n",
       "      <td>3792.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1576</th>\n",
       "      <td>4412.17</td>\n",
       "      <td>124.96</td>\n",
       "      <td>4258.31</td>\n",
       "      <td>-61.12</td>\n",
       "      <td>4085.97</td>\n",
       "      <td>-503.92</td>\n",
       "      <td>4339.44</td>\n",
       "      <td>-263.91</td>\n",
       "      <td>4269.36</td>\n",
       "      <td>-262.96</td>\n",
       "      <td>...</td>\n",
       "      <td>-367.34</td>\n",
       "      <td>4347.59</td>\n",
       "      <td>137.83</td>\n",
       "      <td>4306.40</td>\n",
       "      <td>18.60</td>\n",
       "      <td>4436.91</td>\n",
       "      <td>440.01</td>\n",
       "      <td>4105.64</td>\n",
       "      <td>-189.12</td>\n",
       "      <td>3630.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1577</th>\n",
       "      <td>4258.31</td>\n",
       "      <td>-61.12</td>\n",
       "      <td>4085.97</td>\n",
       "      <td>-503.92</td>\n",
       "      <td>4339.44</td>\n",
       "      <td>-263.91</td>\n",
       "      <td>4269.36</td>\n",
       "      <td>-262.96</td>\n",
       "      <td>4524.85</td>\n",
       "      <td>50.61</td>\n",
       "      <td>...</td>\n",
       "      <td>137.83</td>\n",
       "      <td>4306.40</td>\n",
       "      <td>18.60</td>\n",
       "      <td>4436.91</td>\n",
       "      <td>440.01</td>\n",
       "      <td>4105.64</td>\n",
       "      <td>-189.12</td>\n",
       "      <td>3897.94</td>\n",
       "      <td>-514.23</td>\n",
       "      <td>3709.27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1415 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      close_19  close_diff_20_19  close_18  close_diff_20_18  close_17  \\\n",
       "163    1123.09            339.09   1133.18            335.18   1291.00   \n",
       "164    1133.18            335.18   1291.00            500.79   1247.00   \n",
       "165    1291.00            500.79   1247.00            464.59   1138.93   \n",
       "166    1247.00            464.59   1138.93            502.96   1253.87   \n",
       "167    1138.93            502.96   1253.87            613.53   1388.02   \n",
       "...        ...               ...       ...               ...       ...   \n",
       "1573   4287.80              1.78   3996.90           -421.99   4294.76   \n",
       "1574   3996.90           -421.99   4294.76            -27.92   4412.17   \n",
       "1575   4294.76            -27.92   4412.17            124.96   4258.31   \n",
       "1576   4412.17            124.96   4258.31            -61.12   4085.97   \n",
       "1577   4258.31            -61.12   4085.97           -503.92   4339.44   \n",
       "\n",
       "      close_diff_20_17  close_16  close_diff_20_16  close_15  \\\n",
       "163             500.79   1247.00            464.59   1138.93   \n",
       "164             464.59   1138.93            502.96   1253.87   \n",
       "165             502.96   1253.87            613.53   1388.02   \n",
       "166             613.53   1388.02            730.02   1347.00   \n",
       "167             730.02   1347.00            632.05   1271.00   \n",
       "...                ...       ...               ...       ...   \n",
       "1573            -27.92   4412.17            124.96   4258.31   \n",
       "1574            124.96   4258.31            -61.12   4085.97   \n",
       "1575            -61.12   4085.97           -503.92   4339.44   \n",
       "1576           -503.92   4339.44           -263.91   4269.36   \n",
       "1577           -263.91   4269.36           -262.96   4524.85   \n",
       "\n",
       "      close_diff_20_15  ...  close_diff_20_4  close_3  close_diff_20_3  \\\n",
       "163             502.96  ...           137.72   980.00            45.97   \n",
       "164             613.53  ...            45.97  1061.00           121.00   \n",
       "165             730.02  ...           121.00  1056.52            97.22   \n",
       "166             632.05  ...            97.22  1051.03            46.92   \n",
       "167             521.00  ...            46.92  1118.99            -4.10   \n",
       "...                ...  ...              ...      ...              ...   \n",
       "1573            -61.12  ...          -154.25  4215.73          -428.55   \n",
       "1574           -503.92  ...          -428.55  4117.25          -509.25   \n",
       "1575           -263.91  ...          -509.25  4196.44          -367.34   \n",
       "1576           -262.96  ...          -367.34  4347.59           137.83   \n",
       "1577             50.61  ...           137.83  4306.40            18.60   \n",
       "\n",
       "      close_2  close_diff_20_2  close_1  close_diff_20_1  close_0  \\\n",
       "163   1061.00           121.00  1056.52            97.22  1051.03   \n",
       "164   1056.52            97.22  1051.03            46.92  1118.99   \n",
       "165   1051.03            46.92  1118.99            -4.10  1251.96   \n",
       "166   1118.99            -4.10  1251.96           118.78  1177.01   \n",
       "167   1251.96           118.78  1177.01          -113.99  1085.50   \n",
       "...       ...              ...      ...              ...      ...   \n",
       "1573  4117.25          -509.25  4196.44          -367.34  4347.59   \n",
       "1574  4196.44          -367.34  4347.59           137.83  4306.40   \n",
       "1575  4347.59           137.83  4306.40            18.60  4436.91   \n",
       "1576  4306.40            18.60  4436.91           440.01  4105.64   \n",
       "1577  4436.91           440.01  4105.64          -189.12  3897.94   \n",
       "\n",
       "      close_diff_20_0    close  \n",
       "163             46.92   924.55  \n",
       "164             -4.10   938.67  \n",
       "165            118.78   969.99  \n",
       "166           -113.99   911.00  \n",
       "167           -161.50   938.11  \n",
       "...               ...      ...  \n",
       "1573           137.83  4063.56  \n",
       "1574            18.60  4037.23  \n",
       "1575           440.01  3792.75  \n",
       "1576          -189.12  3630.19  \n",
       "1577          -514.23  3709.27  \n",
       "\n",
       "[1415 rows x 41 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>close_19</th>\n",
       "      <th>close_diff_20_19</th>\n",
       "      <th>close_18</th>\n",
       "      <th>close_diff_20_18</th>\n",
       "      <th>close_17</th>\n",
       "      <th>close_diff_20_17</th>\n",
       "      <th>close_16</th>\n",
       "      <th>close_diff_20_16</th>\n",
       "      <th>close_15</th>\n",
       "      <th>close_diff_20_15</th>\n",
       "      <th>...</th>\n",
       "      <th>close_diff_20_4</th>\n",
       "      <th>close_3</th>\n",
       "      <th>close_diff_20_3</th>\n",
       "      <th>close_2</th>\n",
       "      <th>close_diff_20_2</th>\n",
       "      <th>close_1</th>\n",
       "      <th>close_diff_20_1</th>\n",
       "      <th>close_0</th>\n",
       "      <th>close_diff_20_0</th>\n",
       "      <th>close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1578</th>\n",
       "      <td>4085.97</td>\n",
       "      <td>-503.92</td>\n",
       "      <td>4339.44</td>\n",
       "      <td>-263.91</td>\n",
       "      <td>4269.36</td>\n",
       "      <td>-262.96</td>\n",
       "      <td>4524.85</td>\n",
       "      <td>50.61</td>\n",
       "      <td>4041.2</td>\n",
       "      <td>-476.8</td>\n",
       "      <td>...</td>\n",
       "      <td>18.6</td>\n",
       "      <td>4436.91</td>\n",
       "      <td>440.01</td>\n",
       "      <td>4105.64</td>\n",
       "      <td>-189.12</td>\n",
       "      <td>3897.94</td>\n",
       "      <td>-514.23</td>\n",
       "      <td>4089.37</td>\n",
       "      <td>-168.94</td>\n",
       "      <td>3725.46</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      close_19  close_diff_20_19  close_18  close_diff_20_18  close_17  \\\n",
       "1578   4085.97           -503.92   4339.44           -263.91   4269.36   \n",
       "\n",
       "      close_diff_20_17  close_16  close_diff_20_16  close_15  \\\n",
       "1578           -262.96   4524.85             50.61    4041.2   \n",
       "\n",
       "      close_diff_20_15  ...  close_diff_20_4  close_3  close_diff_20_3  \\\n",
       "1578            -476.8  ...             18.6  4436.91           440.01   \n",
       "\n",
       "      close_2  close_diff_20_2  close_1  close_diff_20_1  close_0  \\\n",
       "1578  4105.64          -189.12  3897.94          -514.23  4089.37   \n",
       "\n",
       "      close_diff_20_0    close  \n",
       "1578          -168.94  3725.46  \n",
       "\n",
       "[1 rows x 41 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (1415, 1, 40) (1415, 1)\n",
      "Model: \"sequential_25\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_109 (LSTM)              (None, 1, 100)            56400     \n",
      "_________________________________________________________________\n",
      "lstm_110 (LSTM)              (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_85 (Dropout)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 136,901\n",
      "Trainable params: 136,901\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Y shape (1415, 1)\n",
      "Train on 1415 samples, validate on 283 samples\n",
      "Epoch 1/100\n",
      " - 5s - loss: 0.0574 - mse: 0.0574 - val_loss: 0.1564 - val_mse: 0.1564\n",
      "Epoch 2/100\n",
      " - 0s - loss: 0.0204 - mse: 0.0204 - val_loss: 0.0210 - val_mse: 0.0210\n",
      "Epoch 3/100\n",
      " - 0s - loss: 0.0112 - mse: 0.0112 - val_loss: 0.0297 - val_mse: 0.0297\n",
      "Epoch 4/100\n",
      " - 0s - loss: 0.0382 - mse: 0.0382 - val_loss: 0.0770 - val_mse: 0.0770\n",
      "Epoch 5/100\n",
      " - 0s - loss: 0.0137 - mse: 0.0137 - val_loss: 0.0209 - val_mse: 0.0209\n",
      "Epoch 6/100\n",
      " - 0s - loss: 0.0292 - mse: 0.0292 - val_loss: 0.0661 - val_mse: 0.0661\n",
      "Epoch 7/100\n",
      " - 0s - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0192 - val_mse: 0.0192\n",
      "Epoch 8/100\n",
      " - 0s - loss: 0.0181 - mse: 0.0181 - val_loss: 0.0430 - val_mse: 0.0430\n",
      "Epoch 9/100\n",
      " - 0s - loss: 0.0077 - mse: 0.0077 - val_loss: 0.0181 - val_mse: 0.0181\n",
      "Epoch 10/100\n",
      " - 0s - loss: 0.0124 - mse: 0.0124 - val_loss: 0.0274 - val_mse: 0.0274\n",
      "Epoch 11/100\n",
      " - 0s - loss: 0.0073 - mse: 0.0073 - val_loss: 0.0178 - val_mse: 0.0178\n",
      "Epoch 12/100\n",
      " - 0s - loss: 0.0121 - mse: 0.0121 - val_loss: 0.0274 - val_mse: 0.0274\n",
      "Epoch 13/100\n",
      " - 0s - loss: 0.0068 - mse: 0.0068 - val_loss: 0.0175 - val_mse: 0.0175\n",
      "Epoch 14/100\n",
      " - 0s - loss: 0.0104 - mse: 0.0104 - val_loss: 0.0236 - val_mse: 0.0236\n",
      "Epoch 15/100\n",
      " - 0s - loss: 0.0059 - mse: 0.0059 - val_loss: 0.0173 - val_mse: 0.0173\n",
      "Epoch 16/100\n",
      " - 0s - loss: 0.0079 - mse: 0.0079 - val_loss: 0.0194 - val_mse: 0.0194\n",
      "Epoch 17/100\n",
      " - 0s - loss: 0.0065 - mse: 0.0065 - val_loss: 0.0170 - val_mse: 0.0170\n",
      "Epoch 18/100\n",
      " - 0s - loss: 0.0093 - mse: 0.0093 - val_loss: 0.0215 - val_mse: 0.0215\n",
      "Epoch 19/100\n",
      " - 0s - loss: 0.0068 - mse: 0.0068 - val_loss: 0.0169 - val_mse: 0.0169\n",
      "Epoch 20/100\n",
      " - 1s - loss: 0.0098 - mse: 0.0098 - val_loss: 0.0219 - val_mse: 0.0219\n",
      "Epoch 21/100\n",
      " - 1s - loss: 0.0076 - mse: 0.0076 - val_loss: 0.0168 - val_mse: 0.0168\n",
      "Epoch 22/100\n",
      " - 1s - loss: 0.0118 - mse: 0.0118 - val_loss: 0.0251 - val_mse: 0.0251\n",
      "Epoch 23/100\n",
      " - 1s - loss: 0.0080 - mse: 0.0080 - val_loss: 0.0171 - val_mse: 0.0171\n",
      "Epoch 24/100\n",
      " - 1s - loss: 0.0111 - mse: 0.0111 - val_loss: 0.0251 - val_mse: 0.0251\n",
      "Epoch 25/100\n",
      " - 1s - loss: 0.0073 - mse: 0.0073 - val_loss: 0.0168 - val_mse: 0.0168\n",
      "Epoch 26/100\n",
      " - 1s - loss: 0.0105 - mse: 0.0105 - val_loss: 0.0241 - val_mse: 0.0241\n",
      "Epoch 27/100\n",
      " - 1s - loss: 0.0072 - mse: 0.0072 - val_loss: 0.0169 - val_mse: 0.0169\n",
      "Epoch 28/100\n",
      " - 0s - loss: 0.0094 - mse: 0.0094 - val_loss: 0.0216 - val_mse: 0.0216\n",
      "Epoch 29/100\n",
      " - 1s - loss: 0.0063 - mse: 0.0063 - val_loss: 0.0170 - val_mse: 0.0170\n",
      "Epoch 30/100\n",
      " - 1s - loss: 0.0087 - mse: 0.0087 - val_loss: 0.0203 - val_mse: 0.0203\n",
      "Epoch 31/100\n",
      " - 0s - loss: 0.0068 - mse: 0.0068 - val_loss: 0.0167 - val_mse: 0.0167\n",
      "Epoch 32/100\n",
      " - 0s - loss: 0.0093 - mse: 0.0093 - val_loss: 0.0211 - val_mse: 0.0211\n",
      "Epoch 33/100\n",
      " - 0s - loss: 0.0068 - mse: 0.0068 - val_loss: 0.0167 - val_mse: 0.0167\n",
      "Epoch 34/100\n",
      " - 0s - loss: 0.0099 - mse: 0.0099 - val_loss: 0.0223 - val_mse: 0.0223\n",
      "Epoch 35/100\n",
      " - 1s - loss: 0.0068 - mse: 0.0068 - val_loss: 0.0168 - val_mse: 0.0168\n",
      "Epoch 36/100\n",
      " - 0s - loss: 0.0089 - mse: 0.0089 - val_loss: 0.0212 - val_mse: 0.0212\n",
      "Epoch 37/100\n",
      " - 0s - loss: 0.0064 - mse: 0.0064 - val_loss: 0.0166 - val_mse: 0.0166\n",
      "Epoch 38/100\n",
      " - 0s - loss: 0.0081 - mse: 0.0081 - val_loss: 0.0197 - val_mse: 0.0197\n",
      "Epoch 39/100\n",
      " - 0s - loss: 0.0056 - mse: 0.0056 - val_loss: 0.0163 - val_mse: 0.0163\n",
      "Epoch 40/100\n",
      " - 0s - loss: 0.0074 - mse: 0.0074 - val_loss: 0.0183 - val_mse: 0.0183\n",
      "Epoch 41/100\n",
      " - 0s - loss: 0.0062 - mse: 0.0062 - val_loss: 0.0162 - val_mse: 0.0162\n",
      "Epoch 42/100\n",
      " - 0s - loss: 0.0073 - mse: 0.0073 - val_loss: 0.0181 - val_mse: 0.0181\n",
      "Epoch 43/100\n",
      " - 0s - loss: 0.0057 - mse: 0.0057 - val_loss: 0.0162 - val_mse: 0.0162\n",
      "Epoch 44/100\n",
      " - 0s - loss: 0.0072 - mse: 0.0072 - val_loss: 0.0182 - val_mse: 0.0182\n",
      "Epoch 45/100\n",
      " - 0s - loss: 0.0058 - mse: 0.0058 - val_loss: 0.0161 - val_mse: 0.0161\n",
      "Epoch 46/100\n",
      " - 0s - loss: 0.0068 - mse: 0.0068 - val_loss: 0.0169 - val_mse: 0.0169\n",
      "Epoch 47/100\n",
      " - 0s - loss: 0.0054 - mse: 0.0054 - val_loss: 0.0159 - val_mse: 0.0159\n",
      "Epoch 48/100\n",
      " - 0s - loss: 0.0074 - mse: 0.0074 - val_loss: 0.0177 - val_mse: 0.0177\n",
      "Epoch 49/100\n",
      " - 0s - loss: 0.0062 - mse: 0.0062 - val_loss: 0.0161 - val_mse: 0.0161\n",
      "Epoch 50/100\n",
      " - 0s - loss: 0.0087 - mse: 0.0087 - val_loss: 0.0192 - val_mse: 0.0192\n",
      "Epoch 51/100\n",
      " - 0s - loss: 0.0069 - mse: 0.0069 - val_loss: 0.0161 - val_mse: 0.0161\n",
      "Epoch 52/100\n",
      " - 0s - loss: 0.0103 - mse: 0.0103 - val_loss: 0.0220 - val_mse: 0.0220\n",
      "Epoch 53/100\n",
      " - 0s - loss: 0.0068 - mse: 0.0068 - val_loss: 0.0162 - val_mse: 0.0162\n",
      "Epoch 54/100\n",
      " - 0s - loss: 0.0091 - mse: 0.0091 - val_loss: 0.0207 - val_mse: 0.0207\n",
      "Epoch 55/100\n",
      " - 0s - loss: 0.0068 - mse: 0.0068 - val_loss: 0.0163 - val_mse: 0.0163\n",
      "Epoch 56/100\n",
      " - 0s - loss: 0.0088 - mse: 0.0088 - val_loss: 0.0205 - val_mse: 0.0205\n",
      "Epoch 57/100\n",
      " - 0s - loss: 0.0062 - mse: 0.0062 - val_loss: 0.0162 - val_mse: 0.0162\n",
      "Epoch 58/100\n",
      " - 1s - loss: 0.0076 - mse: 0.0076 - val_loss: 0.0184 - val_mse: 0.0184\n",
      "Epoch 59/100\n",
      " - 0s - loss: 0.0059 - mse: 0.0059 - val_loss: 0.0160 - val_mse: 0.0160\n",
      "Epoch 60/100\n",
      " - 0s - loss: 0.0078 - mse: 0.0078 - val_loss: 0.0187 - val_mse: 0.0187\n",
      "Epoch 61/100\n",
      " - 0s - loss: 0.0058 - mse: 0.0058 - val_loss: 0.0159 - val_mse: 0.0159\n",
      "Epoch 62/100\n",
      " - 0s - loss: 0.0069 - mse: 0.0069 - val_loss: 0.0170 - val_mse: 0.0170\n",
      "Epoch 63/100\n",
      " - 0s - loss: 0.0056 - mse: 0.0056 - val_loss: 0.0159 - val_mse: 0.0159\n",
      "Epoch 64/100\n",
      " - 1s - loss: 0.0063 - mse: 0.0063 - val_loss: 0.0166 - val_mse: 0.0166\n",
      "Epoch 65/100\n",
      " - 1s - loss: 0.0055 - mse: 0.0055 - val_loss: 0.0157 - val_mse: 0.0157\n",
      "Epoch 66/100\n",
      " - 0s - loss: 0.0068 - mse: 0.0068 - val_loss: 0.0172 - val_mse: 0.0172\n",
      "Epoch 67/100\n",
      " - 0s - loss: 0.0057 - mse: 0.0057 - val_loss: 0.0157 - val_mse: 0.0157\n",
      "Epoch 68/100\n",
      " - 0s - loss: 0.0073 - mse: 0.0073 - val_loss: 0.0178 - val_mse: 0.0178\n",
      "Epoch 69/100\n",
      " - 0s - loss: 0.0059 - mse: 0.0059 - val_loss: 0.0159 - val_mse: 0.0159\n",
      "Epoch 70/100\n",
      " - 1s - loss: 0.0068 - mse: 0.0068 - val_loss: 0.0170 - val_mse: 0.0170\n",
      "Epoch 71/100\n",
      " - 0s - loss: 0.0056 - mse: 0.0056 - val_loss: 0.0156 - val_mse: 0.0156\n",
      "Epoch 72/100\n",
      " - 0s - loss: 0.0061 - mse: 0.0061 - val_loss: 0.0162 - val_mse: 0.0162\n",
      "real [[3725.46]]\n",
      "Test RMSE: 331.294\n",
      "Diff [[-331.29393355]]\n",
      "% Diff [[-8.89269872]] %\n",
      "Predictions [[4056.75393355]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "layers = 1\n",
    "neurons = [100, 100]\n",
    "\n",
    "columns = columns_12\n",
    "num_features = len(columns)\n",
    "\n",
    "crypto = crypto\n",
    "execute_test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Añadir neuronas no ha mejorado resultados en todos los casos pero si en unos pocos en el test, consiguiendo buenos datos en el set de validación pero no mejores que antes. Probaremos añadiendo capas y dejando las neuronas mas bajas. Dejaremos la capa base con mas neuronas.\n",
    "\n",
    "El error en BTC puede deberse a un estancamiento por un lr muy alto. Quizás sin callbacks o con lr mas bajo hubieramos alcanzado un minimo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading... ETH\n",
      "Extracting columns columns for ETH\n",
      "Proccessing and arranging columns for LSTM model\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>close_19</th>\n",
       "      <th>close_diff_20_19</th>\n",
       "      <th>close_18</th>\n",
       "      <th>close_diff_20_18</th>\n",
       "      <th>close_17</th>\n",
       "      <th>close_diff_20_17</th>\n",
       "      <th>close_16</th>\n",
       "      <th>close_diff_20_16</th>\n",
       "      <th>close_15</th>\n",
       "      <th>close_diff_20_15</th>\n",
       "      <th>...</th>\n",
       "      <th>close_diff_20_4</th>\n",
       "      <th>close_3</th>\n",
       "      <th>close_diff_20_3</th>\n",
       "      <th>close_2</th>\n",
       "      <th>close_diff_20_2</th>\n",
       "      <th>close_1</th>\n",
       "      <th>close_diff_20_1</th>\n",
       "      <th>close_0</th>\n",
       "      <th>close_diff_20_0</th>\n",
       "      <th>close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>1123.09</td>\n",
       "      <td>339.09</td>\n",
       "      <td>1133.18</td>\n",
       "      <td>335.18</td>\n",
       "      <td>1291.00</td>\n",
       "      <td>500.79</td>\n",
       "      <td>1247.00</td>\n",
       "      <td>464.59</td>\n",
       "      <td>1138.93</td>\n",
       "      <td>502.96</td>\n",
       "      <td>...</td>\n",
       "      <td>137.72</td>\n",
       "      <td>980.00</td>\n",
       "      <td>45.97</td>\n",
       "      <td>1061.00</td>\n",
       "      <td>121.00</td>\n",
       "      <td>1056.52</td>\n",
       "      <td>97.22</td>\n",
       "      <td>1051.03</td>\n",
       "      <td>46.92</td>\n",
       "      <td>924.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>1133.18</td>\n",
       "      <td>335.18</td>\n",
       "      <td>1291.00</td>\n",
       "      <td>500.79</td>\n",
       "      <td>1247.00</td>\n",
       "      <td>464.59</td>\n",
       "      <td>1138.93</td>\n",
       "      <td>502.96</td>\n",
       "      <td>1253.87</td>\n",
       "      <td>613.53</td>\n",
       "      <td>...</td>\n",
       "      <td>45.97</td>\n",
       "      <td>1061.00</td>\n",
       "      <td>121.00</td>\n",
       "      <td>1056.52</td>\n",
       "      <td>97.22</td>\n",
       "      <td>1051.03</td>\n",
       "      <td>46.92</td>\n",
       "      <td>1118.99</td>\n",
       "      <td>-4.10</td>\n",
       "      <td>938.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>1291.00</td>\n",
       "      <td>500.79</td>\n",
       "      <td>1247.00</td>\n",
       "      <td>464.59</td>\n",
       "      <td>1138.93</td>\n",
       "      <td>502.96</td>\n",
       "      <td>1253.87</td>\n",
       "      <td>613.53</td>\n",
       "      <td>1388.02</td>\n",
       "      <td>730.02</td>\n",
       "      <td>...</td>\n",
       "      <td>121.00</td>\n",
       "      <td>1056.52</td>\n",
       "      <td>97.22</td>\n",
       "      <td>1051.03</td>\n",
       "      <td>46.92</td>\n",
       "      <td>1118.99</td>\n",
       "      <td>-4.10</td>\n",
       "      <td>1251.96</td>\n",
       "      <td>118.78</td>\n",
       "      <td>969.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>1247.00</td>\n",
       "      <td>464.59</td>\n",
       "      <td>1138.93</td>\n",
       "      <td>502.96</td>\n",
       "      <td>1253.87</td>\n",
       "      <td>613.53</td>\n",
       "      <td>1388.02</td>\n",
       "      <td>730.02</td>\n",
       "      <td>1347.00</td>\n",
       "      <td>632.05</td>\n",
       "      <td>...</td>\n",
       "      <td>97.22</td>\n",
       "      <td>1051.03</td>\n",
       "      <td>46.92</td>\n",
       "      <td>1118.99</td>\n",
       "      <td>-4.10</td>\n",
       "      <td>1251.96</td>\n",
       "      <td>118.78</td>\n",
       "      <td>1177.01</td>\n",
       "      <td>-113.99</td>\n",
       "      <td>911.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>1138.93</td>\n",
       "      <td>502.96</td>\n",
       "      <td>1253.87</td>\n",
       "      <td>613.53</td>\n",
       "      <td>1388.02</td>\n",
       "      <td>730.02</td>\n",
       "      <td>1347.00</td>\n",
       "      <td>632.05</td>\n",
       "      <td>1271.00</td>\n",
       "      <td>521.00</td>\n",
       "      <td>...</td>\n",
       "      <td>46.92</td>\n",
       "      <td>1118.99</td>\n",
       "      <td>-4.10</td>\n",
       "      <td>1251.96</td>\n",
       "      <td>118.78</td>\n",
       "      <td>1177.01</td>\n",
       "      <td>-113.99</td>\n",
       "      <td>1085.50</td>\n",
       "      <td>-161.50</td>\n",
       "      <td>938.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1573</th>\n",
       "      <td>4287.80</td>\n",
       "      <td>1.78</td>\n",
       "      <td>3996.90</td>\n",
       "      <td>-421.99</td>\n",
       "      <td>4294.76</td>\n",
       "      <td>-27.92</td>\n",
       "      <td>4412.17</td>\n",
       "      <td>124.96</td>\n",
       "      <td>4258.31</td>\n",
       "      <td>-61.12</td>\n",
       "      <td>...</td>\n",
       "      <td>-154.25</td>\n",
       "      <td>4215.73</td>\n",
       "      <td>-428.55</td>\n",
       "      <td>4117.25</td>\n",
       "      <td>-509.25</td>\n",
       "      <td>4196.44</td>\n",
       "      <td>-367.34</td>\n",
       "      <td>4347.59</td>\n",
       "      <td>137.83</td>\n",
       "      <td>4063.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1574</th>\n",
       "      <td>3996.90</td>\n",
       "      <td>-421.99</td>\n",
       "      <td>4294.76</td>\n",
       "      <td>-27.92</td>\n",
       "      <td>4412.17</td>\n",
       "      <td>124.96</td>\n",
       "      <td>4258.31</td>\n",
       "      <td>-61.12</td>\n",
       "      <td>4085.97</td>\n",
       "      <td>-503.92</td>\n",
       "      <td>...</td>\n",
       "      <td>-428.55</td>\n",
       "      <td>4117.25</td>\n",
       "      <td>-509.25</td>\n",
       "      <td>4196.44</td>\n",
       "      <td>-367.34</td>\n",
       "      <td>4347.59</td>\n",
       "      <td>137.83</td>\n",
       "      <td>4306.40</td>\n",
       "      <td>18.60</td>\n",
       "      <td>4037.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1575</th>\n",
       "      <td>4294.76</td>\n",
       "      <td>-27.92</td>\n",
       "      <td>4412.17</td>\n",
       "      <td>124.96</td>\n",
       "      <td>4258.31</td>\n",
       "      <td>-61.12</td>\n",
       "      <td>4085.97</td>\n",
       "      <td>-503.92</td>\n",
       "      <td>4339.44</td>\n",
       "      <td>-263.91</td>\n",
       "      <td>...</td>\n",
       "      <td>-509.25</td>\n",
       "      <td>4196.44</td>\n",
       "      <td>-367.34</td>\n",
       "      <td>4347.59</td>\n",
       "      <td>137.83</td>\n",
       "      <td>4306.40</td>\n",
       "      <td>18.60</td>\n",
       "      <td>4436.91</td>\n",
       "      <td>440.01</td>\n",
       "      <td>3792.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1576</th>\n",
       "      <td>4412.17</td>\n",
       "      <td>124.96</td>\n",
       "      <td>4258.31</td>\n",
       "      <td>-61.12</td>\n",
       "      <td>4085.97</td>\n",
       "      <td>-503.92</td>\n",
       "      <td>4339.44</td>\n",
       "      <td>-263.91</td>\n",
       "      <td>4269.36</td>\n",
       "      <td>-262.96</td>\n",
       "      <td>...</td>\n",
       "      <td>-367.34</td>\n",
       "      <td>4347.59</td>\n",
       "      <td>137.83</td>\n",
       "      <td>4306.40</td>\n",
       "      <td>18.60</td>\n",
       "      <td>4436.91</td>\n",
       "      <td>440.01</td>\n",
       "      <td>4105.64</td>\n",
       "      <td>-189.12</td>\n",
       "      <td>3630.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1577</th>\n",
       "      <td>4258.31</td>\n",
       "      <td>-61.12</td>\n",
       "      <td>4085.97</td>\n",
       "      <td>-503.92</td>\n",
       "      <td>4339.44</td>\n",
       "      <td>-263.91</td>\n",
       "      <td>4269.36</td>\n",
       "      <td>-262.96</td>\n",
       "      <td>4524.85</td>\n",
       "      <td>50.61</td>\n",
       "      <td>...</td>\n",
       "      <td>137.83</td>\n",
       "      <td>4306.40</td>\n",
       "      <td>18.60</td>\n",
       "      <td>4436.91</td>\n",
       "      <td>440.01</td>\n",
       "      <td>4105.64</td>\n",
       "      <td>-189.12</td>\n",
       "      <td>3897.94</td>\n",
       "      <td>-514.23</td>\n",
       "      <td>3709.27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1415 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      close_19  close_diff_20_19  close_18  close_diff_20_18  close_17  \\\n",
       "163    1123.09            339.09   1133.18            335.18   1291.00   \n",
       "164    1133.18            335.18   1291.00            500.79   1247.00   \n",
       "165    1291.00            500.79   1247.00            464.59   1138.93   \n",
       "166    1247.00            464.59   1138.93            502.96   1253.87   \n",
       "167    1138.93            502.96   1253.87            613.53   1388.02   \n",
       "...        ...               ...       ...               ...       ...   \n",
       "1573   4287.80              1.78   3996.90           -421.99   4294.76   \n",
       "1574   3996.90           -421.99   4294.76            -27.92   4412.17   \n",
       "1575   4294.76            -27.92   4412.17            124.96   4258.31   \n",
       "1576   4412.17            124.96   4258.31            -61.12   4085.97   \n",
       "1577   4258.31            -61.12   4085.97           -503.92   4339.44   \n",
       "\n",
       "      close_diff_20_17  close_16  close_diff_20_16  close_15  \\\n",
       "163             500.79   1247.00            464.59   1138.93   \n",
       "164             464.59   1138.93            502.96   1253.87   \n",
       "165             502.96   1253.87            613.53   1388.02   \n",
       "166             613.53   1388.02            730.02   1347.00   \n",
       "167             730.02   1347.00            632.05   1271.00   \n",
       "...                ...       ...               ...       ...   \n",
       "1573            -27.92   4412.17            124.96   4258.31   \n",
       "1574            124.96   4258.31            -61.12   4085.97   \n",
       "1575            -61.12   4085.97           -503.92   4339.44   \n",
       "1576           -503.92   4339.44           -263.91   4269.36   \n",
       "1577           -263.91   4269.36           -262.96   4524.85   \n",
       "\n",
       "      close_diff_20_15  ...  close_diff_20_4  close_3  close_diff_20_3  \\\n",
       "163             502.96  ...           137.72   980.00            45.97   \n",
       "164             613.53  ...            45.97  1061.00           121.00   \n",
       "165             730.02  ...           121.00  1056.52            97.22   \n",
       "166             632.05  ...            97.22  1051.03            46.92   \n",
       "167             521.00  ...            46.92  1118.99            -4.10   \n",
       "...                ...  ...              ...      ...              ...   \n",
       "1573            -61.12  ...          -154.25  4215.73          -428.55   \n",
       "1574           -503.92  ...          -428.55  4117.25          -509.25   \n",
       "1575           -263.91  ...          -509.25  4196.44          -367.34   \n",
       "1576           -262.96  ...          -367.34  4347.59           137.83   \n",
       "1577             50.61  ...           137.83  4306.40            18.60   \n",
       "\n",
       "      close_2  close_diff_20_2  close_1  close_diff_20_1  close_0  \\\n",
       "163   1061.00           121.00  1056.52            97.22  1051.03   \n",
       "164   1056.52            97.22  1051.03            46.92  1118.99   \n",
       "165   1051.03            46.92  1118.99            -4.10  1251.96   \n",
       "166   1118.99            -4.10  1251.96           118.78  1177.01   \n",
       "167   1251.96           118.78  1177.01          -113.99  1085.50   \n",
       "...       ...              ...      ...              ...      ...   \n",
       "1573  4117.25          -509.25  4196.44          -367.34  4347.59   \n",
       "1574  4196.44          -367.34  4347.59           137.83  4306.40   \n",
       "1575  4347.59           137.83  4306.40            18.60  4436.91   \n",
       "1576  4306.40            18.60  4436.91           440.01  4105.64   \n",
       "1577  4436.91           440.01  4105.64          -189.12  3897.94   \n",
       "\n",
       "      close_diff_20_0    close  \n",
       "163             46.92   924.55  \n",
       "164             -4.10   938.67  \n",
       "165            118.78   969.99  \n",
       "166           -113.99   911.00  \n",
       "167           -161.50   938.11  \n",
       "...               ...      ...  \n",
       "1573           137.83  4063.56  \n",
       "1574            18.60  4037.23  \n",
       "1575           440.01  3792.75  \n",
       "1576          -189.12  3630.19  \n",
       "1577          -514.23  3709.27  \n",
       "\n",
       "[1415 rows x 41 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>close_19</th>\n",
       "      <th>close_diff_20_19</th>\n",
       "      <th>close_18</th>\n",
       "      <th>close_diff_20_18</th>\n",
       "      <th>close_17</th>\n",
       "      <th>close_diff_20_17</th>\n",
       "      <th>close_16</th>\n",
       "      <th>close_diff_20_16</th>\n",
       "      <th>close_15</th>\n",
       "      <th>close_diff_20_15</th>\n",
       "      <th>...</th>\n",
       "      <th>close_diff_20_4</th>\n",
       "      <th>close_3</th>\n",
       "      <th>close_diff_20_3</th>\n",
       "      <th>close_2</th>\n",
       "      <th>close_diff_20_2</th>\n",
       "      <th>close_1</th>\n",
       "      <th>close_diff_20_1</th>\n",
       "      <th>close_0</th>\n",
       "      <th>close_diff_20_0</th>\n",
       "      <th>close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1578</th>\n",
       "      <td>4085.97</td>\n",
       "      <td>-503.92</td>\n",
       "      <td>4339.44</td>\n",
       "      <td>-263.91</td>\n",
       "      <td>4269.36</td>\n",
       "      <td>-262.96</td>\n",
       "      <td>4524.85</td>\n",
       "      <td>50.61</td>\n",
       "      <td>4041.2</td>\n",
       "      <td>-476.8</td>\n",
       "      <td>...</td>\n",
       "      <td>18.6</td>\n",
       "      <td>4436.91</td>\n",
       "      <td>440.01</td>\n",
       "      <td>4105.64</td>\n",
       "      <td>-189.12</td>\n",
       "      <td>3897.94</td>\n",
       "      <td>-514.23</td>\n",
       "      <td>4089.37</td>\n",
       "      <td>-168.94</td>\n",
       "      <td>3725.46</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      close_19  close_diff_20_19  close_18  close_diff_20_18  close_17  \\\n",
       "1578   4085.97           -503.92   4339.44           -263.91   4269.36   \n",
       "\n",
       "      close_diff_20_17  close_16  close_diff_20_16  close_15  \\\n",
       "1578           -262.96   4524.85             50.61    4041.2   \n",
       "\n",
       "      close_diff_20_15  ...  close_diff_20_4  close_3  close_diff_20_3  \\\n",
       "1578            -476.8  ...             18.6  4436.91           440.01   \n",
       "\n",
       "      close_2  close_diff_20_2  close_1  close_diff_20_1  close_0  \\\n",
       "1578  4105.64          -189.12  3897.94          -514.23  4089.37   \n",
       "\n",
       "      close_diff_20_0    close  \n",
       "1578          -168.94  3725.46  \n",
       "\n",
       "[1 rows x 41 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (1415, 1, 40) (1415, 1)\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 1, 100)            56400     \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 1, 20)             9680      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1, 20)             0         \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 20)                3280      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 20)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 21        \n",
      "=================================================================\n",
      "Total params: 69,381\n",
      "Trainable params: 69,381\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Y shape (1415, 1)\n",
      "Train on 1415 samples, validate on 283 samples\n",
      "Epoch 1/100\n",
      " - 7s - loss: 0.0778 - mse: 0.0778 - val_loss: 0.3249 - val_mse: 0.3249\n",
      "Epoch 2/100\n",
      " - 0s - loss: 0.0499 - mse: 0.0499 - val_loss: 0.1796 - val_mse: 0.1796\n",
      "Epoch 3/100\n",
      " - 0s - loss: 0.0374 - mse: 0.0374 - val_loss: 0.0813 - val_mse: 0.0813\n",
      "Epoch 4/100\n",
      " - 0s - loss: 0.0207 - mse: 0.0207 - val_loss: 0.0273 - val_mse: 0.0273\n",
      "Epoch 5/100\n",
      " - 0s - loss: 0.0098 - mse: 0.0098 - val_loss: 0.0191 - val_mse: 0.0191\n",
      "Epoch 6/100\n",
      " - 0s - loss: 0.0089 - mse: 0.0089 - val_loss: 0.0182 - val_mse: 0.0182\n",
      "Epoch 7/100\n",
      " - 0s - loss: 0.0088 - mse: 0.0088 - val_loss: 0.0184 - val_mse: 0.0184\n",
      "Epoch 8/100\n",
      " - 0s - loss: 0.0098 - mse: 0.0098 - val_loss: 0.0183 - val_mse: 0.0183\n",
      "Epoch 9/100\n",
      " - 0s - loss: 0.0090 - mse: 0.0090 - val_loss: 0.0177 - val_mse: 0.0177\n",
      "Epoch 10/100\n",
      " - 0s - loss: 0.0089 - mse: 0.0089 - val_loss: 0.0174 - val_mse: 0.0174\n",
      "Epoch 11/100\n",
      " - 0s - loss: 0.0085 - mse: 0.0085 - val_loss: 0.0174 - val_mse: 0.0174\n",
      "Epoch 12/100\n",
      " - 0s - loss: 0.0085 - mse: 0.0085 - val_loss: 0.0171 - val_mse: 0.0171\n",
      "Epoch 13/100\n",
      " - 0s - loss: 0.0093 - mse: 0.0093 - val_loss: 0.0177 - val_mse: 0.0177\n",
      "Epoch 14/100\n",
      " - 0s - loss: 0.0115 - mse: 0.0115 - val_loss: 0.0237 - val_mse: 0.0237\n",
      "Epoch 15/100\n",
      " - 0s - loss: 0.0089 - mse: 0.0089 - val_loss: 0.0169 - val_mse: 0.0169\n",
      "Epoch 16/100\n",
      " - 0s - loss: 0.0084 - mse: 0.0084 - val_loss: 0.0168 - val_mse: 0.0168\n",
      "Epoch 17/100\n",
      " - 0s - loss: 0.0083 - mse: 0.0083 - val_loss: 0.0168 - val_mse: 0.0168\n",
      "Epoch 18/100\n",
      " - 0s - loss: 0.0080 - mse: 0.0080 - val_loss: 0.0174 - val_mse: 0.0174\n",
      "Epoch 19/100\n",
      " - 0s - loss: 0.0085 - mse: 0.0085 - val_loss: 0.0170 - val_mse: 0.0170\n",
      "Epoch 20/100\n",
      " - 0s - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0185 - val_mse: 0.0185\n",
      "Epoch 21/100\n",
      " - 0s - loss: 0.0091 - mse: 0.0091 - val_loss: 0.0167 - val_mse: 0.0167\n",
      "Epoch 22/100\n",
      " - 0s - loss: 0.0093 - mse: 0.0093 - val_loss: 0.0181 - val_mse: 0.0181\n",
      "Epoch 23/100\n",
      " - 0s - loss: 0.0081 - mse: 0.0081 - val_loss: 0.0166 - val_mse: 0.0166\n",
      "Epoch 24/100\n",
      " - 1s - loss: 0.0089 - mse: 0.0089 - val_loss: 0.0188 - val_mse: 0.0188\n",
      "Epoch 25/100\n",
      " - 0s - loss: 0.0078 - mse: 0.0078 - val_loss: 0.0166 - val_mse: 0.0166\n",
      "Epoch 26/100\n",
      " - 0s - loss: 0.0078 - mse: 0.0078 - val_loss: 0.0169 - val_mse: 0.0169\n",
      "Epoch 27/100\n",
      " - 0s - loss: 0.0072 - mse: 0.0072 - val_loss: 0.0164 - val_mse: 0.0164\n",
      "Epoch 28/100\n",
      " - 0s - loss: 0.0073 - mse: 0.0073 - val_loss: 0.0163 - val_mse: 0.0163\n",
      "Epoch 29/100\n",
      " - 1s - loss: 0.0070 - mse: 0.0070 - val_loss: 0.0163 - val_mse: 0.0163\n",
      "Epoch 30/100\n",
      " - 1s - loss: 0.0066 - mse: 0.0066 - val_loss: 0.0160 - val_mse: 0.0160\n",
      "Epoch 31/100\n",
      " - 1s - loss: 0.0072 - mse: 0.0072 - val_loss: 0.0163 - val_mse: 0.0163\n",
      "Epoch 32/100\n",
      " - 1s - loss: 0.0082 - mse: 0.0082 - val_loss: 0.0171 - val_mse: 0.0171\n",
      "Epoch 33/100\n",
      " - 1s - loss: 0.0079 - mse: 0.0079 - val_loss: 0.0162 - val_mse: 0.0162\n",
      "Epoch 34/100\n",
      " - 1s - loss: 0.0074 - mse: 0.0074 - val_loss: 0.0159 - val_mse: 0.0159\n",
      "Epoch 35/100\n",
      " - 1s - loss: 0.0070 - mse: 0.0070 - val_loss: 0.0162 - val_mse: 0.0162\n",
      "Epoch 36/100\n",
      " - 1s - loss: 0.0066 - mse: 0.0066 - val_loss: 0.0158 - val_mse: 0.0158\n",
      "Epoch 37/100\n",
      " - 1s - loss: 0.0062 - mse: 0.0062 - val_loss: 0.0158 - val_mse: 0.0158\n",
      "Epoch 38/100\n",
      " - 0s - loss: 0.0070 - mse: 0.0070 - val_loss: 0.0158 - val_mse: 0.0158\n",
      "Epoch 39/100\n",
      " - 0s - loss: 0.0062 - mse: 0.0062 - val_loss: 0.0156 - val_mse: 0.0156\n",
      "Epoch 40/100\n",
      " - 1s - loss: 0.0073 - mse: 0.0073 - val_loss: 0.0156 - val_mse: 0.0156\n",
      "Epoch 41/100\n",
      " - 0s - loss: 0.0066 - mse: 0.0066 - val_loss: 0.0155 - val_mse: 0.0155\n",
      "Epoch 42/100\n",
      " - 1s - loss: 0.0071 - mse: 0.0071 - val_loss: 0.0156 - val_mse: 0.0156\n",
      "Epoch 43/100\n",
      " - 0s - loss: 0.0059 - mse: 0.0059 - val_loss: 0.0153 - val_mse: 0.0153\n",
      "Epoch 44/100\n",
      " - 0s - loss: 0.0064 - mse: 0.0064 - val_loss: 0.0153 - val_mse: 0.0153\n",
      "Epoch 45/100\n",
      " - 0s - loss: 0.0059 - mse: 0.0059 - val_loss: 0.0152 - val_mse: 0.0152\n",
      "Epoch 46/100\n",
      " - 0s - loss: 0.0066 - mse: 0.0066 - val_loss: 0.0154 - val_mse: 0.0154\n",
      "Epoch 47/100\n",
      " - 0s - loss: 0.0066 - mse: 0.0066 - val_loss: 0.0153 - val_mse: 0.0153\n",
      "Epoch 48/100\n",
      " - 0s - loss: 0.0082 - mse: 0.0082 - val_loss: 0.0156 - val_mse: 0.0156\n",
      "Epoch 49/100\n",
      " - 0s - loss: 0.0067 - mse: 0.0067 - val_loss: 0.0153 - val_mse: 0.0153\n",
      "Epoch 50/100\n",
      " - 0s - loss: 0.0067 - mse: 0.0067 - val_loss: 0.0155 - val_mse: 0.0155\n",
      "Epoch 51/100\n",
      " - 0s - loss: 0.0067 - mse: 0.0067 - val_loss: 0.0154 - val_mse: 0.0154\n",
      "Epoch 52/100\n",
      " - 0s - loss: 0.0073 - mse: 0.0073 - val_loss: 0.0154 - val_mse: 0.0154\n",
      "Epoch 53/100\n",
      " - 0s - loss: 0.0062 - mse: 0.0062 - val_loss: 0.0151 - val_mse: 0.0151\n",
      "Epoch 54/100\n",
      " - 0s - loss: 0.0069 - mse: 0.0069 - val_loss: 0.0155 - val_mse: 0.0155\n",
      "Epoch 55/100\n",
      " - 0s - loss: 0.0076 - mse: 0.0076 - val_loss: 0.0155 - val_mse: 0.0155\n",
      "Epoch 56/100\n",
      " - 0s - loss: 0.0081 - mse: 0.0081 - val_loss: 0.0155 - val_mse: 0.0155\n",
      "Epoch 57/100\n",
      " - 0s - loss: 0.0072 - mse: 0.0072 - val_loss: 0.0153 - val_mse: 0.0153\n",
      "Epoch 58/100\n",
      " - 0s - loss: 0.0077 - mse: 0.0077 - val_loss: 0.0155 - val_mse: 0.0155\n",
      "Epoch 59/100\n",
      " - 0s - loss: 0.0074 - mse: 0.0074 - val_loss: 0.0154 - val_mse: 0.0154\n",
      "Epoch 60/100\n",
      " - 0s - loss: 0.0069 - mse: 0.0069 - val_loss: 0.0155 - val_mse: 0.0155\n",
      "Epoch 61/100\n",
      " - 0s - loss: 0.0065 - mse: 0.0065 - val_loss: 0.0153 - val_mse: 0.0153\n",
      "Epoch 62/100\n",
      " - 0s - loss: 0.0076 - mse: 0.0076 - val_loss: 0.0154 - val_mse: 0.0154\n",
      "Epoch 63/100\n",
      " - 0s - loss: 0.0063 - mse: 0.0063 - val_loss: 0.0151 - val_mse: 0.0151\n",
      "Epoch 64/100\n",
      " - 0s - loss: 0.0082 - mse: 0.0082 - val_loss: 0.0157 - val_mse: 0.0157\n",
      "Epoch 65/100\n",
      " - 0s - loss: 0.0094 - mse: 0.0094 - val_loss: 0.0161 - val_mse: 0.0161\n",
      "Epoch 66/100\n",
      " - 0s - loss: 0.0093 - mse: 0.0093 - val_loss: 0.0156 - val_mse: 0.0156\n",
      "Epoch 67/100\n",
      " - 0s - loss: 0.0099 - mse: 0.0099 - val_loss: 0.0168 - val_mse: 0.0168\n",
      "Epoch 68/100\n",
      " - 0s - loss: 0.0098 - mse: 0.0098 - val_loss: 0.0158 - val_mse: 0.0158\n",
      "Epoch 69/100\n",
      " - 0s - loss: 0.0104 - mse: 0.0104 - val_loss: 0.0183 - val_mse: 0.0183\n",
      "Epoch 70/100\n",
      " - 0s - loss: 0.0088 - mse: 0.0088 - val_loss: 0.0166 - val_mse: 0.0166\n",
      "real [[3725.46]]\n",
      "Test RMSE: 159.687\n",
      "Diff [[-159.68702816]]\n",
      "% Diff [[-4.28637076]] %\n",
      "Predictions [[3885.14702816]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "layers = 2\n",
    "neurons = [100, 20, 20]\n",
    "\n",
    "columns = columns_12\n",
    "num_features = len(columns)\n",
    "\n",
    "crypto = crypto\n",
    "execute_test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos mejoras, aunque la diferencia de precio no esta obteniendo buenas predicciones en la fila de test. Como hemos comentado es posible que no tenga una relacion secuencial tan alta como el precio.\n",
    "\n",
    "Sin embargo seguimos viendo como las funciones de perdida son más bajas que con el modelo usado como base. Esto es algo positivo.\n",
    "\n",
    "Probaremos ahora a bajar capas de nuevo y subir neuronas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading... ETH\n",
      "Extracting columns columns for ETH\n",
      "Proccessing and arranging columns for LSTM model\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>close_19</th>\n",
       "      <th>close_diff_20_19</th>\n",
       "      <th>close_18</th>\n",
       "      <th>close_diff_20_18</th>\n",
       "      <th>close_17</th>\n",
       "      <th>close_diff_20_17</th>\n",
       "      <th>close_16</th>\n",
       "      <th>close_diff_20_16</th>\n",
       "      <th>close_15</th>\n",
       "      <th>close_diff_20_15</th>\n",
       "      <th>...</th>\n",
       "      <th>close_diff_20_4</th>\n",
       "      <th>close_3</th>\n",
       "      <th>close_diff_20_3</th>\n",
       "      <th>close_2</th>\n",
       "      <th>close_diff_20_2</th>\n",
       "      <th>close_1</th>\n",
       "      <th>close_diff_20_1</th>\n",
       "      <th>close_0</th>\n",
       "      <th>close_diff_20_0</th>\n",
       "      <th>close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>1123.09</td>\n",
       "      <td>339.09</td>\n",
       "      <td>1133.18</td>\n",
       "      <td>335.18</td>\n",
       "      <td>1291.00</td>\n",
       "      <td>500.79</td>\n",
       "      <td>1247.00</td>\n",
       "      <td>464.59</td>\n",
       "      <td>1138.93</td>\n",
       "      <td>502.96</td>\n",
       "      <td>...</td>\n",
       "      <td>137.72</td>\n",
       "      <td>980.00</td>\n",
       "      <td>45.97</td>\n",
       "      <td>1061.00</td>\n",
       "      <td>121.00</td>\n",
       "      <td>1056.52</td>\n",
       "      <td>97.22</td>\n",
       "      <td>1051.03</td>\n",
       "      <td>46.92</td>\n",
       "      <td>924.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>1133.18</td>\n",
       "      <td>335.18</td>\n",
       "      <td>1291.00</td>\n",
       "      <td>500.79</td>\n",
       "      <td>1247.00</td>\n",
       "      <td>464.59</td>\n",
       "      <td>1138.93</td>\n",
       "      <td>502.96</td>\n",
       "      <td>1253.87</td>\n",
       "      <td>613.53</td>\n",
       "      <td>...</td>\n",
       "      <td>45.97</td>\n",
       "      <td>1061.00</td>\n",
       "      <td>121.00</td>\n",
       "      <td>1056.52</td>\n",
       "      <td>97.22</td>\n",
       "      <td>1051.03</td>\n",
       "      <td>46.92</td>\n",
       "      <td>1118.99</td>\n",
       "      <td>-4.10</td>\n",
       "      <td>938.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>1291.00</td>\n",
       "      <td>500.79</td>\n",
       "      <td>1247.00</td>\n",
       "      <td>464.59</td>\n",
       "      <td>1138.93</td>\n",
       "      <td>502.96</td>\n",
       "      <td>1253.87</td>\n",
       "      <td>613.53</td>\n",
       "      <td>1388.02</td>\n",
       "      <td>730.02</td>\n",
       "      <td>...</td>\n",
       "      <td>121.00</td>\n",
       "      <td>1056.52</td>\n",
       "      <td>97.22</td>\n",
       "      <td>1051.03</td>\n",
       "      <td>46.92</td>\n",
       "      <td>1118.99</td>\n",
       "      <td>-4.10</td>\n",
       "      <td>1251.96</td>\n",
       "      <td>118.78</td>\n",
       "      <td>969.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>1247.00</td>\n",
       "      <td>464.59</td>\n",
       "      <td>1138.93</td>\n",
       "      <td>502.96</td>\n",
       "      <td>1253.87</td>\n",
       "      <td>613.53</td>\n",
       "      <td>1388.02</td>\n",
       "      <td>730.02</td>\n",
       "      <td>1347.00</td>\n",
       "      <td>632.05</td>\n",
       "      <td>...</td>\n",
       "      <td>97.22</td>\n",
       "      <td>1051.03</td>\n",
       "      <td>46.92</td>\n",
       "      <td>1118.99</td>\n",
       "      <td>-4.10</td>\n",
       "      <td>1251.96</td>\n",
       "      <td>118.78</td>\n",
       "      <td>1177.01</td>\n",
       "      <td>-113.99</td>\n",
       "      <td>911.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>1138.93</td>\n",
       "      <td>502.96</td>\n",
       "      <td>1253.87</td>\n",
       "      <td>613.53</td>\n",
       "      <td>1388.02</td>\n",
       "      <td>730.02</td>\n",
       "      <td>1347.00</td>\n",
       "      <td>632.05</td>\n",
       "      <td>1271.00</td>\n",
       "      <td>521.00</td>\n",
       "      <td>...</td>\n",
       "      <td>46.92</td>\n",
       "      <td>1118.99</td>\n",
       "      <td>-4.10</td>\n",
       "      <td>1251.96</td>\n",
       "      <td>118.78</td>\n",
       "      <td>1177.01</td>\n",
       "      <td>-113.99</td>\n",
       "      <td>1085.50</td>\n",
       "      <td>-161.50</td>\n",
       "      <td>938.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1573</th>\n",
       "      <td>4287.80</td>\n",
       "      <td>1.78</td>\n",
       "      <td>3996.90</td>\n",
       "      <td>-421.99</td>\n",
       "      <td>4294.76</td>\n",
       "      <td>-27.92</td>\n",
       "      <td>4412.17</td>\n",
       "      <td>124.96</td>\n",
       "      <td>4258.31</td>\n",
       "      <td>-61.12</td>\n",
       "      <td>...</td>\n",
       "      <td>-154.25</td>\n",
       "      <td>4215.73</td>\n",
       "      <td>-428.55</td>\n",
       "      <td>4117.25</td>\n",
       "      <td>-509.25</td>\n",
       "      <td>4196.44</td>\n",
       "      <td>-367.34</td>\n",
       "      <td>4347.59</td>\n",
       "      <td>137.83</td>\n",
       "      <td>4063.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1574</th>\n",
       "      <td>3996.90</td>\n",
       "      <td>-421.99</td>\n",
       "      <td>4294.76</td>\n",
       "      <td>-27.92</td>\n",
       "      <td>4412.17</td>\n",
       "      <td>124.96</td>\n",
       "      <td>4258.31</td>\n",
       "      <td>-61.12</td>\n",
       "      <td>4085.97</td>\n",
       "      <td>-503.92</td>\n",
       "      <td>...</td>\n",
       "      <td>-428.55</td>\n",
       "      <td>4117.25</td>\n",
       "      <td>-509.25</td>\n",
       "      <td>4196.44</td>\n",
       "      <td>-367.34</td>\n",
       "      <td>4347.59</td>\n",
       "      <td>137.83</td>\n",
       "      <td>4306.40</td>\n",
       "      <td>18.60</td>\n",
       "      <td>4037.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1575</th>\n",
       "      <td>4294.76</td>\n",
       "      <td>-27.92</td>\n",
       "      <td>4412.17</td>\n",
       "      <td>124.96</td>\n",
       "      <td>4258.31</td>\n",
       "      <td>-61.12</td>\n",
       "      <td>4085.97</td>\n",
       "      <td>-503.92</td>\n",
       "      <td>4339.44</td>\n",
       "      <td>-263.91</td>\n",
       "      <td>...</td>\n",
       "      <td>-509.25</td>\n",
       "      <td>4196.44</td>\n",
       "      <td>-367.34</td>\n",
       "      <td>4347.59</td>\n",
       "      <td>137.83</td>\n",
       "      <td>4306.40</td>\n",
       "      <td>18.60</td>\n",
       "      <td>4436.91</td>\n",
       "      <td>440.01</td>\n",
       "      <td>3792.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1576</th>\n",
       "      <td>4412.17</td>\n",
       "      <td>124.96</td>\n",
       "      <td>4258.31</td>\n",
       "      <td>-61.12</td>\n",
       "      <td>4085.97</td>\n",
       "      <td>-503.92</td>\n",
       "      <td>4339.44</td>\n",
       "      <td>-263.91</td>\n",
       "      <td>4269.36</td>\n",
       "      <td>-262.96</td>\n",
       "      <td>...</td>\n",
       "      <td>-367.34</td>\n",
       "      <td>4347.59</td>\n",
       "      <td>137.83</td>\n",
       "      <td>4306.40</td>\n",
       "      <td>18.60</td>\n",
       "      <td>4436.91</td>\n",
       "      <td>440.01</td>\n",
       "      <td>4105.64</td>\n",
       "      <td>-189.12</td>\n",
       "      <td>3630.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1577</th>\n",
       "      <td>4258.31</td>\n",
       "      <td>-61.12</td>\n",
       "      <td>4085.97</td>\n",
       "      <td>-503.92</td>\n",
       "      <td>4339.44</td>\n",
       "      <td>-263.91</td>\n",
       "      <td>4269.36</td>\n",
       "      <td>-262.96</td>\n",
       "      <td>4524.85</td>\n",
       "      <td>50.61</td>\n",
       "      <td>...</td>\n",
       "      <td>137.83</td>\n",
       "      <td>4306.40</td>\n",
       "      <td>18.60</td>\n",
       "      <td>4436.91</td>\n",
       "      <td>440.01</td>\n",
       "      <td>4105.64</td>\n",
       "      <td>-189.12</td>\n",
       "      <td>3897.94</td>\n",
       "      <td>-514.23</td>\n",
       "      <td>3709.27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1415 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      close_19  close_diff_20_19  close_18  close_diff_20_18  close_17  \\\n",
       "163    1123.09            339.09   1133.18            335.18   1291.00   \n",
       "164    1133.18            335.18   1291.00            500.79   1247.00   \n",
       "165    1291.00            500.79   1247.00            464.59   1138.93   \n",
       "166    1247.00            464.59   1138.93            502.96   1253.87   \n",
       "167    1138.93            502.96   1253.87            613.53   1388.02   \n",
       "...        ...               ...       ...               ...       ...   \n",
       "1573   4287.80              1.78   3996.90           -421.99   4294.76   \n",
       "1574   3996.90           -421.99   4294.76            -27.92   4412.17   \n",
       "1575   4294.76            -27.92   4412.17            124.96   4258.31   \n",
       "1576   4412.17            124.96   4258.31            -61.12   4085.97   \n",
       "1577   4258.31            -61.12   4085.97           -503.92   4339.44   \n",
       "\n",
       "      close_diff_20_17  close_16  close_diff_20_16  close_15  \\\n",
       "163             500.79   1247.00            464.59   1138.93   \n",
       "164             464.59   1138.93            502.96   1253.87   \n",
       "165             502.96   1253.87            613.53   1388.02   \n",
       "166             613.53   1388.02            730.02   1347.00   \n",
       "167             730.02   1347.00            632.05   1271.00   \n",
       "...                ...       ...               ...       ...   \n",
       "1573            -27.92   4412.17            124.96   4258.31   \n",
       "1574            124.96   4258.31            -61.12   4085.97   \n",
       "1575            -61.12   4085.97           -503.92   4339.44   \n",
       "1576           -503.92   4339.44           -263.91   4269.36   \n",
       "1577           -263.91   4269.36           -262.96   4524.85   \n",
       "\n",
       "      close_diff_20_15  ...  close_diff_20_4  close_3  close_diff_20_3  \\\n",
       "163             502.96  ...           137.72   980.00            45.97   \n",
       "164             613.53  ...            45.97  1061.00           121.00   \n",
       "165             730.02  ...           121.00  1056.52            97.22   \n",
       "166             632.05  ...            97.22  1051.03            46.92   \n",
       "167             521.00  ...            46.92  1118.99            -4.10   \n",
       "...                ...  ...              ...      ...              ...   \n",
       "1573            -61.12  ...          -154.25  4215.73          -428.55   \n",
       "1574           -503.92  ...          -428.55  4117.25          -509.25   \n",
       "1575           -263.91  ...          -509.25  4196.44          -367.34   \n",
       "1576           -262.96  ...          -367.34  4347.59           137.83   \n",
       "1577             50.61  ...           137.83  4306.40            18.60   \n",
       "\n",
       "      close_2  close_diff_20_2  close_1  close_diff_20_1  close_0  \\\n",
       "163   1061.00           121.00  1056.52            97.22  1051.03   \n",
       "164   1056.52            97.22  1051.03            46.92  1118.99   \n",
       "165   1051.03            46.92  1118.99            -4.10  1251.96   \n",
       "166   1118.99            -4.10  1251.96           118.78  1177.01   \n",
       "167   1251.96           118.78  1177.01          -113.99  1085.50   \n",
       "...       ...              ...      ...              ...      ...   \n",
       "1573  4117.25          -509.25  4196.44          -367.34  4347.59   \n",
       "1574  4196.44          -367.34  4347.59           137.83  4306.40   \n",
       "1575  4347.59           137.83  4306.40            18.60  4436.91   \n",
       "1576  4306.40            18.60  4436.91           440.01  4105.64   \n",
       "1577  4436.91           440.01  4105.64          -189.12  3897.94   \n",
       "\n",
       "      close_diff_20_0    close  \n",
       "163             46.92   924.55  \n",
       "164             -4.10   938.67  \n",
       "165            118.78   969.99  \n",
       "166           -113.99   911.00  \n",
       "167           -161.50   938.11  \n",
       "...               ...      ...  \n",
       "1573           137.83  4063.56  \n",
       "1574            18.60  4037.23  \n",
       "1575           440.01  3792.75  \n",
       "1576          -189.12  3630.19  \n",
       "1577          -514.23  3709.27  \n",
       "\n",
       "[1415 rows x 41 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>close_19</th>\n",
       "      <th>close_diff_20_19</th>\n",
       "      <th>close_18</th>\n",
       "      <th>close_diff_20_18</th>\n",
       "      <th>close_17</th>\n",
       "      <th>close_diff_20_17</th>\n",
       "      <th>close_16</th>\n",
       "      <th>close_diff_20_16</th>\n",
       "      <th>close_15</th>\n",
       "      <th>close_diff_20_15</th>\n",
       "      <th>...</th>\n",
       "      <th>close_diff_20_4</th>\n",
       "      <th>close_3</th>\n",
       "      <th>close_diff_20_3</th>\n",
       "      <th>close_2</th>\n",
       "      <th>close_diff_20_2</th>\n",
       "      <th>close_1</th>\n",
       "      <th>close_diff_20_1</th>\n",
       "      <th>close_0</th>\n",
       "      <th>close_diff_20_0</th>\n",
       "      <th>close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1578</th>\n",
       "      <td>4085.97</td>\n",
       "      <td>-503.92</td>\n",
       "      <td>4339.44</td>\n",
       "      <td>-263.91</td>\n",
       "      <td>4269.36</td>\n",
       "      <td>-262.96</td>\n",
       "      <td>4524.85</td>\n",
       "      <td>50.61</td>\n",
       "      <td>4041.2</td>\n",
       "      <td>-476.8</td>\n",
       "      <td>...</td>\n",
       "      <td>18.6</td>\n",
       "      <td>4436.91</td>\n",
       "      <td>440.01</td>\n",
       "      <td>4105.64</td>\n",
       "      <td>-189.12</td>\n",
       "      <td>3897.94</td>\n",
       "      <td>-514.23</td>\n",
       "      <td>4089.37</td>\n",
       "      <td>-168.94</td>\n",
       "      <td>3725.46</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      close_19  close_diff_20_19  close_18  close_diff_20_18  close_17  \\\n",
       "1578   4085.97           -503.92   4339.44           -263.91   4269.36   \n",
       "\n",
       "      close_diff_20_17  close_16  close_diff_20_16  close_15  \\\n",
       "1578           -262.96   4524.85             50.61    4041.2   \n",
       "\n",
       "      close_diff_20_15  ...  close_diff_20_4  close_3  close_diff_20_3  \\\n",
       "1578            -476.8  ...             18.6  4436.91           440.01   \n",
       "\n",
       "      close_2  close_diff_20_2  close_1  close_diff_20_1  close_0  \\\n",
       "1578  4105.64          -189.12  3897.94          -514.23  4089.37   \n",
       "\n",
       "      close_diff_20_0    close  \n",
       "1578          -168.94  3725.46  \n",
       "\n",
       "[1 rows x 41 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (1415, 1, 40) (1415, 1)\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_4 (LSTM)                (None, 1, 200)            192800    \n",
      "_________________________________________________________________\n",
      "lstm_5 (LSTM)                (None, 100)               120400    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 313,301\n",
      "Trainable params: 313,301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Y shape (1415, 1)\n",
      "Train on 1415 samples, validate on 283 samples\n",
      "Epoch 1/100\n",
      " - 5s - loss: 0.0649 - mse: 0.0649 - val_loss: 0.1463 - val_mse: 0.1463\n",
      "Epoch 2/100\n",
      " - 0s - loss: 0.0185 - mse: 0.0185 - val_loss: 0.0233 - val_mse: 0.0233\n",
      "Epoch 3/100\n",
      " - 0s - loss: 0.0060 - mse: 0.0060 - val_loss: 0.0204 - val_mse: 0.0204\n",
      "Epoch 4/100\n",
      " - 0s - loss: 0.0115 - mse: 0.0115 - val_loss: 0.0175 - val_mse: 0.0175\n",
      "Epoch 5/100\n",
      " - 0s - loss: 0.0132 - mse: 0.0132 - val_loss: 0.0287 - val_mse: 0.0287\n",
      "Epoch 6/100\n",
      " - 0s - loss: 0.0364 - mse: 0.0364 - val_loss: 0.0489 - val_mse: 0.0489\n",
      "Epoch 7/100\n",
      " - 0s - loss: 0.0244 - mse: 0.0244 - val_loss: 0.0358 - val_mse: 0.0358\n",
      "Epoch 8/100\n",
      " - 1s - loss: 0.0804 - mse: 0.0804 - val_loss: 0.2773 - val_mse: 0.2773\n",
      "Epoch 9/100\n",
      " - 1s - loss: 0.0145 - mse: 0.0145 - val_loss: 0.0234 - val_mse: 0.0234\n",
      "Epoch 10/100\n",
      " - 1s - loss: 0.0120 - mse: 0.0120 - val_loss: 0.0184 - val_mse: 0.0184\n",
      "Epoch 11/100\n",
      " - 0s - loss: 0.0204 - mse: 0.0204 - val_loss: 0.0497 - val_mse: 0.0497\n",
      "Epoch 12/100\n",
      " - 0s - loss: 0.0068 - mse: 0.0068 - val_loss: 0.0182 - val_mse: 0.0182\n",
      "Epoch 13/100\n",
      " - 0s - loss: 0.0088 - mse: 0.0088 - val_loss: 0.0220 - val_mse: 0.0220\n",
      "Epoch 14/100\n",
      " - 0s - loss: 0.0061 - mse: 0.0061 - val_loss: 0.0176 - val_mse: 0.0176\n",
      "Epoch 15/100\n",
      " - 1s - loss: 0.0072 - mse: 0.0072 - val_loss: 0.0188 - val_mse: 0.0188\n",
      "Epoch 16/100\n",
      " - 0s - loss: 0.0056 - mse: 0.0056 - val_loss: 0.0173 - val_mse: 0.0173\n",
      "Epoch 17/100\n",
      " - 1s - loss: 0.0073 - mse: 0.0073 - val_loss: 0.0196 - val_mse: 0.0196\n",
      "Epoch 18/100\n",
      " - 1s - loss: 0.0060 - mse: 0.0060 - val_loss: 0.0170 - val_mse: 0.0170\n",
      "Epoch 19/100\n",
      " - 0s - loss: 0.0070 - mse: 0.0070 - val_loss: 0.0185 - val_mse: 0.0185\n",
      "Epoch 20/100\n",
      " - 1s - loss: 0.0056 - mse: 0.0056 - val_loss: 0.0168 - val_mse: 0.0168\n",
      "Epoch 21/100\n",
      " - 1s - loss: 0.0078 - mse: 0.0078 - val_loss: 0.0185 - val_mse: 0.0185\n",
      "Epoch 22/100\n",
      " - 1s - loss: 0.0069 - mse: 0.0069 - val_loss: 0.0169 - val_mse: 0.0169\n",
      "Epoch 23/100\n",
      " - 1s - loss: 0.0114 - mse: 0.0114 - val_loss: 0.0241 - val_mse: 0.0241\n",
      "Epoch 24/100\n",
      " - 0s - loss: 0.0082 - mse: 0.0082 - val_loss: 0.0171 - val_mse: 0.0171\n",
      "Epoch 25/100\n",
      " - 0s - loss: 0.0133 - mse: 0.0133 - val_loss: 0.0271 - val_mse: 0.0271\n",
      "Epoch 26/100\n",
      " - 1s - loss: 0.0088 - mse: 0.0088 - val_loss: 0.0171 - val_mse: 0.0171\n",
      "Epoch 27/100\n",
      " - 1s - loss: 0.0130 - mse: 0.0130 - val_loss: 0.0272 - val_mse: 0.0272\n",
      "Epoch 28/100\n",
      " - 1s - loss: 0.0082 - mse: 0.0082 - val_loss: 0.0173 - val_mse: 0.0173\n",
      "Epoch 29/100\n",
      " - 1s - loss: 0.0114 - mse: 0.0114 - val_loss: 0.0253 - val_mse: 0.0253\n",
      "Epoch 30/100\n",
      " - 1s - loss: 0.0070 - mse: 0.0070 - val_loss: 0.0173 - val_mse: 0.0173\n",
      "Epoch 31/100\n",
      " - 1s - loss: 0.0088 - mse: 0.0088 - val_loss: 0.0208 - val_mse: 0.0208\n",
      "Epoch 32/100\n",
      " - 1s - loss: 0.0064 - mse: 0.0064 - val_loss: 0.0171 - val_mse: 0.0171\n",
      "Epoch 33/100\n",
      " - 1s - loss: 0.0084 - mse: 0.0084 - val_loss: 0.0204 - val_mse: 0.0204\n",
      "Epoch 34/100\n",
      " - 1s - loss: 0.0061 - mse: 0.0061 - val_loss: 0.0167 - val_mse: 0.0167\n",
      "Epoch 35/100\n",
      " - 1s - loss: 0.0085 - mse: 0.0085 - val_loss: 0.0201 - val_mse: 0.0201\n",
      "Epoch 36/100\n",
      " - 1s - loss: 0.0066 - mse: 0.0066 - val_loss: 0.0169 - val_mse: 0.0169\n",
      "Epoch 37/100\n",
      " - 1s - loss: 0.0082 - mse: 0.0082 - val_loss: 0.0188 - val_mse: 0.0188\n",
      "Epoch 38/100\n",
      " - 1s - loss: 0.0067 - mse: 0.0067 - val_loss: 0.0165 - val_mse: 0.0165\n",
      "Epoch 39/100\n",
      " - 1s - loss: 0.0083 - mse: 0.0083 - val_loss: 0.0195 - val_mse: 0.0195\n",
      "Epoch 40/100\n",
      " - 1s - loss: 0.0067 - mse: 0.0067 - val_loss: 0.0166 - val_mse: 0.0166\n",
      "Epoch 41/100\n",
      " - 1s - loss: 0.0094 - mse: 0.0094 - val_loss: 0.0205 - val_mse: 0.0205\n",
      "Epoch 42/100\n",
      " - 1s - loss: 0.0074 - mse: 0.0074 - val_loss: 0.0166 - val_mse: 0.0166\n",
      "Epoch 43/100\n",
      " - 1s - loss: 0.0103 - mse: 0.0103 - val_loss: 0.0220 - val_mse: 0.0220\n",
      "Epoch 44/100\n",
      " - 1s - loss: 0.0071 - mse: 0.0071 - val_loss: 0.0166 - val_mse: 0.0166\n",
      "Epoch 45/100\n",
      " - 1s - loss: 0.0107 - mse: 0.0107 - val_loss: 0.0228 - val_mse: 0.0228\n",
      "real [[3725.46]]\n",
      "Test RMSE: 316.142\n",
      "Diff [[-316.1421018]]\n",
      "% Diff [[-8.48598836]] %\n",
      "Predictions [[4041.6021018]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "layers = 1\n",
    "neurons = [200, 100]\n",
    "\n",
    "columns = columns_12\n",
    "num_features = len(columns)\n",
    "\n",
    "crypto = crypto\n",
    "execute_test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que tenemos algo de overfitting en esta prueba. Sin embargo los datos de perdidas son bastante buenos. Seguiremos con esta idea e intentaremos paliar el overfitting más adelante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading... ETH\n",
      "Extracting columns columns for ETH\n",
      "Proccessing and arranging columns for LSTM model\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>close_19</th>\n",
       "      <th>close_diff_20_19</th>\n",
       "      <th>close_18</th>\n",
       "      <th>close_diff_20_18</th>\n",
       "      <th>close_17</th>\n",
       "      <th>close_diff_20_17</th>\n",
       "      <th>close_16</th>\n",
       "      <th>close_diff_20_16</th>\n",
       "      <th>close_15</th>\n",
       "      <th>close_diff_20_15</th>\n",
       "      <th>...</th>\n",
       "      <th>close_diff_20_4</th>\n",
       "      <th>close_3</th>\n",
       "      <th>close_diff_20_3</th>\n",
       "      <th>close_2</th>\n",
       "      <th>close_diff_20_2</th>\n",
       "      <th>close_1</th>\n",
       "      <th>close_diff_20_1</th>\n",
       "      <th>close_0</th>\n",
       "      <th>close_diff_20_0</th>\n",
       "      <th>close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>1123.09</td>\n",
       "      <td>339.09</td>\n",
       "      <td>1133.18</td>\n",
       "      <td>335.18</td>\n",
       "      <td>1291.00</td>\n",
       "      <td>500.79</td>\n",
       "      <td>1247.00</td>\n",
       "      <td>464.59</td>\n",
       "      <td>1138.93</td>\n",
       "      <td>502.96</td>\n",
       "      <td>...</td>\n",
       "      <td>137.72</td>\n",
       "      <td>980.00</td>\n",
       "      <td>45.97</td>\n",
       "      <td>1061.00</td>\n",
       "      <td>121.00</td>\n",
       "      <td>1056.52</td>\n",
       "      <td>97.22</td>\n",
       "      <td>1051.03</td>\n",
       "      <td>46.92</td>\n",
       "      <td>924.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>1133.18</td>\n",
       "      <td>335.18</td>\n",
       "      <td>1291.00</td>\n",
       "      <td>500.79</td>\n",
       "      <td>1247.00</td>\n",
       "      <td>464.59</td>\n",
       "      <td>1138.93</td>\n",
       "      <td>502.96</td>\n",
       "      <td>1253.87</td>\n",
       "      <td>613.53</td>\n",
       "      <td>...</td>\n",
       "      <td>45.97</td>\n",
       "      <td>1061.00</td>\n",
       "      <td>121.00</td>\n",
       "      <td>1056.52</td>\n",
       "      <td>97.22</td>\n",
       "      <td>1051.03</td>\n",
       "      <td>46.92</td>\n",
       "      <td>1118.99</td>\n",
       "      <td>-4.10</td>\n",
       "      <td>938.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>1291.00</td>\n",
       "      <td>500.79</td>\n",
       "      <td>1247.00</td>\n",
       "      <td>464.59</td>\n",
       "      <td>1138.93</td>\n",
       "      <td>502.96</td>\n",
       "      <td>1253.87</td>\n",
       "      <td>613.53</td>\n",
       "      <td>1388.02</td>\n",
       "      <td>730.02</td>\n",
       "      <td>...</td>\n",
       "      <td>121.00</td>\n",
       "      <td>1056.52</td>\n",
       "      <td>97.22</td>\n",
       "      <td>1051.03</td>\n",
       "      <td>46.92</td>\n",
       "      <td>1118.99</td>\n",
       "      <td>-4.10</td>\n",
       "      <td>1251.96</td>\n",
       "      <td>118.78</td>\n",
       "      <td>969.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>1247.00</td>\n",
       "      <td>464.59</td>\n",
       "      <td>1138.93</td>\n",
       "      <td>502.96</td>\n",
       "      <td>1253.87</td>\n",
       "      <td>613.53</td>\n",
       "      <td>1388.02</td>\n",
       "      <td>730.02</td>\n",
       "      <td>1347.00</td>\n",
       "      <td>632.05</td>\n",
       "      <td>...</td>\n",
       "      <td>97.22</td>\n",
       "      <td>1051.03</td>\n",
       "      <td>46.92</td>\n",
       "      <td>1118.99</td>\n",
       "      <td>-4.10</td>\n",
       "      <td>1251.96</td>\n",
       "      <td>118.78</td>\n",
       "      <td>1177.01</td>\n",
       "      <td>-113.99</td>\n",
       "      <td>911.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>1138.93</td>\n",
       "      <td>502.96</td>\n",
       "      <td>1253.87</td>\n",
       "      <td>613.53</td>\n",
       "      <td>1388.02</td>\n",
       "      <td>730.02</td>\n",
       "      <td>1347.00</td>\n",
       "      <td>632.05</td>\n",
       "      <td>1271.00</td>\n",
       "      <td>521.00</td>\n",
       "      <td>...</td>\n",
       "      <td>46.92</td>\n",
       "      <td>1118.99</td>\n",
       "      <td>-4.10</td>\n",
       "      <td>1251.96</td>\n",
       "      <td>118.78</td>\n",
       "      <td>1177.01</td>\n",
       "      <td>-113.99</td>\n",
       "      <td>1085.50</td>\n",
       "      <td>-161.50</td>\n",
       "      <td>938.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1573</th>\n",
       "      <td>4287.80</td>\n",
       "      <td>1.78</td>\n",
       "      <td>3996.90</td>\n",
       "      <td>-421.99</td>\n",
       "      <td>4294.76</td>\n",
       "      <td>-27.92</td>\n",
       "      <td>4412.17</td>\n",
       "      <td>124.96</td>\n",
       "      <td>4258.31</td>\n",
       "      <td>-61.12</td>\n",
       "      <td>...</td>\n",
       "      <td>-154.25</td>\n",
       "      <td>4215.73</td>\n",
       "      <td>-428.55</td>\n",
       "      <td>4117.25</td>\n",
       "      <td>-509.25</td>\n",
       "      <td>4196.44</td>\n",
       "      <td>-367.34</td>\n",
       "      <td>4347.59</td>\n",
       "      <td>137.83</td>\n",
       "      <td>4063.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1574</th>\n",
       "      <td>3996.90</td>\n",
       "      <td>-421.99</td>\n",
       "      <td>4294.76</td>\n",
       "      <td>-27.92</td>\n",
       "      <td>4412.17</td>\n",
       "      <td>124.96</td>\n",
       "      <td>4258.31</td>\n",
       "      <td>-61.12</td>\n",
       "      <td>4085.97</td>\n",
       "      <td>-503.92</td>\n",
       "      <td>...</td>\n",
       "      <td>-428.55</td>\n",
       "      <td>4117.25</td>\n",
       "      <td>-509.25</td>\n",
       "      <td>4196.44</td>\n",
       "      <td>-367.34</td>\n",
       "      <td>4347.59</td>\n",
       "      <td>137.83</td>\n",
       "      <td>4306.40</td>\n",
       "      <td>18.60</td>\n",
       "      <td>4037.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1575</th>\n",
       "      <td>4294.76</td>\n",
       "      <td>-27.92</td>\n",
       "      <td>4412.17</td>\n",
       "      <td>124.96</td>\n",
       "      <td>4258.31</td>\n",
       "      <td>-61.12</td>\n",
       "      <td>4085.97</td>\n",
       "      <td>-503.92</td>\n",
       "      <td>4339.44</td>\n",
       "      <td>-263.91</td>\n",
       "      <td>...</td>\n",
       "      <td>-509.25</td>\n",
       "      <td>4196.44</td>\n",
       "      <td>-367.34</td>\n",
       "      <td>4347.59</td>\n",
       "      <td>137.83</td>\n",
       "      <td>4306.40</td>\n",
       "      <td>18.60</td>\n",
       "      <td>4436.91</td>\n",
       "      <td>440.01</td>\n",
       "      <td>3792.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1576</th>\n",
       "      <td>4412.17</td>\n",
       "      <td>124.96</td>\n",
       "      <td>4258.31</td>\n",
       "      <td>-61.12</td>\n",
       "      <td>4085.97</td>\n",
       "      <td>-503.92</td>\n",
       "      <td>4339.44</td>\n",
       "      <td>-263.91</td>\n",
       "      <td>4269.36</td>\n",
       "      <td>-262.96</td>\n",
       "      <td>...</td>\n",
       "      <td>-367.34</td>\n",
       "      <td>4347.59</td>\n",
       "      <td>137.83</td>\n",
       "      <td>4306.40</td>\n",
       "      <td>18.60</td>\n",
       "      <td>4436.91</td>\n",
       "      <td>440.01</td>\n",
       "      <td>4105.64</td>\n",
       "      <td>-189.12</td>\n",
       "      <td>3630.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1577</th>\n",
       "      <td>4258.31</td>\n",
       "      <td>-61.12</td>\n",
       "      <td>4085.97</td>\n",
       "      <td>-503.92</td>\n",
       "      <td>4339.44</td>\n",
       "      <td>-263.91</td>\n",
       "      <td>4269.36</td>\n",
       "      <td>-262.96</td>\n",
       "      <td>4524.85</td>\n",
       "      <td>50.61</td>\n",
       "      <td>...</td>\n",
       "      <td>137.83</td>\n",
       "      <td>4306.40</td>\n",
       "      <td>18.60</td>\n",
       "      <td>4436.91</td>\n",
       "      <td>440.01</td>\n",
       "      <td>4105.64</td>\n",
       "      <td>-189.12</td>\n",
       "      <td>3897.94</td>\n",
       "      <td>-514.23</td>\n",
       "      <td>3709.27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1415 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      close_19  close_diff_20_19  close_18  close_diff_20_18  close_17  \\\n",
       "163    1123.09            339.09   1133.18            335.18   1291.00   \n",
       "164    1133.18            335.18   1291.00            500.79   1247.00   \n",
       "165    1291.00            500.79   1247.00            464.59   1138.93   \n",
       "166    1247.00            464.59   1138.93            502.96   1253.87   \n",
       "167    1138.93            502.96   1253.87            613.53   1388.02   \n",
       "...        ...               ...       ...               ...       ...   \n",
       "1573   4287.80              1.78   3996.90           -421.99   4294.76   \n",
       "1574   3996.90           -421.99   4294.76            -27.92   4412.17   \n",
       "1575   4294.76            -27.92   4412.17            124.96   4258.31   \n",
       "1576   4412.17            124.96   4258.31            -61.12   4085.97   \n",
       "1577   4258.31            -61.12   4085.97           -503.92   4339.44   \n",
       "\n",
       "      close_diff_20_17  close_16  close_diff_20_16  close_15  \\\n",
       "163             500.79   1247.00            464.59   1138.93   \n",
       "164             464.59   1138.93            502.96   1253.87   \n",
       "165             502.96   1253.87            613.53   1388.02   \n",
       "166             613.53   1388.02            730.02   1347.00   \n",
       "167             730.02   1347.00            632.05   1271.00   \n",
       "...                ...       ...               ...       ...   \n",
       "1573            -27.92   4412.17            124.96   4258.31   \n",
       "1574            124.96   4258.31            -61.12   4085.97   \n",
       "1575            -61.12   4085.97           -503.92   4339.44   \n",
       "1576           -503.92   4339.44           -263.91   4269.36   \n",
       "1577           -263.91   4269.36           -262.96   4524.85   \n",
       "\n",
       "      close_diff_20_15  ...  close_diff_20_4  close_3  close_diff_20_3  \\\n",
       "163             502.96  ...           137.72   980.00            45.97   \n",
       "164             613.53  ...            45.97  1061.00           121.00   \n",
       "165             730.02  ...           121.00  1056.52            97.22   \n",
       "166             632.05  ...            97.22  1051.03            46.92   \n",
       "167             521.00  ...            46.92  1118.99            -4.10   \n",
       "...                ...  ...              ...      ...              ...   \n",
       "1573            -61.12  ...          -154.25  4215.73          -428.55   \n",
       "1574           -503.92  ...          -428.55  4117.25          -509.25   \n",
       "1575           -263.91  ...          -509.25  4196.44          -367.34   \n",
       "1576           -262.96  ...          -367.34  4347.59           137.83   \n",
       "1577             50.61  ...           137.83  4306.40            18.60   \n",
       "\n",
       "      close_2  close_diff_20_2  close_1  close_diff_20_1  close_0  \\\n",
       "163   1061.00           121.00  1056.52            97.22  1051.03   \n",
       "164   1056.52            97.22  1051.03            46.92  1118.99   \n",
       "165   1051.03            46.92  1118.99            -4.10  1251.96   \n",
       "166   1118.99            -4.10  1251.96           118.78  1177.01   \n",
       "167   1251.96           118.78  1177.01          -113.99  1085.50   \n",
       "...       ...              ...      ...              ...      ...   \n",
       "1573  4117.25          -509.25  4196.44          -367.34  4347.59   \n",
       "1574  4196.44          -367.34  4347.59           137.83  4306.40   \n",
       "1575  4347.59           137.83  4306.40            18.60  4436.91   \n",
       "1576  4306.40            18.60  4436.91           440.01  4105.64   \n",
       "1577  4436.91           440.01  4105.64          -189.12  3897.94   \n",
       "\n",
       "      close_diff_20_0    close  \n",
       "163             46.92   924.55  \n",
       "164             -4.10   938.67  \n",
       "165            118.78   969.99  \n",
       "166           -113.99   911.00  \n",
       "167           -161.50   938.11  \n",
       "...               ...      ...  \n",
       "1573           137.83  4063.56  \n",
       "1574            18.60  4037.23  \n",
       "1575           440.01  3792.75  \n",
       "1576          -189.12  3630.19  \n",
       "1577          -514.23  3709.27  \n",
       "\n",
       "[1415 rows x 41 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>close_19</th>\n",
       "      <th>close_diff_20_19</th>\n",
       "      <th>close_18</th>\n",
       "      <th>close_diff_20_18</th>\n",
       "      <th>close_17</th>\n",
       "      <th>close_diff_20_17</th>\n",
       "      <th>close_16</th>\n",
       "      <th>close_diff_20_16</th>\n",
       "      <th>close_15</th>\n",
       "      <th>close_diff_20_15</th>\n",
       "      <th>...</th>\n",
       "      <th>close_diff_20_4</th>\n",
       "      <th>close_3</th>\n",
       "      <th>close_diff_20_3</th>\n",
       "      <th>close_2</th>\n",
       "      <th>close_diff_20_2</th>\n",
       "      <th>close_1</th>\n",
       "      <th>close_diff_20_1</th>\n",
       "      <th>close_0</th>\n",
       "      <th>close_diff_20_0</th>\n",
       "      <th>close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1578</th>\n",
       "      <td>4085.97</td>\n",
       "      <td>-503.92</td>\n",
       "      <td>4339.44</td>\n",
       "      <td>-263.91</td>\n",
       "      <td>4269.36</td>\n",
       "      <td>-262.96</td>\n",
       "      <td>4524.85</td>\n",
       "      <td>50.61</td>\n",
       "      <td>4041.2</td>\n",
       "      <td>-476.8</td>\n",
       "      <td>...</td>\n",
       "      <td>18.6</td>\n",
       "      <td>4436.91</td>\n",
       "      <td>440.01</td>\n",
       "      <td>4105.64</td>\n",
       "      <td>-189.12</td>\n",
       "      <td>3897.94</td>\n",
       "      <td>-514.23</td>\n",
       "      <td>4089.37</td>\n",
       "      <td>-168.94</td>\n",
       "      <td>3725.46</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      close_19  close_diff_20_19  close_18  close_diff_20_18  close_17  \\\n",
       "1578   4085.97           -503.92   4339.44           -263.91   4269.36   \n",
       "\n",
       "      close_diff_20_17  close_16  close_diff_20_16  close_15  \\\n",
       "1578           -262.96   4524.85             50.61    4041.2   \n",
       "\n",
       "      close_diff_20_15  ...  close_diff_20_4  close_3  close_diff_20_3  \\\n",
       "1578            -476.8  ...             18.6  4436.91           440.01   \n",
       "\n",
       "      close_2  close_diff_20_2  close_1  close_diff_20_1  close_0  \\\n",
       "1578  4105.64          -189.12  3897.94          -514.23  4089.37   \n",
       "\n",
       "      close_diff_20_0    close  \n",
       "1578          -168.94  3725.46  \n",
       "\n",
       "[1 rows x 41 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (1415, 1, 40) (1415, 1)\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_6 (LSTM)                (None, 1, 200)            192800    \n",
      "_________________________________________________________________\n",
      "lstm_7 (LSTM)                (None, 1, 100)            120400    \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 1, 100)            0         \n",
      "_________________________________________________________________\n",
      "lstm_8 (LSTM)                (None, 50)                30200     \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 343,451\n",
      "Trainable params: 343,451\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Y shape (1415, 1)\n",
      "Train on 1415 samples, validate on 283 samples\n",
      "Epoch 1/100\n",
      " - 7s - loss: 0.0726 - mse: 0.0726 - val_loss: 0.2536 - val_mse: 0.2536\n",
      "Epoch 2/100\n",
      " - 0s - loss: 0.0308 - mse: 0.0308 - val_loss: 0.0279 - val_mse: 0.0279\n",
      "Epoch 3/100\n",
      " - 1s - loss: 0.0248 - mse: 0.0248 - val_loss: 0.0580 - val_mse: 0.0580\n",
      "Epoch 4/100\n",
      " - 1s - loss: 0.0644 - mse: 0.0644 - val_loss: 0.1966 - val_mse: 0.1966\n",
      "Epoch 5/100\n",
      " - 1s - loss: 0.0072 - mse: 0.0072 - val_loss: 0.0185 - val_mse: 0.0185\n",
      "Epoch 6/100\n",
      " - 1s - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0194 - val_mse: 0.0194\n",
      "Epoch 7/100\n",
      " - 1s - loss: 0.0114 - mse: 0.0114 - val_loss: 0.0232 - val_mse: 0.0232\n",
      "Epoch 8/100\n",
      " - 1s - loss: 0.0363 - mse: 0.0363 - val_loss: 0.0959 - val_mse: 0.0959\n",
      "Epoch 9/100\n",
      " - 1s - loss: 0.0083 - mse: 0.0083 - val_loss: 0.0177 - val_mse: 0.0177\n",
      "Epoch 10/100\n",
      " - 1s - loss: 0.0120 - mse: 0.0120 - val_loss: 0.0255 - val_mse: 0.0255\n",
      "Epoch 11/100\n",
      " - 1s - loss: 0.0098 - mse: 0.0098 - val_loss: 0.0179 - val_mse: 0.0179\n",
      "Epoch 12/100\n",
      " - 1s - loss: 0.0165 - mse: 0.0165 - val_loss: 0.0364 - val_mse: 0.0364\n",
      "Epoch 13/100\n",
      " - 1s - loss: 0.0091 - mse: 0.0091 - val_loss: 0.0180 - val_mse: 0.0180\n",
      "Epoch 14/100\n",
      " - 1s - loss: 0.0129 - mse: 0.0129 - val_loss: 0.0274 - val_mse: 0.0274\n",
      "Epoch 15/100\n",
      " - 1s - loss: 0.0098 - mse: 0.0098 - val_loss: 0.0181 - val_mse: 0.0181\n",
      "Epoch 16/100\n",
      " - 1s - loss: 0.0118 - mse: 0.0118 - val_loss: 0.0275 - val_mse: 0.0275\n",
      "Epoch 17/100\n",
      " - 1s - loss: 0.0077 - mse: 0.0077 - val_loss: 0.0184 - val_mse: 0.0184\n",
      "Epoch 18/100\n",
      " - 1s - loss: 0.0091 - mse: 0.0091 - val_loss: 0.0202 - val_mse: 0.0202\n",
      "Epoch 19/100\n",
      " - 1s - loss: 0.0078 - mse: 0.0078 - val_loss: 0.0179 - val_mse: 0.0179\n",
      "Epoch 20/100\n",
      " - 1s - loss: 0.0092 - mse: 0.0092 - val_loss: 0.0207 - val_mse: 0.0207\n",
      "Epoch 21/100\n",
      " - 1s - loss: 0.0070 - mse: 0.0070 - val_loss: 0.0177 - val_mse: 0.0177\n",
      "Epoch 22/100\n",
      " - 1s - loss: 0.0073 - mse: 0.0073 - val_loss: 0.0186 - val_mse: 0.0186\n",
      "Epoch 23/100\n",
      " - 1s - loss: 0.0066 - mse: 0.0066 - val_loss: 0.0174 - val_mse: 0.0174\n",
      "Epoch 24/100\n",
      " - 1s - loss: 0.0077 - mse: 0.0077 - val_loss: 0.0185 - val_mse: 0.0185\n",
      "Epoch 25/100\n",
      " - 1s - loss: 0.0072 - mse: 0.0072 - val_loss: 0.0173 - val_mse: 0.0173\n",
      "Epoch 26/100\n",
      " - 1s - loss: 0.0089 - mse: 0.0089 - val_loss: 0.0201 - val_mse: 0.0201\n",
      "Epoch 27/100\n",
      " - 1s - loss: 0.0077 - mse: 0.0077 - val_loss: 0.0176 - val_mse: 0.0176\n",
      "Epoch 28/100\n",
      " - 1s - loss: 0.0082 - mse: 0.0082 - val_loss: 0.0181 - val_mse: 0.0181\n",
      "Epoch 29/100\n",
      " - 1s - loss: 0.0084 - mse: 0.0084 - val_loss: 0.0171 - val_mse: 0.0171\n",
      "Epoch 30/100\n",
      " - 1s - loss: 0.0097 - mse: 0.0097 - val_loss: 0.0198 - val_mse: 0.0198\n",
      "Epoch 31/100\n",
      " - 1s - loss: 0.0086 - mse: 0.0086 - val_loss: 0.0173 - val_mse: 0.0173\n",
      "Epoch 32/100\n",
      " - 1s - loss: 0.0099 - mse: 0.0099 - val_loss: 0.0204 - val_mse: 0.0204\n",
      "Epoch 33/100\n",
      " - 1s - loss: 0.0088 - mse: 0.0088 - val_loss: 0.0173 - val_mse: 0.0173\n",
      "Epoch 34/100\n",
      " - 1s - loss: 0.0112 - mse: 0.0112 - val_loss: 0.0222 - val_mse: 0.0222\n",
      "Epoch 35/100\n",
      " - 1s - loss: 0.0090 - mse: 0.0090 - val_loss: 0.0174 - val_mse: 0.0174\n",
      "Epoch 36/100\n",
      " - 1s - loss: 0.0108 - mse: 0.0108 - val_loss: 0.0223 - val_mse: 0.0223\n",
      "Epoch 37/100\n",
      " - 1s - loss: 0.0082 - mse: 0.0082 - val_loss: 0.0178 - val_mse: 0.0178\n",
      "Epoch 38/100\n",
      " - 1s - loss: 0.0086 - mse: 0.0086 - val_loss: 0.0195 - val_mse: 0.0195\n",
      "Epoch 39/100\n",
      " - 1s - loss: 0.0068 - mse: 0.0068 - val_loss: 0.0174 - val_mse: 0.0174\n",
      "Epoch 40/100\n",
      " - 1s - loss: 0.0081 - mse: 0.0081 - val_loss: 0.0183 - val_mse: 0.0183\n",
      "Epoch 41/100\n",
      " - 1s - loss: 0.0071 - mse: 0.0071 - val_loss: 0.0171 - val_mse: 0.0171\n",
      "Epoch 42/100\n",
      " - 1s - loss: 0.0081 - mse: 0.0081 - val_loss: 0.0187 - val_mse: 0.0187\n",
      "Epoch 43/100\n",
      " - 1s - loss: 0.0082 - mse: 0.0082 - val_loss: 0.0170 - val_mse: 0.0170\n",
      "Epoch 44/100\n",
      " - 1s - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0201 - val_mse: 0.0201\n",
      "Epoch 45/100\n",
      " - 1s - loss: 0.0086 - mse: 0.0086 - val_loss: 0.0172 - val_mse: 0.0172\n",
      "Epoch 46/100\n",
      " - 1s - loss: 0.0100 - mse: 0.0100 - val_loss: 0.0228 - val_mse: 0.0228\n",
      "Epoch 47/100\n",
      " - 1s - loss: 0.0075 - mse: 0.0075 - val_loss: 0.0177 - val_mse: 0.0177\n",
      "Epoch 48/100\n",
      " - 1s - loss: 0.0072 - mse: 0.0072 - val_loss: 0.0177 - val_mse: 0.0177\n",
      "real [[3725.46]]\n",
      "Test RMSE: 245.259\n",
      "Diff [[-245.25859523]]\n",
      "% Diff [[-6.58331039]] %\n",
      "Predictions [[3970.71859523]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "layers = 2\n",
    "neurons = [200, 100, 50]\n",
    "\n",
    "columns = columns_12\n",
    "num_features = len(columns)\n",
    "\n",
    "crypto = crypto\n",
    "execute_test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definitivamente añadiendo capas nuestro modelo se hace mucho más complejo de manejar y obtiene valores de perdidas peores. Sin embargo los test realzados son mejores. Probaremos una vez más a subir el numero de nueronas con solo una capa oculta. Posiblemente esto genere más overfitting que seremos capaces de resolver más adelante.\n",
    "\n",
    "Tengamos en cuenta que si a este modelo le quitamos o añadimos paciencia al early stopping junto con un lr mas bajo y epocas mas altas, posiblemente obtengamos buenos resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading... ETH\n",
      "Extracting columns columns for ETH\n",
      "Proccessing and arranging columns for LSTM model\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>close_19</th>\n",
       "      <th>close_diff_20_19</th>\n",
       "      <th>close_18</th>\n",
       "      <th>close_diff_20_18</th>\n",
       "      <th>close_17</th>\n",
       "      <th>close_diff_20_17</th>\n",
       "      <th>close_16</th>\n",
       "      <th>close_diff_20_16</th>\n",
       "      <th>close_15</th>\n",
       "      <th>close_diff_20_15</th>\n",
       "      <th>...</th>\n",
       "      <th>close_diff_20_4</th>\n",
       "      <th>close_3</th>\n",
       "      <th>close_diff_20_3</th>\n",
       "      <th>close_2</th>\n",
       "      <th>close_diff_20_2</th>\n",
       "      <th>close_1</th>\n",
       "      <th>close_diff_20_1</th>\n",
       "      <th>close_0</th>\n",
       "      <th>close_diff_20_0</th>\n",
       "      <th>close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>1123.09</td>\n",
       "      <td>339.09</td>\n",
       "      <td>1133.18</td>\n",
       "      <td>335.18</td>\n",
       "      <td>1291.00</td>\n",
       "      <td>500.79</td>\n",
       "      <td>1247.00</td>\n",
       "      <td>464.59</td>\n",
       "      <td>1138.93</td>\n",
       "      <td>502.96</td>\n",
       "      <td>...</td>\n",
       "      <td>137.72</td>\n",
       "      <td>980.00</td>\n",
       "      <td>45.97</td>\n",
       "      <td>1061.00</td>\n",
       "      <td>121.00</td>\n",
       "      <td>1056.52</td>\n",
       "      <td>97.22</td>\n",
       "      <td>1051.03</td>\n",
       "      <td>46.92</td>\n",
       "      <td>924.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>1133.18</td>\n",
       "      <td>335.18</td>\n",
       "      <td>1291.00</td>\n",
       "      <td>500.79</td>\n",
       "      <td>1247.00</td>\n",
       "      <td>464.59</td>\n",
       "      <td>1138.93</td>\n",
       "      <td>502.96</td>\n",
       "      <td>1253.87</td>\n",
       "      <td>613.53</td>\n",
       "      <td>...</td>\n",
       "      <td>45.97</td>\n",
       "      <td>1061.00</td>\n",
       "      <td>121.00</td>\n",
       "      <td>1056.52</td>\n",
       "      <td>97.22</td>\n",
       "      <td>1051.03</td>\n",
       "      <td>46.92</td>\n",
       "      <td>1118.99</td>\n",
       "      <td>-4.10</td>\n",
       "      <td>938.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>1291.00</td>\n",
       "      <td>500.79</td>\n",
       "      <td>1247.00</td>\n",
       "      <td>464.59</td>\n",
       "      <td>1138.93</td>\n",
       "      <td>502.96</td>\n",
       "      <td>1253.87</td>\n",
       "      <td>613.53</td>\n",
       "      <td>1388.02</td>\n",
       "      <td>730.02</td>\n",
       "      <td>...</td>\n",
       "      <td>121.00</td>\n",
       "      <td>1056.52</td>\n",
       "      <td>97.22</td>\n",
       "      <td>1051.03</td>\n",
       "      <td>46.92</td>\n",
       "      <td>1118.99</td>\n",
       "      <td>-4.10</td>\n",
       "      <td>1251.96</td>\n",
       "      <td>118.78</td>\n",
       "      <td>969.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>1247.00</td>\n",
       "      <td>464.59</td>\n",
       "      <td>1138.93</td>\n",
       "      <td>502.96</td>\n",
       "      <td>1253.87</td>\n",
       "      <td>613.53</td>\n",
       "      <td>1388.02</td>\n",
       "      <td>730.02</td>\n",
       "      <td>1347.00</td>\n",
       "      <td>632.05</td>\n",
       "      <td>...</td>\n",
       "      <td>97.22</td>\n",
       "      <td>1051.03</td>\n",
       "      <td>46.92</td>\n",
       "      <td>1118.99</td>\n",
       "      <td>-4.10</td>\n",
       "      <td>1251.96</td>\n",
       "      <td>118.78</td>\n",
       "      <td>1177.01</td>\n",
       "      <td>-113.99</td>\n",
       "      <td>911.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>1138.93</td>\n",
       "      <td>502.96</td>\n",
       "      <td>1253.87</td>\n",
       "      <td>613.53</td>\n",
       "      <td>1388.02</td>\n",
       "      <td>730.02</td>\n",
       "      <td>1347.00</td>\n",
       "      <td>632.05</td>\n",
       "      <td>1271.00</td>\n",
       "      <td>521.00</td>\n",
       "      <td>...</td>\n",
       "      <td>46.92</td>\n",
       "      <td>1118.99</td>\n",
       "      <td>-4.10</td>\n",
       "      <td>1251.96</td>\n",
       "      <td>118.78</td>\n",
       "      <td>1177.01</td>\n",
       "      <td>-113.99</td>\n",
       "      <td>1085.50</td>\n",
       "      <td>-161.50</td>\n",
       "      <td>938.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1573</th>\n",
       "      <td>4287.80</td>\n",
       "      <td>1.78</td>\n",
       "      <td>3996.90</td>\n",
       "      <td>-421.99</td>\n",
       "      <td>4294.76</td>\n",
       "      <td>-27.92</td>\n",
       "      <td>4412.17</td>\n",
       "      <td>124.96</td>\n",
       "      <td>4258.31</td>\n",
       "      <td>-61.12</td>\n",
       "      <td>...</td>\n",
       "      <td>-154.25</td>\n",
       "      <td>4215.73</td>\n",
       "      <td>-428.55</td>\n",
       "      <td>4117.25</td>\n",
       "      <td>-509.25</td>\n",
       "      <td>4196.44</td>\n",
       "      <td>-367.34</td>\n",
       "      <td>4347.59</td>\n",
       "      <td>137.83</td>\n",
       "      <td>4063.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1574</th>\n",
       "      <td>3996.90</td>\n",
       "      <td>-421.99</td>\n",
       "      <td>4294.76</td>\n",
       "      <td>-27.92</td>\n",
       "      <td>4412.17</td>\n",
       "      <td>124.96</td>\n",
       "      <td>4258.31</td>\n",
       "      <td>-61.12</td>\n",
       "      <td>4085.97</td>\n",
       "      <td>-503.92</td>\n",
       "      <td>...</td>\n",
       "      <td>-428.55</td>\n",
       "      <td>4117.25</td>\n",
       "      <td>-509.25</td>\n",
       "      <td>4196.44</td>\n",
       "      <td>-367.34</td>\n",
       "      <td>4347.59</td>\n",
       "      <td>137.83</td>\n",
       "      <td>4306.40</td>\n",
       "      <td>18.60</td>\n",
       "      <td>4037.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1575</th>\n",
       "      <td>4294.76</td>\n",
       "      <td>-27.92</td>\n",
       "      <td>4412.17</td>\n",
       "      <td>124.96</td>\n",
       "      <td>4258.31</td>\n",
       "      <td>-61.12</td>\n",
       "      <td>4085.97</td>\n",
       "      <td>-503.92</td>\n",
       "      <td>4339.44</td>\n",
       "      <td>-263.91</td>\n",
       "      <td>...</td>\n",
       "      <td>-509.25</td>\n",
       "      <td>4196.44</td>\n",
       "      <td>-367.34</td>\n",
       "      <td>4347.59</td>\n",
       "      <td>137.83</td>\n",
       "      <td>4306.40</td>\n",
       "      <td>18.60</td>\n",
       "      <td>4436.91</td>\n",
       "      <td>440.01</td>\n",
       "      <td>3792.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1576</th>\n",
       "      <td>4412.17</td>\n",
       "      <td>124.96</td>\n",
       "      <td>4258.31</td>\n",
       "      <td>-61.12</td>\n",
       "      <td>4085.97</td>\n",
       "      <td>-503.92</td>\n",
       "      <td>4339.44</td>\n",
       "      <td>-263.91</td>\n",
       "      <td>4269.36</td>\n",
       "      <td>-262.96</td>\n",
       "      <td>...</td>\n",
       "      <td>-367.34</td>\n",
       "      <td>4347.59</td>\n",
       "      <td>137.83</td>\n",
       "      <td>4306.40</td>\n",
       "      <td>18.60</td>\n",
       "      <td>4436.91</td>\n",
       "      <td>440.01</td>\n",
       "      <td>4105.64</td>\n",
       "      <td>-189.12</td>\n",
       "      <td>3630.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1577</th>\n",
       "      <td>4258.31</td>\n",
       "      <td>-61.12</td>\n",
       "      <td>4085.97</td>\n",
       "      <td>-503.92</td>\n",
       "      <td>4339.44</td>\n",
       "      <td>-263.91</td>\n",
       "      <td>4269.36</td>\n",
       "      <td>-262.96</td>\n",
       "      <td>4524.85</td>\n",
       "      <td>50.61</td>\n",
       "      <td>...</td>\n",
       "      <td>137.83</td>\n",
       "      <td>4306.40</td>\n",
       "      <td>18.60</td>\n",
       "      <td>4436.91</td>\n",
       "      <td>440.01</td>\n",
       "      <td>4105.64</td>\n",
       "      <td>-189.12</td>\n",
       "      <td>3897.94</td>\n",
       "      <td>-514.23</td>\n",
       "      <td>3709.27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1415 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      close_19  close_diff_20_19  close_18  close_diff_20_18  close_17  \\\n",
       "163    1123.09            339.09   1133.18            335.18   1291.00   \n",
       "164    1133.18            335.18   1291.00            500.79   1247.00   \n",
       "165    1291.00            500.79   1247.00            464.59   1138.93   \n",
       "166    1247.00            464.59   1138.93            502.96   1253.87   \n",
       "167    1138.93            502.96   1253.87            613.53   1388.02   \n",
       "...        ...               ...       ...               ...       ...   \n",
       "1573   4287.80              1.78   3996.90           -421.99   4294.76   \n",
       "1574   3996.90           -421.99   4294.76            -27.92   4412.17   \n",
       "1575   4294.76            -27.92   4412.17            124.96   4258.31   \n",
       "1576   4412.17            124.96   4258.31            -61.12   4085.97   \n",
       "1577   4258.31            -61.12   4085.97           -503.92   4339.44   \n",
       "\n",
       "      close_diff_20_17  close_16  close_diff_20_16  close_15  \\\n",
       "163             500.79   1247.00            464.59   1138.93   \n",
       "164             464.59   1138.93            502.96   1253.87   \n",
       "165             502.96   1253.87            613.53   1388.02   \n",
       "166             613.53   1388.02            730.02   1347.00   \n",
       "167             730.02   1347.00            632.05   1271.00   \n",
       "...                ...       ...               ...       ...   \n",
       "1573            -27.92   4412.17            124.96   4258.31   \n",
       "1574            124.96   4258.31            -61.12   4085.97   \n",
       "1575            -61.12   4085.97           -503.92   4339.44   \n",
       "1576           -503.92   4339.44           -263.91   4269.36   \n",
       "1577           -263.91   4269.36           -262.96   4524.85   \n",
       "\n",
       "      close_diff_20_15  ...  close_diff_20_4  close_3  close_diff_20_3  \\\n",
       "163             502.96  ...           137.72   980.00            45.97   \n",
       "164             613.53  ...            45.97  1061.00           121.00   \n",
       "165             730.02  ...           121.00  1056.52            97.22   \n",
       "166             632.05  ...            97.22  1051.03            46.92   \n",
       "167             521.00  ...            46.92  1118.99            -4.10   \n",
       "...                ...  ...              ...      ...              ...   \n",
       "1573            -61.12  ...          -154.25  4215.73          -428.55   \n",
       "1574           -503.92  ...          -428.55  4117.25          -509.25   \n",
       "1575           -263.91  ...          -509.25  4196.44          -367.34   \n",
       "1576           -262.96  ...          -367.34  4347.59           137.83   \n",
       "1577             50.61  ...           137.83  4306.40            18.60   \n",
       "\n",
       "      close_2  close_diff_20_2  close_1  close_diff_20_1  close_0  \\\n",
       "163   1061.00           121.00  1056.52            97.22  1051.03   \n",
       "164   1056.52            97.22  1051.03            46.92  1118.99   \n",
       "165   1051.03            46.92  1118.99            -4.10  1251.96   \n",
       "166   1118.99            -4.10  1251.96           118.78  1177.01   \n",
       "167   1251.96           118.78  1177.01          -113.99  1085.50   \n",
       "...       ...              ...      ...              ...      ...   \n",
       "1573  4117.25          -509.25  4196.44          -367.34  4347.59   \n",
       "1574  4196.44          -367.34  4347.59           137.83  4306.40   \n",
       "1575  4347.59           137.83  4306.40            18.60  4436.91   \n",
       "1576  4306.40            18.60  4436.91           440.01  4105.64   \n",
       "1577  4436.91           440.01  4105.64          -189.12  3897.94   \n",
       "\n",
       "      close_diff_20_0    close  \n",
       "163             46.92   924.55  \n",
       "164             -4.10   938.67  \n",
       "165            118.78   969.99  \n",
       "166           -113.99   911.00  \n",
       "167           -161.50   938.11  \n",
       "...               ...      ...  \n",
       "1573           137.83  4063.56  \n",
       "1574            18.60  4037.23  \n",
       "1575           440.01  3792.75  \n",
       "1576          -189.12  3630.19  \n",
       "1577          -514.23  3709.27  \n",
       "\n",
       "[1415 rows x 41 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>close_19</th>\n",
       "      <th>close_diff_20_19</th>\n",
       "      <th>close_18</th>\n",
       "      <th>close_diff_20_18</th>\n",
       "      <th>close_17</th>\n",
       "      <th>close_diff_20_17</th>\n",
       "      <th>close_16</th>\n",
       "      <th>close_diff_20_16</th>\n",
       "      <th>close_15</th>\n",
       "      <th>close_diff_20_15</th>\n",
       "      <th>...</th>\n",
       "      <th>close_diff_20_4</th>\n",
       "      <th>close_3</th>\n",
       "      <th>close_diff_20_3</th>\n",
       "      <th>close_2</th>\n",
       "      <th>close_diff_20_2</th>\n",
       "      <th>close_1</th>\n",
       "      <th>close_diff_20_1</th>\n",
       "      <th>close_0</th>\n",
       "      <th>close_diff_20_0</th>\n",
       "      <th>close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1578</th>\n",
       "      <td>4085.97</td>\n",
       "      <td>-503.92</td>\n",
       "      <td>4339.44</td>\n",
       "      <td>-263.91</td>\n",
       "      <td>4269.36</td>\n",
       "      <td>-262.96</td>\n",
       "      <td>4524.85</td>\n",
       "      <td>50.61</td>\n",
       "      <td>4041.2</td>\n",
       "      <td>-476.8</td>\n",
       "      <td>...</td>\n",
       "      <td>18.6</td>\n",
       "      <td>4436.91</td>\n",
       "      <td>440.01</td>\n",
       "      <td>4105.64</td>\n",
       "      <td>-189.12</td>\n",
       "      <td>3897.94</td>\n",
       "      <td>-514.23</td>\n",
       "      <td>4089.37</td>\n",
       "      <td>-168.94</td>\n",
       "      <td>3725.46</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      close_19  close_diff_20_19  close_18  close_diff_20_18  close_17  \\\n",
       "1578   4085.97           -503.92   4339.44           -263.91   4269.36   \n",
       "\n",
       "      close_diff_20_17  close_16  close_diff_20_16  close_15  \\\n",
       "1578           -262.96   4524.85             50.61    4041.2   \n",
       "\n",
       "      close_diff_20_15  ...  close_diff_20_4  close_3  close_diff_20_3  \\\n",
       "1578            -476.8  ...             18.6  4436.91           440.01   \n",
       "\n",
       "      close_2  close_diff_20_2  close_1  close_diff_20_1  close_0  \\\n",
       "1578  4105.64          -189.12  3897.94          -514.23  4089.37   \n",
       "\n",
       "      close_diff_20_0    close  \n",
       "1578          -168.94  3725.46  \n",
       "\n",
       "[1 rows x 41 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (1415, 1, 40) (1415, 1)\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_9 (LSTM)                (None, 1, 400)            705600    \n",
      "_________________________________________________________________\n",
      "lstm_10 (LSTM)               (None, 200)               480800    \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 1,186,601\n",
      "Trainable params: 1,186,601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Y shape (1415, 1)\n",
      "Train on 1415 samples, validate on 283 samples\n",
      "Epoch 1/100\n",
      " - 5s - loss: 0.0696 - mse: 0.0696 - val_loss: 0.1018 - val_mse: 0.1018\n",
      "Epoch 2/100\n",
      " - 1s - loss: 0.0214 - mse: 0.0214 - val_loss: 0.0843 - val_mse: 0.0843\n",
      "Epoch 3/100\n",
      " - 1s - loss: 0.0981 - mse: 0.0981 - val_loss: 0.4503 - val_mse: 0.4503\n",
      "Epoch 4/100\n",
      " - 1s - loss: 0.0981 - mse: 0.0981 - val_loss: 0.4503 - val_mse: 0.4503\n",
      "Epoch 5/100\n",
      " - 1s - loss: 0.0981 - mse: 0.0981 - val_loss: 0.4503 - val_mse: 0.4503\n",
      "Epoch 6/100\n",
      " - 1s - loss: 0.0981 - mse: 0.0981 - val_loss: 0.4503 - val_mse: 0.4503\n",
      "Epoch 7/100\n",
      " - 1s - loss: 0.0981 - mse: 0.0981 - val_loss: 0.4503 - val_mse: 0.4503\n",
      "Epoch 8/100\n",
      " - 1s - loss: 0.0981 - mse: 0.0981 - val_loss: 0.4503 - val_mse: 0.4503\n",
      "Epoch 9/100\n",
      " - 1s - loss: 0.0981 - mse: 0.0981 - val_loss: 0.4503 - val_mse: 0.4503\n",
      "Epoch 10/100\n",
      " - 1s - loss: 0.0981 - mse: 0.0981 - val_loss: 0.4503 - val_mse: 0.4503\n",
      "Epoch 11/100\n",
      " - 1s - loss: 0.0981 - mse: 0.0981 - val_loss: 0.4503 - val_mse: 0.4503\n",
      "Epoch 12/100\n",
      " - 1s - loss: 0.0981 - mse: 0.0981 - val_loss: 0.4503 - val_mse: 0.4503\n",
      "Epoch 13/100\n",
      " - 1s - loss: 0.0981 - mse: 0.0981 - val_loss: 0.4503 - val_mse: 0.4503\n",
      "Epoch 14/100\n",
      " - 1s - loss: 0.0981 - mse: 0.0981 - val_loss: 0.4503 - val_mse: 0.4503\n",
      "Epoch 15/100\n",
      " - 1s - loss: 0.0981 - mse: 0.0981 - val_loss: 0.4503 - val_mse: 0.4503\n",
      "Epoch 16/100\n",
      " - 1s - loss: 0.0981 - mse: 0.0981 - val_loss: 0.4503 - val_mse: 0.4503\n",
      "Epoch 17/100\n",
      " - 1s - loss: 0.0981 - mse: 0.0981 - val_loss: 0.4503 - val_mse: 0.4503\n",
      "Epoch 18/100\n",
      " - 1s - loss: 0.0981 - mse: 0.0981 - val_loss: 0.4503 - val_mse: 0.4503\n",
      "Epoch 19/100\n",
      " - 1s - loss: 0.0981 - mse: 0.0981 - val_loss: 0.4503 - val_mse: 0.4503\n",
      "Epoch 20/100\n",
      " - 1s - loss: 0.0981 - mse: 0.0981 - val_loss: 0.4503 - val_mse: 0.4503\n",
      "Epoch 21/100\n",
      " - 1s - loss: 0.0981 - mse: 0.0981 - val_loss: 0.4503 - val_mse: 0.4503\n",
      "Epoch 22/100\n",
      " - 1s - loss: 0.0981 - mse: 0.0981 - val_loss: 0.4503 - val_mse: 0.4503\n",
      "Epoch 23/100\n",
      " - 1s - loss: 0.0981 - mse: 0.0981 - val_loss: 0.4503 - val_mse: 0.4503\n",
      "Epoch 24/100\n",
      " - 1s - loss: 0.0981 - mse: 0.0981 - val_loss: 0.4503 - val_mse: 0.4503\n",
      "Epoch 25/100\n",
      " - 1s - loss: 0.0981 - mse: 0.0981 - val_loss: 0.4503 - val_mse: 0.4503\n",
      "Epoch 26/100\n",
      " - 1s - loss: 0.0981 - mse: 0.0981 - val_loss: 0.4503 - val_mse: 0.4503\n",
      "Epoch 27/100\n",
      " - 1s - loss: 0.0981 - mse: 0.0981 - val_loss: 0.4503 - val_mse: 0.4503\n",
      "real [[3725.46]]\n",
      "Test RMSE: 74.136\n",
      "Diff [[-74.13573524]]\n",
      "% Diff [[-1.98997534]] %\n",
      "Predictions [[3799.59573524]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "layers = 1\n",
    "neurons = [400, 200]\n",
    "\n",
    "columns = columns_12\n",
    "num_features = len(columns)\n",
    "\n",
    "crypto = crypto\n",
    "execute_test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bajaremos el numero de nueronas y lo igualamos a la capa oculta. El earlystopping esta impidiendo que el modelo encuentre minimos a tiempo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading... ETH\n",
      "Extracting columns columns for ETH\n",
      "Proccessing and arranging columns for LSTM model\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>close_19</th>\n",
       "      <th>close_diff_20_19</th>\n",
       "      <th>close_18</th>\n",
       "      <th>close_diff_20_18</th>\n",
       "      <th>close_17</th>\n",
       "      <th>close_diff_20_17</th>\n",
       "      <th>close_16</th>\n",
       "      <th>close_diff_20_16</th>\n",
       "      <th>close_15</th>\n",
       "      <th>close_diff_20_15</th>\n",
       "      <th>...</th>\n",
       "      <th>close_diff_20_4</th>\n",
       "      <th>close_3</th>\n",
       "      <th>close_diff_20_3</th>\n",
       "      <th>close_2</th>\n",
       "      <th>close_diff_20_2</th>\n",
       "      <th>close_1</th>\n",
       "      <th>close_diff_20_1</th>\n",
       "      <th>close_0</th>\n",
       "      <th>close_diff_20_0</th>\n",
       "      <th>close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>1123.09</td>\n",
       "      <td>339.09</td>\n",
       "      <td>1133.18</td>\n",
       "      <td>335.18</td>\n",
       "      <td>1291.00</td>\n",
       "      <td>500.79</td>\n",
       "      <td>1247.00</td>\n",
       "      <td>464.59</td>\n",
       "      <td>1138.93</td>\n",
       "      <td>502.96</td>\n",
       "      <td>...</td>\n",
       "      <td>137.72</td>\n",
       "      <td>980.00</td>\n",
       "      <td>45.97</td>\n",
       "      <td>1061.00</td>\n",
       "      <td>121.00</td>\n",
       "      <td>1056.52</td>\n",
       "      <td>97.22</td>\n",
       "      <td>1051.03</td>\n",
       "      <td>46.92</td>\n",
       "      <td>924.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>1133.18</td>\n",
       "      <td>335.18</td>\n",
       "      <td>1291.00</td>\n",
       "      <td>500.79</td>\n",
       "      <td>1247.00</td>\n",
       "      <td>464.59</td>\n",
       "      <td>1138.93</td>\n",
       "      <td>502.96</td>\n",
       "      <td>1253.87</td>\n",
       "      <td>613.53</td>\n",
       "      <td>...</td>\n",
       "      <td>45.97</td>\n",
       "      <td>1061.00</td>\n",
       "      <td>121.00</td>\n",
       "      <td>1056.52</td>\n",
       "      <td>97.22</td>\n",
       "      <td>1051.03</td>\n",
       "      <td>46.92</td>\n",
       "      <td>1118.99</td>\n",
       "      <td>-4.10</td>\n",
       "      <td>938.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>1291.00</td>\n",
       "      <td>500.79</td>\n",
       "      <td>1247.00</td>\n",
       "      <td>464.59</td>\n",
       "      <td>1138.93</td>\n",
       "      <td>502.96</td>\n",
       "      <td>1253.87</td>\n",
       "      <td>613.53</td>\n",
       "      <td>1388.02</td>\n",
       "      <td>730.02</td>\n",
       "      <td>...</td>\n",
       "      <td>121.00</td>\n",
       "      <td>1056.52</td>\n",
       "      <td>97.22</td>\n",
       "      <td>1051.03</td>\n",
       "      <td>46.92</td>\n",
       "      <td>1118.99</td>\n",
       "      <td>-4.10</td>\n",
       "      <td>1251.96</td>\n",
       "      <td>118.78</td>\n",
       "      <td>969.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>1247.00</td>\n",
       "      <td>464.59</td>\n",
       "      <td>1138.93</td>\n",
       "      <td>502.96</td>\n",
       "      <td>1253.87</td>\n",
       "      <td>613.53</td>\n",
       "      <td>1388.02</td>\n",
       "      <td>730.02</td>\n",
       "      <td>1347.00</td>\n",
       "      <td>632.05</td>\n",
       "      <td>...</td>\n",
       "      <td>97.22</td>\n",
       "      <td>1051.03</td>\n",
       "      <td>46.92</td>\n",
       "      <td>1118.99</td>\n",
       "      <td>-4.10</td>\n",
       "      <td>1251.96</td>\n",
       "      <td>118.78</td>\n",
       "      <td>1177.01</td>\n",
       "      <td>-113.99</td>\n",
       "      <td>911.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>1138.93</td>\n",
       "      <td>502.96</td>\n",
       "      <td>1253.87</td>\n",
       "      <td>613.53</td>\n",
       "      <td>1388.02</td>\n",
       "      <td>730.02</td>\n",
       "      <td>1347.00</td>\n",
       "      <td>632.05</td>\n",
       "      <td>1271.00</td>\n",
       "      <td>521.00</td>\n",
       "      <td>...</td>\n",
       "      <td>46.92</td>\n",
       "      <td>1118.99</td>\n",
       "      <td>-4.10</td>\n",
       "      <td>1251.96</td>\n",
       "      <td>118.78</td>\n",
       "      <td>1177.01</td>\n",
       "      <td>-113.99</td>\n",
       "      <td>1085.50</td>\n",
       "      <td>-161.50</td>\n",
       "      <td>938.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1573</th>\n",
       "      <td>4287.80</td>\n",
       "      <td>1.78</td>\n",
       "      <td>3996.90</td>\n",
       "      <td>-421.99</td>\n",
       "      <td>4294.76</td>\n",
       "      <td>-27.92</td>\n",
       "      <td>4412.17</td>\n",
       "      <td>124.96</td>\n",
       "      <td>4258.31</td>\n",
       "      <td>-61.12</td>\n",
       "      <td>...</td>\n",
       "      <td>-154.25</td>\n",
       "      <td>4215.73</td>\n",
       "      <td>-428.55</td>\n",
       "      <td>4117.25</td>\n",
       "      <td>-509.25</td>\n",
       "      <td>4196.44</td>\n",
       "      <td>-367.34</td>\n",
       "      <td>4347.59</td>\n",
       "      <td>137.83</td>\n",
       "      <td>4063.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1574</th>\n",
       "      <td>3996.90</td>\n",
       "      <td>-421.99</td>\n",
       "      <td>4294.76</td>\n",
       "      <td>-27.92</td>\n",
       "      <td>4412.17</td>\n",
       "      <td>124.96</td>\n",
       "      <td>4258.31</td>\n",
       "      <td>-61.12</td>\n",
       "      <td>4085.97</td>\n",
       "      <td>-503.92</td>\n",
       "      <td>...</td>\n",
       "      <td>-428.55</td>\n",
       "      <td>4117.25</td>\n",
       "      <td>-509.25</td>\n",
       "      <td>4196.44</td>\n",
       "      <td>-367.34</td>\n",
       "      <td>4347.59</td>\n",
       "      <td>137.83</td>\n",
       "      <td>4306.40</td>\n",
       "      <td>18.60</td>\n",
       "      <td>4037.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1575</th>\n",
       "      <td>4294.76</td>\n",
       "      <td>-27.92</td>\n",
       "      <td>4412.17</td>\n",
       "      <td>124.96</td>\n",
       "      <td>4258.31</td>\n",
       "      <td>-61.12</td>\n",
       "      <td>4085.97</td>\n",
       "      <td>-503.92</td>\n",
       "      <td>4339.44</td>\n",
       "      <td>-263.91</td>\n",
       "      <td>...</td>\n",
       "      <td>-509.25</td>\n",
       "      <td>4196.44</td>\n",
       "      <td>-367.34</td>\n",
       "      <td>4347.59</td>\n",
       "      <td>137.83</td>\n",
       "      <td>4306.40</td>\n",
       "      <td>18.60</td>\n",
       "      <td>4436.91</td>\n",
       "      <td>440.01</td>\n",
       "      <td>3792.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1576</th>\n",
       "      <td>4412.17</td>\n",
       "      <td>124.96</td>\n",
       "      <td>4258.31</td>\n",
       "      <td>-61.12</td>\n",
       "      <td>4085.97</td>\n",
       "      <td>-503.92</td>\n",
       "      <td>4339.44</td>\n",
       "      <td>-263.91</td>\n",
       "      <td>4269.36</td>\n",
       "      <td>-262.96</td>\n",
       "      <td>...</td>\n",
       "      <td>-367.34</td>\n",
       "      <td>4347.59</td>\n",
       "      <td>137.83</td>\n",
       "      <td>4306.40</td>\n",
       "      <td>18.60</td>\n",
       "      <td>4436.91</td>\n",
       "      <td>440.01</td>\n",
       "      <td>4105.64</td>\n",
       "      <td>-189.12</td>\n",
       "      <td>3630.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1577</th>\n",
       "      <td>4258.31</td>\n",
       "      <td>-61.12</td>\n",
       "      <td>4085.97</td>\n",
       "      <td>-503.92</td>\n",
       "      <td>4339.44</td>\n",
       "      <td>-263.91</td>\n",
       "      <td>4269.36</td>\n",
       "      <td>-262.96</td>\n",
       "      <td>4524.85</td>\n",
       "      <td>50.61</td>\n",
       "      <td>...</td>\n",
       "      <td>137.83</td>\n",
       "      <td>4306.40</td>\n",
       "      <td>18.60</td>\n",
       "      <td>4436.91</td>\n",
       "      <td>440.01</td>\n",
       "      <td>4105.64</td>\n",
       "      <td>-189.12</td>\n",
       "      <td>3897.94</td>\n",
       "      <td>-514.23</td>\n",
       "      <td>3709.27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1415 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      close_19  close_diff_20_19  close_18  close_diff_20_18  close_17  \\\n",
       "163    1123.09            339.09   1133.18            335.18   1291.00   \n",
       "164    1133.18            335.18   1291.00            500.79   1247.00   \n",
       "165    1291.00            500.79   1247.00            464.59   1138.93   \n",
       "166    1247.00            464.59   1138.93            502.96   1253.87   \n",
       "167    1138.93            502.96   1253.87            613.53   1388.02   \n",
       "...        ...               ...       ...               ...       ...   \n",
       "1573   4287.80              1.78   3996.90           -421.99   4294.76   \n",
       "1574   3996.90           -421.99   4294.76            -27.92   4412.17   \n",
       "1575   4294.76            -27.92   4412.17            124.96   4258.31   \n",
       "1576   4412.17            124.96   4258.31            -61.12   4085.97   \n",
       "1577   4258.31            -61.12   4085.97           -503.92   4339.44   \n",
       "\n",
       "      close_diff_20_17  close_16  close_diff_20_16  close_15  \\\n",
       "163             500.79   1247.00            464.59   1138.93   \n",
       "164             464.59   1138.93            502.96   1253.87   \n",
       "165             502.96   1253.87            613.53   1388.02   \n",
       "166             613.53   1388.02            730.02   1347.00   \n",
       "167             730.02   1347.00            632.05   1271.00   \n",
       "...                ...       ...               ...       ...   \n",
       "1573            -27.92   4412.17            124.96   4258.31   \n",
       "1574            124.96   4258.31            -61.12   4085.97   \n",
       "1575            -61.12   4085.97           -503.92   4339.44   \n",
       "1576           -503.92   4339.44           -263.91   4269.36   \n",
       "1577           -263.91   4269.36           -262.96   4524.85   \n",
       "\n",
       "      close_diff_20_15  ...  close_diff_20_4  close_3  close_diff_20_3  \\\n",
       "163             502.96  ...           137.72   980.00            45.97   \n",
       "164             613.53  ...            45.97  1061.00           121.00   \n",
       "165             730.02  ...           121.00  1056.52            97.22   \n",
       "166             632.05  ...            97.22  1051.03            46.92   \n",
       "167             521.00  ...            46.92  1118.99            -4.10   \n",
       "...                ...  ...              ...      ...              ...   \n",
       "1573            -61.12  ...          -154.25  4215.73          -428.55   \n",
       "1574           -503.92  ...          -428.55  4117.25          -509.25   \n",
       "1575           -263.91  ...          -509.25  4196.44          -367.34   \n",
       "1576           -262.96  ...          -367.34  4347.59           137.83   \n",
       "1577             50.61  ...           137.83  4306.40            18.60   \n",
       "\n",
       "      close_2  close_diff_20_2  close_1  close_diff_20_1  close_0  \\\n",
       "163   1061.00           121.00  1056.52            97.22  1051.03   \n",
       "164   1056.52            97.22  1051.03            46.92  1118.99   \n",
       "165   1051.03            46.92  1118.99            -4.10  1251.96   \n",
       "166   1118.99            -4.10  1251.96           118.78  1177.01   \n",
       "167   1251.96           118.78  1177.01          -113.99  1085.50   \n",
       "...       ...              ...      ...              ...      ...   \n",
       "1573  4117.25          -509.25  4196.44          -367.34  4347.59   \n",
       "1574  4196.44          -367.34  4347.59           137.83  4306.40   \n",
       "1575  4347.59           137.83  4306.40            18.60  4436.91   \n",
       "1576  4306.40            18.60  4436.91           440.01  4105.64   \n",
       "1577  4436.91           440.01  4105.64          -189.12  3897.94   \n",
       "\n",
       "      close_diff_20_0    close  \n",
       "163             46.92   924.55  \n",
       "164             -4.10   938.67  \n",
       "165            118.78   969.99  \n",
       "166           -113.99   911.00  \n",
       "167           -161.50   938.11  \n",
       "...               ...      ...  \n",
       "1573           137.83  4063.56  \n",
       "1574            18.60  4037.23  \n",
       "1575           440.01  3792.75  \n",
       "1576          -189.12  3630.19  \n",
       "1577          -514.23  3709.27  \n",
       "\n",
       "[1415 rows x 41 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>close_19</th>\n",
       "      <th>close_diff_20_19</th>\n",
       "      <th>close_18</th>\n",
       "      <th>close_diff_20_18</th>\n",
       "      <th>close_17</th>\n",
       "      <th>close_diff_20_17</th>\n",
       "      <th>close_16</th>\n",
       "      <th>close_diff_20_16</th>\n",
       "      <th>close_15</th>\n",
       "      <th>close_diff_20_15</th>\n",
       "      <th>...</th>\n",
       "      <th>close_diff_20_4</th>\n",
       "      <th>close_3</th>\n",
       "      <th>close_diff_20_3</th>\n",
       "      <th>close_2</th>\n",
       "      <th>close_diff_20_2</th>\n",
       "      <th>close_1</th>\n",
       "      <th>close_diff_20_1</th>\n",
       "      <th>close_0</th>\n",
       "      <th>close_diff_20_0</th>\n",
       "      <th>close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1578</th>\n",
       "      <td>4085.97</td>\n",
       "      <td>-503.92</td>\n",
       "      <td>4339.44</td>\n",
       "      <td>-263.91</td>\n",
       "      <td>4269.36</td>\n",
       "      <td>-262.96</td>\n",
       "      <td>4524.85</td>\n",
       "      <td>50.61</td>\n",
       "      <td>4041.2</td>\n",
       "      <td>-476.8</td>\n",
       "      <td>...</td>\n",
       "      <td>18.6</td>\n",
       "      <td>4436.91</td>\n",
       "      <td>440.01</td>\n",
       "      <td>4105.64</td>\n",
       "      <td>-189.12</td>\n",
       "      <td>3897.94</td>\n",
       "      <td>-514.23</td>\n",
       "      <td>4089.37</td>\n",
       "      <td>-168.94</td>\n",
       "      <td>3725.46</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      close_19  close_diff_20_19  close_18  close_diff_20_18  close_17  \\\n",
       "1578   4085.97           -503.92   4339.44           -263.91   4269.36   \n",
       "\n",
       "      close_diff_20_17  close_16  close_diff_20_16  close_15  \\\n",
       "1578           -262.96   4524.85             50.61    4041.2   \n",
       "\n",
       "      close_diff_20_15  ...  close_diff_20_4  close_3  close_diff_20_3  \\\n",
       "1578            -476.8  ...             18.6  4436.91           440.01   \n",
       "\n",
       "      close_2  close_diff_20_2  close_1  close_diff_20_1  close_0  \\\n",
       "1578  4105.64          -189.12  3897.94          -514.23  4089.37   \n",
       "\n",
       "      close_diff_20_0    close  \n",
       "1578          -168.94  3725.46  \n",
       "\n",
       "[1 rows x 41 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (1415, 1, 40) (1415, 1)\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_11 (LSTM)               (None, 1, 300)            409200    \n",
      "_________________________________________________________________\n",
      "lstm_12 (LSTM)               (None, 300)               721200    \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 301       \n",
      "=================================================================\n",
      "Total params: 1,130,701\n",
      "Trainable params: 1,130,701\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Y shape (1415, 1)\n",
      "Train on 1415 samples, validate on 283 samples\n",
      "Epoch 1/100\n",
      " - 5s - loss: 0.0397 - mse: 0.0397 - val_loss: 0.0208 - val_mse: 0.0208\n",
      "Epoch 2/100\n",
      " - 1s - loss: 0.0681 - mse: 0.0681 - val_loss: 0.0317 - val_mse: 0.0317\n",
      "Epoch 3/100\n",
      " - 1s - loss: 0.0159 - mse: 0.0159 - val_loss: 0.0451 - val_mse: 0.0451\n",
      "Epoch 4/100\n",
      " - 1s - loss: 0.0863 - mse: 0.0863 - val_loss: 0.2859 - val_mse: 0.2859\n",
      "Epoch 5/100\n",
      " - 1s - loss: 0.0072 - mse: 0.0072 - val_loss: 0.0176 - val_mse: 0.0176\n",
      "Epoch 6/100\n",
      " - 1s - loss: 0.0088 - mse: 0.0088 - val_loss: 0.0204 - val_mse: 0.0204\n",
      "Epoch 7/100\n",
      " - 1s - loss: 0.0126 - mse: 0.0126 - val_loss: 0.0177 - val_mse: 0.0177\n",
      "Epoch 8/100\n",
      " - 1s - loss: 0.0125 - mse: 0.0125 - val_loss: 0.0228 - val_mse: 0.0228\n",
      "Epoch 9/100\n",
      " - 1s - loss: 0.0295 - mse: 0.0295 - val_loss: 0.0444 - val_mse: 0.0444\n",
      "Epoch 10/100\n",
      " - 1s - loss: 0.0181 - mse: 0.0181 - val_loss: 0.0239 - val_mse: 0.0239\n",
      "Epoch 11/100\n",
      " - 1s - loss: 0.0520 - mse: 0.0520 - val_loss: 0.1514 - val_mse: 0.1514\n",
      "Epoch 12/100\n",
      " - 1s - loss: 0.0057 - mse: 0.0057 - val_loss: 0.0182 - val_mse: 0.0182\n",
      "Epoch 13/100\n",
      " - 1s - loss: 0.0062 - mse: 0.0062 - val_loss: 0.0178 - val_mse: 0.0178\n",
      "Epoch 14/100\n",
      " - 1s - loss: 0.0053 - mse: 0.0053 - val_loss: 0.0175 - val_mse: 0.0175\n",
      "Epoch 15/100\n",
      " - 1s - loss: 0.0052 - mse: 0.0052 - val_loss: 0.0173 - val_mse: 0.0173\n",
      "Epoch 16/100\n",
      " - 1s - loss: 0.0052 - mse: 0.0052 - val_loss: 0.0171 - val_mse: 0.0171\n",
      "Epoch 17/100\n",
      " - 1s - loss: 0.0052 - mse: 0.0052 - val_loss: 0.0169 - val_mse: 0.0169\n",
      "Epoch 18/100\n",
      " - 1s - loss: 0.0052 - mse: 0.0052 - val_loss: 0.0167 - val_mse: 0.0167\n",
      "Epoch 19/100\n",
      " - 1s - loss: 0.0056 - mse: 0.0056 - val_loss: 0.0166 - val_mse: 0.0166\n",
      "Epoch 20/100\n",
      " - 1s - loss: 0.0064 - mse: 0.0064 - val_loss: 0.0166 - val_mse: 0.0166\n",
      "Epoch 21/100\n",
      " - 1s - loss: 0.0077 - mse: 0.0077 - val_loss: 0.0172 - val_mse: 0.0172\n",
      "Epoch 22/100\n",
      " - 1s - loss: 0.0173 - mse: 0.0173 - val_loss: 0.0290 - val_mse: 0.0290\n",
      "Epoch 23/100\n",
      " - 1s - loss: 0.0150 - mse: 0.0150 - val_loss: 0.0207 - val_mse: 0.0207\n",
      "Epoch 24/100\n",
      " - 1s - loss: 0.0407 - mse: 0.0407 - val_loss: 0.0986 - val_mse: 0.0986\n",
      "Epoch 25/100\n",
      " - 1s - loss: 0.0085 - mse: 0.0085 - val_loss: 0.0178 - val_mse: 0.0178\n",
      "Epoch 26/100\n",
      " - 1s - loss: 0.0106 - mse: 0.0106 - val_loss: 0.0219 - val_mse: 0.0219\n",
      "Epoch 27/100\n",
      " - 1s - loss: 0.0103 - mse: 0.0103 - val_loss: 0.0176 - val_mse: 0.0176\n",
      "Epoch 28/100\n",
      " - 1s - loss: 0.0156 - mse: 0.0156 - val_loss: 0.0352 - val_mse: 0.0352\n",
      "Epoch 29/100\n",
      " - 1s - loss: 0.0097 - mse: 0.0097 - val_loss: 0.0175 - val_mse: 0.0175\n",
      "Epoch 30/100\n",
      " - 1s - loss: 0.0151 - mse: 0.0151 - val_loss: 0.0327 - val_mse: 0.0327\n",
      "Epoch 31/100\n",
      " - 1s - loss: 0.0087 - mse: 0.0087 - val_loss: 0.0177 - val_mse: 0.0177\n",
      "Epoch 32/100\n",
      " - 1s - loss: 0.0137 - mse: 0.0137 - val_loss: 0.0302 - val_mse: 0.0302\n",
      "Epoch 33/100\n",
      " - 1s - loss: 0.0083 - mse: 0.0083 - val_loss: 0.0178 - val_mse: 0.0178\n",
      "Epoch 34/100\n",
      " - 1s - loss: 0.0123 - mse: 0.0123 - val_loss: 0.0277 - val_mse: 0.0277\n",
      "Epoch 35/100\n",
      " - 1s - loss: 0.0078 - mse: 0.0078 - val_loss: 0.0178 - val_mse: 0.0178\n",
      "Epoch 36/100\n",
      " - 1s - loss: 0.0105 - mse: 0.0105 - val_loss: 0.0238 - val_mse: 0.0238\n",
      "Epoch 37/100\n",
      " - 1s - loss: 0.0075 - mse: 0.0075 - val_loss: 0.0176 - val_mse: 0.0176\n",
      "Epoch 38/100\n",
      " - 1s - loss: 0.0099 - mse: 0.0099 - val_loss: 0.0222 - val_mse: 0.0222\n",
      "Epoch 39/100\n",
      " - 1s - loss: 0.0070 - mse: 0.0070 - val_loss: 0.0174 - val_mse: 0.0174\n",
      "Epoch 40/100\n",
      " - 1s - loss: 0.0097 - mse: 0.0097 - val_loss: 0.0215 - val_mse: 0.0215\n",
      "Epoch 41/100\n",
      " - 1s - loss: 0.0073 - mse: 0.0073 - val_loss: 0.0173 - val_mse: 0.0173\n",
      "real [[3725.46]]\n",
      "Test RMSE: 307.338\n",
      "Diff [[-307.33805097]]\n",
      "% Diff [[-8.24966718]] %\n",
      "Predictions [[4032.79805097]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "layers = 1\n",
    "neurons = [300, 300]\n",
    "\n",
    "columns = columns_12\n",
    "num_features = len(columns)\n",
    "\n",
    "crypto = crypto\n",
    "execute_test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nos quedaremos con dos capas ocultas y 300 + 150 neuronas. Probemos sin early stop porque nos esta impidiendo llegar a minimos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading... ETH\n",
      "Extracting columns columns for ETH\n",
      "Proccessing and arranging columns for LSTM model\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>close_19</th>\n",
       "      <th>close_diff_20_19</th>\n",
       "      <th>close_18</th>\n",
       "      <th>close_diff_20_18</th>\n",
       "      <th>close_17</th>\n",
       "      <th>close_diff_20_17</th>\n",
       "      <th>close_16</th>\n",
       "      <th>close_diff_20_16</th>\n",
       "      <th>close_15</th>\n",
       "      <th>close_diff_20_15</th>\n",
       "      <th>...</th>\n",
       "      <th>close_diff_20_4</th>\n",
       "      <th>close_3</th>\n",
       "      <th>close_diff_20_3</th>\n",
       "      <th>close_2</th>\n",
       "      <th>close_diff_20_2</th>\n",
       "      <th>close_1</th>\n",
       "      <th>close_diff_20_1</th>\n",
       "      <th>close_0</th>\n",
       "      <th>close_diff_20_0</th>\n",
       "      <th>close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>1123.09</td>\n",
       "      <td>339.09</td>\n",
       "      <td>1133.18</td>\n",
       "      <td>335.18</td>\n",
       "      <td>1291.00</td>\n",
       "      <td>500.79</td>\n",
       "      <td>1247.00</td>\n",
       "      <td>464.59</td>\n",
       "      <td>1138.93</td>\n",
       "      <td>502.96</td>\n",
       "      <td>...</td>\n",
       "      <td>137.72</td>\n",
       "      <td>980.00</td>\n",
       "      <td>45.97</td>\n",
       "      <td>1061.00</td>\n",
       "      <td>121.00</td>\n",
       "      <td>1056.52</td>\n",
       "      <td>97.22</td>\n",
       "      <td>1051.03</td>\n",
       "      <td>46.92</td>\n",
       "      <td>924.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>1133.18</td>\n",
       "      <td>335.18</td>\n",
       "      <td>1291.00</td>\n",
       "      <td>500.79</td>\n",
       "      <td>1247.00</td>\n",
       "      <td>464.59</td>\n",
       "      <td>1138.93</td>\n",
       "      <td>502.96</td>\n",
       "      <td>1253.87</td>\n",
       "      <td>613.53</td>\n",
       "      <td>...</td>\n",
       "      <td>45.97</td>\n",
       "      <td>1061.00</td>\n",
       "      <td>121.00</td>\n",
       "      <td>1056.52</td>\n",
       "      <td>97.22</td>\n",
       "      <td>1051.03</td>\n",
       "      <td>46.92</td>\n",
       "      <td>1118.99</td>\n",
       "      <td>-4.10</td>\n",
       "      <td>938.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>1291.00</td>\n",
       "      <td>500.79</td>\n",
       "      <td>1247.00</td>\n",
       "      <td>464.59</td>\n",
       "      <td>1138.93</td>\n",
       "      <td>502.96</td>\n",
       "      <td>1253.87</td>\n",
       "      <td>613.53</td>\n",
       "      <td>1388.02</td>\n",
       "      <td>730.02</td>\n",
       "      <td>...</td>\n",
       "      <td>121.00</td>\n",
       "      <td>1056.52</td>\n",
       "      <td>97.22</td>\n",
       "      <td>1051.03</td>\n",
       "      <td>46.92</td>\n",
       "      <td>1118.99</td>\n",
       "      <td>-4.10</td>\n",
       "      <td>1251.96</td>\n",
       "      <td>118.78</td>\n",
       "      <td>969.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>1247.00</td>\n",
       "      <td>464.59</td>\n",
       "      <td>1138.93</td>\n",
       "      <td>502.96</td>\n",
       "      <td>1253.87</td>\n",
       "      <td>613.53</td>\n",
       "      <td>1388.02</td>\n",
       "      <td>730.02</td>\n",
       "      <td>1347.00</td>\n",
       "      <td>632.05</td>\n",
       "      <td>...</td>\n",
       "      <td>97.22</td>\n",
       "      <td>1051.03</td>\n",
       "      <td>46.92</td>\n",
       "      <td>1118.99</td>\n",
       "      <td>-4.10</td>\n",
       "      <td>1251.96</td>\n",
       "      <td>118.78</td>\n",
       "      <td>1177.01</td>\n",
       "      <td>-113.99</td>\n",
       "      <td>911.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>1138.93</td>\n",
       "      <td>502.96</td>\n",
       "      <td>1253.87</td>\n",
       "      <td>613.53</td>\n",
       "      <td>1388.02</td>\n",
       "      <td>730.02</td>\n",
       "      <td>1347.00</td>\n",
       "      <td>632.05</td>\n",
       "      <td>1271.00</td>\n",
       "      <td>521.00</td>\n",
       "      <td>...</td>\n",
       "      <td>46.92</td>\n",
       "      <td>1118.99</td>\n",
       "      <td>-4.10</td>\n",
       "      <td>1251.96</td>\n",
       "      <td>118.78</td>\n",
       "      <td>1177.01</td>\n",
       "      <td>-113.99</td>\n",
       "      <td>1085.50</td>\n",
       "      <td>-161.50</td>\n",
       "      <td>938.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1573</th>\n",
       "      <td>4287.80</td>\n",
       "      <td>1.78</td>\n",
       "      <td>3996.90</td>\n",
       "      <td>-421.99</td>\n",
       "      <td>4294.76</td>\n",
       "      <td>-27.92</td>\n",
       "      <td>4412.17</td>\n",
       "      <td>124.96</td>\n",
       "      <td>4258.31</td>\n",
       "      <td>-61.12</td>\n",
       "      <td>...</td>\n",
       "      <td>-154.25</td>\n",
       "      <td>4215.73</td>\n",
       "      <td>-428.55</td>\n",
       "      <td>4117.25</td>\n",
       "      <td>-509.25</td>\n",
       "      <td>4196.44</td>\n",
       "      <td>-367.34</td>\n",
       "      <td>4347.59</td>\n",
       "      <td>137.83</td>\n",
       "      <td>4063.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1574</th>\n",
       "      <td>3996.90</td>\n",
       "      <td>-421.99</td>\n",
       "      <td>4294.76</td>\n",
       "      <td>-27.92</td>\n",
       "      <td>4412.17</td>\n",
       "      <td>124.96</td>\n",
       "      <td>4258.31</td>\n",
       "      <td>-61.12</td>\n",
       "      <td>4085.97</td>\n",
       "      <td>-503.92</td>\n",
       "      <td>...</td>\n",
       "      <td>-428.55</td>\n",
       "      <td>4117.25</td>\n",
       "      <td>-509.25</td>\n",
       "      <td>4196.44</td>\n",
       "      <td>-367.34</td>\n",
       "      <td>4347.59</td>\n",
       "      <td>137.83</td>\n",
       "      <td>4306.40</td>\n",
       "      <td>18.60</td>\n",
       "      <td>4037.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1575</th>\n",
       "      <td>4294.76</td>\n",
       "      <td>-27.92</td>\n",
       "      <td>4412.17</td>\n",
       "      <td>124.96</td>\n",
       "      <td>4258.31</td>\n",
       "      <td>-61.12</td>\n",
       "      <td>4085.97</td>\n",
       "      <td>-503.92</td>\n",
       "      <td>4339.44</td>\n",
       "      <td>-263.91</td>\n",
       "      <td>...</td>\n",
       "      <td>-509.25</td>\n",
       "      <td>4196.44</td>\n",
       "      <td>-367.34</td>\n",
       "      <td>4347.59</td>\n",
       "      <td>137.83</td>\n",
       "      <td>4306.40</td>\n",
       "      <td>18.60</td>\n",
       "      <td>4436.91</td>\n",
       "      <td>440.01</td>\n",
       "      <td>3792.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1576</th>\n",
       "      <td>4412.17</td>\n",
       "      <td>124.96</td>\n",
       "      <td>4258.31</td>\n",
       "      <td>-61.12</td>\n",
       "      <td>4085.97</td>\n",
       "      <td>-503.92</td>\n",
       "      <td>4339.44</td>\n",
       "      <td>-263.91</td>\n",
       "      <td>4269.36</td>\n",
       "      <td>-262.96</td>\n",
       "      <td>...</td>\n",
       "      <td>-367.34</td>\n",
       "      <td>4347.59</td>\n",
       "      <td>137.83</td>\n",
       "      <td>4306.40</td>\n",
       "      <td>18.60</td>\n",
       "      <td>4436.91</td>\n",
       "      <td>440.01</td>\n",
       "      <td>4105.64</td>\n",
       "      <td>-189.12</td>\n",
       "      <td>3630.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1577</th>\n",
       "      <td>4258.31</td>\n",
       "      <td>-61.12</td>\n",
       "      <td>4085.97</td>\n",
       "      <td>-503.92</td>\n",
       "      <td>4339.44</td>\n",
       "      <td>-263.91</td>\n",
       "      <td>4269.36</td>\n",
       "      <td>-262.96</td>\n",
       "      <td>4524.85</td>\n",
       "      <td>50.61</td>\n",
       "      <td>...</td>\n",
       "      <td>137.83</td>\n",
       "      <td>4306.40</td>\n",
       "      <td>18.60</td>\n",
       "      <td>4436.91</td>\n",
       "      <td>440.01</td>\n",
       "      <td>4105.64</td>\n",
       "      <td>-189.12</td>\n",
       "      <td>3897.94</td>\n",
       "      <td>-514.23</td>\n",
       "      <td>3709.27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1415 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      close_19  close_diff_20_19  close_18  close_diff_20_18  close_17  \\\n",
       "163    1123.09            339.09   1133.18            335.18   1291.00   \n",
       "164    1133.18            335.18   1291.00            500.79   1247.00   \n",
       "165    1291.00            500.79   1247.00            464.59   1138.93   \n",
       "166    1247.00            464.59   1138.93            502.96   1253.87   \n",
       "167    1138.93            502.96   1253.87            613.53   1388.02   \n",
       "...        ...               ...       ...               ...       ...   \n",
       "1573   4287.80              1.78   3996.90           -421.99   4294.76   \n",
       "1574   3996.90           -421.99   4294.76            -27.92   4412.17   \n",
       "1575   4294.76            -27.92   4412.17            124.96   4258.31   \n",
       "1576   4412.17            124.96   4258.31            -61.12   4085.97   \n",
       "1577   4258.31            -61.12   4085.97           -503.92   4339.44   \n",
       "\n",
       "      close_diff_20_17  close_16  close_diff_20_16  close_15  \\\n",
       "163             500.79   1247.00            464.59   1138.93   \n",
       "164             464.59   1138.93            502.96   1253.87   \n",
       "165             502.96   1253.87            613.53   1388.02   \n",
       "166             613.53   1388.02            730.02   1347.00   \n",
       "167             730.02   1347.00            632.05   1271.00   \n",
       "...                ...       ...               ...       ...   \n",
       "1573            -27.92   4412.17            124.96   4258.31   \n",
       "1574            124.96   4258.31            -61.12   4085.97   \n",
       "1575            -61.12   4085.97           -503.92   4339.44   \n",
       "1576           -503.92   4339.44           -263.91   4269.36   \n",
       "1577           -263.91   4269.36           -262.96   4524.85   \n",
       "\n",
       "      close_diff_20_15  ...  close_diff_20_4  close_3  close_diff_20_3  \\\n",
       "163             502.96  ...           137.72   980.00            45.97   \n",
       "164             613.53  ...            45.97  1061.00           121.00   \n",
       "165             730.02  ...           121.00  1056.52            97.22   \n",
       "166             632.05  ...            97.22  1051.03            46.92   \n",
       "167             521.00  ...            46.92  1118.99            -4.10   \n",
       "...                ...  ...              ...      ...              ...   \n",
       "1573            -61.12  ...          -154.25  4215.73          -428.55   \n",
       "1574           -503.92  ...          -428.55  4117.25          -509.25   \n",
       "1575           -263.91  ...          -509.25  4196.44          -367.34   \n",
       "1576           -262.96  ...          -367.34  4347.59           137.83   \n",
       "1577             50.61  ...           137.83  4306.40            18.60   \n",
       "\n",
       "      close_2  close_diff_20_2  close_1  close_diff_20_1  close_0  \\\n",
       "163   1061.00           121.00  1056.52            97.22  1051.03   \n",
       "164   1056.52            97.22  1051.03            46.92  1118.99   \n",
       "165   1051.03            46.92  1118.99            -4.10  1251.96   \n",
       "166   1118.99            -4.10  1251.96           118.78  1177.01   \n",
       "167   1251.96           118.78  1177.01          -113.99  1085.50   \n",
       "...       ...              ...      ...              ...      ...   \n",
       "1573  4117.25          -509.25  4196.44          -367.34  4347.59   \n",
       "1574  4196.44          -367.34  4347.59           137.83  4306.40   \n",
       "1575  4347.59           137.83  4306.40            18.60  4436.91   \n",
       "1576  4306.40            18.60  4436.91           440.01  4105.64   \n",
       "1577  4436.91           440.01  4105.64          -189.12  3897.94   \n",
       "\n",
       "      close_diff_20_0    close  \n",
       "163             46.92   924.55  \n",
       "164             -4.10   938.67  \n",
       "165            118.78   969.99  \n",
       "166           -113.99   911.00  \n",
       "167           -161.50   938.11  \n",
       "...               ...      ...  \n",
       "1573           137.83  4063.56  \n",
       "1574            18.60  4037.23  \n",
       "1575           440.01  3792.75  \n",
       "1576          -189.12  3630.19  \n",
       "1577          -514.23  3709.27  \n",
       "\n",
       "[1415 rows x 41 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>close_19</th>\n",
       "      <th>close_diff_20_19</th>\n",
       "      <th>close_18</th>\n",
       "      <th>close_diff_20_18</th>\n",
       "      <th>close_17</th>\n",
       "      <th>close_diff_20_17</th>\n",
       "      <th>close_16</th>\n",
       "      <th>close_diff_20_16</th>\n",
       "      <th>close_15</th>\n",
       "      <th>close_diff_20_15</th>\n",
       "      <th>...</th>\n",
       "      <th>close_diff_20_4</th>\n",
       "      <th>close_3</th>\n",
       "      <th>close_diff_20_3</th>\n",
       "      <th>close_2</th>\n",
       "      <th>close_diff_20_2</th>\n",
       "      <th>close_1</th>\n",
       "      <th>close_diff_20_1</th>\n",
       "      <th>close_0</th>\n",
       "      <th>close_diff_20_0</th>\n",
       "      <th>close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1578</th>\n",
       "      <td>4085.97</td>\n",
       "      <td>-503.92</td>\n",
       "      <td>4339.44</td>\n",
       "      <td>-263.91</td>\n",
       "      <td>4269.36</td>\n",
       "      <td>-262.96</td>\n",
       "      <td>4524.85</td>\n",
       "      <td>50.61</td>\n",
       "      <td>4041.2</td>\n",
       "      <td>-476.8</td>\n",
       "      <td>...</td>\n",
       "      <td>18.6</td>\n",
       "      <td>4436.91</td>\n",
       "      <td>440.01</td>\n",
       "      <td>4105.64</td>\n",
       "      <td>-189.12</td>\n",
       "      <td>3897.94</td>\n",
       "      <td>-514.23</td>\n",
       "      <td>4089.37</td>\n",
       "      <td>-168.94</td>\n",
       "      <td>3725.46</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      close_19  close_diff_20_19  close_18  close_diff_20_18  close_17  \\\n",
       "1578   4085.97           -503.92   4339.44           -263.91   4269.36   \n",
       "\n",
       "      close_diff_20_17  close_16  close_diff_20_16  close_15  \\\n",
       "1578           -262.96   4524.85             50.61    4041.2   \n",
       "\n",
       "      close_diff_20_15  ...  close_diff_20_4  close_3  close_diff_20_3  \\\n",
       "1578            -476.8  ...             18.6  4436.91           440.01   \n",
       "\n",
       "      close_2  close_diff_20_2  close_1  close_diff_20_1  close_0  \\\n",
       "1578  4105.64          -189.12  3897.94          -514.23  4089.37   \n",
       "\n",
       "      close_diff_20_0    close  \n",
       "1578          -168.94  3725.46  \n",
       "\n",
       "[1 rows x 41 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (1415, 1, 40) (1415, 1)\n",
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_20 (LSTM)               (None, 1, 300)            409200    \n",
      "_________________________________________________________________\n",
      "lstm_21 (LSTM)               (None, 150)               270600    \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 150)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1)                 151       \n",
      "=================================================================\n",
      "Total params: 679,951\n",
      "Trainable params: 679,951\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Y shape (1415, 1)\n",
      "Train on 1415 samples, validate on 283 samples\n",
      "Epoch 1/100\n",
      " - 5s - loss: 0.0803 - mse: 0.0803 - val_loss: 0.1985 - val_mse: 0.1985\n",
      "Epoch 2/100\n",
      " - 1s - loss: 0.0126 - mse: 0.0126 - val_loss: 0.0281 - val_mse: 0.0281\n",
      "Epoch 3/100\n",
      " - 1s - loss: 0.0244 - mse: 0.0244 - val_loss: 0.0184 - val_mse: 0.0184\n",
      "Epoch 4/100\n",
      " - 1s - loss: 0.0213 - mse: 0.0213 - val_loss: 0.0455 - val_mse: 0.0455\n",
      "Epoch 5/100\n",
      " - 1s - loss: 0.0807 - mse: 0.0807 - val_loss: 0.2464 - val_mse: 0.2464\n",
      "Epoch 6/100\n",
      " - 1s - loss: 0.0061 - mse: 0.0061 - val_loss: 0.0177 - val_mse: 0.0177\n",
      "Epoch 7/100\n",
      " - 1s - loss: 0.0074 - mse: 0.0074 - val_loss: 0.0181 - val_mse: 0.0181\n",
      "Epoch 8/100\n",
      " - 1s - loss: 0.0076 - mse: 0.0076 - val_loss: 0.0185 - val_mse: 0.0185\n",
      "Epoch 9/100\n",
      " - 1s - loss: 0.0162 - mse: 0.0162 - val_loss: 0.0266 - val_mse: 0.0266\n",
      "Epoch 10/100\n",
      " - 1s - loss: 0.0157 - mse: 0.0157 - val_loss: 0.0235 - val_mse: 0.0235\n",
      "Epoch 11/100\n",
      " - 1s - loss: 0.0500 - mse: 0.0500 - val_loss: 0.1390 - val_mse: 0.1390\n",
      "Epoch 12/100\n",
      " - 1s - loss: 0.0060 - mse: 0.0060 - val_loss: 0.0181 - val_mse: 0.0181\n",
      "Epoch 13/100\n",
      " - 1s - loss: 0.0067 - mse: 0.0067 - val_loss: 0.0177 - val_mse: 0.0177\n",
      "Epoch 14/100\n",
      " - 1s - loss: 0.0056 - mse: 0.0056 - val_loss: 0.0175 - val_mse: 0.0175\n",
      "Epoch 15/100\n",
      " - 1s - loss: 0.0057 - mse: 0.0057 - val_loss: 0.0179 - val_mse: 0.0179\n",
      "Epoch 16/100\n",
      " - 1s - loss: 0.0057 - mse: 0.0057 - val_loss: 0.0171 - val_mse: 0.0171\n",
      "Epoch 17/100\n",
      " - 1s - loss: 0.0070 - mse: 0.0070 - val_loss: 0.0180 - val_mse: 0.0180\n",
      "Epoch 18/100\n",
      " - 1s - loss: 0.0073 - mse: 0.0073 - val_loss: 0.0170 - val_mse: 0.0170\n",
      "Epoch 19/100\n",
      " - 1s - loss: 0.0131 - mse: 0.0131 - val_loss: 0.0250 - val_mse: 0.0250\n",
      "Epoch 20/100\n",
      " - 1s - loss: 0.0116 - mse: 0.0116 - val_loss: 0.0179 - val_mse: 0.0179\n",
      "Epoch 21/100\n",
      " - 1s - loss: 0.0239 - mse: 0.0239 - val_loss: 0.0498 - val_mse: 0.0498\n",
      "Epoch 22/100\n",
      " - 1s - loss: 0.0105 - mse: 0.0105 - val_loss: 0.0176 - val_mse: 0.0176\n",
      "Epoch 23/100\n",
      " - 1s - loss: 0.0171 - mse: 0.0171 - val_loss: 0.0356 - val_mse: 0.0356\n",
      "Epoch 24/100\n",
      " - 1s - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0181 - val_mse: 0.0181\n",
      "Epoch 25/100\n",
      " - 1s - loss: 0.0126 - mse: 0.0126 - val_loss: 0.0275 - val_mse: 0.0275\n",
      "Epoch 26/100\n",
      " - 1s - loss: 0.0088 - mse: 0.0088 - val_loss: 0.0178 - val_mse: 0.0178\n",
      "Epoch 27/100\n",
      " - 1s - loss: 0.0123 - mse: 0.0123 - val_loss: 0.0275 - val_mse: 0.0275\n",
      "Epoch 28/100\n",
      " - 1s - loss: 0.0081 - mse: 0.0081 - val_loss: 0.0178 - val_mse: 0.0178\n",
      "Epoch 29/100\n",
      " - 1s - loss: 0.0109 - mse: 0.0109 - val_loss: 0.0241 - val_mse: 0.0241\n",
      "Epoch 30/100\n",
      " - 1s - loss: 0.0071 - mse: 0.0071 - val_loss: 0.0178 - val_mse: 0.0178\n",
      "Epoch 31/100\n",
      " - 1s - loss: 0.0090 - mse: 0.0090 - val_loss: 0.0206 - val_mse: 0.0206\n",
      "Epoch 32/100\n",
      " - 1s - loss: 0.0071 - mse: 0.0071 - val_loss: 0.0173 - val_mse: 0.0173\n",
      "Epoch 33/100\n",
      " - 1s - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0211 - val_mse: 0.0211\n",
      "Epoch 34/100\n",
      " - 1s - loss: 0.0071 - mse: 0.0071 - val_loss: 0.0171 - val_mse: 0.0171\n",
      "Epoch 35/100\n",
      " - 1s - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0212 - val_mse: 0.0212\n",
      "Epoch 36/100\n",
      " - 1s - loss: 0.0073 - mse: 0.0073 - val_loss: 0.0171 - val_mse: 0.0171\n",
      "Epoch 37/100\n",
      " - 1s - loss: 0.0102 - mse: 0.0102 - val_loss: 0.0222 - val_mse: 0.0222\n",
      "Epoch 38/100\n",
      " - 1s - loss: 0.0073 - mse: 0.0073 - val_loss: 0.0170 - val_mse: 0.0170\n",
      "Epoch 39/100\n",
      " - 1s - loss: 0.0105 - mse: 0.0105 - val_loss: 0.0221 - val_mse: 0.0221\n",
      "Epoch 40/100\n",
      " - 1s - loss: 0.0075 - mse: 0.0075 - val_loss: 0.0171 - val_mse: 0.0171\n",
      "Epoch 41/100\n",
      " - 1s - loss: 0.0102 - mse: 0.0102 - val_loss: 0.0225 - val_mse: 0.0225\n",
      "Epoch 42/100\n",
      " - 1s - loss: 0.0067 - mse: 0.0067 - val_loss: 0.0170 - val_mse: 0.0170\n",
      "Epoch 43/100\n",
      " - 1s - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0213 - val_mse: 0.0213\n",
      "Epoch 44/100\n",
      " - 1s - loss: 0.0066 - mse: 0.0066 - val_loss: 0.0170 - val_mse: 0.0170\n",
      "Epoch 45/100\n",
      " - 1s - loss: 0.0091 - mse: 0.0091 - val_loss: 0.0209 - val_mse: 0.0209\n",
      "Epoch 46/100\n",
      " - 1s - loss: 0.0065 - mse: 0.0065 - val_loss: 0.0169 - val_mse: 0.0169\n",
      "Epoch 47/100\n",
      " - 1s - loss: 0.0083 - mse: 0.0083 - val_loss: 0.0198 - val_mse: 0.0198\n",
      "Epoch 48/100\n",
      " - 1s - loss: 0.0064 - mse: 0.0064 - val_loss: 0.0167 - val_mse: 0.0167\n",
      "Epoch 49/100\n",
      " - 1s - loss: 0.0084 - mse: 0.0084 - val_loss: 0.0196 - val_mse: 0.0196\n",
      "Epoch 50/100\n",
      " - 1s - loss: 0.0062 - mse: 0.0062 - val_loss: 0.0167 - val_mse: 0.0167\n",
      "Epoch 51/100\n",
      " - 1s - loss: 0.0081 - mse: 0.0081 - val_loss: 0.0186 - val_mse: 0.0186\n",
      "Epoch 52/100\n",
      " - 1s - loss: 0.0063 - mse: 0.0063 - val_loss: 0.0165 - val_mse: 0.0165\n",
      "Epoch 53/100\n",
      " - 1s - loss: 0.0087 - mse: 0.0087 - val_loss: 0.0200 - val_mse: 0.0200\n",
      "Epoch 54/100\n",
      " - 1s - loss: 0.0068 - mse: 0.0068 - val_loss: 0.0166 - val_mse: 0.0166\n",
      "Epoch 55/100\n",
      " - 1s - loss: 0.0093 - mse: 0.0093 - val_loss: 0.0206 - val_mse: 0.0206\n",
      "Epoch 56/100\n",
      " - 1s - loss: 0.0066 - mse: 0.0066 - val_loss: 0.0164 - val_mse: 0.0164\n",
      "Epoch 57/100\n",
      " - 1s - loss: 0.0088 - mse: 0.0088 - val_loss: 0.0200 - val_mse: 0.0200\n",
      "Epoch 58/100\n",
      " - 1s - loss: 0.0062 - mse: 0.0062 - val_loss: 0.0165 - val_mse: 0.0165\n",
      "Epoch 59/100\n",
      " - 1s - loss: 0.0091 - mse: 0.0091 - val_loss: 0.0205 - val_mse: 0.0205\n",
      "Epoch 60/100\n",
      " - 1s - loss: 0.0064 - mse: 0.0064 - val_loss: 0.0165 - val_mse: 0.0165\n",
      "Epoch 61/100\n",
      " - 1s - loss: 0.0080 - mse: 0.0080 - val_loss: 0.0187 - val_mse: 0.0187\n",
      "Epoch 62/100\n",
      " - 1s - loss: 0.0067 - mse: 0.0067 - val_loss: 0.0163 - val_mse: 0.0163\n",
      "Epoch 63/100\n",
      " - 1s - loss: 0.0082 - mse: 0.0082 - val_loss: 0.0190 - val_mse: 0.0190\n",
      "Epoch 64/100\n",
      " - 1s - loss: 0.0060 - mse: 0.0060 - val_loss: 0.0162 - val_mse: 0.0162\n",
      "Epoch 65/100\n",
      " - 1s - loss: 0.0079 - mse: 0.0079 - val_loss: 0.0183 - val_mse: 0.0183\n",
      "Epoch 66/100\n",
      " - 1s - loss: 0.0063 - mse: 0.0063 - val_loss: 0.0162 - val_mse: 0.0162\n",
      "Epoch 67/100\n",
      " - 1s - loss: 0.0083 - mse: 0.0083 - val_loss: 0.0193 - val_mse: 0.0193\n",
      "Epoch 68/100\n",
      " - 1s - loss: 0.0062 - mse: 0.0062 - val_loss: 0.0161 - val_mse: 0.0161\n",
      "Epoch 69/100\n",
      " - 1s - loss: 0.0082 - mse: 0.0082 - val_loss: 0.0187 - val_mse: 0.0187\n",
      "Epoch 70/100\n",
      " - 1s - loss: 0.0062 - mse: 0.0062 - val_loss: 0.0162 - val_mse: 0.0162\n",
      "Epoch 71/100\n",
      " - 1s - loss: 0.0076 - mse: 0.0076 - val_loss: 0.0178 - val_mse: 0.0178\n",
      "Epoch 72/100\n",
      " - 1s - loss: 0.0059 - mse: 0.0059 - val_loss: 0.0160 - val_mse: 0.0160\n",
      "Epoch 73/100\n",
      " - 1s - loss: 0.0081 - mse: 0.0081 - val_loss: 0.0186 - val_mse: 0.0186\n",
      "Epoch 74/100\n",
      " - 1s - loss: 0.0059 - mse: 0.0059 - val_loss: 0.0160 - val_mse: 0.0160\n",
      "Epoch 75/100\n",
      " - 1s - loss: 0.0067 - mse: 0.0067 - val_loss: 0.0169 - val_mse: 0.0169\n",
      "Epoch 76/100\n",
      " - 1s - loss: 0.0056 - mse: 0.0056 - val_loss: 0.0158 - val_mse: 0.0158\n",
      "Epoch 77/100\n",
      " - 1s - loss: 0.0069 - mse: 0.0069 - val_loss: 0.0169 - val_mse: 0.0169\n",
      "Epoch 78/100\n",
      " - 1s - loss: 0.0061 - mse: 0.0061 - val_loss: 0.0159 - val_mse: 0.0159\n",
      "Epoch 79/100\n",
      " - 1s - loss: 0.0075 - mse: 0.0075 - val_loss: 0.0179 - val_mse: 0.0179\n",
      "Epoch 80/100\n",
      " - 1s - loss: 0.0061 - mse: 0.0061 - val_loss: 0.0158 - val_mse: 0.0158\n",
      "Epoch 81/100\n",
      " - 1s - loss: 0.0071 - mse: 0.0071 - val_loss: 0.0174 - val_mse: 0.0174\n",
      "Epoch 82/100\n",
      " - 1s - loss: 0.0058 - mse: 0.0058 - val_loss: 0.0157 - val_mse: 0.0157\n",
      "Epoch 83/100\n",
      " - 1s - loss: 0.0069 - mse: 0.0069 - val_loss: 0.0171 - val_mse: 0.0171\n",
      "Epoch 84/100\n",
      " - 1s - loss: 0.0057 - mse: 0.0057 - val_loss: 0.0156 - val_mse: 0.0156\n",
      "Epoch 85/100\n",
      " - 1s - loss: 0.0062 - mse: 0.0062 - val_loss: 0.0162 - val_mse: 0.0162\n",
      "Epoch 86/100\n",
      " - 1s - loss: 0.0049 - mse: 0.0049 - val_loss: 0.0155 - val_mse: 0.0155\n",
      "Epoch 87/100\n",
      " - 1s - loss: 0.0060 - mse: 0.0060 - val_loss: 0.0164 - val_mse: 0.0164\n",
      "Epoch 88/100\n",
      " - 1s - loss: 0.0053 - mse: 0.0053 - val_loss: 0.0154 - val_mse: 0.0154\n",
      "Epoch 89/100\n",
      " - 1s - loss: 0.0054 - mse: 0.0054 - val_loss: 0.0158 - val_mse: 0.0158\n",
      "Epoch 90/100\n",
      " - 1s - loss: 0.0050 - mse: 0.0050 - val_loss: 0.0153 - val_mse: 0.0153\n",
      "Epoch 91/100\n",
      " - 1s - loss: 0.0049 - mse: 0.0049 - val_loss: 0.0152 - val_mse: 0.0152\n",
      "Epoch 92/100\n",
      " - 1s - loss: 0.0047 - mse: 0.0047 - val_loss: 0.0151 - val_mse: 0.0151\n",
      "Epoch 93/100\n",
      " - 1s - loss: 0.0047 - mse: 0.0047 - val_loss: 0.0151 - val_mse: 0.0151\n",
      "Epoch 94/100\n",
      " - 1s - loss: 0.0050 - mse: 0.0050 - val_loss: 0.0151 - val_mse: 0.0151\n",
      "Epoch 95/100\n",
      " - 1s - loss: 0.0048 - mse: 0.0048 - val_loss: 0.0153 - val_mse: 0.0153\n",
      "Epoch 96/100\n",
      " - 1s - loss: 0.0051 - mse: 0.0051 - val_loss: 0.0151 - val_mse: 0.0151\n",
      "Epoch 97/100\n",
      " - 1s - loss: 0.0046 - mse: 0.0046 - val_loss: 0.0149 - val_mse: 0.0149\n",
      "Epoch 98/100\n",
      " - 1s - loss: 0.0048 - mse: 0.0048 - val_loss: 0.0150 - val_mse: 0.0150\n",
      "Epoch 99/100\n",
      " - 1s - loss: 0.0043 - mse: 0.0043 - val_loss: 0.0149 - val_mse: 0.0149\n",
      "Epoch 100/100\n",
      " - 1s - loss: 0.0046 - mse: 0.0046 - val_loss: 0.0149 - val_mse: 0.0149\n",
      "real [[3725.46]]\n",
      "Test RMSE: 323.388\n",
      "Diff [[-323.38757715]]\n",
      "% Diff [[-8.68047374]] %\n",
      "Predictions [[4048.84757715]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "layers = 1\n",
    "neurons = [300, 150]\n",
    "\n",
    "callbacks = ['mc']\n",
    "\n",
    "columns = columns_12\n",
    "num_features = len(columns)\n",
    "\n",
    "crypto = crypto\n",
    "execute_test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hemos obtenido una buena configuración con:\n",
    "\n",
    "2 capas ocultas\n",
    "\n",
    "300 base\n",
    "\n",
    "150 + 75 en capas ocultas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como columnas seguiremos usando el precio como tal dado que los resultados han sido buenos. Si encontraramos dificultades podriamos volver a usar EMA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Añadimos/quitamos ad hoc en el modelo capas de dropout y su activación\n",
    "\n",
    "Tenemos algo de overfitting en nuestro modelo que ya contiene 0.2 de dropout. Se supone que deberíamos subirlo algo y ver si mejora. En caso de aumento de perdidas probaremos a reducirlo de nuevo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### PERIODS ####\n",
    "prev_periods = 20\n",
    "pred_periods = 20\n",
    "\n",
    "#LSTM\n",
    "model_sel = 0 \n",
    "\n",
    "# Cryptos\n",
    "cryptos = ['ETH', 'ADA', 'BTC', 'LNK', 'LTC']\n",
    "\n",
    "#### NORM AND FEATURES CONFIGURATION ####\n",
    "target = 'close'\n",
    "norm_strat = 2\n",
    "\n",
    "#### COLUMNS ####\n",
    "columns_11 = ['op_buy', 'op_sell', 'op_hold'] # Usar softmax\n",
    "columns_12 = ['close', 'close_diff_20']\n",
    "\n",
    "\n",
    "#### Hyper params ####\n",
    "\n",
    "#activations = ['relu', 'sigmoid', 'softmax']\n",
    "#losses = ['mse', 'binary_crossentropy', 'categorical_crossentropy']\n",
    "#metrics_opt = ['mse', 'accuracy']\n",
    "activation = 'relu'\n",
    "loss = 'mse'\n",
    "metrics = ['mse']\n",
    "initial_learning_rate = 0.01\n",
    "\n",
    "optimizer = 'adam'\n",
    "\n",
    "callbacks = ['mc', 'es']\n",
    "batch_size = 64\n",
    "epochs = 100\n",
    "\n",
    "layers = 2\n",
    "neurons = [100, 50, 50]\n",
    "\n",
    "columns = columns_12\n",
    "num_features = len(columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropout 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for crypto in cryptos:\n",
    "    crypto = crypto\n",
    "    execute_test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No observamos mejoras\n",
    "\n",
    "Probamos con Dropout 0.1\n",
    "\n",
    "Eliminaremos el overfitting con regularizers en el kernel l1_l2 si mejora con un dropout mas bajo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for crypto in cryptos:\n",
    "    crypto = crypto\n",
    "    execute_test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No vemos mejoras. Nos quedaremos con Dropout 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que el learning rate puede estar algo alto pues alcanzamos minimos muy pronto y los set de validación no terminan de fijarse en un valor de perdidas (acaban dando pequeños saltos). Probaremos a bajarlo y a eliminar de nuevo el early stop\n",
    "\n",
    "Se han hechos pruebas con el lr shceduler sin exito"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = ['mc']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "learning_rate=0.0005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading... ETH\n",
      "Extracting columns columns for ETH\n",
      "Proccessing and arranging columns for LSTM model\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>close_19</th>\n",
       "      <th>close_diff_20_19</th>\n",
       "      <th>close_18</th>\n",
       "      <th>close_diff_20_18</th>\n",
       "      <th>close_17</th>\n",
       "      <th>close_diff_20_17</th>\n",
       "      <th>close_16</th>\n",
       "      <th>close_diff_20_16</th>\n",
       "      <th>close_15</th>\n",
       "      <th>close_diff_20_15</th>\n",
       "      <th>...</th>\n",
       "      <th>close_diff_20_4</th>\n",
       "      <th>close_3</th>\n",
       "      <th>close_diff_20_3</th>\n",
       "      <th>close_2</th>\n",
       "      <th>close_diff_20_2</th>\n",
       "      <th>close_1</th>\n",
       "      <th>close_diff_20_1</th>\n",
       "      <th>close_0</th>\n",
       "      <th>close_diff_20_0</th>\n",
       "      <th>close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>1123.09</td>\n",
       "      <td>339.09</td>\n",
       "      <td>1133.18</td>\n",
       "      <td>335.18</td>\n",
       "      <td>1291.00</td>\n",
       "      <td>500.79</td>\n",
       "      <td>1247.00</td>\n",
       "      <td>464.59</td>\n",
       "      <td>1138.93</td>\n",
       "      <td>502.96</td>\n",
       "      <td>...</td>\n",
       "      <td>137.72</td>\n",
       "      <td>980.00</td>\n",
       "      <td>45.97</td>\n",
       "      <td>1061.00</td>\n",
       "      <td>121.00</td>\n",
       "      <td>1056.52</td>\n",
       "      <td>97.22</td>\n",
       "      <td>1051.03</td>\n",
       "      <td>46.92</td>\n",
       "      <td>924.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>1133.18</td>\n",
       "      <td>335.18</td>\n",
       "      <td>1291.00</td>\n",
       "      <td>500.79</td>\n",
       "      <td>1247.00</td>\n",
       "      <td>464.59</td>\n",
       "      <td>1138.93</td>\n",
       "      <td>502.96</td>\n",
       "      <td>1253.87</td>\n",
       "      <td>613.53</td>\n",
       "      <td>...</td>\n",
       "      <td>45.97</td>\n",
       "      <td>1061.00</td>\n",
       "      <td>121.00</td>\n",
       "      <td>1056.52</td>\n",
       "      <td>97.22</td>\n",
       "      <td>1051.03</td>\n",
       "      <td>46.92</td>\n",
       "      <td>1118.99</td>\n",
       "      <td>-4.10</td>\n",
       "      <td>938.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>1291.00</td>\n",
       "      <td>500.79</td>\n",
       "      <td>1247.00</td>\n",
       "      <td>464.59</td>\n",
       "      <td>1138.93</td>\n",
       "      <td>502.96</td>\n",
       "      <td>1253.87</td>\n",
       "      <td>613.53</td>\n",
       "      <td>1388.02</td>\n",
       "      <td>730.02</td>\n",
       "      <td>...</td>\n",
       "      <td>121.00</td>\n",
       "      <td>1056.52</td>\n",
       "      <td>97.22</td>\n",
       "      <td>1051.03</td>\n",
       "      <td>46.92</td>\n",
       "      <td>1118.99</td>\n",
       "      <td>-4.10</td>\n",
       "      <td>1251.96</td>\n",
       "      <td>118.78</td>\n",
       "      <td>969.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>1247.00</td>\n",
       "      <td>464.59</td>\n",
       "      <td>1138.93</td>\n",
       "      <td>502.96</td>\n",
       "      <td>1253.87</td>\n",
       "      <td>613.53</td>\n",
       "      <td>1388.02</td>\n",
       "      <td>730.02</td>\n",
       "      <td>1347.00</td>\n",
       "      <td>632.05</td>\n",
       "      <td>...</td>\n",
       "      <td>97.22</td>\n",
       "      <td>1051.03</td>\n",
       "      <td>46.92</td>\n",
       "      <td>1118.99</td>\n",
       "      <td>-4.10</td>\n",
       "      <td>1251.96</td>\n",
       "      <td>118.78</td>\n",
       "      <td>1177.01</td>\n",
       "      <td>-113.99</td>\n",
       "      <td>911.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>1138.93</td>\n",
       "      <td>502.96</td>\n",
       "      <td>1253.87</td>\n",
       "      <td>613.53</td>\n",
       "      <td>1388.02</td>\n",
       "      <td>730.02</td>\n",
       "      <td>1347.00</td>\n",
       "      <td>632.05</td>\n",
       "      <td>1271.00</td>\n",
       "      <td>521.00</td>\n",
       "      <td>...</td>\n",
       "      <td>46.92</td>\n",
       "      <td>1118.99</td>\n",
       "      <td>-4.10</td>\n",
       "      <td>1251.96</td>\n",
       "      <td>118.78</td>\n",
       "      <td>1177.01</td>\n",
       "      <td>-113.99</td>\n",
       "      <td>1085.50</td>\n",
       "      <td>-161.50</td>\n",
       "      <td>938.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1573</th>\n",
       "      <td>4287.80</td>\n",
       "      <td>1.78</td>\n",
       "      <td>3996.90</td>\n",
       "      <td>-421.99</td>\n",
       "      <td>4294.76</td>\n",
       "      <td>-27.92</td>\n",
       "      <td>4412.17</td>\n",
       "      <td>124.96</td>\n",
       "      <td>4258.31</td>\n",
       "      <td>-61.12</td>\n",
       "      <td>...</td>\n",
       "      <td>-154.25</td>\n",
       "      <td>4215.73</td>\n",
       "      <td>-428.55</td>\n",
       "      <td>4117.25</td>\n",
       "      <td>-509.25</td>\n",
       "      <td>4196.44</td>\n",
       "      <td>-367.34</td>\n",
       "      <td>4347.59</td>\n",
       "      <td>137.83</td>\n",
       "      <td>4063.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1574</th>\n",
       "      <td>3996.90</td>\n",
       "      <td>-421.99</td>\n",
       "      <td>4294.76</td>\n",
       "      <td>-27.92</td>\n",
       "      <td>4412.17</td>\n",
       "      <td>124.96</td>\n",
       "      <td>4258.31</td>\n",
       "      <td>-61.12</td>\n",
       "      <td>4085.97</td>\n",
       "      <td>-503.92</td>\n",
       "      <td>...</td>\n",
       "      <td>-428.55</td>\n",
       "      <td>4117.25</td>\n",
       "      <td>-509.25</td>\n",
       "      <td>4196.44</td>\n",
       "      <td>-367.34</td>\n",
       "      <td>4347.59</td>\n",
       "      <td>137.83</td>\n",
       "      <td>4306.40</td>\n",
       "      <td>18.60</td>\n",
       "      <td>4037.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1575</th>\n",
       "      <td>4294.76</td>\n",
       "      <td>-27.92</td>\n",
       "      <td>4412.17</td>\n",
       "      <td>124.96</td>\n",
       "      <td>4258.31</td>\n",
       "      <td>-61.12</td>\n",
       "      <td>4085.97</td>\n",
       "      <td>-503.92</td>\n",
       "      <td>4339.44</td>\n",
       "      <td>-263.91</td>\n",
       "      <td>...</td>\n",
       "      <td>-509.25</td>\n",
       "      <td>4196.44</td>\n",
       "      <td>-367.34</td>\n",
       "      <td>4347.59</td>\n",
       "      <td>137.83</td>\n",
       "      <td>4306.40</td>\n",
       "      <td>18.60</td>\n",
       "      <td>4436.91</td>\n",
       "      <td>440.01</td>\n",
       "      <td>3792.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1576</th>\n",
       "      <td>4412.17</td>\n",
       "      <td>124.96</td>\n",
       "      <td>4258.31</td>\n",
       "      <td>-61.12</td>\n",
       "      <td>4085.97</td>\n",
       "      <td>-503.92</td>\n",
       "      <td>4339.44</td>\n",
       "      <td>-263.91</td>\n",
       "      <td>4269.36</td>\n",
       "      <td>-262.96</td>\n",
       "      <td>...</td>\n",
       "      <td>-367.34</td>\n",
       "      <td>4347.59</td>\n",
       "      <td>137.83</td>\n",
       "      <td>4306.40</td>\n",
       "      <td>18.60</td>\n",
       "      <td>4436.91</td>\n",
       "      <td>440.01</td>\n",
       "      <td>4105.64</td>\n",
       "      <td>-189.12</td>\n",
       "      <td>3630.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1577</th>\n",
       "      <td>4258.31</td>\n",
       "      <td>-61.12</td>\n",
       "      <td>4085.97</td>\n",
       "      <td>-503.92</td>\n",
       "      <td>4339.44</td>\n",
       "      <td>-263.91</td>\n",
       "      <td>4269.36</td>\n",
       "      <td>-262.96</td>\n",
       "      <td>4524.85</td>\n",
       "      <td>50.61</td>\n",
       "      <td>...</td>\n",
       "      <td>137.83</td>\n",
       "      <td>4306.40</td>\n",
       "      <td>18.60</td>\n",
       "      <td>4436.91</td>\n",
       "      <td>440.01</td>\n",
       "      <td>4105.64</td>\n",
       "      <td>-189.12</td>\n",
       "      <td>3897.94</td>\n",
       "      <td>-514.23</td>\n",
       "      <td>3709.27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1415 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      close_19  close_diff_20_19  close_18  close_diff_20_18  close_17  \\\n",
       "163    1123.09            339.09   1133.18            335.18   1291.00   \n",
       "164    1133.18            335.18   1291.00            500.79   1247.00   \n",
       "165    1291.00            500.79   1247.00            464.59   1138.93   \n",
       "166    1247.00            464.59   1138.93            502.96   1253.87   \n",
       "167    1138.93            502.96   1253.87            613.53   1388.02   \n",
       "...        ...               ...       ...               ...       ...   \n",
       "1573   4287.80              1.78   3996.90           -421.99   4294.76   \n",
       "1574   3996.90           -421.99   4294.76            -27.92   4412.17   \n",
       "1575   4294.76            -27.92   4412.17            124.96   4258.31   \n",
       "1576   4412.17            124.96   4258.31            -61.12   4085.97   \n",
       "1577   4258.31            -61.12   4085.97           -503.92   4339.44   \n",
       "\n",
       "      close_diff_20_17  close_16  close_diff_20_16  close_15  \\\n",
       "163             500.79   1247.00            464.59   1138.93   \n",
       "164             464.59   1138.93            502.96   1253.87   \n",
       "165             502.96   1253.87            613.53   1388.02   \n",
       "166             613.53   1388.02            730.02   1347.00   \n",
       "167             730.02   1347.00            632.05   1271.00   \n",
       "...                ...       ...               ...       ...   \n",
       "1573            -27.92   4412.17            124.96   4258.31   \n",
       "1574            124.96   4258.31            -61.12   4085.97   \n",
       "1575            -61.12   4085.97           -503.92   4339.44   \n",
       "1576           -503.92   4339.44           -263.91   4269.36   \n",
       "1577           -263.91   4269.36           -262.96   4524.85   \n",
       "\n",
       "      close_diff_20_15  ...  close_diff_20_4  close_3  close_diff_20_3  \\\n",
       "163             502.96  ...           137.72   980.00            45.97   \n",
       "164             613.53  ...            45.97  1061.00           121.00   \n",
       "165             730.02  ...           121.00  1056.52            97.22   \n",
       "166             632.05  ...            97.22  1051.03            46.92   \n",
       "167             521.00  ...            46.92  1118.99            -4.10   \n",
       "...                ...  ...              ...      ...              ...   \n",
       "1573            -61.12  ...          -154.25  4215.73          -428.55   \n",
       "1574           -503.92  ...          -428.55  4117.25          -509.25   \n",
       "1575           -263.91  ...          -509.25  4196.44          -367.34   \n",
       "1576           -262.96  ...          -367.34  4347.59           137.83   \n",
       "1577             50.61  ...           137.83  4306.40            18.60   \n",
       "\n",
       "      close_2  close_diff_20_2  close_1  close_diff_20_1  close_0  \\\n",
       "163   1061.00           121.00  1056.52            97.22  1051.03   \n",
       "164   1056.52            97.22  1051.03            46.92  1118.99   \n",
       "165   1051.03            46.92  1118.99            -4.10  1251.96   \n",
       "166   1118.99            -4.10  1251.96           118.78  1177.01   \n",
       "167   1251.96           118.78  1177.01          -113.99  1085.50   \n",
       "...       ...              ...      ...              ...      ...   \n",
       "1573  4117.25          -509.25  4196.44          -367.34  4347.59   \n",
       "1574  4196.44          -367.34  4347.59           137.83  4306.40   \n",
       "1575  4347.59           137.83  4306.40            18.60  4436.91   \n",
       "1576  4306.40            18.60  4436.91           440.01  4105.64   \n",
       "1577  4436.91           440.01  4105.64          -189.12  3897.94   \n",
       "\n",
       "      close_diff_20_0    close  \n",
       "163             46.92   924.55  \n",
       "164             -4.10   938.67  \n",
       "165            118.78   969.99  \n",
       "166           -113.99   911.00  \n",
       "167           -161.50   938.11  \n",
       "...               ...      ...  \n",
       "1573           137.83  4063.56  \n",
       "1574            18.60  4037.23  \n",
       "1575           440.01  3792.75  \n",
       "1576          -189.12  3630.19  \n",
       "1577          -514.23  3709.27  \n",
       "\n",
       "[1415 rows x 41 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>close_19</th>\n",
       "      <th>close_diff_20_19</th>\n",
       "      <th>close_18</th>\n",
       "      <th>close_diff_20_18</th>\n",
       "      <th>close_17</th>\n",
       "      <th>close_diff_20_17</th>\n",
       "      <th>close_16</th>\n",
       "      <th>close_diff_20_16</th>\n",
       "      <th>close_15</th>\n",
       "      <th>close_diff_20_15</th>\n",
       "      <th>...</th>\n",
       "      <th>close_diff_20_4</th>\n",
       "      <th>close_3</th>\n",
       "      <th>close_diff_20_3</th>\n",
       "      <th>close_2</th>\n",
       "      <th>close_diff_20_2</th>\n",
       "      <th>close_1</th>\n",
       "      <th>close_diff_20_1</th>\n",
       "      <th>close_0</th>\n",
       "      <th>close_diff_20_0</th>\n",
       "      <th>close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1578</th>\n",
       "      <td>4085.97</td>\n",
       "      <td>-503.92</td>\n",
       "      <td>4339.44</td>\n",
       "      <td>-263.91</td>\n",
       "      <td>4269.36</td>\n",
       "      <td>-262.96</td>\n",
       "      <td>4524.85</td>\n",
       "      <td>50.61</td>\n",
       "      <td>4041.2</td>\n",
       "      <td>-476.8</td>\n",
       "      <td>...</td>\n",
       "      <td>18.6</td>\n",
       "      <td>4436.91</td>\n",
       "      <td>440.01</td>\n",
       "      <td>4105.64</td>\n",
       "      <td>-189.12</td>\n",
       "      <td>3897.94</td>\n",
       "      <td>-514.23</td>\n",
       "      <td>4089.37</td>\n",
       "      <td>-168.94</td>\n",
       "      <td>3725.46</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      close_19  close_diff_20_19  close_18  close_diff_20_18  close_17  \\\n",
       "1578   4085.97           -503.92   4339.44           -263.91   4269.36   \n",
       "\n",
       "      close_diff_20_17  close_16  close_diff_20_16  close_15  \\\n",
       "1578           -262.96   4524.85             50.61    4041.2   \n",
       "\n",
       "      close_diff_20_15  ...  close_diff_20_4  close_3  close_diff_20_3  \\\n",
       "1578            -476.8  ...             18.6  4436.91           440.01   \n",
       "\n",
       "      close_2  close_diff_20_2  close_1  close_diff_20_1  close_0  \\\n",
       "1578  4105.64          -189.12  3897.94          -514.23  4089.37   \n",
       "\n",
       "      close_diff_20_0    close  \n",
       "1578          -168.94  3725.46  \n",
       "\n",
       "[1 rows x 41 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (1415, 1, 40) (1415, 1)\n",
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_22 (LSTM)               (None, 1, 100)            56400     \n",
      "_________________________________________________________________\n",
      "lstm_23 (LSTM)               (None, 1, 50)             30200     \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 1, 50)             0         \n",
      "_________________________________________________________________\n",
      "lstm_24 (LSTM)               (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 106,851\n",
      "Trainable params: 106,851\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Y shape (1415, 1)\n",
      "Train on 1415 samples, validate on 283 samples\n",
      "Epoch 1/100\n",
      " - 6s - loss: 0.0835 - mse: 0.0835 - val_loss: 0.3633 - val_mse: 0.3633\n",
      "Epoch 2/100\n",
      " - 0s - loss: 0.0607 - mse: 0.0607 - val_loss: 0.2466 - val_mse: 0.2466\n",
      "Epoch 3/100\n",
      " - 0s - loss: 0.0398 - mse: 0.0398 - val_loss: 0.1182 - val_mse: 0.1182\n",
      "Epoch 4/100\n",
      " - 0s - loss: 0.0311 - mse: 0.0311 - val_loss: 0.0457 - val_mse: 0.0457\n",
      "Epoch 5/100\n",
      " - 0s - loss: 0.0194 - mse: 0.0194 - val_loss: 0.0234 - val_mse: 0.0234\n",
      "Epoch 6/100\n",
      " - 0s - loss: 0.0101 - mse: 0.0101 - val_loss: 0.0251 - val_mse: 0.0251\n",
      "Epoch 7/100\n",
      " - 0s - loss: 0.0094 - mse: 0.0094 - val_loss: 0.0244 - val_mse: 0.0244\n",
      "Epoch 8/100\n",
      " - 0s - loss: 0.0091 - mse: 0.0091 - val_loss: 0.0234 - val_mse: 0.0234\n",
      "Epoch 9/100\n",
      " - 0s - loss: 0.0172 - mse: 0.0172 - val_loss: 0.0415 - val_mse: 0.0415\n",
      "Epoch 10/100\n",
      " - 0s - loss: 0.0092 - mse: 0.0092 - val_loss: 0.0212 - val_mse: 0.0212\n",
      "Epoch 11/100\n",
      " - 0s - loss: 0.0121 - mse: 0.0121 - val_loss: 0.0293 - val_mse: 0.0293\n",
      "Epoch 12/100\n",
      " - 0s - loss: 0.0082 - mse: 0.0082 - val_loss: 0.0204 - val_mse: 0.0204\n",
      "Epoch 13/100\n",
      " - 0s - loss: 0.0089 - mse: 0.0089 - val_loss: 0.0239 - val_mse: 0.0239\n",
      "Epoch 14/100\n",
      " - 1s - loss: 0.0068 - mse: 0.0068 - val_loss: 0.0201 - val_mse: 0.0201\n",
      "Epoch 15/100\n",
      " - 1s - loss: 0.0074 - mse: 0.0074 - val_loss: 0.0202 - val_mse: 0.0202\n",
      "Epoch 16/100\n",
      " - 1s - loss: 0.0067 - mse: 0.0067 - val_loss: 0.0185 - val_mse: 0.0185\n",
      "Epoch 17/100\n",
      " - 1s - loss: 0.0091 - mse: 0.0091 - val_loss: 0.0231 - val_mse: 0.0231\n",
      "Epoch 18/100\n",
      " - 1s - loss: 0.0070 - mse: 0.0070 - val_loss: 0.0180 - val_mse: 0.0180\n",
      "Epoch 19/100\n",
      " - 1s - loss: 0.0081 - mse: 0.0081 - val_loss: 0.0199 - val_mse: 0.0199\n",
      "Epoch 20/100\n",
      " - 0s - loss: 0.0073 - mse: 0.0073 - val_loss: 0.0181 - val_mse: 0.0181\n",
      "Epoch 21/100\n",
      " - 1s - loss: 0.0076 - mse: 0.0076 - val_loss: 0.0202 - val_mse: 0.0202\n",
      "Epoch 22/100\n",
      " - 1s - loss: 0.0058 - mse: 0.0058 - val_loss: 0.0169 - val_mse: 0.0169\n",
      "Epoch 23/100\n",
      " - 0s - loss: 0.0063 - mse: 0.0063 - val_loss: 0.0182 - val_mse: 0.0182\n",
      "Epoch 24/100\n",
      " - 0s - loss: 0.0062 - mse: 0.0062 - val_loss: 0.0169 - val_mse: 0.0169\n",
      "Epoch 25/100\n",
      " - 0s - loss: 0.0074 - mse: 0.0074 - val_loss: 0.0190 - val_mse: 0.0190\n",
      "Epoch 26/100\n",
      " - 0s - loss: 0.0055 - mse: 0.0055 - val_loss: 0.0165 - val_mse: 0.0165\n",
      "Epoch 27/100\n",
      " - 0s - loss: 0.0061 - mse: 0.0061 - val_loss: 0.0171 - val_mse: 0.0171\n",
      "Epoch 28/100\n",
      " - 0s - loss: 0.0065 - mse: 0.0065 - val_loss: 0.0165 - val_mse: 0.0165\n",
      "Epoch 29/100\n",
      " - 0s - loss: 0.0063 - mse: 0.0063 - val_loss: 0.0172 - val_mse: 0.0172\n",
      "Epoch 30/100\n",
      " - 0s - loss: 0.0054 - mse: 0.0054 - val_loss: 0.0162 - val_mse: 0.0162\n",
      "Epoch 31/100\n",
      " - 0s - loss: 0.0058 - mse: 0.0058 - val_loss: 0.0166 - val_mse: 0.0166\n",
      "Epoch 32/100\n",
      " - 0s - loss: 0.0058 - mse: 0.0058 - val_loss: 0.0164 - val_mse: 0.0164\n",
      "Epoch 33/100\n",
      " - 0s - loss: 0.0055 - mse: 0.0055 - val_loss: 0.0163 - val_mse: 0.0163\n",
      "Epoch 34/100\n",
      " - 0s - loss: 0.0054 - mse: 0.0054 - val_loss: 0.0162 - val_mse: 0.0162\n",
      "Epoch 35/100\n",
      " - 0s - loss: 0.0067 - mse: 0.0067 - val_loss: 0.0170 - val_mse: 0.0170\n",
      "Epoch 36/100\n",
      " - 0s - loss: 0.0063 - mse: 0.0063 - val_loss: 0.0162 - val_mse: 0.0162\n",
      "Epoch 37/100\n",
      " - 0s - loss: 0.0074 - mse: 0.0074 - val_loss: 0.0175 - val_mse: 0.0175\n",
      "Epoch 38/100\n",
      " - 0s - loss: 0.0069 - mse: 0.0069 - val_loss: 0.0162 - val_mse: 0.0162\n",
      "Epoch 39/100\n",
      " - 0s - loss: 0.0078 - mse: 0.0078 - val_loss: 0.0185 - val_mse: 0.0185\n",
      "Epoch 40/100\n",
      " - 0s - loss: 0.0072 - mse: 0.0072 - val_loss: 0.0161 - val_mse: 0.0161\n",
      "Epoch 41/100\n",
      " - 0s - loss: 0.0078 - mse: 0.0078 - val_loss: 0.0183 - val_mse: 0.0183\n",
      "Epoch 42/100\n",
      " - 0s - loss: 0.0063 - mse: 0.0063 - val_loss: 0.0159 - val_mse: 0.0159\n",
      "Epoch 43/100\n",
      " - 0s - loss: 0.0070 - mse: 0.0070 - val_loss: 0.0175 - val_mse: 0.0175\n",
      "Epoch 44/100\n",
      " - 0s - loss: 0.0063 - mse: 0.0063 - val_loss: 0.0161 - val_mse: 0.0161\n",
      "Epoch 45/100\n",
      " - 0s - loss: 0.0080 - mse: 0.0080 - val_loss: 0.0181 - val_mse: 0.0181\n",
      "Epoch 46/100\n",
      " - 1s - loss: 0.0064 - mse: 0.0064 - val_loss: 0.0159 - val_mse: 0.0159\n",
      "Epoch 47/100\n",
      " - 0s - loss: 0.0076 - mse: 0.0076 - val_loss: 0.0194 - val_mse: 0.0194\n",
      "Epoch 48/100\n",
      " - 0s - loss: 0.0055 - mse: 0.0055 - val_loss: 0.0160 - val_mse: 0.0160\n",
      "Epoch 49/100\n",
      " - 0s - loss: 0.0064 - mse: 0.0064 - val_loss: 0.0162 - val_mse: 0.0162\n",
      "Epoch 50/100\n",
      " - 0s - loss: 0.0053 - mse: 0.0053 - val_loss: 0.0156 - val_mse: 0.0156\n",
      "Epoch 51/100\n",
      " - 0s - loss: 0.0057 - mse: 0.0057 - val_loss: 0.0167 - val_mse: 0.0167\n",
      "Epoch 52/100\n",
      " - 0s - loss: 0.0056 - mse: 0.0056 - val_loss: 0.0158 - val_mse: 0.0158\n",
      "Epoch 53/100\n",
      " - 0s - loss: 0.0056 - mse: 0.0056 - val_loss: 0.0157 - val_mse: 0.0157\n",
      "Epoch 54/100\n",
      " - 0s - loss: 0.0051 - mse: 0.0051 - val_loss: 0.0155 - val_mse: 0.0155\n",
      "Epoch 55/100\n",
      " - 0s - loss: 0.0064 - mse: 0.0064 - val_loss: 0.0165 - val_mse: 0.0165\n",
      "Epoch 56/100\n",
      " - 0s - loss: 0.0058 - mse: 0.0058 - val_loss: 0.0156 - val_mse: 0.0156\n",
      "Epoch 57/100\n",
      " - 0s - loss: 0.0068 - mse: 0.0068 - val_loss: 0.0166 - val_mse: 0.0166\n",
      "Epoch 58/100\n",
      " - 0s - loss: 0.0059 - mse: 0.0059 - val_loss: 0.0155 - val_mse: 0.0155\n",
      "Epoch 59/100\n",
      " - 0s - loss: 0.0068 - mse: 0.0068 - val_loss: 0.0169 - val_mse: 0.0169\n",
      "Epoch 60/100\n",
      " - 0s - loss: 0.0064 - mse: 0.0064 - val_loss: 0.0156 - val_mse: 0.0156\n",
      "Epoch 61/100\n",
      " - 0s - loss: 0.0076 - mse: 0.0076 - val_loss: 0.0172 - val_mse: 0.0172\n",
      "Epoch 62/100\n",
      " - 0s - loss: 0.0062 - mse: 0.0062 - val_loss: 0.0158 - val_mse: 0.0158\n",
      "Epoch 63/100\n",
      " - 0s - loss: 0.0073 - mse: 0.0073 - val_loss: 0.0169 - val_mse: 0.0169\n",
      "Epoch 64/100\n",
      " - 1s - loss: 0.0066 - mse: 0.0066 - val_loss: 0.0155 - val_mse: 0.0155\n",
      "Epoch 65/100\n",
      " - 1s - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0223 - val_mse: 0.0223\n",
      "Epoch 66/100\n",
      " - 1s - loss: 0.0059 - mse: 0.0059 - val_loss: 0.0158 - val_mse: 0.0158\n",
      "Epoch 67/100\n",
      " - 1s - loss: 0.0066 - mse: 0.0066 - val_loss: 0.0168 - val_mse: 0.0168\n",
      "Epoch 68/100\n",
      " - 0s - loss: 0.0049 - mse: 0.0049 - val_loss: 0.0155 - val_mse: 0.0155\n",
      "Epoch 69/100\n",
      " - 1s - loss: 0.0058 - mse: 0.0058 - val_loss: 0.0159 - val_mse: 0.0159\n",
      "Epoch 70/100\n",
      " - 1s - loss: 0.0055 - mse: 0.0055 - val_loss: 0.0153 - val_mse: 0.0153\n",
      "Epoch 71/100\n",
      " - 0s - loss: 0.0053 - mse: 0.0053 - val_loss: 0.0155 - val_mse: 0.0155\n",
      "Epoch 72/100\n",
      " - 0s - loss: 0.0047 - mse: 0.0047 - val_loss: 0.0153 - val_mse: 0.0153\n",
      "Epoch 73/100\n",
      " - 0s - loss: 0.0052 - mse: 0.0052 - val_loss: 0.0152 - val_mse: 0.0152\n",
      "Epoch 74/100\n",
      " - 0s - loss: 0.0051 - mse: 0.0051 - val_loss: 0.0152 - val_mse: 0.0152\n",
      "Epoch 75/100\n",
      " - 0s - loss: 0.0048 - mse: 0.0048 - val_loss: 0.0152 - val_mse: 0.0152\n",
      "Epoch 76/100\n",
      " - 0s - loss: 0.0042 - mse: 0.0042 - val_loss: 0.0151 - val_mse: 0.0151\n",
      "Epoch 77/100\n",
      " - 0s - loss: 0.0047 - mse: 0.0047 - val_loss: 0.0151 - val_mse: 0.0151\n",
      "Epoch 78/100\n",
      " - 0s - loss: 0.0047 - mse: 0.0047 - val_loss: 0.0152 - val_mse: 0.0152\n",
      "Epoch 79/100\n",
      " - 0s - loss: 0.0050 - mse: 0.0050 - val_loss: 0.0153 - val_mse: 0.0153\n",
      "Epoch 80/100\n",
      " - 0s - loss: 0.0049 - mse: 0.0049 - val_loss: 0.0151 - val_mse: 0.0151\n",
      "Epoch 81/100\n",
      " - 0s - loss: 0.0051 - mse: 0.0051 - val_loss: 0.0150 - val_mse: 0.0150\n",
      "Epoch 82/100\n",
      " - 0s - loss: 0.0051 - mse: 0.0051 - val_loss: 0.0152 - val_mse: 0.0152\n",
      "Epoch 83/100\n",
      " - 0s - loss: 0.0049 - mse: 0.0049 - val_loss: 0.0149 - val_mse: 0.0149\n",
      "Epoch 84/100\n",
      " - 0s - loss: 0.0053 - mse: 0.0053 - val_loss: 0.0150 - val_mse: 0.0150\n",
      "Epoch 85/100\n",
      " - 0s - loss: 0.0051 - mse: 0.0051 - val_loss: 0.0150 - val_mse: 0.0150\n",
      "Epoch 86/100\n",
      " - 0s - loss: 0.0052 - mse: 0.0052 - val_loss: 0.0150 - val_mse: 0.0150\n",
      "Epoch 87/100\n",
      " - 0s - loss: 0.0047 - mse: 0.0047 - val_loss: 0.0149 - val_mse: 0.0149\n",
      "Epoch 88/100\n",
      " - 0s - loss: 0.0052 - mse: 0.0052 - val_loss: 0.0150 - val_mse: 0.0150\n",
      "Epoch 89/100\n",
      " - 0s - loss: 0.0048 - mse: 0.0048 - val_loss: 0.0149 - val_mse: 0.0149\n",
      "Epoch 90/100\n",
      " - 0s - loss: 0.0049 - mse: 0.0049 - val_loss: 0.0148 - val_mse: 0.0148\n",
      "Epoch 91/100\n",
      " - 0s - loss: 0.0053 - mse: 0.0053 - val_loss: 0.0150 - val_mse: 0.0150\n",
      "Epoch 92/100\n",
      " - 0s - loss: 0.0058 - mse: 0.0058 - val_loss: 0.0154 - val_mse: 0.0154\n",
      "Epoch 93/100\n",
      " - 0s - loss: 0.0061 - mse: 0.0061 - val_loss: 0.0152 - val_mse: 0.0152\n",
      "Epoch 94/100\n",
      " - 0s - loss: 0.0078 - mse: 0.0078 - val_loss: 0.0167 - val_mse: 0.0167\n",
      "Epoch 95/100\n",
      " - 0s - loss: 0.0073 - mse: 0.0073 - val_loss: 0.0152 - val_mse: 0.0152\n",
      "Epoch 96/100\n",
      " - 0s - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0180 - val_mse: 0.0180\n",
      "Epoch 97/100\n",
      " - 0s - loss: 0.0080 - mse: 0.0080 - val_loss: 0.0153 - val_mse: 0.0153\n",
      "Epoch 98/100\n",
      " - 0s - loss: 0.0102 - mse: 0.0102 - val_loss: 0.0205 - val_mse: 0.0205\n",
      "Epoch 99/100\n",
      " - 0s - loss: 0.0065 - mse: 0.0065 - val_loss: 0.0158 - val_mse: 0.0158\n",
      "Epoch 100/100\n",
      " - 0s - loss: 0.0072 - mse: 0.0072 - val_loss: 0.0176 - val_mse: 0.0176\n",
      "real [[3725.46]]\n",
      "Test RMSE: 245.423\n",
      "Diff [[-245.42304114]]\n",
      "% Diff [[-6.5877245]] %\n",
      "Predictions [[3970.88304114]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "optimizer = optimizers.Adam(learning_rate=0.0005)\n",
    "\n",
    "crypto = crypto\n",
    "execute_test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eliminaremos el overfitting que podamos tener con el uso de regularizacion del kernel l1_l2\n",
    "\n",
    "kernel_regularizer=tensorflow.keras.regularizers.l1_l2(l1=0.01, l2=0.01)\n",
    "\n",
    "Aprovechamos para volver a probar una sola capa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### PERIODS ####\n",
    "prev_periods = 20\n",
    "pred_periods = 20\n",
    "\n",
    "#LSTM\n",
    "model_sel = 0 \n",
    "\n",
    "# Cryptos\n",
    "cryptos = ['ETH', 'ADA', 'BTC', 'LNK', 'LTC']\n",
    "\n",
    "#### NORM AND FEATURES CONFIGURATION ####\n",
    "target = 'close'\n",
    "norm_strat = 2\n",
    "\n",
    "#### COLUMNS ####\n",
    "columns_11 = ['op_buy', 'op_sell', 'op_hold'] # Usar softmax\n",
    "columns_12 = ['close', 'close_diff_20']\n",
    "\n",
    "\n",
    "#### Hyper params ####\n",
    "\n",
    "#activations = ['relu', 'sigmoid', 'softmax']\n",
    "#losses = ['mse', 'binary_crossentropy', 'categorical_crossentropy']\n",
    "#metrics_opt = ['mse', 'accuracy']\n",
    "activation = 'relu'\n",
    "loss = 'mse'\n",
    "metrics = ['mse']\n",
    "initial_learning_rate = 0.01\n",
    "\n",
    "optimizer = optimizers.Adam(learning_rate=0.0005)\n",
    "\n",
    "callbacks = ['mc', 'es']\n",
    "batch_size = 64\n",
    "epochs = 100\n",
    "\n",
    "layers = 2\n",
    "neurons = [100, 50, 50]\n",
    "\n",
    "columns = columns_12\n",
    "num_features = len(columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se ha probado regularizar en recurrent layer y bias pero los resultados no son optimos\n",
    "\n",
    "El siguiente resultado aplica solo a kernel\n",
    "\n",
    "Para reducir el contenido no se muestran los resultados aplicados a recurrent y bias. Asi como varias pruebas con regularizers mas altos que tampoco han dado buenos resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crypto = crypto\n",
    "execute_test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No hemos conseguido mejorar el modelo con regularización"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora modificaremos el batch size y epocas\n",
    "\n",
    "Si bien, pareciera que 100 epocas han sido más que suficiente y no tocaremos este parametro a no ser que veamos falta de convergencia al modificar el batch\n",
    "\n",
    "Hemos probado con batch size de 64. Probemos con un batch mas pequeño para actualizar de forma mas recurrente los pesos. Si mejora seguiremos reduciendo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Batch size 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading... ETH\n",
      "Extracting columns columns for ETH\n",
      "Proccessing and arranging columns for LSTM model\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>close_19</th>\n",
       "      <th>close_diff_20_19</th>\n",
       "      <th>close_18</th>\n",
       "      <th>close_diff_20_18</th>\n",
       "      <th>close_17</th>\n",
       "      <th>close_diff_20_17</th>\n",
       "      <th>close_16</th>\n",
       "      <th>close_diff_20_16</th>\n",
       "      <th>close_15</th>\n",
       "      <th>close_diff_20_15</th>\n",
       "      <th>...</th>\n",
       "      <th>close_diff_20_4</th>\n",
       "      <th>close_3</th>\n",
       "      <th>close_diff_20_3</th>\n",
       "      <th>close_2</th>\n",
       "      <th>close_diff_20_2</th>\n",
       "      <th>close_1</th>\n",
       "      <th>close_diff_20_1</th>\n",
       "      <th>close_0</th>\n",
       "      <th>close_diff_20_0</th>\n",
       "      <th>close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>1123.09</td>\n",
       "      <td>339.09</td>\n",
       "      <td>1133.18</td>\n",
       "      <td>335.18</td>\n",
       "      <td>1291.00</td>\n",
       "      <td>500.79</td>\n",
       "      <td>1247.00</td>\n",
       "      <td>464.59</td>\n",
       "      <td>1138.93</td>\n",
       "      <td>502.96</td>\n",
       "      <td>...</td>\n",
       "      <td>137.72</td>\n",
       "      <td>980.00</td>\n",
       "      <td>45.97</td>\n",
       "      <td>1061.00</td>\n",
       "      <td>121.00</td>\n",
       "      <td>1056.52</td>\n",
       "      <td>97.22</td>\n",
       "      <td>1051.03</td>\n",
       "      <td>46.92</td>\n",
       "      <td>924.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>1133.18</td>\n",
       "      <td>335.18</td>\n",
       "      <td>1291.00</td>\n",
       "      <td>500.79</td>\n",
       "      <td>1247.00</td>\n",
       "      <td>464.59</td>\n",
       "      <td>1138.93</td>\n",
       "      <td>502.96</td>\n",
       "      <td>1253.87</td>\n",
       "      <td>613.53</td>\n",
       "      <td>...</td>\n",
       "      <td>45.97</td>\n",
       "      <td>1061.00</td>\n",
       "      <td>121.00</td>\n",
       "      <td>1056.52</td>\n",
       "      <td>97.22</td>\n",
       "      <td>1051.03</td>\n",
       "      <td>46.92</td>\n",
       "      <td>1118.99</td>\n",
       "      <td>-4.10</td>\n",
       "      <td>938.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>1291.00</td>\n",
       "      <td>500.79</td>\n",
       "      <td>1247.00</td>\n",
       "      <td>464.59</td>\n",
       "      <td>1138.93</td>\n",
       "      <td>502.96</td>\n",
       "      <td>1253.87</td>\n",
       "      <td>613.53</td>\n",
       "      <td>1388.02</td>\n",
       "      <td>730.02</td>\n",
       "      <td>...</td>\n",
       "      <td>121.00</td>\n",
       "      <td>1056.52</td>\n",
       "      <td>97.22</td>\n",
       "      <td>1051.03</td>\n",
       "      <td>46.92</td>\n",
       "      <td>1118.99</td>\n",
       "      <td>-4.10</td>\n",
       "      <td>1251.96</td>\n",
       "      <td>118.78</td>\n",
       "      <td>969.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>1247.00</td>\n",
       "      <td>464.59</td>\n",
       "      <td>1138.93</td>\n",
       "      <td>502.96</td>\n",
       "      <td>1253.87</td>\n",
       "      <td>613.53</td>\n",
       "      <td>1388.02</td>\n",
       "      <td>730.02</td>\n",
       "      <td>1347.00</td>\n",
       "      <td>632.05</td>\n",
       "      <td>...</td>\n",
       "      <td>97.22</td>\n",
       "      <td>1051.03</td>\n",
       "      <td>46.92</td>\n",
       "      <td>1118.99</td>\n",
       "      <td>-4.10</td>\n",
       "      <td>1251.96</td>\n",
       "      <td>118.78</td>\n",
       "      <td>1177.01</td>\n",
       "      <td>-113.99</td>\n",
       "      <td>911.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>1138.93</td>\n",
       "      <td>502.96</td>\n",
       "      <td>1253.87</td>\n",
       "      <td>613.53</td>\n",
       "      <td>1388.02</td>\n",
       "      <td>730.02</td>\n",
       "      <td>1347.00</td>\n",
       "      <td>632.05</td>\n",
       "      <td>1271.00</td>\n",
       "      <td>521.00</td>\n",
       "      <td>...</td>\n",
       "      <td>46.92</td>\n",
       "      <td>1118.99</td>\n",
       "      <td>-4.10</td>\n",
       "      <td>1251.96</td>\n",
       "      <td>118.78</td>\n",
       "      <td>1177.01</td>\n",
       "      <td>-113.99</td>\n",
       "      <td>1085.50</td>\n",
       "      <td>-161.50</td>\n",
       "      <td>938.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1573</th>\n",
       "      <td>4287.80</td>\n",
       "      <td>1.78</td>\n",
       "      <td>3996.90</td>\n",
       "      <td>-421.99</td>\n",
       "      <td>4294.76</td>\n",
       "      <td>-27.92</td>\n",
       "      <td>4412.17</td>\n",
       "      <td>124.96</td>\n",
       "      <td>4258.31</td>\n",
       "      <td>-61.12</td>\n",
       "      <td>...</td>\n",
       "      <td>-154.25</td>\n",
       "      <td>4215.73</td>\n",
       "      <td>-428.55</td>\n",
       "      <td>4117.25</td>\n",
       "      <td>-509.25</td>\n",
       "      <td>4196.44</td>\n",
       "      <td>-367.34</td>\n",
       "      <td>4347.59</td>\n",
       "      <td>137.83</td>\n",
       "      <td>4063.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1574</th>\n",
       "      <td>3996.90</td>\n",
       "      <td>-421.99</td>\n",
       "      <td>4294.76</td>\n",
       "      <td>-27.92</td>\n",
       "      <td>4412.17</td>\n",
       "      <td>124.96</td>\n",
       "      <td>4258.31</td>\n",
       "      <td>-61.12</td>\n",
       "      <td>4085.97</td>\n",
       "      <td>-503.92</td>\n",
       "      <td>...</td>\n",
       "      <td>-428.55</td>\n",
       "      <td>4117.25</td>\n",
       "      <td>-509.25</td>\n",
       "      <td>4196.44</td>\n",
       "      <td>-367.34</td>\n",
       "      <td>4347.59</td>\n",
       "      <td>137.83</td>\n",
       "      <td>4306.40</td>\n",
       "      <td>18.60</td>\n",
       "      <td>4037.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1575</th>\n",
       "      <td>4294.76</td>\n",
       "      <td>-27.92</td>\n",
       "      <td>4412.17</td>\n",
       "      <td>124.96</td>\n",
       "      <td>4258.31</td>\n",
       "      <td>-61.12</td>\n",
       "      <td>4085.97</td>\n",
       "      <td>-503.92</td>\n",
       "      <td>4339.44</td>\n",
       "      <td>-263.91</td>\n",
       "      <td>...</td>\n",
       "      <td>-509.25</td>\n",
       "      <td>4196.44</td>\n",
       "      <td>-367.34</td>\n",
       "      <td>4347.59</td>\n",
       "      <td>137.83</td>\n",
       "      <td>4306.40</td>\n",
       "      <td>18.60</td>\n",
       "      <td>4436.91</td>\n",
       "      <td>440.01</td>\n",
       "      <td>3792.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1576</th>\n",
       "      <td>4412.17</td>\n",
       "      <td>124.96</td>\n",
       "      <td>4258.31</td>\n",
       "      <td>-61.12</td>\n",
       "      <td>4085.97</td>\n",
       "      <td>-503.92</td>\n",
       "      <td>4339.44</td>\n",
       "      <td>-263.91</td>\n",
       "      <td>4269.36</td>\n",
       "      <td>-262.96</td>\n",
       "      <td>...</td>\n",
       "      <td>-367.34</td>\n",
       "      <td>4347.59</td>\n",
       "      <td>137.83</td>\n",
       "      <td>4306.40</td>\n",
       "      <td>18.60</td>\n",
       "      <td>4436.91</td>\n",
       "      <td>440.01</td>\n",
       "      <td>4105.64</td>\n",
       "      <td>-189.12</td>\n",
       "      <td>3630.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1577</th>\n",
       "      <td>4258.31</td>\n",
       "      <td>-61.12</td>\n",
       "      <td>4085.97</td>\n",
       "      <td>-503.92</td>\n",
       "      <td>4339.44</td>\n",
       "      <td>-263.91</td>\n",
       "      <td>4269.36</td>\n",
       "      <td>-262.96</td>\n",
       "      <td>4524.85</td>\n",
       "      <td>50.61</td>\n",
       "      <td>...</td>\n",
       "      <td>137.83</td>\n",
       "      <td>4306.40</td>\n",
       "      <td>18.60</td>\n",
       "      <td>4436.91</td>\n",
       "      <td>440.01</td>\n",
       "      <td>4105.64</td>\n",
       "      <td>-189.12</td>\n",
       "      <td>3897.94</td>\n",
       "      <td>-514.23</td>\n",
       "      <td>3709.27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1415 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      close_19  close_diff_20_19  close_18  close_diff_20_18  close_17  \\\n",
       "163    1123.09            339.09   1133.18            335.18   1291.00   \n",
       "164    1133.18            335.18   1291.00            500.79   1247.00   \n",
       "165    1291.00            500.79   1247.00            464.59   1138.93   \n",
       "166    1247.00            464.59   1138.93            502.96   1253.87   \n",
       "167    1138.93            502.96   1253.87            613.53   1388.02   \n",
       "...        ...               ...       ...               ...       ...   \n",
       "1573   4287.80              1.78   3996.90           -421.99   4294.76   \n",
       "1574   3996.90           -421.99   4294.76            -27.92   4412.17   \n",
       "1575   4294.76            -27.92   4412.17            124.96   4258.31   \n",
       "1576   4412.17            124.96   4258.31            -61.12   4085.97   \n",
       "1577   4258.31            -61.12   4085.97           -503.92   4339.44   \n",
       "\n",
       "      close_diff_20_17  close_16  close_diff_20_16  close_15  \\\n",
       "163             500.79   1247.00            464.59   1138.93   \n",
       "164             464.59   1138.93            502.96   1253.87   \n",
       "165             502.96   1253.87            613.53   1388.02   \n",
       "166             613.53   1388.02            730.02   1347.00   \n",
       "167             730.02   1347.00            632.05   1271.00   \n",
       "...                ...       ...               ...       ...   \n",
       "1573            -27.92   4412.17            124.96   4258.31   \n",
       "1574            124.96   4258.31            -61.12   4085.97   \n",
       "1575            -61.12   4085.97           -503.92   4339.44   \n",
       "1576           -503.92   4339.44           -263.91   4269.36   \n",
       "1577           -263.91   4269.36           -262.96   4524.85   \n",
       "\n",
       "      close_diff_20_15  ...  close_diff_20_4  close_3  close_diff_20_3  \\\n",
       "163             502.96  ...           137.72   980.00            45.97   \n",
       "164             613.53  ...            45.97  1061.00           121.00   \n",
       "165             730.02  ...           121.00  1056.52            97.22   \n",
       "166             632.05  ...            97.22  1051.03            46.92   \n",
       "167             521.00  ...            46.92  1118.99            -4.10   \n",
       "...                ...  ...              ...      ...              ...   \n",
       "1573            -61.12  ...          -154.25  4215.73          -428.55   \n",
       "1574           -503.92  ...          -428.55  4117.25          -509.25   \n",
       "1575           -263.91  ...          -509.25  4196.44          -367.34   \n",
       "1576           -262.96  ...          -367.34  4347.59           137.83   \n",
       "1577             50.61  ...           137.83  4306.40            18.60   \n",
       "\n",
       "      close_2  close_diff_20_2  close_1  close_diff_20_1  close_0  \\\n",
       "163   1061.00           121.00  1056.52            97.22  1051.03   \n",
       "164   1056.52            97.22  1051.03            46.92  1118.99   \n",
       "165   1051.03            46.92  1118.99            -4.10  1251.96   \n",
       "166   1118.99            -4.10  1251.96           118.78  1177.01   \n",
       "167   1251.96           118.78  1177.01          -113.99  1085.50   \n",
       "...       ...              ...      ...              ...      ...   \n",
       "1573  4117.25          -509.25  4196.44          -367.34  4347.59   \n",
       "1574  4196.44          -367.34  4347.59           137.83  4306.40   \n",
       "1575  4347.59           137.83  4306.40            18.60  4436.91   \n",
       "1576  4306.40            18.60  4436.91           440.01  4105.64   \n",
       "1577  4436.91           440.01  4105.64          -189.12  3897.94   \n",
       "\n",
       "      close_diff_20_0    close  \n",
       "163             46.92   924.55  \n",
       "164             -4.10   938.67  \n",
       "165            118.78   969.99  \n",
       "166           -113.99   911.00  \n",
       "167           -161.50   938.11  \n",
       "...               ...      ...  \n",
       "1573           137.83  4063.56  \n",
       "1574            18.60  4037.23  \n",
       "1575           440.01  3792.75  \n",
       "1576          -189.12  3630.19  \n",
       "1577          -514.23  3709.27  \n",
       "\n",
       "[1415 rows x 41 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>close_19</th>\n",
       "      <th>close_diff_20_19</th>\n",
       "      <th>close_18</th>\n",
       "      <th>close_diff_20_18</th>\n",
       "      <th>close_17</th>\n",
       "      <th>close_diff_20_17</th>\n",
       "      <th>close_16</th>\n",
       "      <th>close_diff_20_16</th>\n",
       "      <th>close_15</th>\n",
       "      <th>close_diff_20_15</th>\n",
       "      <th>...</th>\n",
       "      <th>close_diff_20_4</th>\n",
       "      <th>close_3</th>\n",
       "      <th>close_diff_20_3</th>\n",
       "      <th>close_2</th>\n",
       "      <th>close_diff_20_2</th>\n",
       "      <th>close_1</th>\n",
       "      <th>close_diff_20_1</th>\n",
       "      <th>close_0</th>\n",
       "      <th>close_diff_20_0</th>\n",
       "      <th>close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1578</th>\n",
       "      <td>4085.97</td>\n",
       "      <td>-503.92</td>\n",
       "      <td>4339.44</td>\n",
       "      <td>-263.91</td>\n",
       "      <td>4269.36</td>\n",
       "      <td>-262.96</td>\n",
       "      <td>4524.85</td>\n",
       "      <td>50.61</td>\n",
       "      <td>4041.2</td>\n",
       "      <td>-476.8</td>\n",
       "      <td>...</td>\n",
       "      <td>18.6</td>\n",
       "      <td>4436.91</td>\n",
       "      <td>440.01</td>\n",
       "      <td>4105.64</td>\n",
       "      <td>-189.12</td>\n",
       "      <td>3897.94</td>\n",
       "      <td>-514.23</td>\n",
       "      <td>4089.37</td>\n",
       "      <td>-168.94</td>\n",
       "      <td>3725.46</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      close_19  close_diff_20_19  close_18  close_diff_20_18  close_17  \\\n",
       "1578   4085.97           -503.92   4339.44           -263.91   4269.36   \n",
       "\n",
       "      close_diff_20_17  close_16  close_diff_20_16  close_15  \\\n",
       "1578           -262.96   4524.85             50.61    4041.2   \n",
       "\n",
       "      close_diff_20_15  ...  close_diff_20_4  close_3  close_diff_20_3  \\\n",
       "1578            -476.8  ...             18.6  4436.91           440.01   \n",
       "\n",
       "      close_2  close_diff_20_2  close_1  close_diff_20_1  close_0  \\\n",
       "1578  4105.64          -189.12  3897.94          -514.23  4089.37   \n",
       "\n",
       "      close_diff_20_0    close  \n",
       "1578          -168.94  3725.46  \n",
       "\n",
       "[1 rows x 41 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (1415, 1, 40) (1415, 1)\n",
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_28 (LSTM)               (None, 1, 100)            56400     \n",
      "_________________________________________________________________\n",
      "lstm_29 (LSTM)               (None, 1, 50)             30200     \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 1, 50)             0         \n",
      "_________________________________________________________________\n",
      "lstm_30 (LSTM)               (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 106,851\n",
      "Trainable params: 106,851\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Y shape (1415, 1)\n",
      "Train on 1415 samples, validate on 283 samples\n",
      "Epoch 1/100\n",
      " - 6s - loss: 0.0754 - mse: 0.0754 - val_loss: 0.2900 - val_mse: 0.2900\n",
      "Epoch 2/100\n",
      " - 1s - loss: 0.0500 - mse: 0.0500 - val_loss: 0.1232 - val_mse: 0.1232\n",
      "Epoch 3/100\n",
      " - 1s - loss: 0.0312 - mse: 0.0312 - val_loss: 0.0259 - val_mse: 0.0259\n",
      "Epoch 4/100\n",
      " - 1s - loss: 0.0155 - mse: 0.0155 - val_loss: 0.0264 - val_mse: 0.0264\n",
      "Epoch 5/100\n",
      " - 1s - loss: 0.0128 - mse: 0.0128 - val_loss: 0.0212 - val_mse: 0.0212\n",
      "Epoch 6/100\n",
      " - 1s - loss: 0.0109 - mse: 0.0109 - val_loss: 0.0235 - val_mse: 0.0235\n",
      "Epoch 7/100\n",
      " - 1s - loss: 0.0108 - mse: 0.0108 - val_loss: 0.0192 - val_mse: 0.0192\n",
      "Epoch 8/100\n",
      " - 1s - loss: 0.0102 - mse: 0.0102 - val_loss: 0.0227 - val_mse: 0.0227\n",
      "Epoch 9/100\n",
      " - 1s - loss: 0.0092 - mse: 0.0092 - val_loss: 0.0182 - val_mse: 0.0182\n",
      "Epoch 10/100\n",
      " - 1s - loss: 0.0088 - mse: 0.0088 - val_loss: 0.0200 - val_mse: 0.0200\n",
      "Epoch 11/100\n",
      " - 1s - loss: 0.0078 - mse: 0.0078 - val_loss: 0.0176 - val_mse: 0.0176\n",
      "Epoch 12/100\n",
      " - 1s - loss: 0.0075 - mse: 0.0075 - val_loss: 0.0184 - val_mse: 0.0184\n",
      "Epoch 13/100\n",
      " - 1s - loss: 0.0072 - mse: 0.0072 - val_loss: 0.0175 - val_mse: 0.0175\n",
      "Epoch 14/100\n",
      " - 1s - loss: 0.0071 - mse: 0.0071 - val_loss: 0.0177 - val_mse: 0.0177\n",
      "Epoch 15/100\n",
      " - 1s - loss: 0.0060 - mse: 0.0060 - val_loss: 0.0168 - val_mse: 0.0168\n",
      "Epoch 16/100\n",
      " - 1s - loss: 0.0064 - mse: 0.0064 - val_loss: 0.0171 - val_mse: 0.0171\n",
      "Epoch 17/100\n",
      " - 1s - loss: 0.0059 - mse: 0.0059 - val_loss: 0.0166 - val_mse: 0.0166\n",
      "Epoch 18/100\n",
      " - 1s - loss: 0.0062 - mse: 0.0062 - val_loss: 0.0168 - val_mse: 0.0168\n",
      "Epoch 19/100\n",
      " - 1s - loss: 0.0060 - mse: 0.0060 - val_loss: 0.0163 - val_mse: 0.0163\n",
      "Epoch 20/100\n",
      " - 1s - loss: 0.0065 - mse: 0.0065 - val_loss: 0.0170 - val_mse: 0.0170\n",
      "Epoch 21/100\n",
      " - 1s - loss: 0.0058 - mse: 0.0058 - val_loss: 0.0162 - val_mse: 0.0162\n",
      "Epoch 22/100\n",
      " - 1s - loss: 0.0065 - mse: 0.0065 - val_loss: 0.0165 - val_mse: 0.0165\n",
      "Epoch 23/100\n",
      " - 1s - loss: 0.0057 - mse: 0.0057 - val_loss: 0.0161 - val_mse: 0.0161\n",
      "Epoch 24/100\n",
      " - 1s - loss: 0.0065 - mse: 0.0065 - val_loss: 0.0167 - val_mse: 0.0167\n",
      "Epoch 25/100\n",
      " - 1s - loss: 0.0053 - mse: 0.0053 - val_loss: 0.0158 - val_mse: 0.0158\n",
      "Epoch 26/100\n",
      " - 1s - loss: 0.0066 - mse: 0.0066 - val_loss: 0.0163 - val_mse: 0.0163\n",
      "Epoch 27/100\n",
      " - 1s - loss: 0.0051 - mse: 0.0051 - val_loss: 0.0157 - val_mse: 0.0157\n",
      "Epoch 28/100\n",
      " - 1s - loss: 0.0061 - mse: 0.0061 - val_loss: 0.0158 - val_mse: 0.0158\n",
      "Epoch 29/100\n",
      " - 1s - loss: 0.0059 - mse: 0.0059 - val_loss: 0.0156 - val_mse: 0.0156\n",
      "Epoch 30/100\n",
      " - 1s - loss: 0.0057 - mse: 0.0057 - val_loss: 0.0156 - val_mse: 0.0156\n",
      "Epoch 31/100\n",
      " - 1s - loss: 0.0064 - mse: 0.0064 - val_loss: 0.0158 - val_mse: 0.0158\n",
      "Epoch 32/100\n",
      " - 1s - loss: 0.0054 - mse: 0.0054 - val_loss: 0.0154 - val_mse: 0.0154\n",
      "Epoch 33/100\n",
      " - 1s - loss: 0.0061 - mse: 0.0061 - val_loss: 0.0157 - val_mse: 0.0157\n",
      "Epoch 34/100\n",
      " - 1s - loss: 0.0052 - mse: 0.0052 - val_loss: 0.0153 - val_mse: 0.0153\n",
      "Epoch 35/100\n",
      " - 1s - loss: 0.0061 - mse: 0.0061 - val_loss: 0.0155 - val_mse: 0.0155\n",
      "Epoch 36/100\n",
      " - 1s - loss: 0.0053 - mse: 0.0053 - val_loss: 0.0151 - val_mse: 0.0151\n",
      "Epoch 37/100\n",
      " - 1s - loss: 0.0058 - mse: 0.0058 - val_loss: 0.0152 - val_mse: 0.0152\n",
      "Epoch 38/100\n",
      " - 1s - loss: 0.0055 - mse: 0.0055 - val_loss: 0.0151 - val_mse: 0.0151\n",
      "Epoch 39/100\n",
      " - 1s - loss: 0.0050 - mse: 0.0050 - val_loss: 0.0151 - val_mse: 0.0151\n",
      "Epoch 40/100\n",
      " - 1s - loss: 0.0059 - mse: 0.0059 - val_loss: 0.0152 - val_mse: 0.0152\n",
      "Epoch 41/100\n",
      " - 1s - loss: 0.0052 - mse: 0.0052 - val_loss: 0.0149 - val_mse: 0.0149\n",
      "Epoch 42/100\n",
      " - 1s - loss: 0.0053 - mse: 0.0053 - val_loss: 0.0149 - val_mse: 0.0149\n",
      "Epoch 43/100\n",
      " - 1s - loss: 0.0053 - mse: 0.0053 - val_loss: 0.0150 - val_mse: 0.0150\n",
      "Epoch 44/100\n",
      " - 1s - loss: 0.0061 - mse: 0.0061 - val_loss: 0.0156 - val_mse: 0.0156\n",
      "Epoch 45/100\n",
      " - 1s - loss: 0.0056 - mse: 0.0056 - val_loss: 0.0154 - val_mse: 0.0154\n",
      "Epoch 46/100\n",
      " - 1s - loss: 0.0076 - mse: 0.0076 - val_loss: 0.0161 - val_mse: 0.0161\n",
      "Epoch 47/100\n",
      " - 1s - loss: 0.0053 - mse: 0.0053 - val_loss: 0.0150 - val_mse: 0.0150\n",
      "Epoch 48/100\n",
      " - 1s - loss: 0.0065 - mse: 0.0065 - val_loss: 0.0156 - val_mse: 0.0156\n",
      "Epoch 49/100\n",
      " - 1s - loss: 0.0052 - mse: 0.0052 - val_loss: 0.0147 - val_mse: 0.0147\n",
      "Epoch 50/100\n",
      " - 1s - loss: 0.0062 - mse: 0.0062 - val_loss: 0.0149 - val_mse: 0.0149\n",
      "Epoch 51/100\n",
      " - 1s - loss: 0.0051 - mse: 0.0051 - val_loss: 0.0147 - val_mse: 0.0147\n",
      "Epoch 52/100\n",
      " - 1s - loss: 0.0051 - mse: 0.0051 - val_loss: 0.0147 - val_mse: 0.0147\n",
      "Epoch 53/100\n",
      " - 1s - loss: 0.0052 - mse: 0.0052 - val_loss: 0.0147 - val_mse: 0.0147\n",
      "Epoch 54/100\n",
      " - 1s - loss: 0.0051 - mse: 0.0051 - val_loss: 0.0146 - val_mse: 0.0146\n",
      "Epoch 55/100\n",
      " - 1s - loss: 0.0053 - mse: 0.0053 - val_loss: 0.0148 - val_mse: 0.0148\n",
      "Epoch 56/100\n",
      " - 1s - loss: 0.0047 - mse: 0.0047 - val_loss: 0.0146 - val_mse: 0.0146\n",
      "Epoch 57/100\n",
      " - 1s - loss: 0.0052 - mse: 0.0052 - val_loss: 0.0147 - val_mse: 0.0147\n",
      "Epoch 58/100\n",
      " - 1s - loss: 0.0051 - mse: 0.0051 - val_loss: 0.0146 - val_mse: 0.0146\n",
      "Epoch 59/100\n",
      " - 1s - loss: 0.0051 - mse: 0.0051 - val_loss: 0.0146 - val_mse: 0.0146\n",
      "Epoch 60/100\n",
      " - 1s - loss: 0.0054 - mse: 0.0054 - val_loss: 0.0147 - val_mse: 0.0147\n",
      "Epoch 61/100\n",
      " - 1s - loss: 0.0050 - mse: 0.0050 - val_loss: 0.0145 - val_mse: 0.0145\n",
      "Epoch 62/100\n",
      " - 1s - loss: 0.0058 - mse: 0.0058 - val_loss: 0.0146 - val_mse: 0.0146\n",
      "Epoch 63/100\n",
      " - 1s - loss: 0.0051 - mse: 0.0051 - val_loss: 0.0145 - val_mse: 0.0145\n",
      "Epoch 64/100\n",
      " - 1s - loss: 0.0054 - mse: 0.0054 - val_loss: 0.0145 - val_mse: 0.0145\n",
      "Epoch 65/100\n",
      " - 1s - loss: 0.0050 - mse: 0.0050 - val_loss: 0.0147 - val_mse: 0.0147\n",
      "Epoch 66/100\n",
      " - 1s - loss: 0.0048 - mse: 0.0048 - val_loss: 0.0146 - val_mse: 0.0146\n",
      "Epoch 67/100\n",
      " - 1s - loss: 0.0054 - mse: 0.0054 - val_loss: 0.0145 - val_mse: 0.0145\n",
      "Epoch 68/100\n",
      " - 1s - loss: 0.0051 - mse: 0.0051 - val_loss: 0.0144 - val_mse: 0.0144\n",
      "Epoch 69/100\n",
      " - 1s - loss: 0.0054 - mse: 0.0054 - val_loss: 0.0144 - val_mse: 0.0144\n",
      "Epoch 70/100\n",
      " - 1s - loss: 0.0053 - mse: 0.0053 - val_loss: 0.0145 - val_mse: 0.0145\n",
      "Epoch 71/100\n",
      " - 1s - loss: 0.0049 - mse: 0.0049 - val_loss: 0.0144 - val_mse: 0.0144\n",
      "Epoch 72/100\n",
      " - 1s - loss: 0.0059 - mse: 0.0059 - val_loss: 0.0147 - val_mse: 0.0147\n",
      "Epoch 73/100\n",
      " - 1s - loss: 0.0049 - mse: 0.0049 - val_loss: 0.0144 - val_mse: 0.0144\n",
      "Epoch 74/100\n",
      " - 1s - loss: 0.0053 - mse: 0.0053 - val_loss: 0.0147 - val_mse: 0.0147\n",
      "Epoch 75/100\n",
      " - 1s - loss: 0.0050 - mse: 0.0050 - val_loss: 0.0144 - val_mse: 0.0144\n",
      "Epoch 76/100\n",
      " - 1s - loss: 0.0055 - mse: 0.0055 - val_loss: 0.0145 - val_mse: 0.0145\n",
      "Epoch 77/100\n",
      " - 1s - loss: 0.0053 - mse: 0.0053 - val_loss: 0.0147 - val_mse: 0.0147\n",
      "Epoch 78/100\n",
      " - 1s - loss: 0.0048 - mse: 0.0048 - val_loss: 0.0144 - val_mse: 0.0144\n",
      "Epoch 79/100\n",
      " - 1s - loss: 0.0054 - mse: 0.0054 - val_loss: 0.0144 - val_mse: 0.0144\n",
      "Epoch 80/100\n",
      " - 1s - loss: 0.0052 - mse: 0.0052 - val_loss: 0.0144 - val_mse: 0.0144\n",
      "Epoch 81/100\n",
      " - 1s - loss: 0.0047 - mse: 0.0047 - val_loss: 0.0143 - val_mse: 0.0143\n",
      "real [[3725.46]]\n",
      "Test RMSE: 285.608\n",
      "Diff [[-285.608383]]\n",
      "% Diff [[-7.66639242]] %\n",
      "Predictions [[4011.068383]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "batch_size = 32\n",
    "\n",
    "crypto = crypto\n",
    "execute_test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Batch size 16\n",
    "\n",
    "El entrenamiento se hace muy lento y por ello bajaremos el numeor de epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading... BTC\n",
      "Extracting columns columns for BTC\n",
      "Proccessing and arranging columns for LSTM model\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>close_19</th>\n",
       "      <th>close_diff_20_19</th>\n",
       "      <th>close_18</th>\n",
       "      <th>close_diff_20_18</th>\n",
       "      <th>close_17</th>\n",
       "      <th>close_diff_20_17</th>\n",
       "      <th>close_16</th>\n",
       "      <th>close_diff_20_16</th>\n",
       "      <th>close_15</th>\n",
       "      <th>close_diff_20_15</th>\n",
       "      <th>...</th>\n",
       "      <th>close_diff_20_4</th>\n",
       "      <th>close_3</th>\n",
       "      <th>close_diff_20_3</th>\n",
       "      <th>close_2</th>\n",
       "      <th>close_diff_20_2</th>\n",
       "      <th>close_1</th>\n",
       "      <th>close_diff_20_1</th>\n",
       "      <th>close_0</th>\n",
       "      <th>close_diff_20_0</th>\n",
       "      <th>close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>16150.03</td>\n",
       "      <td>-2706.22</td>\n",
       "      <td>14902.54</td>\n",
       "      <td>-2392.66</td>\n",
       "      <td>14400.00</td>\n",
       "      <td>-2088.98</td>\n",
       "      <td>14907.09</td>\n",
       "      <td>-585.55</td>\n",
       "      <td>13238.78</td>\n",
       "      <td>-87.83</td>\n",
       "      <td>...</td>\n",
       "      <td>-3915.06</td>\n",
       "      <td>10799.18</td>\n",
       "      <td>-4120.33</td>\n",
       "      <td>11349.99</td>\n",
       "      <td>-3709.55</td>\n",
       "      <td>11175.27</td>\n",
       "      <td>-5785.12</td>\n",
       "      <td>11089.00</td>\n",
       "      <td>-5980.79</td>\n",
       "      <td>10000.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>14902.54</td>\n",
       "      <td>-2392.66</td>\n",
       "      <td>14400.00</td>\n",
       "      <td>-2088.98</td>\n",
       "      <td>14907.09</td>\n",
       "      <td>-585.55</td>\n",
       "      <td>13238.78</td>\n",
       "      <td>-87.83</td>\n",
       "      <td>13740.01</td>\n",
       "      <td>440.01</td>\n",
       "      <td>...</td>\n",
       "      <td>-4120.33</td>\n",
       "      <td>11349.99</td>\n",
       "      <td>-3709.55</td>\n",
       "      <td>11175.27</td>\n",
       "      <td>-5785.12</td>\n",
       "      <td>11089.00</td>\n",
       "      <td>-5980.79</td>\n",
       "      <td>11491.00</td>\n",
       "      <td>-4659.03</td>\n",
       "      <td>10159.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>14400.00</td>\n",
       "      <td>-2088.98</td>\n",
       "      <td>14907.09</td>\n",
       "      <td>-585.55</td>\n",
       "      <td>13238.78</td>\n",
       "      <td>-87.83</td>\n",
       "      <td>13740.01</td>\n",
       "      <td>440.01</td>\n",
       "      <td>14210.00</td>\n",
       "      <td>710.00</td>\n",
       "      <td>...</td>\n",
       "      <td>-3709.55</td>\n",
       "      <td>11175.27</td>\n",
       "      <td>-5785.12</td>\n",
       "      <td>11089.00</td>\n",
       "      <td>-5980.79</td>\n",
       "      <td>11491.00</td>\n",
       "      <td>-4659.03</td>\n",
       "      <td>11879.95</td>\n",
       "      <td>-3022.59</td>\n",
       "      <td>11039.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>14907.09</td>\n",
       "      <td>-585.55</td>\n",
       "      <td>13238.78</td>\n",
       "      <td>-87.83</td>\n",
       "      <td>13740.01</td>\n",
       "      <td>440.01</td>\n",
       "      <td>14210.00</td>\n",
       "      <td>710.00</td>\n",
       "      <td>13474.99</td>\n",
       "      <td>-224.35</td>\n",
       "      <td>...</td>\n",
       "      <td>-5785.12</td>\n",
       "      <td>11089.00</td>\n",
       "      <td>-5980.79</td>\n",
       "      <td>11491.00</td>\n",
       "      <td>-4659.03</td>\n",
       "      <td>11879.95</td>\n",
       "      <td>-3022.59</td>\n",
       "      <td>11251.00</td>\n",
       "      <td>-3149.00</td>\n",
       "      <td>10383.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>13238.78</td>\n",
       "      <td>-87.83</td>\n",
       "      <td>13740.01</td>\n",
       "      <td>440.01</td>\n",
       "      <td>14210.00</td>\n",
       "      <td>710.00</td>\n",
       "      <td>13474.99</td>\n",
       "      <td>-224.35</td>\n",
       "      <td>13539.93</td>\n",
       "      <td>-2149.08</td>\n",
       "      <td>...</td>\n",
       "      <td>-5980.79</td>\n",
       "      <td>11491.00</td>\n",
       "      <td>-4659.03</td>\n",
       "      <td>11879.95</td>\n",
       "      <td>-3022.59</td>\n",
       "      <td>11251.00</td>\n",
       "      <td>-3149.00</td>\n",
       "      <td>10237.51</td>\n",
       "      <td>-4669.58</td>\n",
       "      <td>11153.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1593</th>\n",
       "      <td>50588.95</td>\n",
       "      <td>-9755.92</td>\n",
       "      <td>50471.19</td>\n",
       "      <td>-6420.43</td>\n",
       "      <td>47545.59</td>\n",
       "      <td>-10506.65</td>\n",
       "      <td>47140.54</td>\n",
       "      <td>-12566.97</td>\n",
       "      <td>49389.99</td>\n",
       "      <td>-9232.03</td>\n",
       "      <td>...</td>\n",
       "      <td>-7892.18</td>\n",
       "      <td>50838.81</td>\n",
       "      <td>-2762.24</td>\n",
       "      <td>50820.00</td>\n",
       "      <td>1667.53</td>\n",
       "      <td>50399.66</td>\n",
       "      <td>1003.33</td>\n",
       "      <td>50775.49</td>\n",
       "      <td>333.57</td>\n",
       "      <td>43084.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1594</th>\n",
       "      <td>50471.19</td>\n",
       "      <td>-6420.43</td>\n",
       "      <td>47545.59</td>\n",
       "      <td>-10506.65</td>\n",
       "      <td>47140.54</td>\n",
       "      <td>-12566.97</td>\n",
       "      <td>49389.99</td>\n",
       "      <td>-9232.03</td>\n",
       "      <td>50053.90</td>\n",
       "      <td>-6193.28</td>\n",
       "      <td>...</td>\n",
       "      <td>-2762.24</td>\n",
       "      <td>50820.00</td>\n",
       "      <td>1667.53</td>\n",
       "      <td>50399.66</td>\n",
       "      <td>1003.33</td>\n",
       "      <td>50775.49</td>\n",
       "      <td>333.57</td>\n",
       "      <td>50701.44</td>\n",
       "      <td>112.49</td>\n",
       "      <td>43071.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1595</th>\n",
       "      <td>47545.59</td>\n",
       "      <td>-10506.65</td>\n",
       "      <td>47140.54</td>\n",
       "      <td>-12566.97</td>\n",
       "      <td>49389.99</td>\n",
       "      <td>-9232.03</td>\n",
       "      <td>50053.90</td>\n",
       "      <td>-6193.28</td>\n",
       "      <td>46702.75</td>\n",
       "      <td>-10838.52</td>\n",
       "      <td>...</td>\n",
       "      <td>1667.53</td>\n",
       "      <td>50399.66</td>\n",
       "      <td>1003.33</td>\n",
       "      <td>50775.49</td>\n",
       "      <td>333.57</td>\n",
       "      <td>50701.44</td>\n",
       "      <td>112.49</td>\n",
       "      <td>47543.74</td>\n",
       "      <td>-2927.45</td>\n",
       "      <td>42201.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1596</th>\n",
       "      <td>47140.54</td>\n",
       "      <td>-12566.97</td>\n",
       "      <td>49389.99</td>\n",
       "      <td>-9232.03</td>\n",
       "      <td>50053.90</td>\n",
       "      <td>-6193.28</td>\n",
       "      <td>46702.75</td>\n",
       "      <td>-10838.52</td>\n",
       "      <td>48343.28</td>\n",
       "      <td>-8795.01</td>\n",
       "      <td>...</td>\n",
       "      <td>1003.33</td>\n",
       "      <td>50775.49</td>\n",
       "      <td>333.57</td>\n",
       "      <td>50701.44</td>\n",
       "      <td>112.49</td>\n",
       "      <td>47543.74</td>\n",
       "      <td>-2927.45</td>\n",
       "      <td>46464.66</td>\n",
       "      <td>-1080.93</td>\n",
       "      <td>42352.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1597</th>\n",
       "      <td>49389.99</td>\n",
       "      <td>-9232.03</td>\n",
       "      <td>50053.90</td>\n",
       "      <td>-6193.28</td>\n",
       "      <td>46702.75</td>\n",
       "      <td>-10838.52</td>\n",
       "      <td>48343.28</td>\n",
       "      <td>-8795.01</td>\n",
       "      <td>48864.98</td>\n",
       "      <td>-10095.38</td>\n",
       "      <td>...</td>\n",
       "      <td>333.57</td>\n",
       "      <td>50701.44</td>\n",
       "      <td>112.49</td>\n",
       "      <td>47543.74</td>\n",
       "      <td>-2927.45</td>\n",
       "      <td>46464.66</td>\n",
       "      <td>-1080.93</td>\n",
       "      <td>47120.87</td>\n",
       "      <td>-19.67</td>\n",
       "      <td>41660.01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1435 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      close_19  close_diff_20_19  close_18  close_diff_20_18  close_17  \\\n",
       "163   16150.03          -2706.22  14902.54          -2392.66  14400.00   \n",
       "164   14902.54          -2392.66  14400.00          -2088.98  14907.09   \n",
       "165   14400.00          -2088.98  14907.09           -585.55  13238.78   \n",
       "166   14907.09           -585.55  13238.78            -87.83  13740.01   \n",
       "167   13238.78            -87.83  13740.01            440.01  14210.00   \n",
       "...        ...               ...       ...               ...       ...   \n",
       "1593  50588.95          -9755.92  50471.19          -6420.43  47545.59   \n",
       "1594  50471.19          -6420.43  47545.59         -10506.65  47140.54   \n",
       "1595  47545.59         -10506.65  47140.54         -12566.97  49389.99   \n",
       "1596  47140.54         -12566.97  49389.99          -9232.03  50053.90   \n",
       "1597  49389.99          -9232.03  50053.90          -6193.28  46702.75   \n",
       "\n",
       "      close_diff_20_17  close_16  close_diff_20_16  close_15  \\\n",
       "163           -2088.98  14907.09           -585.55  13238.78   \n",
       "164            -585.55  13238.78            -87.83  13740.01   \n",
       "165             -87.83  13740.01            440.01  14210.00   \n",
       "166             440.01  14210.00            710.00  13474.99   \n",
       "167             710.00  13474.99           -224.35  13539.93   \n",
       "...                ...       ...               ...       ...   \n",
       "1593         -10506.65  47140.54         -12566.97  49389.99   \n",
       "1594         -12566.97  49389.99          -9232.03  50053.90   \n",
       "1595          -9232.03  50053.90          -6193.28  46702.75   \n",
       "1596          -6193.28  46702.75         -10838.52  48343.28   \n",
       "1597         -10838.52  48343.28          -8795.01  48864.98   \n",
       "\n",
       "      close_diff_20_15  ...  close_diff_20_4   close_3  close_diff_20_3  \\\n",
       "163             -87.83  ...         -3915.06  10799.18         -4120.33   \n",
       "164             440.01  ...         -4120.33  11349.99         -3709.55   \n",
       "165             710.00  ...         -3709.55  11175.27         -5785.12   \n",
       "166            -224.35  ...         -5785.12  11089.00         -5980.79   \n",
       "167           -2149.08  ...         -5980.79  11491.00         -4659.03   \n",
       "...                ...  ...              ...       ...              ...   \n",
       "1593          -9232.03  ...         -7892.18  50838.81         -2762.24   \n",
       "1594          -6193.28  ...         -2762.24  50820.00          1667.53   \n",
       "1595         -10838.52  ...          1667.53  50399.66          1003.33   \n",
       "1596          -8795.01  ...          1003.33  50775.49           333.57   \n",
       "1597         -10095.38  ...           333.57  50701.44           112.49   \n",
       "\n",
       "       close_2  close_diff_20_2   close_1  close_diff_20_1   close_0  \\\n",
       "163   11349.99         -3709.55  11175.27         -5785.12  11089.00   \n",
       "164   11175.27         -5785.12  11089.00         -5980.79  11491.00   \n",
       "165   11089.00         -5980.79  11491.00         -4659.03  11879.95   \n",
       "166   11491.00         -4659.03  11879.95         -3022.59  11251.00   \n",
       "167   11879.95         -3022.59  11251.00         -3149.00  10237.51   \n",
       "...        ...              ...       ...              ...       ...   \n",
       "1593  50820.00          1667.53  50399.66          1003.33  50775.49   \n",
       "1594  50399.66          1003.33  50775.49           333.57  50701.44   \n",
       "1595  50775.49           333.57  50701.44           112.49  47543.74   \n",
       "1596  50701.44           112.49  47543.74         -2927.45  46464.66   \n",
       "1597  47543.74         -2927.45  46464.66         -1080.93  47120.87   \n",
       "\n",
       "      close_diff_20_0     close  \n",
       "163          -5980.79  10000.09  \n",
       "164          -4659.03  10159.98  \n",
       "165          -3022.59  11039.55  \n",
       "166          -3149.00  10383.43  \n",
       "167          -4669.58  11153.00  \n",
       "...               ...       ...  \n",
       "1593           333.57  43084.29  \n",
       "1594           112.49  43071.66  \n",
       "1595         -2927.45  42201.62  \n",
       "1596         -1080.93  42352.12  \n",
       "1597           -19.67  41660.01  \n",
       "\n",
       "[1435 rows x 41 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>close_19</th>\n",
       "      <th>close_diff_20_19</th>\n",
       "      <th>close_18</th>\n",
       "      <th>close_diff_20_18</th>\n",
       "      <th>close_17</th>\n",
       "      <th>close_diff_20_17</th>\n",
       "      <th>close_16</th>\n",
       "      <th>close_diff_20_16</th>\n",
       "      <th>close_15</th>\n",
       "      <th>close_diff_20_15</th>\n",
       "      <th>...</th>\n",
       "      <th>close_diff_20_4</th>\n",
       "      <th>close_3</th>\n",
       "      <th>close_diff_20_3</th>\n",
       "      <th>close_2</th>\n",
       "      <th>close_diff_20_2</th>\n",
       "      <th>close_1</th>\n",
       "      <th>close_diff_20_1</th>\n",
       "      <th>close_0</th>\n",
       "      <th>close_diff_20_0</th>\n",
       "      <th>close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1598</th>\n",
       "      <td>50053.9</td>\n",
       "      <td>-6193.28</td>\n",
       "      <td>46702.75</td>\n",
       "      <td>-10838.52</td>\n",
       "      <td>48343.28</td>\n",
       "      <td>-8795.01</td>\n",
       "      <td>48864.98</td>\n",
       "      <td>-10095.38</td>\n",
       "      <td>47632.38</td>\n",
       "      <td>-6094.15</td>\n",
       "      <td>...</td>\n",
       "      <td>112.49</td>\n",
       "      <td>47543.74</td>\n",
       "      <td>-2927.45</td>\n",
       "      <td>46464.66</td>\n",
       "      <td>-1080.93</td>\n",
       "      <td>47120.87</td>\n",
       "      <td>-19.67</td>\n",
       "      <td>46216.93</td>\n",
       "      <td>-3173.06</td>\n",
       "      <td>41761.89</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      close_19  close_diff_20_19  close_18  close_diff_20_18  close_17  \\\n",
       "1598   50053.9          -6193.28  46702.75         -10838.52  48343.28   \n",
       "\n",
       "      close_diff_20_17  close_16  close_diff_20_16  close_15  \\\n",
       "1598          -8795.01  48864.98         -10095.38  47632.38   \n",
       "\n",
       "      close_diff_20_15  ...  close_diff_20_4   close_3  close_diff_20_3  \\\n",
       "1598          -6094.15  ...           112.49  47543.74         -2927.45   \n",
       "\n",
       "       close_2  close_diff_20_2   close_1  close_diff_20_1   close_0  \\\n",
       "1598  46464.66         -1080.93  47120.87           -19.67  46216.93   \n",
       "\n",
       "      close_diff_20_0     close  \n",
       "1598         -3173.06  41761.89  \n",
       "\n",
       "[1 rows x 41 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (1435, 1, 40) (1435, 1)\n",
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_40 (LSTM)               (None, 1, 100)            56400     \n",
      "_________________________________________________________________\n",
      "lstm_41 (LSTM)               (None, 1, 50)             30200     \n",
      "_________________________________________________________________\n",
      "dropout_25 (Dropout)         (None, 1, 50)             0         \n",
      "_________________________________________________________________\n",
      "lstm_42 (LSTM)               (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_26 (Dropout)         (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 106,851\n",
      "Trainable params: 106,851\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Y shape (1435, 1)\n",
      "Train on 1435 samples, validate on 287 samples\n",
      "Epoch 1/70\n",
      " - 7s - loss: 0.0272 - mse: 0.0272 - val_loss: 0.0177 - val_mse: 0.0177\n",
      "Epoch 2/70\n",
      " - 1s - loss: 0.0869 - mse: 0.0869 - val_loss: 0.0883 - val_mse: 0.0883\n",
      "Epoch 3/70\n",
      " - 1s - loss: 0.0361 - mse: 0.0361 - val_loss: 0.0289 - val_mse: 0.0289\n",
      "Epoch 4/70\n",
      " - 1s - loss: 0.0179 - mse: 0.0179 - val_loss: 0.0191 - val_mse: 0.0191\n",
      "Epoch 5/70\n",
      " - 1s - loss: 0.0101 - mse: 0.0101 - val_loss: 0.0168 - val_mse: 0.0168\n",
      "Epoch 6/70\n",
      " - 1s - loss: 0.0085 - mse: 0.0085 - val_loss: 0.0165 - val_mse: 0.0165\n",
      "Epoch 7/70\n",
      " - 1s - loss: 0.0085 - mse: 0.0085 - val_loss: 0.0165 - val_mse: 0.0165\n",
      "Epoch 8/70\n",
      " - 1s - loss: 0.0077 - mse: 0.0077 - val_loss: 0.0158 - val_mse: 0.0158\n",
      "Epoch 9/70\n",
      " - 3s - loss: 0.0067 - mse: 0.0067 - val_loss: 0.0153 - val_mse: 0.0153\n",
      "Epoch 10/70\n",
      " - 2s - loss: 0.0072 - mse: 0.0072 - val_loss: 0.0152 - val_mse: 0.0152\n",
      "Epoch 11/70\n",
      " - 2s - loss: 0.0071 - mse: 0.0071 - val_loss: 0.0149 - val_mse: 0.0149\n",
      "Epoch 12/70\n",
      " - 2s - loss: 0.0071 - mse: 0.0071 - val_loss: 0.0145 - val_mse: 0.0145\n",
      "Epoch 13/70\n",
      " - 1s - loss: 0.0069 - mse: 0.0069 - val_loss: 0.0145 - val_mse: 0.0145\n",
      "Epoch 14/70\n",
      " - 1s - loss: 0.0068 - mse: 0.0068 - val_loss: 0.0140 - val_mse: 0.0140\n",
      "Epoch 15/70\n",
      " - 1s - loss: 0.0068 - mse: 0.0068 - val_loss: 0.0136 - val_mse: 0.0136\n",
      "Epoch 16/70\n",
      " - 1s - loss: 0.0064 - mse: 0.0064 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 17/70\n",
      " - 1s - loss: 0.0061 - mse: 0.0061 - val_loss: 0.0132 - val_mse: 0.0132\n",
      "Epoch 18/70\n",
      " - 1s - loss: 0.0068 - mse: 0.0068 - val_loss: 0.0130 - val_mse: 0.0130\n",
      "Epoch 19/70\n",
      " - 1s - loss: 0.0063 - mse: 0.0063 - val_loss: 0.0126 - val_mse: 0.0126\n",
      "Epoch 20/70\n",
      " - 1s - loss: 0.0065 - mse: 0.0065 - val_loss: 0.0125 - val_mse: 0.0125\n",
      "Epoch 21/70\n",
      " - 1s - loss: 0.0062 - mse: 0.0062 - val_loss: 0.0125 - val_mse: 0.0125\n",
      "Epoch 22/70\n",
      " - 1s - loss: 0.0062 - mse: 0.0062 - val_loss: 0.0126 - val_mse: 0.0126\n",
      "Epoch 23/70\n",
      " - 1s - loss: 0.0064 - mse: 0.0064 - val_loss: 0.0124 - val_mse: 0.0124\n",
      "Epoch 24/70\n",
      " - 1s - loss: 0.0063 - mse: 0.0063 - val_loss: 0.0123 - val_mse: 0.0123\n",
      "Epoch 25/70\n",
      " - 1s - loss: 0.0056 - mse: 0.0056 - val_loss: 0.0120 - val_mse: 0.0120\n",
      "Epoch 26/70\n",
      " - 1s - loss: 0.0059 - mse: 0.0059 - val_loss: 0.0120 - val_mse: 0.0120\n",
      "Epoch 27/70\n",
      " - 1s - loss: 0.0057 - mse: 0.0057 - val_loss: 0.0117 - val_mse: 0.0117\n",
      "Epoch 28/70\n",
      " - 1s - loss: 0.0059 - mse: 0.0059 - val_loss: 0.0116 - val_mse: 0.0116\n",
      "Epoch 29/70\n",
      " - 1s - loss: 0.0060 - mse: 0.0060 - val_loss: 0.0116 - val_mse: 0.0116\n",
      "Epoch 30/70\n",
      " - 1s - loss: 0.0068 - mse: 0.0068 - val_loss: 0.0124 - val_mse: 0.0124\n",
      "Epoch 31/70\n",
      " - 1s - loss: 0.0059 - mse: 0.0059 - val_loss: 0.0122 - val_mse: 0.0122\n",
      "Epoch 32/70\n",
      " - 1s - loss: 0.0058 - mse: 0.0058 - val_loss: 0.0119 - val_mse: 0.0119\n",
      "Epoch 33/70\n",
      " - 1s - loss: 0.0054 - mse: 0.0054 - val_loss: 0.0117 - val_mse: 0.0117\n",
      "Epoch 34/70\n",
      " - 1s - loss: 0.0057 - mse: 0.0057 - val_loss: 0.0116 - val_mse: 0.0116\n",
      "Epoch 35/70\n",
      " - 2s - loss: 0.0057 - mse: 0.0057 - val_loss: 0.0116 - val_mse: 0.0116\n",
      "Epoch 36/70\n",
      " - 1s - loss: 0.0059 - mse: 0.0059 - val_loss: 0.0116 - val_mse: 0.0116\n",
      "Epoch 37/70\n",
      " - 1s - loss: 0.0060 - mse: 0.0060 - val_loss: 0.0118 - val_mse: 0.0118\n",
      "Epoch 38/70\n",
      " - 1s - loss: 0.0058 - mse: 0.0058 - val_loss: 0.0119 - val_mse: 0.0119\n",
      "Epoch 39/70\n",
      " - 1s - loss: 0.0055 - mse: 0.0055 - val_loss: 0.0115 - val_mse: 0.0115\n",
      "Epoch 40/70\n",
      " - 1s - loss: 0.0057 - mse: 0.0057 - val_loss: 0.0118 - val_mse: 0.0118\n",
      "Epoch 41/70\n",
      " - 1s - loss: 0.0052 - mse: 0.0052 - val_loss: 0.0116 - val_mse: 0.0116\n",
      "Epoch 42/70\n",
      " - 1s - loss: 0.0058 - mse: 0.0058 - val_loss: 0.0116 - val_mse: 0.0116\n",
      "Epoch 43/70\n",
      " - 1s - loss: 0.0060 - mse: 0.0060 - val_loss: 0.0115 - val_mse: 0.0115\n",
      "Epoch 44/70\n",
      " - 1s - loss: 0.0063 - mse: 0.0063 - val_loss: 0.0118 - val_mse: 0.0118\n",
      "Epoch 45/70\n",
      " - 1s - loss: 0.0056 - mse: 0.0056 - val_loss: 0.0118 - val_mse: 0.0118\n",
      "Epoch 46/70\n",
      " - 1s - loss: 0.0053 - mse: 0.0053 - val_loss: 0.0113 - val_mse: 0.0113\n",
      "Epoch 47/70\n",
      " - 1s - loss: 0.0054 - mse: 0.0054 - val_loss: 0.0114 - val_mse: 0.0114\n",
      "Epoch 48/70\n",
      " - 1s - loss: 0.0057 - mse: 0.0057 - val_loss: 0.0114 - val_mse: 0.0114\n",
      "Epoch 49/70\n",
      " - 1s - loss: 0.0059 - mse: 0.0059 - val_loss: 0.0116 - val_mse: 0.0116\n",
      "Epoch 50/70\n",
      " - 1s - loss: 0.0057 - mse: 0.0057 - val_loss: 0.0116 - val_mse: 0.0116\n",
      "Epoch 51/70\n",
      " - 1s - loss: 0.0057 - mse: 0.0057 - val_loss: 0.0113 - val_mse: 0.0113\n",
      "Epoch 52/70\n",
      " - 1s - loss: 0.0057 - mse: 0.0057 - val_loss: 0.0117 - val_mse: 0.0117\n",
      "Epoch 53/70\n",
      " - 1s - loss: 0.0053 - mse: 0.0053 - val_loss: 0.0114 - val_mse: 0.0114\n",
      "Epoch 54/70\n",
      " - 1s - loss: 0.0054 - mse: 0.0054 - val_loss: 0.0113 - val_mse: 0.0113\n",
      "Epoch 55/70\n",
      " - 2s - loss: 0.0056 - mse: 0.0056 - val_loss: 0.0115 - val_mse: 0.0115\n",
      "Epoch 56/70\n",
      " - 1s - loss: 0.0059 - mse: 0.0059 - val_loss: 0.0117 - val_mse: 0.0117\n",
      "Epoch 57/70\n",
      " - 1s - loss: 0.0057 - mse: 0.0057 - val_loss: 0.0116 - val_mse: 0.0116\n",
      "Epoch 58/70\n",
      " - 1s - loss: 0.0054 - mse: 0.0054 - val_loss: 0.0113 - val_mse: 0.0113\n",
      "Epoch 59/70\n",
      " - 1s - loss: 0.0055 - mse: 0.0055 - val_loss: 0.0112 - val_mse: 0.0112\n",
      "Epoch 60/70\n",
      " - 1s - loss: 0.0055 - mse: 0.0055 - val_loss: 0.0112 - val_mse: 0.0112\n",
      "Epoch 61/70\n",
      " - 1s - loss: 0.0052 - mse: 0.0052 - val_loss: 0.0112 - val_mse: 0.0112\n",
      "Epoch 62/70\n",
      " - 1s - loss: 0.0057 - mse: 0.0057 - val_loss: 0.0114 - val_mse: 0.0114\n",
      "Epoch 63/70\n",
      " - 1s - loss: 0.0057 - mse: 0.0057 - val_loss: 0.0113 - val_mse: 0.0113\n",
      "Epoch 64/70\n",
      " - 1s - loss: 0.0055 - mse: 0.0055 - val_loss: 0.0115 - val_mse: 0.0115\n",
      "Epoch 65/70\n",
      " - 1s - loss: 0.0055 - mse: 0.0055 - val_loss: 0.0113 - val_mse: 0.0113\n",
      "Epoch 66/70\n",
      " - 1s - loss: 0.0056 - mse: 0.0056 - val_loss: 0.0112 - val_mse: 0.0112\n",
      "real [[41761.89]]\n",
      "Test RMSE: 3633.961\n",
      "Diff [[-3633.96085853]]\n",
      "% Diff [[-8.70161973]] %\n",
      "Predictions [[45395.85085853]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs = 70\n",
    "\n",
    "batch_size = 16\n",
    "\n",
    "crypto = crypto\n",
    "execute_test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Batch size 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 70\n",
    "\n",
    "batch_size = 8\n",
    "\n",
    "crypto = crypto\n",
    "execute_test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nos quedaremos con un bacth size de 16. Observamos ligeras mejoras. Con 8 se descontrola algo el aprendizaje. Se vuelve muy lento. Posiblemente se vuelva a probar mas adelante una vez seteados los demas parametros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probaremos otras activaciones y funcion de perdidas\n",
    "\n",
    "msle podria funcionar porque los movimientos del mercado son proporcionales al volumen de inversion y precios de la moneda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 70\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading... BTC\n",
      "Extracting columns columns for BTC\n",
      "Proccessing and arranging columns for LSTM model\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>close_19</th>\n",
       "      <th>close_diff_20_19</th>\n",
       "      <th>close_18</th>\n",
       "      <th>close_diff_20_18</th>\n",
       "      <th>close_17</th>\n",
       "      <th>close_diff_20_17</th>\n",
       "      <th>close_16</th>\n",
       "      <th>close_diff_20_16</th>\n",
       "      <th>close_15</th>\n",
       "      <th>close_diff_20_15</th>\n",
       "      <th>...</th>\n",
       "      <th>close_diff_20_4</th>\n",
       "      <th>close_3</th>\n",
       "      <th>close_diff_20_3</th>\n",
       "      <th>close_2</th>\n",
       "      <th>close_diff_20_2</th>\n",
       "      <th>close_1</th>\n",
       "      <th>close_diff_20_1</th>\n",
       "      <th>close_0</th>\n",
       "      <th>close_diff_20_0</th>\n",
       "      <th>close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>16150.03</td>\n",
       "      <td>-2706.22</td>\n",
       "      <td>14902.54</td>\n",
       "      <td>-2392.66</td>\n",
       "      <td>14400.00</td>\n",
       "      <td>-2088.98</td>\n",
       "      <td>14907.09</td>\n",
       "      <td>-585.55</td>\n",
       "      <td>13238.78</td>\n",
       "      <td>-87.83</td>\n",
       "      <td>...</td>\n",
       "      <td>-3915.06</td>\n",
       "      <td>10799.18</td>\n",
       "      <td>-4120.33</td>\n",
       "      <td>11349.99</td>\n",
       "      <td>-3709.55</td>\n",
       "      <td>11175.27</td>\n",
       "      <td>-5785.12</td>\n",
       "      <td>11089.00</td>\n",
       "      <td>-5980.79</td>\n",
       "      <td>10000.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>14902.54</td>\n",
       "      <td>-2392.66</td>\n",
       "      <td>14400.00</td>\n",
       "      <td>-2088.98</td>\n",
       "      <td>14907.09</td>\n",
       "      <td>-585.55</td>\n",
       "      <td>13238.78</td>\n",
       "      <td>-87.83</td>\n",
       "      <td>13740.01</td>\n",
       "      <td>440.01</td>\n",
       "      <td>...</td>\n",
       "      <td>-4120.33</td>\n",
       "      <td>11349.99</td>\n",
       "      <td>-3709.55</td>\n",
       "      <td>11175.27</td>\n",
       "      <td>-5785.12</td>\n",
       "      <td>11089.00</td>\n",
       "      <td>-5980.79</td>\n",
       "      <td>11491.00</td>\n",
       "      <td>-4659.03</td>\n",
       "      <td>10159.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>14400.00</td>\n",
       "      <td>-2088.98</td>\n",
       "      <td>14907.09</td>\n",
       "      <td>-585.55</td>\n",
       "      <td>13238.78</td>\n",
       "      <td>-87.83</td>\n",
       "      <td>13740.01</td>\n",
       "      <td>440.01</td>\n",
       "      <td>14210.00</td>\n",
       "      <td>710.00</td>\n",
       "      <td>...</td>\n",
       "      <td>-3709.55</td>\n",
       "      <td>11175.27</td>\n",
       "      <td>-5785.12</td>\n",
       "      <td>11089.00</td>\n",
       "      <td>-5980.79</td>\n",
       "      <td>11491.00</td>\n",
       "      <td>-4659.03</td>\n",
       "      <td>11879.95</td>\n",
       "      <td>-3022.59</td>\n",
       "      <td>11039.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>14907.09</td>\n",
       "      <td>-585.55</td>\n",
       "      <td>13238.78</td>\n",
       "      <td>-87.83</td>\n",
       "      <td>13740.01</td>\n",
       "      <td>440.01</td>\n",
       "      <td>14210.00</td>\n",
       "      <td>710.00</td>\n",
       "      <td>13474.99</td>\n",
       "      <td>-224.35</td>\n",
       "      <td>...</td>\n",
       "      <td>-5785.12</td>\n",
       "      <td>11089.00</td>\n",
       "      <td>-5980.79</td>\n",
       "      <td>11491.00</td>\n",
       "      <td>-4659.03</td>\n",
       "      <td>11879.95</td>\n",
       "      <td>-3022.59</td>\n",
       "      <td>11251.00</td>\n",
       "      <td>-3149.00</td>\n",
       "      <td>10383.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>13238.78</td>\n",
       "      <td>-87.83</td>\n",
       "      <td>13740.01</td>\n",
       "      <td>440.01</td>\n",
       "      <td>14210.00</td>\n",
       "      <td>710.00</td>\n",
       "      <td>13474.99</td>\n",
       "      <td>-224.35</td>\n",
       "      <td>13539.93</td>\n",
       "      <td>-2149.08</td>\n",
       "      <td>...</td>\n",
       "      <td>-5980.79</td>\n",
       "      <td>11491.00</td>\n",
       "      <td>-4659.03</td>\n",
       "      <td>11879.95</td>\n",
       "      <td>-3022.59</td>\n",
       "      <td>11251.00</td>\n",
       "      <td>-3149.00</td>\n",
       "      <td>10237.51</td>\n",
       "      <td>-4669.58</td>\n",
       "      <td>11153.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1593</th>\n",
       "      <td>50588.95</td>\n",
       "      <td>-9755.92</td>\n",
       "      <td>50471.19</td>\n",
       "      <td>-6420.43</td>\n",
       "      <td>47545.59</td>\n",
       "      <td>-10506.65</td>\n",
       "      <td>47140.54</td>\n",
       "      <td>-12566.97</td>\n",
       "      <td>49389.99</td>\n",
       "      <td>-9232.03</td>\n",
       "      <td>...</td>\n",
       "      <td>-7892.18</td>\n",
       "      <td>50838.81</td>\n",
       "      <td>-2762.24</td>\n",
       "      <td>50820.00</td>\n",
       "      <td>1667.53</td>\n",
       "      <td>50399.66</td>\n",
       "      <td>1003.33</td>\n",
       "      <td>50775.49</td>\n",
       "      <td>333.57</td>\n",
       "      <td>43084.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1594</th>\n",
       "      <td>50471.19</td>\n",
       "      <td>-6420.43</td>\n",
       "      <td>47545.59</td>\n",
       "      <td>-10506.65</td>\n",
       "      <td>47140.54</td>\n",
       "      <td>-12566.97</td>\n",
       "      <td>49389.99</td>\n",
       "      <td>-9232.03</td>\n",
       "      <td>50053.90</td>\n",
       "      <td>-6193.28</td>\n",
       "      <td>...</td>\n",
       "      <td>-2762.24</td>\n",
       "      <td>50820.00</td>\n",
       "      <td>1667.53</td>\n",
       "      <td>50399.66</td>\n",
       "      <td>1003.33</td>\n",
       "      <td>50775.49</td>\n",
       "      <td>333.57</td>\n",
       "      <td>50701.44</td>\n",
       "      <td>112.49</td>\n",
       "      <td>43071.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1595</th>\n",
       "      <td>47545.59</td>\n",
       "      <td>-10506.65</td>\n",
       "      <td>47140.54</td>\n",
       "      <td>-12566.97</td>\n",
       "      <td>49389.99</td>\n",
       "      <td>-9232.03</td>\n",
       "      <td>50053.90</td>\n",
       "      <td>-6193.28</td>\n",
       "      <td>46702.75</td>\n",
       "      <td>-10838.52</td>\n",
       "      <td>...</td>\n",
       "      <td>1667.53</td>\n",
       "      <td>50399.66</td>\n",
       "      <td>1003.33</td>\n",
       "      <td>50775.49</td>\n",
       "      <td>333.57</td>\n",
       "      <td>50701.44</td>\n",
       "      <td>112.49</td>\n",
       "      <td>47543.74</td>\n",
       "      <td>-2927.45</td>\n",
       "      <td>42201.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1596</th>\n",
       "      <td>47140.54</td>\n",
       "      <td>-12566.97</td>\n",
       "      <td>49389.99</td>\n",
       "      <td>-9232.03</td>\n",
       "      <td>50053.90</td>\n",
       "      <td>-6193.28</td>\n",
       "      <td>46702.75</td>\n",
       "      <td>-10838.52</td>\n",
       "      <td>48343.28</td>\n",
       "      <td>-8795.01</td>\n",
       "      <td>...</td>\n",
       "      <td>1003.33</td>\n",
       "      <td>50775.49</td>\n",
       "      <td>333.57</td>\n",
       "      <td>50701.44</td>\n",
       "      <td>112.49</td>\n",
       "      <td>47543.74</td>\n",
       "      <td>-2927.45</td>\n",
       "      <td>46464.66</td>\n",
       "      <td>-1080.93</td>\n",
       "      <td>42352.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1597</th>\n",
       "      <td>49389.99</td>\n",
       "      <td>-9232.03</td>\n",
       "      <td>50053.90</td>\n",
       "      <td>-6193.28</td>\n",
       "      <td>46702.75</td>\n",
       "      <td>-10838.52</td>\n",
       "      <td>48343.28</td>\n",
       "      <td>-8795.01</td>\n",
       "      <td>48864.98</td>\n",
       "      <td>-10095.38</td>\n",
       "      <td>...</td>\n",
       "      <td>333.57</td>\n",
       "      <td>50701.44</td>\n",
       "      <td>112.49</td>\n",
       "      <td>47543.74</td>\n",
       "      <td>-2927.45</td>\n",
       "      <td>46464.66</td>\n",
       "      <td>-1080.93</td>\n",
       "      <td>47120.87</td>\n",
       "      <td>-19.67</td>\n",
       "      <td>41660.01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1435 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      close_19  close_diff_20_19  close_18  close_diff_20_18  close_17  \\\n",
       "163   16150.03          -2706.22  14902.54          -2392.66  14400.00   \n",
       "164   14902.54          -2392.66  14400.00          -2088.98  14907.09   \n",
       "165   14400.00          -2088.98  14907.09           -585.55  13238.78   \n",
       "166   14907.09           -585.55  13238.78            -87.83  13740.01   \n",
       "167   13238.78            -87.83  13740.01            440.01  14210.00   \n",
       "...        ...               ...       ...               ...       ...   \n",
       "1593  50588.95          -9755.92  50471.19          -6420.43  47545.59   \n",
       "1594  50471.19          -6420.43  47545.59         -10506.65  47140.54   \n",
       "1595  47545.59         -10506.65  47140.54         -12566.97  49389.99   \n",
       "1596  47140.54         -12566.97  49389.99          -9232.03  50053.90   \n",
       "1597  49389.99          -9232.03  50053.90          -6193.28  46702.75   \n",
       "\n",
       "      close_diff_20_17  close_16  close_diff_20_16  close_15  \\\n",
       "163           -2088.98  14907.09           -585.55  13238.78   \n",
       "164            -585.55  13238.78            -87.83  13740.01   \n",
       "165             -87.83  13740.01            440.01  14210.00   \n",
       "166             440.01  14210.00            710.00  13474.99   \n",
       "167             710.00  13474.99           -224.35  13539.93   \n",
       "...                ...       ...               ...       ...   \n",
       "1593         -10506.65  47140.54         -12566.97  49389.99   \n",
       "1594         -12566.97  49389.99          -9232.03  50053.90   \n",
       "1595          -9232.03  50053.90          -6193.28  46702.75   \n",
       "1596          -6193.28  46702.75         -10838.52  48343.28   \n",
       "1597         -10838.52  48343.28          -8795.01  48864.98   \n",
       "\n",
       "      close_diff_20_15  ...  close_diff_20_4   close_3  close_diff_20_3  \\\n",
       "163             -87.83  ...         -3915.06  10799.18         -4120.33   \n",
       "164             440.01  ...         -4120.33  11349.99         -3709.55   \n",
       "165             710.00  ...         -3709.55  11175.27         -5785.12   \n",
       "166            -224.35  ...         -5785.12  11089.00         -5980.79   \n",
       "167           -2149.08  ...         -5980.79  11491.00         -4659.03   \n",
       "...                ...  ...              ...       ...              ...   \n",
       "1593          -9232.03  ...         -7892.18  50838.81         -2762.24   \n",
       "1594          -6193.28  ...         -2762.24  50820.00          1667.53   \n",
       "1595         -10838.52  ...          1667.53  50399.66          1003.33   \n",
       "1596          -8795.01  ...          1003.33  50775.49           333.57   \n",
       "1597         -10095.38  ...           333.57  50701.44           112.49   \n",
       "\n",
       "       close_2  close_diff_20_2   close_1  close_diff_20_1   close_0  \\\n",
       "163   11349.99         -3709.55  11175.27         -5785.12  11089.00   \n",
       "164   11175.27         -5785.12  11089.00         -5980.79  11491.00   \n",
       "165   11089.00         -5980.79  11491.00         -4659.03  11879.95   \n",
       "166   11491.00         -4659.03  11879.95         -3022.59  11251.00   \n",
       "167   11879.95         -3022.59  11251.00         -3149.00  10237.51   \n",
       "...        ...              ...       ...              ...       ...   \n",
       "1593  50820.00          1667.53  50399.66          1003.33  50775.49   \n",
       "1594  50399.66          1003.33  50775.49           333.57  50701.44   \n",
       "1595  50775.49           333.57  50701.44           112.49  47543.74   \n",
       "1596  50701.44           112.49  47543.74         -2927.45  46464.66   \n",
       "1597  47543.74         -2927.45  46464.66         -1080.93  47120.87   \n",
       "\n",
       "      close_diff_20_0     close  \n",
       "163          -5980.79  10000.09  \n",
       "164          -4659.03  10159.98  \n",
       "165          -3022.59  11039.55  \n",
       "166          -3149.00  10383.43  \n",
       "167          -4669.58  11153.00  \n",
       "...               ...       ...  \n",
       "1593           333.57  43084.29  \n",
       "1594           112.49  43071.66  \n",
       "1595         -2927.45  42201.62  \n",
       "1596         -1080.93  42352.12  \n",
       "1597           -19.67  41660.01  \n",
       "\n",
       "[1435 rows x 41 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>close_19</th>\n",
       "      <th>close_diff_20_19</th>\n",
       "      <th>close_18</th>\n",
       "      <th>close_diff_20_18</th>\n",
       "      <th>close_17</th>\n",
       "      <th>close_diff_20_17</th>\n",
       "      <th>close_16</th>\n",
       "      <th>close_diff_20_16</th>\n",
       "      <th>close_15</th>\n",
       "      <th>close_diff_20_15</th>\n",
       "      <th>...</th>\n",
       "      <th>close_diff_20_4</th>\n",
       "      <th>close_3</th>\n",
       "      <th>close_diff_20_3</th>\n",
       "      <th>close_2</th>\n",
       "      <th>close_diff_20_2</th>\n",
       "      <th>close_1</th>\n",
       "      <th>close_diff_20_1</th>\n",
       "      <th>close_0</th>\n",
       "      <th>close_diff_20_0</th>\n",
       "      <th>close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1598</th>\n",
       "      <td>50053.9</td>\n",
       "      <td>-6193.28</td>\n",
       "      <td>46702.75</td>\n",
       "      <td>-10838.52</td>\n",
       "      <td>48343.28</td>\n",
       "      <td>-8795.01</td>\n",
       "      <td>48864.98</td>\n",
       "      <td>-10095.38</td>\n",
       "      <td>47632.38</td>\n",
       "      <td>-6094.15</td>\n",
       "      <td>...</td>\n",
       "      <td>112.49</td>\n",
       "      <td>47543.74</td>\n",
       "      <td>-2927.45</td>\n",
       "      <td>46464.66</td>\n",
       "      <td>-1080.93</td>\n",
       "      <td>47120.87</td>\n",
       "      <td>-19.67</td>\n",
       "      <td>46216.93</td>\n",
       "      <td>-3173.06</td>\n",
       "      <td>41761.89</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      close_19  close_diff_20_19  close_18  close_diff_20_18  close_17  \\\n",
       "1598   50053.9          -6193.28  46702.75         -10838.52  48343.28   \n",
       "\n",
       "      close_diff_20_17  close_16  close_diff_20_16  close_15  \\\n",
       "1598          -8795.01  48864.98         -10095.38  47632.38   \n",
       "\n",
       "      close_diff_20_15  ...  close_diff_20_4   close_3  close_diff_20_3  \\\n",
       "1598          -6094.15  ...           112.49  47543.74         -2927.45   \n",
       "\n",
       "       close_2  close_diff_20_2   close_1  close_diff_20_1   close_0  \\\n",
       "1598  46464.66         -1080.93  47120.87           -19.67  46216.93   \n",
       "\n",
       "      close_diff_20_0     close  \n",
       "1598         -3173.06  41761.89  \n",
       "\n",
       "[1 rows x 41 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (1435, 1, 40) (1435, 1)\n",
      "Model: \"sequential_21\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_55 (LSTM)               (None, 1, 100)            56400     \n",
      "_________________________________________________________________\n",
      "lstm_56 (LSTM)               (None, 1, 50)             30200     \n",
      "_________________________________________________________________\n",
      "dropout_35 (Dropout)         (None, 1, 50)             0         \n",
      "_________________________________________________________________\n",
      "lstm_57 (LSTM)               (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_36 (Dropout)         (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 106,851\n",
      "Trainable params: 106,851\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Y shape (1435, 1)\n",
      "Train on 1435 samples, validate on 287 samples\n",
      "Epoch 1/70\n",
      " - 6s - loss: 0.0113 - msle: 0.0113 - val_loss: 0.0104 - val_msle: 0.0104\n",
      "Epoch 2/70\n",
      " - 1s - loss: 0.0571 - msle: 0.0571 - val_loss: 0.0587 - val_msle: 0.0587\n",
      "Epoch 3/70\n",
      " - 1s - loss: 0.0376 - msle: 0.0376 - val_loss: 0.0181 - val_msle: 0.0181\n",
      "Epoch 4/70\n",
      " - 1s - loss: 0.0135 - msle: 0.0135 - val_loss: 0.0065 - val_msle: 0.0065\n",
      "Epoch 5/70\n",
      " - 1s - loss: 0.0046 - msle: 0.0046 - val_loss: 0.0067 - val_msle: 0.0067\n",
      "Epoch 6/70\n",
      " - 1s - loss: 0.0040 - msle: 0.0040 - val_loss: 0.0061 - val_msle: 0.0061\n",
      "Epoch 7/70\n",
      " - 1s - loss: 0.0038 - msle: 0.0038 - val_loss: 0.0063 - val_msle: 0.0063\n",
      "Epoch 8/70\n",
      " - 1s - loss: 0.0033 - msle: 0.0033 - val_loss: 0.0060 - val_msle: 0.0060\n",
      "Epoch 9/70\n",
      " - 1s - loss: 0.0031 - msle: 0.0031 - val_loss: 0.0060 - val_msle: 0.0060\n",
      "Epoch 10/70\n",
      " - 1s - loss: 0.0033 - msle: 0.0033 - val_loss: 0.0059 - val_msle: 0.0059\n",
      "Epoch 11/70\n",
      " - 1s - loss: 0.0030 - msle: 0.0030 - val_loss: 0.0060 - val_msle: 0.0060\n",
      "Epoch 12/70\n",
      " - 1s - loss: 0.0032 - msle: 0.0032 - val_loss: 0.0058 - val_msle: 0.0058\n",
      "Epoch 13/70\n",
      " - 1s - loss: 0.0029 - msle: 0.0029 - val_loss: 0.0058 - val_msle: 0.0058\n",
      "Epoch 14/70\n",
      " - 1s - loss: 0.0029 - msle: 0.0029 - val_loss: 0.0057 - val_msle: 0.0057\n",
      "Epoch 15/70\n",
      " - 1s - loss: 0.0028 - msle: 0.0028 - val_loss: 0.0057 - val_msle: 0.0057\n",
      "Epoch 16/70\n",
      " - 1s - loss: 0.0029 - msle: 0.0029 - val_loss: 0.0057 - val_msle: 0.0057\n",
      "Epoch 17/70\n",
      " - 1s - loss: 0.0029 - msle: 0.0029 - val_loss: 0.0056 - val_msle: 0.0056\n",
      "Epoch 18/70\n",
      " - 1s - loss: 0.0026 - msle: 0.0026 - val_loss: 0.0055 - val_msle: 0.0055\n",
      "Epoch 19/70\n",
      " - 1s - loss: 0.0028 - msle: 0.0028 - val_loss: 0.0055 - val_msle: 0.0055\n",
      "Epoch 20/70\n",
      " - 1s - loss: 0.0029 - msle: 0.0029 - val_loss: 0.0054 - val_msle: 0.0054\n",
      "Epoch 21/70\n",
      " - 1s - loss: 0.0027 - msle: 0.0027 - val_loss: 0.0054 - val_msle: 0.0054\n",
      "Epoch 22/70\n",
      " - 1s - loss: 0.0027 - msle: 0.0027 - val_loss: 0.0053 - val_msle: 0.0053\n",
      "Epoch 23/70\n",
      " - 1s - loss: 0.0027 - msle: 0.0027 - val_loss: 0.0053 - val_msle: 0.0053\n",
      "Epoch 24/70\n",
      " - 1s - loss: 0.0028 - msle: 0.0028 - val_loss: 0.0052 - val_msle: 0.0052\n",
      "Epoch 25/70\n",
      " - 1s - loss: 0.0025 - msle: 0.0025 - val_loss: 0.0051 - val_msle: 0.0051\n",
      "Epoch 26/70\n",
      " - 1s - loss: 0.0027 - msle: 0.0027 - val_loss: 0.0050 - val_msle: 0.0050\n",
      "Epoch 27/70\n",
      " - 1s - loss: 0.0026 - msle: 0.0026 - val_loss: 0.0050 - val_msle: 0.0050\n",
      "Epoch 28/70\n",
      " - 1s - loss: 0.0026 - msle: 0.0026 - val_loss: 0.0049 - val_msle: 0.0049\n",
      "Epoch 29/70\n",
      " - 1s - loss: 0.0025 - msle: 0.0025 - val_loss: 0.0048 - val_msle: 0.0048\n",
      "Epoch 30/70\n",
      " - 1s - loss: 0.0024 - msle: 0.0024 - val_loss: 0.0048 - val_msle: 0.0048\n",
      "Epoch 31/70\n",
      " - 1s - loss: 0.0025 - msle: 0.0025 - val_loss: 0.0047 - val_msle: 0.0047\n",
      "Epoch 32/70\n",
      " - 1s - loss: 0.0025 - msle: 0.0025 - val_loss: 0.0047 - val_msle: 0.0047\n",
      "Epoch 33/70\n",
      " - 1s - loss: 0.0024 - msle: 0.0024 - val_loss: 0.0047 - val_msle: 0.0047\n",
      "Epoch 34/70\n",
      " - 1s - loss: 0.0025 - msle: 0.0025 - val_loss: 0.0046 - val_msle: 0.0046\n",
      "Epoch 35/70\n",
      " - 1s - loss: 0.0024 - msle: 0.0024 - val_loss: 0.0046 - val_msle: 0.0046\n",
      "Epoch 36/70\n",
      " - 1s - loss: 0.0024 - msle: 0.0024 - val_loss: 0.0045 - val_msle: 0.0045\n",
      "Epoch 37/70\n",
      " - 1s - loss: 0.0023 - msle: 0.0023 - val_loss: 0.0045 - val_msle: 0.0045\n",
      "Epoch 38/70\n",
      " - 1s - loss: 0.0025 - msle: 0.0025 - val_loss: 0.0044 - val_msle: 0.0044\n",
      "Epoch 39/70\n",
      " - 1s - loss: 0.0023 - msle: 0.0023 - val_loss: 0.0044 - val_msle: 0.0044\n",
      "Epoch 40/70\n",
      " - 1s - loss: 0.0025 - msle: 0.0025 - val_loss: 0.0043 - val_msle: 0.0043\n",
      "Epoch 41/70\n",
      " - 1s - loss: 0.0024 - msle: 0.0024 - val_loss: 0.0043 - val_msle: 0.0043\n",
      "Epoch 42/70\n",
      " - 1s - loss: 0.0024 - msle: 0.0024 - val_loss: 0.0043 - val_msle: 0.0043\n",
      "Epoch 43/70\n",
      " - 1s - loss: 0.0023 - msle: 0.0023 - val_loss: 0.0043 - val_msle: 0.0043\n",
      "Epoch 44/70\n",
      " - 1s - loss: 0.0024 - msle: 0.0024 - val_loss: 0.0042 - val_msle: 0.0042\n",
      "Epoch 45/70\n",
      " - 1s - loss: 0.0022 - msle: 0.0022 - val_loss: 0.0042 - val_msle: 0.0042\n",
      "Epoch 46/70\n",
      " - 1s - loss: 0.0024 - msle: 0.0024 - val_loss: 0.0042 - val_msle: 0.0042\n",
      "Epoch 47/70\n",
      " - 1s - loss: 0.0022 - msle: 0.0022 - val_loss: 0.0042 - val_msle: 0.0042\n",
      "Epoch 48/70\n",
      " - 1s - loss: 0.0024 - msle: 0.0024 - val_loss: 0.0043 - val_msle: 0.0043\n",
      "Epoch 49/70\n",
      " - 1s - loss: 0.0022 - msle: 0.0022 - val_loss: 0.0043 - val_msle: 0.0043\n",
      "Epoch 50/70\n",
      " - 1s - loss: 0.0024 - msle: 0.0024 - val_loss: 0.0041 - val_msle: 0.0041\n",
      "Epoch 51/70\n",
      " - 1s - loss: 0.0022 - msle: 0.0022 - val_loss: 0.0041 - val_msle: 0.0041\n",
      "Epoch 52/70\n",
      " - 1s - loss: 0.0024 - msle: 0.0024 - val_loss: 0.0042 - val_msle: 0.0042\n",
      "Epoch 53/70\n",
      " - 1s - loss: 0.0022 - msle: 0.0022 - val_loss: 0.0041 - val_msle: 0.0041\n",
      "Epoch 54/70\n",
      " - 1s - loss: 0.0023 - msle: 0.0023 - val_loss: 0.0041 - val_msle: 0.0041\n",
      "Epoch 55/70\n",
      " - 1s - loss: 0.0022 - msle: 0.0022 - val_loss: 0.0041 - val_msle: 0.0041\n",
      "Epoch 56/70\n",
      " - 1s - loss: 0.0023 - msle: 0.0023 - val_loss: 0.0041 - val_msle: 0.0041\n",
      "Epoch 57/70\n",
      " - 1s - loss: 0.0023 - msle: 0.0023 - val_loss: 0.0041 - val_msle: 0.0041\n",
      "Epoch 58/70\n",
      " - 1s - loss: 0.0023 - msle: 0.0023 - val_loss: 0.0042 - val_msle: 0.0042\n",
      "Epoch 59/70\n",
      " - 1s - loss: 0.0021 - msle: 0.0021 - val_loss: 0.0041 - val_msle: 0.0041\n",
      "Epoch 60/70\n",
      " - 1s - loss: 0.0023 - msle: 0.0023 - val_loss: 0.0041 - val_msle: 0.0041\n",
      "Epoch 61/70\n",
      " - 1s - loss: 0.0022 - msle: 0.0022 - val_loss: 0.0040 - val_msle: 0.0040\n",
      "Epoch 62/70\n",
      " - 1s - loss: 0.0023 - msle: 0.0023 - val_loss: 0.0043 - val_msle: 0.0043\n",
      "Epoch 63/70\n",
      " - 1s - loss: 0.0021 - msle: 0.0021 - val_loss: 0.0041 - val_msle: 0.0041\n",
      "Epoch 64/70\n",
      " - 1s - loss: 0.0023 - msle: 0.0023 - val_loss: 0.0041 - val_msle: 0.0041\n",
      "Epoch 65/70\n",
      " - 1s - loss: 0.0021 - msle: 0.0021 - val_loss: 0.0040 - val_msle: 0.0040\n",
      "Epoch 66/70\n",
      " - 1s - loss: 0.0023 - msle: 0.0023 - val_loss: 0.0041 - val_msle: 0.0041\n",
      "Epoch 67/70\n",
      " - 1s - loss: 0.0023 - msle: 0.0023 - val_loss: 0.0040 - val_msle: 0.0040\n",
      "Epoch 68/70\n",
      " - 1s - loss: 0.0022 - msle: 0.0022 - val_loss: 0.0040 - val_msle: 0.0040\n",
      "Epoch 69/70\n",
      " - 1s - loss: 0.0021 - msle: 0.0021 - val_loss: 0.0040 - val_msle: 0.0040\n",
      "Epoch 70/70\n",
      " - 1s - loss: 0.0021 - msle: 0.0021 - val_loss: 0.0040 - val_msle: 0.0040\n",
      "real [[41761.89]]\n",
      "Test RMSE: 3471.508\n",
      "Diff [[-3471.50819931]]\n",
      "% Diff [[-8.31262234]] %\n",
      "Predictions [[45233.39819931]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "activation = 'relu'\n",
    "loss = 'msle'\n",
    "metrics = ['msle']\n",
    "\n",
    "crypto = crypto\n",
    "execute_test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La distribucion de precios se asemeja a una distribucion log normal (right skewed). Por eso esta funcion de periddas funciona mejor\n",
    "\n",
    "Puede perjudicar a close_diff porque no sigue la misma distribución\n",
    "\n",
    "De todas formas no dejaremos de lado mse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading... BTC\n",
      "Extracting columns columns for BTC\n",
      "Proccessing and arranging columns for LSTM model\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>close_19</th>\n",
       "      <th>close_diff_20_19</th>\n",
       "      <th>close_18</th>\n",
       "      <th>close_diff_20_18</th>\n",
       "      <th>close_17</th>\n",
       "      <th>close_diff_20_17</th>\n",
       "      <th>close_16</th>\n",
       "      <th>close_diff_20_16</th>\n",
       "      <th>close_15</th>\n",
       "      <th>close_diff_20_15</th>\n",
       "      <th>...</th>\n",
       "      <th>close_diff_20_4</th>\n",
       "      <th>close_3</th>\n",
       "      <th>close_diff_20_3</th>\n",
       "      <th>close_2</th>\n",
       "      <th>close_diff_20_2</th>\n",
       "      <th>close_1</th>\n",
       "      <th>close_diff_20_1</th>\n",
       "      <th>close_0</th>\n",
       "      <th>close_diff_20_0</th>\n",
       "      <th>close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>16150.03</td>\n",
       "      <td>-2706.22</td>\n",
       "      <td>14902.54</td>\n",
       "      <td>-2392.66</td>\n",
       "      <td>14400.00</td>\n",
       "      <td>-2088.98</td>\n",
       "      <td>14907.09</td>\n",
       "      <td>-585.55</td>\n",
       "      <td>13238.78</td>\n",
       "      <td>-87.83</td>\n",
       "      <td>...</td>\n",
       "      <td>-3915.06</td>\n",
       "      <td>10799.18</td>\n",
       "      <td>-4120.33</td>\n",
       "      <td>11349.99</td>\n",
       "      <td>-3709.55</td>\n",
       "      <td>11175.27</td>\n",
       "      <td>-5785.12</td>\n",
       "      <td>11089.00</td>\n",
       "      <td>-5980.79</td>\n",
       "      <td>10000.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>14902.54</td>\n",
       "      <td>-2392.66</td>\n",
       "      <td>14400.00</td>\n",
       "      <td>-2088.98</td>\n",
       "      <td>14907.09</td>\n",
       "      <td>-585.55</td>\n",
       "      <td>13238.78</td>\n",
       "      <td>-87.83</td>\n",
       "      <td>13740.01</td>\n",
       "      <td>440.01</td>\n",
       "      <td>...</td>\n",
       "      <td>-4120.33</td>\n",
       "      <td>11349.99</td>\n",
       "      <td>-3709.55</td>\n",
       "      <td>11175.27</td>\n",
       "      <td>-5785.12</td>\n",
       "      <td>11089.00</td>\n",
       "      <td>-5980.79</td>\n",
       "      <td>11491.00</td>\n",
       "      <td>-4659.03</td>\n",
       "      <td>10159.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>14400.00</td>\n",
       "      <td>-2088.98</td>\n",
       "      <td>14907.09</td>\n",
       "      <td>-585.55</td>\n",
       "      <td>13238.78</td>\n",
       "      <td>-87.83</td>\n",
       "      <td>13740.01</td>\n",
       "      <td>440.01</td>\n",
       "      <td>14210.00</td>\n",
       "      <td>710.00</td>\n",
       "      <td>...</td>\n",
       "      <td>-3709.55</td>\n",
       "      <td>11175.27</td>\n",
       "      <td>-5785.12</td>\n",
       "      <td>11089.00</td>\n",
       "      <td>-5980.79</td>\n",
       "      <td>11491.00</td>\n",
       "      <td>-4659.03</td>\n",
       "      <td>11879.95</td>\n",
       "      <td>-3022.59</td>\n",
       "      <td>11039.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>14907.09</td>\n",
       "      <td>-585.55</td>\n",
       "      <td>13238.78</td>\n",
       "      <td>-87.83</td>\n",
       "      <td>13740.01</td>\n",
       "      <td>440.01</td>\n",
       "      <td>14210.00</td>\n",
       "      <td>710.00</td>\n",
       "      <td>13474.99</td>\n",
       "      <td>-224.35</td>\n",
       "      <td>...</td>\n",
       "      <td>-5785.12</td>\n",
       "      <td>11089.00</td>\n",
       "      <td>-5980.79</td>\n",
       "      <td>11491.00</td>\n",
       "      <td>-4659.03</td>\n",
       "      <td>11879.95</td>\n",
       "      <td>-3022.59</td>\n",
       "      <td>11251.00</td>\n",
       "      <td>-3149.00</td>\n",
       "      <td>10383.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>13238.78</td>\n",
       "      <td>-87.83</td>\n",
       "      <td>13740.01</td>\n",
       "      <td>440.01</td>\n",
       "      <td>14210.00</td>\n",
       "      <td>710.00</td>\n",
       "      <td>13474.99</td>\n",
       "      <td>-224.35</td>\n",
       "      <td>13539.93</td>\n",
       "      <td>-2149.08</td>\n",
       "      <td>...</td>\n",
       "      <td>-5980.79</td>\n",
       "      <td>11491.00</td>\n",
       "      <td>-4659.03</td>\n",
       "      <td>11879.95</td>\n",
       "      <td>-3022.59</td>\n",
       "      <td>11251.00</td>\n",
       "      <td>-3149.00</td>\n",
       "      <td>10237.51</td>\n",
       "      <td>-4669.58</td>\n",
       "      <td>11153.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1593</th>\n",
       "      <td>50588.95</td>\n",
       "      <td>-9755.92</td>\n",
       "      <td>50471.19</td>\n",
       "      <td>-6420.43</td>\n",
       "      <td>47545.59</td>\n",
       "      <td>-10506.65</td>\n",
       "      <td>47140.54</td>\n",
       "      <td>-12566.97</td>\n",
       "      <td>49389.99</td>\n",
       "      <td>-9232.03</td>\n",
       "      <td>...</td>\n",
       "      <td>-7892.18</td>\n",
       "      <td>50838.81</td>\n",
       "      <td>-2762.24</td>\n",
       "      <td>50820.00</td>\n",
       "      <td>1667.53</td>\n",
       "      <td>50399.66</td>\n",
       "      <td>1003.33</td>\n",
       "      <td>50775.49</td>\n",
       "      <td>333.57</td>\n",
       "      <td>43084.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1594</th>\n",
       "      <td>50471.19</td>\n",
       "      <td>-6420.43</td>\n",
       "      <td>47545.59</td>\n",
       "      <td>-10506.65</td>\n",
       "      <td>47140.54</td>\n",
       "      <td>-12566.97</td>\n",
       "      <td>49389.99</td>\n",
       "      <td>-9232.03</td>\n",
       "      <td>50053.90</td>\n",
       "      <td>-6193.28</td>\n",
       "      <td>...</td>\n",
       "      <td>-2762.24</td>\n",
       "      <td>50820.00</td>\n",
       "      <td>1667.53</td>\n",
       "      <td>50399.66</td>\n",
       "      <td>1003.33</td>\n",
       "      <td>50775.49</td>\n",
       "      <td>333.57</td>\n",
       "      <td>50701.44</td>\n",
       "      <td>112.49</td>\n",
       "      <td>43071.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1595</th>\n",
       "      <td>47545.59</td>\n",
       "      <td>-10506.65</td>\n",
       "      <td>47140.54</td>\n",
       "      <td>-12566.97</td>\n",
       "      <td>49389.99</td>\n",
       "      <td>-9232.03</td>\n",
       "      <td>50053.90</td>\n",
       "      <td>-6193.28</td>\n",
       "      <td>46702.75</td>\n",
       "      <td>-10838.52</td>\n",
       "      <td>...</td>\n",
       "      <td>1667.53</td>\n",
       "      <td>50399.66</td>\n",
       "      <td>1003.33</td>\n",
       "      <td>50775.49</td>\n",
       "      <td>333.57</td>\n",
       "      <td>50701.44</td>\n",
       "      <td>112.49</td>\n",
       "      <td>47543.74</td>\n",
       "      <td>-2927.45</td>\n",
       "      <td>42201.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1596</th>\n",
       "      <td>47140.54</td>\n",
       "      <td>-12566.97</td>\n",
       "      <td>49389.99</td>\n",
       "      <td>-9232.03</td>\n",
       "      <td>50053.90</td>\n",
       "      <td>-6193.28</td>\n",
       "      <td>46702.75</td>\n",
       "      <td>-10838.52</td>\n",
       "      <td>48343.28</td>\n",
       "      <td>-8795.01</td>\n",
       "      <td>...</td>\n",
       "      <td>1003.33</td>\n",
       "      <td>50775.49</td>\n",
       "      <td>333.57</td>\n",
       "      <td>50701.44</td>\n",
       "      <td>112.49</td>\n",
       "      <td>47543.74</td>\n",
       "      <td>-2927.45</td>\n",
       "      <td>46464.66</td>\n",
       "      <td>-1080.93</td>\n",
       "      <td>42352.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1597</th>\n",
       "      <td>49389.99</td>\n",
       "      <td>-9232.03</td>\n",
       "      <td>50053.90</td>\n",
       "      <td>-6193.28</td>\n",
       "      <td>46702.75</td>\n",
       "      <td>-10838.52</td>\n",
       "      <td>48343.28</td>\n",
       "      <td>-8795.01</td>\n",
       "      <td>48864.98</td>\n",
       "      <td>-10095.38</td>\n",
       "      <td>...</td>\n",
       "      <td>333.57</td>\n",
       "      <td>50701.44</td>\n",
       "      <td>112.49</td>\n",
       "      <td>47543.74</td>\n",
       "      <td>-2927.45</td>\n",
       "      <td>46464.66</td>\n",
       "      <td>-1080.93</td>\n",
       "      <td>47120.87</td>\n",
       "      <td>-19.67</td>\n",
       "      <td>41660.01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1435 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      close_19  close_diff_20_19  close_18  close_diff_20_18  close_17  \\\n",
       "163   16150.03          -2706.22  14902.54          -2392.66  14400.00   \n",
       "164   14902.54          -2392.66  14400.00          -2088.98  14907.09   \n",
       "165   14400.00          -2088.98  14907.09           -585.55  13238.78   \n",
       "166   14907.09           -585.55  13238.78            -87.83  13740.01   \n",
       "167   13238.78            -87.83  13740.01            440.01  14210.00   \n",
       "...        ...               ...       ...               ...       ...   \n",
       "1593  50588.95          -9755.92  50471.19          -6420.43  47545.59   \n",
       "1594  50471.19          -6420.43  47545.59         -10506.65  47140.54   \n",
       "1595  47545.59         -10506.65  47140.54         -12566.97  49389.99   \n",
       "1596  47140.54         -12566.97  49389.99          -9232.03  50053.90   \n",
       "1597  49389.99          -9232.03  50053.90          -6193.28  46702.75   \n",
       "\n",
       "      close_diff_20_17  close_16  close_diff_20_16  close_15  \\\n",
       "163           -2088.98  14907.09           -585.55  13238.78   \n",
       "164            -585.55  13238.78            -87.83  13740.01   \n",
       "165             -87.83  13740.01            440.01  14210.00   \n",
       "166             440.01  14210.00            710.00  13474.99   \n",
       "167             710.00  13474.99           -224.35  13539.93   \n",
       "...                ...       ...               ...       ...   \n",
       "1593         -10506.65  47140.54         -12566.97  49389.99   \n",
       "1594         -12566.97  49389.99          -9232.03  50053.90   \n",
       "1595          -9232.03  50053.90          -6193.28  46702.75   \n",
       "1596          -6193.28  46702.75         -10838.52  48343.28   \n",
       "1597         -10838.52  48343.28          -8795.01  48864.98   \n",
       "\n",
       "      close_diff_20_15  ...  close_diff_20_4   close_3  close_diff_20_3  \\\n",
       "163             -87.83  ...         -3915.06  10799.18         -4120.33   \n",
       "164             440.01  ...         -4120.33  11349.99         -3709.55   \n",
       "165             710.00  ...         -3709.55  11175.27         -5785.12   \n",
       "166            -224.35  ...         -5785.12  11089.00         -5980.79   \n",
       "167           -2149.08  ...         -5980.79  11491.00         -4659.03   \n",
       "...                ...  ...              ...       ...              ...   \n",
       "1593          -9232.03  ...         -7892.18  50838.81         -2762.24   \n",
       "1594          -6193.28  ...         -2762.24  50820.00          1667.53   \n",
       "1595         -10838.52  ...          1667.53  50399.66          1003.33   \n",
       "1596          -8795.01  ...          1003.33  50775.49           333.57   \n",
       "1597         -10095.38  ...           333.57  50701.44           112.49   \n",
       "\n",
       "       close_2  close_diff_20_2   close_1  close_diff_20_1   close_0  \\\n",
       "163   11349.99         -3709.55  11175.27         -5785.12  11089.00   \n",
       "164   11175.27         -5785.12  11089.00         -5980.79  11491.00   \n",
       "165   11089.00         -5980.79  11491.00         -4659.03  11879.95   \n",
       "166   11491.00         -4659.03  11879.95         -3022.59  11251.00   \n",
       "167   11879.95         -3022.59  11251.00         -3149.00  10237.51   \n",
       "...        ...              ...       ...              ...       ...   \n",
       "1593  50820.00          1667.53  50399.66          1003.33  50775.49   \n",
       "1594  50399.66          1003.33  50775.49           333.57  50701.44   \n",
       "1595  50775.49           333.57  50701.44           112.49  47543.74   \n",
       "1596  50701.44           112.49  47543.74         -2927.45  46464.66   \n",
       "1597  47543.74         -2927.45  46464.66         -1080.93  47120.87   \n",
       "\n",
       "      close_diff_20_0     close  \n",
       "163          -5980.79  10000.09  \n",
       "164          -4659.03  10159.98  \n",
       "165          -3022.59  11039.55  \n",
       "166          -3149.00  10383.43  \n",
       "167          -4669.58  11153.00  \n",
       "...               ...       ...  \n",
       "1593           333.57  43084.29  \n",
       "1594           112.49  43071.66  \n",
       "1595         -2927.45  42201.62  \n",
       "1596         -1080.93  42352.12  \n",
       "1597           -19.67  41660.01  \n",
       "\n",
       "[1435 rows x 41 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>close_19</th>\n",
       "      <th>close_diff_20_19</th>\n",
       "      <th>close_18</th>\n",
       "      <th>close_diff_20_18</th>\n",
       "      <th>close_17</th>\n",
       "      <th>close_diff_20_17</th>\n",
       "      <th>close_16</th>\n",
       "      <th>close_diff_20_16</th>\n",
       "      <th>close_15</th>\n",
       "      <th>close_diff_20_15</th>\n",
       "      <th>...</th>\n",
       "      <th>close_diff_20_4</th>\n",
       "      <th>close_3</th>\n",
       "      <th>close_diff_20_3</th>\n",
       "      <th>close_2</th>\n",
       "      <th>close_diff_20_2</th>\n",
       "      <th>close_1</th>\n",
       "      <th>close_diff_20_1</th>\n",
       "      <th>close_0</th>\n",
       "      <th>close_diff_20_0</th>\n",
       "      <th>close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1598</th>\n",
       "      <td>50053.9</td>\n",
       "      <td>-6193.28</td>\n",
       "      <td>46702.75</td>\n",
       "      <td>-10838.52</td>\n",
       "      <td>48343.28</td>\n",
       "      <td>-8795.01</td>\n",
       "      <td>48864.98</td>\n",
       "      <td>-10095.38</td>\n",
       "      <td>47632.38</td>\n",
       "      <td>-6094.15</td>\n",
       "      <td>...</td>\n",
       "      <td>112.49</td>\n",
       "      <td>47543.74</td>\n",
       "      <td>-2927.45</td>\n",
       "      <td>46464.66</td>\n",
       "      <td>-1080.93</td>\n",
       "      <td>47120.87</td>\n",
       "      <td>-19.67</td>\n",
       "      <td>46216.93</td>\n",
       "      <td>-3173.06</td>\n",
       "      <td>41761.89</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      close_19  close_diff_20_19  close_18  close_diff_20_18  close_17  \\\n",
       "1598   50053.9          -6193.28  46702.75         -10838.52  48343.28   \n",
       "\n",
       "      close_diff_20_17  close_16  close_diff_20_16  close_15  \\\n",
       "1598          -8795.01  48864.98         -10095.38  47632.38   \n",
       "\n",
       "      close_diff_20_15  ...  close_diff_20_4   close_3  close_diff_20_3  \\\n",
       "1598          -6094.15  ...           112.49  47543.74         -2927.45   \n",
       "\n",
       "       close_2  close_diff_20_2   close_1  close_diff_20_1   close_0  \\\n",
       "1598  46464.66         -1080.93  47120.87           -19.67  46216.93   \n",
       "\n",
       "      close_diff_20_0     close  \n",
       "1598         -3173.06  41761.89  \n",
       "\n",
       "[1 rows x 41 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (1435, 1, 40) (1435, 1)\n",
      "Model: \"sequential_19\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_49 (LSTM)               (None, 1, 100)            56400     \n",
      "_________________________________________________________________\n",
      "lstm_50 (LSTM)               (None, 1, 50)             30200     \n",
      "_________________________________________________________________\n",
      "dropout_31 (Dropout)         (None, 1, 50)             0         \n",
      "_________________________________________________________________\n",
      "lstm_51 (LSTM)               (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_32 (Dropout)         (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 106,851\n",
      "Trainable params: 106,851\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Y shape (1435, 1)\n",
      "Train on 1435 samples, validate on 287 samples\n",
      "Epoch 1/70\n",
      " - 5s - loss: 0.2398 - mae: 0.2398 - val_loss: 0.6895 - val_mae: 0.6895\n",
      "Epoch 2/70\n",
      " - 1s - loss: 0.1919 - mae: 0.1919 - val_loss: 0.2085 - val_mae: 0.2085\n",
      "Epoch 3/70\n",
      " - 1s - loss: 0.2581 - mae: 0.2581 - val_loss: 0.4531 - val_mae: 0.4531\n",
      "Epoch 4/70\n",
      " - 1s - loss: 0.0633 - mae: 0.0633 - val_loss: 0.1117 - val_mae: 0.1117\n",
      "Epoch 5/70\n",
      " - 1s - loss: 0.0727 - mae: 0.0727 - val_loss: 0.1063 - val_mae: 0.1063\n",
      "Epoch 6/70\n",
      " - 1s - loss: 0.0949 - mae: 0.0949 - val_loss: 0.1397 - val_mae: 0.1397\n",
      "Epoch 7/70\n",
      " - 1s - loss: 0.0818 - mae: 0.0818 - val_loss: 0.1073 - val_mae: 0.1073\n",
      "Epoch 8/70\n",
      " - 1s - loss: 0.0674 - mae: 0.0674 - val_loss: 0.1158 - val_mae: 0.1158\n",
      "Epoch 9/70\n",
      " - 1s - loss: 0.0715 - mae: 0.0715 - val_loss: 0.1057 - val_mae: 0.1057\n",
      "Epoch 10/70\n",
      " - 1s - loss: 0.0615 - mae: 0.0615 - val_loss: 0.1085 - val_mae: 0.1085\n",
      "Epoch 11/70\n",
      " - 1s - loss: 0.0626 - mae: 0.0626 - val_loss: 0.1083 - val_mae: 0.1083\n",
      "Epoch 12/70\n",
      " - 1s - loss: 0.0555 - mae: 0.0555 - val_loss: 0.1037 - val_mae: 0.1037\n",
      "Epoch 13/70\n",
      " - 1s - loss: 0.0574 - mae: 0.0574 - val_loss: 0.1092 - val_mae: 0.1092\n",
      "Epoch 14/70\n",
      " - 1s - loss: 0.0594 - mae: 0.0594 - val_loss: 0.1038 - val_mae: 0.1038\n",
      "Epoch 15/70\n",
      " - 1s - loss: 0.0539 - mae: 0.0539 - val_loss: 0.1030 - val_mae: 0.1030\n",
      "Epoch 16/70\n",
      " - 1s - loss: 0.0551 - mae: 0.0551 - val_loss: 0.1064 - val_mae: 0.1064\n",
      "Epoch 17/70\n",
      " - 1s - loss: 0.0558 - mae: 0.0558 - val_loss: 0.0998 - val_mae: 0.0998\n",
      "Epoch 18/70\n",
      " - 1s - loss: 0.0538 - mae: 0.0538 - val_loss: 0.1004 - val_mae: 0.1004\n",
      "Epoch 19/70\n",
      " - 1s - loss: 0.0562 - mae: 0.0562 - val_loss: 0.0974 - val_mae: 0.0974\n",
      "Epoch 20/70\n",
      " - 1s - loss: 0.0499 - mae: 0.0499 - val_loss: 0.1031 - val_mae: 0.1031\n",
      "Epoch 21/70\n",
      " - 1s - loss: 0.0537 - mae: 0.0537 - val_loss: 0.0952 - val_mae: 0.0952\n",
      "Epoch 22/70\n",
      " - 1s - loss: 0.0494 - mae: 0.0494 - val_loss: 0.0996 - val_mae: 0.0996\n",
      "Epoch 23/70\n",
      " - 1s - loss: 0.0501 - mae: 0.0501 - val_loss: 0.0935 - val_mae: 0.0935\n",
      "Epoch 24/70\n",
      " - 1s - loss: 0.0498 - mae: 0.0498 - val_loss: 0.0931 - val_mae: 0.0931\n",
      "Epoch 25/70\n",
      " - 1s - loss: 0.0512 - mae: 0.0512 - val_loss: 0.0929 - val_mae: 0.0929\n",
      "Epoch 26/70\n",
      " - 1s - loss: 0.0512 - mae: 0.0512 - val_loss: 0.0907 - val_mae: 0.0907\n",
      "Epoch 27/70\n",
      " - 1s - loss: 0.0503 - mae: 0.0503 - val_loss: 0.0905 - val_mae: 0.0905\n",
      "Epoch 28/70\n",
      " - 1s - loss: 0.0482 - mae: 0.0482 - val_loss: 0.0903 - val_mae: 0.0903\n",
      "Epoch 29/70\n",
      " - 1s - loss: 0.0488 - mae: 0.0488 - val_loss: 0.0888 - val_mae: 0.0888\n",
      "Epoch 30/70\n",
      " - 1s - loss: 0.0486 - mae: 0.0486 - val_loss: 0.0888 - val_mae: 0.0888\n",
      "Epoch 31/70\n",
      " - 1s - loss: 0.0494 - mae: 0.0494 - val_loss: 0.0882 - val_mae: 0.0882\n",
      "Epoch 32/70\n",
      " - 1s - loss: 0.0488 - mae: 0.0488 - val_loss: 0.0865 - val_mae: 0.0865\n",
      "Epoch 33/70\n",
      " - 1s - loss: 0.0484 - mae: 0.0484 - val_loss: 0.0862 - val_mae: 0.0862\n",
      "Epoch 34/70\n",
      " - 1s - loss: 0.0480 - mae: 0.0480 - val_loss: 0.0867 - val_mae: 0.0867\n",
      "Epoch 35/70\n",
      " - 1s - loss: 0.0470 - mae: 0.0470 - val_loss: 0.0866 - val_mae: 0.0866\n",
      "Epoch 36/70\n",
      " - 1s - loss: 0.0484 - mae: 0.0484 - val_loss: 0.0860 - val_mae: 0.0860\n",
      "Epoch 37/70\n",
      " - 1s - loss: 0.0455 - mae: 0.0455 - val_loss: 0.0848 - val_mae: 0.0848\n",
      "Epoch 38/70\n",
      " - 1s - loss: 0.0477 - mae: 0.0477 - val_loss: 0.0854 - val_mae: 0.0854\n",
      "Epoch 39/70\n",
      " - 1s - loss: 0.0467 - mae: 0.0467 - val_loss: 0.0874 - val_mae: 0.0874\n",
      "Epoch 40/70\n",
      " - 1s - loss: 0.0470 - mae: 0.0470 - val_loss: 0.0855 - val_mae: 0.0855\n",
      "Epoch 41/70\n",
      " - 1s - loss: 0.0490 - mae: 0.0490 - val_loss: 0.0881 - val_mae: 0.0881\n",
      "Epoch 42/70\n",
      " - 1s - loss: 0.0468 - mae: 0.0468 - val_loss: 0.0859 - val_mae: 0.0859\n",
      "Epoch 43/70\n",
      " - 1s - loss: 0.0473 - mae: 0.0473 - val_loss: 0.0849 - val_mae: 0.0849\n",
      "Epoch 44/70\n",
      " - 1s - loss: 0.0456 - mae: 0.0456 - val_loss: 0.0871 - val_mae: 0.0871\n",
      "Epoch 45/70\n",
      " - 1s - loss: 0.0490 - mae: 0.0490 - val_loss: 0.0903 - val_mae: 0.0903\n",
      "Epoch 46/70\n",
      " - 1s - loss: 0.0459 - mae: 0.0459 - val_loss: 0.0852 - val_mae: 0.0852\n",
      "Epoch 47/70\n",
      " - 1s - loss: 0.0481 - mae: 0.0481 - val_loss: 0.0849 - val_mae: 0.0849\n",
      "Epoch 48/70\n",
      " - 1s - loss: 0.0472 - mae: 0.0472 - val_loss: 0.0889 - val_mae: 0.0889\n",
      "Epoch 49/70\n",
      " - 1s - loss: 0.0454 - mae: 0.0454 - val_loss: 0.0869 - val_mae: 0.0869\n",
      "Epoch 50/70\n",
      " - 1s - loss: 0.0473 - mae: 0.0473 - val_loss: 0.0874 - val_mae: 0.0874\n",
      "Epoch 51/70\n",
      " - 1s - loss: 0.0466 - mae: 0.0466 - val_loss: 0.0861 - val_mae: 0.0861\n",
      "Epoch 52/70\n",
      " - 1s - loss: 0.0446 - mae: 0.0446 - val_loss: 0.0855 - val_mae: 0.0855\n",
      "Epoch 53/70\n",
      " - 1s - loss: 0.0450 - mae: 0.0450 - val_loss: 0.0842 - val_mae: 0.0842\n",
      "Epoch 54/70\n",
      " - 1s - loss: 0.0460 - mae: 0.0460 - val_loss: 0.0842 - val_mae: 0.0842\n",
      "Epoch 55/70\n",
      " - 1s - loss: 0.0456 - mae: 0.0456 - val_loss: 0.0842 - val_mae: 0.0842\n",
      "Epoch 56/70\n",
      " - 1s - loss: 0.0456 - mae: 0.0456 - val_loss: 0.0842 - val_mae: 0.0842\n",
      "Epoch 57/70\n",
      " - 1s - loss: 0.0442 - mae: 0.0442 - val_loss: 0.0842 - val_mae: 0.0842\n",
      "Epoch 58/70\n",
      " - 1s - loss: 0.0469 - mae: 0.0469 - val_loss: 0.0871 - val_mae: 0.0871\n",
      "Epoch 59/70\n",
      " - 1s - loss: 0.0456 - mae: 0.0456 - val_loss: 0.0846 - val_mae: 0.0846\n",
      "Epoch 60/70\n",
      " - 1s - loss: 0.0471 - mae: 0.0471 - val_loss: 0.0852 - val_mae: 0.0852\n",
      "Epoch 61/70\n",
      " - 1s - loss: 0.0447 - mae: 0.0447 - val_loss: 0.0863 - val_mae: 0.0863\n",
      "Epoch 62/70\n",
      " - 1s - loss: 0.0448 - mae: 0.0448 - val_loss: 0.0865 - val_mae: 0.0865\n",
      "Epoch 63/70\n",
      " - 1s - loss: 0.0468 - mae: 0.0468 - val_loss: 0.0869 - val_mae: 0.0869\n",
      "Epoch 64/70\n",
      " - 1s - loss: 0.0416 - mae: 0.0416 - val_loss: 0.0856 - val_mae: 0.0856\n",
      "Epoch 65/70\n",
      " - 1s - loss: 0.0468 - mae: 0.0468 - val_loss: 0.0863 - val_mae: 0.0863\n",
      "Epoch 66/70\n",
      " - 1s - loss: 0.0439 - mae: 0.0439 - val_loss: 0.0841 - val_mae: 0.0841\n",
      "Epoch 67/70\n",
      " - 1s - loss: 0.0464 - mae: 0.0464 - val_loss: 0.0842 - val_mae: 0.0842\n",
      "Epoch 68/70\n",
      " - 1s - loss: 0.0462 - mae: 0.0462 - val_loss: 0.0864 - val_mae: 0.0864\n",
      "Epoch 69/70\n",
      " - 1s - loss: 0.0449 - mae: 0.0449 - val_loss: 0.0852 - val_mae: 0.0852\n",
      "Epoch 70/70\n",
      " - 1s - loss: 0.0441 - mae: 0.0441 - val_loss: 0.0853 - val_mae: 0.0853\n",
      "real [[41761.89]]\n",
      "Test RMSE: 3416.920\n",
      "Diff [[-3416.92030306]]\n",
      "% Diff [[-8.18191012]] %\n",
      "Predictions [[45178.81030306]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "activation = 'relu'\n",
    "loss = 'mae'\n",
    "metrics = ['mae']\n",
    "\n",
    "crypto = crypto\n",
    "execute_test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtenemos mejores resultados con la funcion de perdidas: msle\n",
    "\n",
    "Probaremos ahora diferentes activaciones\n",
    "\n",
    "- Leaky ReLU para evitar dying neurons\n",
    "- Swish ha demostrado buen comportamiento según algunos papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = 'msle'\n",
    "metrics = ['msle']\n",
    "\n",
    "epochs = 70"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils.generic_utils import get_custom_objects\n",
    "from keras import backend as K\n",
    "from keras.layers import Activation\n",
    "from keras.layers import LeakyReLU\n",
    "\n",
    "def custom_activation(x, beta = 1):\n",
    "        return (K.sigmoid(beta * x) * x)\n",
    "\n",
    "get_custom_objects().update({'custom_activation': Activation(custom_activation)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading... BTC\n",
      "Extracting columns columns for BTC\n",
      "Proccessing and arranging columns for LSTM model\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>close_19</th>\n",
       "      <th>close_diff_20_19</th>\n",
       "      <th>close_18</th>\n",
       "      <th>close_diff_20_18</th>\n",
       "      <th>close_17</th>\n",
       "      <th>close_diff_20_17</th>\n",
       "      <th>close_16</th>\n",
       "      <th>close_diff_20_16</th>\n",
       "      <th>close_15</th>\n",
       "      <th>close_diff_20_15</th>\n",
       "      <th>...</th>\n",
       "      <th>close_diff_20_4</th>\n",
       "      <th>close_3</th>\n",
       "      <th>close_diff_20_3</th>\n",
       "      <th>close_2</th>\n",
       "      <th>close_diff_20_2</th>\n",
       "      <th>close_1</th>\n",
       "      <th>close_diff_20_1</th>\n",
       "      <th>close_0</th>\n",
       "      <th>close_diff_20_0</th>\n",
       "      <th>close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>16150.03</td>\n",
       "      <td>-2706.22</td>\n",
       "      <td>14902.54</td>\n",
       "      <td>-2392.66</td>\n",
       "      <td>14400.00</td>\n",
       "      <td>-2088.98</td>\n",
       "      <td>14907.09</td>\n",
       "      <td>-585.55</td>\n",
       "      <td>13238.78</td>\n",
       "      <td>-87.83</td>\n",
       "      <td>...</td>\n",
       "      <td>-3915.06</td>\n",
       "      <td>10799.18</td>\n",
       "      <td>-4120.33</td>\n",
       "      <td>11349.99</td>\n",
       "      <td>-3709.55</td>\n",
       "      <td>11175.27</td>\n",
       "      <td>-5785.12</td>\n",
       "      <td>11089.00</td>\n",
       "      <td>-5980.79</td>\n",
       "      <td>10000.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>14902.54</td>\n",
       "      <td>-2392.66</td>\n",
       "      <td>14400.00</td>\n",
       "      <td>-2088.98</td>\n",
       "      <td>14907.09</td>\n",
       "      <td>-585.55</td>\n",
       "      <td>13238.78</td>\n",
       "      <td>-87.83</td>\n",
       "      <td>13740.01</td>\n",
       "      <td>440.01</td>\n",
       "      <td>...</td>\n",
       "      <td>-4120.33</td>\n",
       "      <td>11349.99</td>\n",
       "      <td>-3709.55</td>\n",
       "      <td>11175.27</td>\n",
       "      <td>-5785.12</td>\n",
       "      <td>11089.00</td>\n",
       "      <td>-5980.79</td>\n",
       "      <td>11491.00</td>\n",
       "      <td>-4659.03</td>\n",
       "      <td>10159.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>14400.00</td>\n",
       "      <td>-2088.98</td>\n",
       "      <td>14907.09</td>\n",
       "      <td>-585.55</td>\n",
       "      <td>13238.78</td>\n",
       "      <td>-87.83</td>\n",
       "      <td>13740.01</td>\n",
       "      <td>440.01</td>\n",
       "      <td>14210.00</td>\n",
       "      <td>710.00</td>\n",
       "      <td>...</td>\n",
       "      <td>-3709.55</td>\n",
       "      <td>11175.27</td>\n",
       "      <td>-5785.12</td>\n",
       "      <td>11089.00</td>\n",
       "      <td>-5980.79</td>\n",
       "      <td>11491.00</td>\n",
       "      <td>-4659.03</td>\n",
       "      <td>11879.95</td>\n",
       "      <td>-3022.59</td>\n",
       "      <td>11039.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>14907.09</td>\n",
       "      <td>-585.55</td>\n",
       "      <td>13238.78</td>\n",
       "      <td>-87.83</td>\n",
       "      <td>13740.01</td>\n",
       "      <td>440.01</td>\n",
       "      <td>14210.00</td>\n",
       "      <td>710.00</td>\n",
       "      <td>13474.99</td>\n",
       "      <td>-224.35</td>\n",
       "      <td>...</td>\n",
       "      <td>-5785.12</td>\n",
       "      <td>11089.00</td>\n",
       "      <td>-5980.79</td>\n",
       "      <td>11491.00</td>\n",
       "      <td>-4659.03</td>\n",
       "      <td>11879.95</td>\n",
       "      <td>-3022.59</td>\n",
       "      <td>11251.00</td>\n",
       "      <td>-3149.00</td>\n",
       "      <td>10383.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>13238.78</td>\n",
       "      <td>-87.83</td>\n",
       "      <td>13740.01</td>\n",
       "      <td>440.01</td>\n",
       "      <td>14210.00</td>\n",
       "      <td>710.00</td>\n",
       "      <td>13474.99</td>\n",
       "      <td>-224.35</td>\n",
       "      <td>13539.93</td>\n",
       "      <td>-2149.08</td>\n",
       "      <td>...</td>\n",
       "      <td>-5980.79</td>\n",
       "      <td>11491.00</td>\n",
       "      <td>-4659.03</td>\n",
       "      <td>11879.95</td>\n",
       "      <td>-3022.59</td>\n",
       "      <td>11251.00</td>\n",
       "      <td>-3149.00</td>\n",
       "      <td>10237.51</td>\n",
       "      <td>-4669.58</td>\n",
       "      <td>11153.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1593</th>\n",
       "      <td>50588.95</td>\n",
       "      <td>-9755.92</td>\n",
       "      <td>50471.19</td>\n",
       "      <td>-6420.43</td>\n",
       "      <td>47545.59</td>\n",
       "      <td>-10506.65</td>\n",
       "      <td>47140.54</td>\n",
       "      <td>-12566.97</td>\n",
       "      <td>49389.99</td>\n",
       "      <td>-9232.03</td>\n",
       "      <td>...</td>\n",
       "      <td>-7892.18</td>\n",
       "      <td>50838.81</td>\n",
       "      <td>-2762.24</td>\n",
       "      <td>50820.00</td>\n",
       "      <td>1667.53</td>\n",
       "      <td>50399.66</td>\n",
       "      <td>1003.33</td>\n",
       "      <td>50775.49</td>\n",
       "      <td>333.57</td>\n",
       "      <td>43084.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1594</th>\n",
       "      <td>50471.19</td>\n",
       "      <td>-6420.43</td>\n",
       "      <td>47545.59</td>\n",
       "      <td>-10506.65</td>\n",
       "      <td>47140.54</td>\n",
       "      <td>-12566.97</td>\n",
       "      <td>49389.99</td>\n",
       "      <td>-9232.03</td>\n",
       "      <td>50053.90</td>\n",
       "      <td>-6193.28</td>\n",
       "      <td>...</td>\n",
       "      <td>-2762.24</td>\n",
       "      <td>50820.00</td>\n",
       "      <td>1667.53</td>\n",
       "      <td>50399.66</td>\n",
       "      <td>1003.33</td>\n",
       "      <td>50775.49</td>\n",
       "      <td>333.57</td>\n",
       "      <td>50701.44</td>\n",
       "      <td>112.49</td>\n",
       "      <td>43071.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1595</th>\n",
       "      <td>47545.59</td>\n",
       "      <td>-10506.65</td>\n",
       "      <td>47140.54</td>\n",
       "      <td>-12566.97</td>\n",
       "      <td>49389.99</td>\n",
       "      <td>-9232.03</td>\n",
       "      <td>50053.90</td>\n",
       "      <td>-6193.28</td>\n",
       "      <td>46702.75</td>\n",
       "      <td>-10838.52</td>\n",
       "      <td>...</td>\n",
       "      <td>1667.53</td>\n",
       "      <td>50399.66</td>\n",
       "      <td>1003.33</td>\n",
       "      <td>50775.49</td>\n",
       "      <td>333.57</td>\n",
       "      <td>50701.44</td>\n",
       "      <td>112.49</td>\n",
       "      <td>47543.74</td>\n",
       "      <td>-2927.45</td>\n",
       "      <td>42201.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1596</th>\n",
       "      <td>47140.54</td>\n",
       "      <td>-12566.97</td>\n",
       "      <td>49389.99</td>\n",
       "      <td>-9232.03</td>\n",
       "      <td>50053.90</td>\n",
       "      <td>-6193.28</td>\n",
       "      <td>46702.75</td>\n",
       "      <td>-10838.52</td>\n",
       "      <td>48343.28</td>\n",
       "      <td>-8795.01</td>\n",
       "      <td>...</td>\n",
       "      <td>1003.33</td>\n",
       "      <td>50775.49</td>\n",
       "      <td>333.57</td>\n",
       "      <td>50701.44</td>\n",
       "      <td>112.49</td>\n",
       "      <td>47543.74</td>\n",
       "      <td>-2927.45</td>\n",
       "      <td>46464.66</td>\n",
       "      <td>-1080.93</td>\n",
       "      <td>42352.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1597</th>\n",
       "      <td>49389.99</td>\n",
       "      <td>-9232.03</td>\n",
       "      <td>50053.90</td>\n",
       "      <td>-6193.28</td>\n",
       "      <td>46702.75</td>\n",
       "      <td>-10838.52</td>\n",
       "      <td>48343.28</td>\n",
       "      <td>-8795.01</td>\n",
       "      <td>48864.98</td>\n",
       "      <td>-10095.38</td>\n",
       "      <td>...</td>\n",
       "      <td>333.57</td>\n",
       "      <td>50701.44</td>\n",
       "      <td>112.49</td>\n",
       "      <td>47543.74</td>\n",
       "      <td>-2927.45</td>\n",
       "      <td>46464.66</td>\n",
       "      <td>-1080.93</td>\n",
       "      <td>47120.87</td>\n",
       "      <td>-19.67</td>\n",
       "      <td>41660.01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1435 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      close_19  close_diff_20_19  close_18  close_diff_20_18  close_17  \\\n",
       "163   16150.03          -2706.22  14902.54          -2392.66  14400.00   \n",
       "164   14902.54          -2392.66  14400.00          -2088.98  14907.09   \n",
       "165   14400.00          -2088.98  14907.09           -585.55  13238.78   \n",
       "166   14907.09           -585.55  13238.78            -87.83  13740.01   \n",
       "167   13238.78            -87.83  13740.01            440.01  14210.00   \n",
       "...        ...               ...       ...               ...       ...   \n",
       "1593  50588.95          -9755.92  50471.19          -6420.43  47545.59   \n",
       "1594  50471.19          -6420.43  47545.59         -10506.65  47140.54   \n",
       "1595  47545.59         -10506.65  47140.54         -12566.97  49389.99   \n",
       "1596  47140.54         -12566.97  49389.99          -9232.03  50053.90   \n",
       "1597  49389.99          -9232.03  50053.90          -6193.28  46702.75   \n",
       "\n",
       "      close_diff_20_17  close_16  close_diff_20_16  close_15  \\\n",
       "163           -2088.98  14907.09           -585.55  13238.78   \n",
       "164            -585.55  13238.78            -87.83  13740.01   \n",
       "165             -87.83  13740.01            440.01  14210.00   \n",
       "166             440.01  14210.00            710.00  13474.99   \n",
       "167             710.00  13474.99           -224.35  13539.93   \n",
       "...                ...       ...               ...       ...   \n",
       "1593         -10506.65  47140.54         -12566.97  49389.99   \n",
       "1594         -12566.97  49389.99          -9232.03  50053.90   \n",
       "1595          -9232.03  50053.90          -6193.28  46702.75   \n",
       "1596          -6193.28  46702.75         -10838.52  48343.28   \n",
       "1597         -10838.52  48343.28          -8795.01  48864.98   \n",
       "\n",
       "      close_diff_20_15  ...  close_diff_20_4   close_3  close_diff_20_3  \\\n",
       "163             -87.83  ...         -3915.06  10799.18         -4120.33   \n",
       "164             440.01  ...         -4120.33  11349.99         -3709.55   \n",
       "165             710.00  ...         -3709.55  11175.27         -5785.12   \n",
       "166            -224.35  ...         -5785.12  11089.00         -5980.79   \n",
       "167           -2149.08  ...         -5980.79  11491.00         -4659.03   \n",
       "...                ...  ...              ...       ...              ...   \n",
       "1593          -9232.03  ...         -7892.18  50838.81         -2762.24   \n",
       "1594          -6193.28  ...         -2762.24  50820.00          1667.53   \n",
       "1595         -10838.52  ...          1667.53  50399.66          1003.33   \n",
       "1596          -8795.01  ...          1003.33  50775.49           333.57   \n",
       "1597         -10095.38  ...           333.57  50701.44           112.49   \n",
       "\n",
       "       close_2  close_diff_20_2   close_1  close_diff_20_1   close_0  \\\n",
       "163   11349.99         -3709.55  11175.27         -5785.12  11089.00   \n",
       "164   11175.27         -5785.12  11089.00         -5980.79  11491.00   \n",
       "165   11089.00         -5980.79  11491.00         -4659.03  11879.95   \n",
       "166   11491.00         -4659.03  11879.95         -3022.59  11251.00   \n",
       "167   11879.95         -3022.59  11251.00         -3149.00  10237.51   \n",
       "...        ...              ...       ...              ...       ...   \n",
       "1593  50820.00          1667.53  50399.66          1003.33  50775.49   \n",
       "1594  50399.66          1003.33  50775.49           333.57  50701.44   \n",
       "1595  50775.49           333.57  50701.44           112.49  47543.74   \n",
       "1596  50701.44           112.49  47543.74         -2927.45  46464.66   \n",
       "1597  47543.74         -2927.45  46464.66         -1080.93  47120.87   \n",
       "\n",
       "      close_diff_20_0     close  \n",
       "163          -5980.79  10000.09  \n",
       "164          -4659.03  10159.98  \n",
       "165          -3022.59  11039.55  \n",
       "166          -3149.00  10383.43  \n",
       "167          -4669.58  11153.00  \n",
       "...               ...       ...  \n",
       "1593           333.57  43084.29  \n",
       "1594           112.49  43071.66  \n",
       "1595         -2927.45  42201.62  \n",
       "1596         -1080.93  42352.12  \n",
       "1597           -19.67  41660.01  \n",
       "\n",
       "[1435 rows x 41 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>close_19</th>\n",
       "      <th>close_diff_20_19</th>\n",
       "      <th>close_18</th>\n",
       "      <th>close_diff_20_18</th>\n",
       "      <th>close_17</th>\n",
       "      <th>close_diff_20_17</th>\n",
       "      <th>close_16</th>\n",
       "      <th>close_diff_20_16</th>\n",
       "      <th>close_15</th>\n",
       "      <th>close_diff_20_15</th>\n",
       "      <th>...</th>\n",
       "      <th>close_diff_20_4</th>\n",
       "      <th>close_3</th>\n",
       "      <th>close_diff_20_3</th>\n",
       "      <th>close_2</th>\n",
       "      <th>close_diff_20_2</th>\n",
       "      <th>close_1</th>\n",
       "      <th>close_diff_20_1</th>\n",
       "      <th>close_0</th>\n",
       "      <th>close_diff_20_0</th>\n",
       "      <th>close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1598</th>\n",
       "      <td>50053.9</td>\n",
       "      <td>-6193.28</td>\n",
       "      <td>46702.75</td>\n",
       "      <td>-10838.52</td>\n",
       "      <td>48343.28</td>\n",
       "      <td>-8795.01</td>\n",
       "      <td>48864.98</td>\n",
       "      <td>-10095.38</td>\n",
       "      <td>47632.38</td>\n",
       "      <td>-6094.15</td>\n",
       "      <td>...</td>\n",
       "      <td>112.49</td>\n",
       "      <td>47543.74</td>\n",
       "      <td>-2927.45</td>\n",
       "      <td>46464.66</td>\n",
       "      <td>-1080.93</td>\n",
       "      <td>47120.87</td>\n",
       "      <td>-19.67</td>\n",
       "      <td>46216.93</td>\n",
       "      <td>-3173.06</td>\n",
       "      <td>41761.89</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      close_19  close_diff_20_19  close_18  close_diff_20_18  close_17  \\\n",
       "1598   50053.9          -6193.28  46702.75         -10838.52  48343.28   \n",
       "\n",
       "      close_diff_20_17  close_16  close_diff_20_16  close_15  \\\n",
       "1598          -8795.01  48864.98         -10095.38  47632.38   \n",
       "\n",
       "      close_diff_20_15  ...  close_diff_20_4   close_3  close_diff_20_3  \\\n",
       "1598          -6094.15  ...           112.49  47543.74         -2927.45   \n",
       "\n",
       "       close_2  close_diff_20_2   close_1  close_diff_20_1   close_0  \\\n",
       "1598  46464.66         -1080.93  47120.87           -19.67  46216.93   \n",
       "\n",
       "      close_diff_20_0     close  \n",
       "1598         -3173.06  41761.89  \n",
       "\n",
       "[1 rows x 41 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (1435, 1, 40) (1435, 1)\n",
      "Model: \"sequential_20\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_52 (LSTM)               (None, 1, 100)            56400     \n",
      "_________________________________________________________________\n",
      "lstm_53 (LSTM)               (None, 1, 50)             30200     \n",
      "_________________________________________________________________\n",
      "dropout_33 (Dropout)         (None, 1, 50)             0         \n",
      "_________________________________________________________________\n",
      "lstm_54 (LSTM)               (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_34 (Dropout)         (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 1)                 51        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 106,851\n",
      "Trainable params: 106,851\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Y shape (1435, 1)\n",
      "Train on 1435 samples, validate on 287 samples\n",
      "Epoch 1/70\n",
      " - 5s - loss: 0.0133 - msle: 0.0133 - val_loss: 0.0138 - val_msle: 0.0138\n",
      "Epoch 2/70\n",
      " - 1s - loss: 0.0576 - msle: 0.0576 - val_loss: 0.0635 - val_msle: 0.0635\n",
      "Epoch 3/70\n",
      " - 1s - loss: 0.0423 - msle: 0.0423 - val_loss: 0.0333 - val_msle: 0.0333\n",
      "Epoch 4/70\n",
      " - 1s - loss: 0.0130 - msle: 0.0130 - val_loss: 0.0066 - val_msle: 0.0066\n",
      "Epoch 5/70\n",
      " - 1s - loss: 0.0037 - msle: 0.0037 - val_loss: 0.0061 - val_msle: 0.0061\n",
      "Epoch 6/70\n",
      " - 1s - loss: 0.0035 - msle: 0.0035 - val_loss: 0.0062 - val_msle: 0.0062\n",
      "Epoch 7/70\n",
      " - 1s - loss: 0.0033 - msle: 0.0033 - val_loss: 0.0060 - val_msle: 0.0060\n",
      "Epoch 8/70\n",
      " - 1s - loss: 0.0032 - msle: 0.0032 - val_loss: 0.0061 - val_msle: 0.0061\n",
      "Epoch 9/70\n",
      " - 1s - loss: 0.0032 - msle: 0.0032 - val_loss: 0.0058 - val_msle: 0.0058\n",
      "Epoch 10/70\n",
      " - 1s - loss: 0.0030 - msle: 0.0030 - val_loss: 0.0059 - val_msle: 0.0059\n",
      "Epoch 11/70\n",
      " - 1s - loss: 0.0033 - msle: 0.0033 - val_loss: 0.0058 - val_msle: 0.0058\n",
      "Epoch 12/70\n",
      " - 1s - loss: 0.0030 - msle: 0.0030 - val_loss: 0.0059 - val_msle: 0.0059\n",
      "Epoch 13/70\n",
      " - 1s - loss: 0.0031 - msle: 0.0031 - val_loss: 0.0057 - val_msle: 0.0057\n",
      "Epoch 14/70\n",
      " - 1s - loss: 0.0028 - msle: 0.0028 - val_loss: 0.0056 - val_msle: 0.0056\n",
      "Epoch 15/70\n",
      " - 1s - loss: 0.0027 - msle: 0.0027 - val_loss: 0.0056 - val_msle: 0.0056\n",
      "Epoch 16/70\n",
      " - 1s - loss: 0.0026 - msle: 0.0026 - val_loss: 0.0057 - val_msle: 0.0057\n",
      "Epoch 17/70\n",
      " - 1s - loss: 0.0028 - msle: 0.0028 - val_loss: 0.0054 - val_msle: 0.0054\n",
      "Epoch 18/70\n",
      " - 1s - loss: 0.0027 - msle: 0.0027 - val_loss: 0.0055 - val_msle: 0.0055\n",
      "Epoch 19/70\n",
      " - 1s - loss: 0.0027 - msle: 0.0027 - val_loss: 0.0053 - val_msle: 0.0053\n",
      "Epoch 20/70\n",
      " - 1s - loss: 0.0025 - msle: 0.0025 - val_loss: 0.0053 - val_msle: 0.0053\n",
      "Epoch 21/70\n",
      " - 1s - loss: 0.0027 - msle: 0.0027 - val_loss: 0.0052 - val_msle: 0.0052\n",
      "Epoch 22/70\n",
      " - 1s - loss: 0.0027 - msle: 0.0027 - val_loss: 0.0051 - val_msle: 0.0051\n",
      "Epoch 23/70\n",
      " - 1s - loss: 0.0025 - msle: 0.0025 - val_loss: 0.0051 - val_msle: 0.0051\n",
      "Epoch 24/70\n",
      " - 1s - loss: 0.0027 - msle: 0.0027 - val_loss: 0.0051 - val_msle: 0.0051\n",
      "Epoch 25/70\n",
      " - 1s - loss: 0.0025 - msle: 0.0025 - val_loss: 0.0049 - val_msle: 0.0049\n",
      "Epoch 26/70\n",
      " - 1s - loss: 0.0025 - msle: 0.0025 - val_loss: 0.0049 - val_msle: 0.0049\n",
      "Epoch 27/70\n",
      " - 1s - loss: 0.0025 - msle: 0.0025 - val_loss: 0.0048 - val_msle: 0.0048\n",
      "Epoch 28/70\n",
      " - 1s - loss: 0.0023 - msle: 0.0023 - val_loss: 0.0048 - val_msle: 0.0048\n",
      "Epoch 29/70\n",
      " - 1s - loss: 0.0024 - msle: 0.0024 - val_loss: 0.0047 - val_msle: 0.0047\n",
      "Epoch 30/70\n",
      " - 1s - loss: 0.0024 - msle: 0.0024 - val_loss: 0.0046 - val_msle: 0.0046\n",
      "Epoch 31/70\n",
      " - 1s - loss: 0.0023 - msle: 0.0023 - val_loss: 0.0046 - val_msle: 0.0046\n",
      "Epoch 32/70\n",
      " - 1s - loss: 0.0024 - msle: 0.0024 - val_loss: 0.0045 - val_msle: 0.0045\n",
      "Epoch 33/70\n",
      " - 1s - loss: 0.0022 - msle: 0.0022 - val_loss: 0.0045 - val_msle: 0.0045\n",
      "Epoch 34/70\n",
      " - 1s - loss: 0.0024 - msle: 0.0024 - val_loss: 0.0044 - val_msle: 0.0044\n",
      "Epoch 35/70\n",
      " - 1s - loss: 0.0025 - msle: 0.0025 - val_loss: 0.0044 - val_msle: 0.0044\n",
      "Epoch 36/70\n",
      " - 1s - loss: 0.0023 - msle: 0.0023 - val_loss: 0.0043 - val_msle: 0.0043\n",
      "Epoch 37/70\n",
      " - 1s - loss: 0.0024 - msle: 0.0024 - val_loss: 0.0043 - val_msle: 0.0043\n",
      "Epoch 38/70\n",
      " - 1s - loss: 0.0024 - msle: 0.0024 - val_loss: 0.0043 - val_msle: 0.0043\n",
      "Epoch 39/70\n",
      " - 1s - loss: 0.0023 - msle: 0.0023 - val_loss: 0.0042 - val_msle: 0.0042\n",
      "Epoch 40/70\n",
      " - 1s - loss: 0.0023 - msle: 0.0023 - val_loss: 0.0042 - val_msle: 0.0042\n",
      "Epoch 41/70\n",
      " - 1s - loss: 0.0022 - msle: 0.0022 - val_loss: 0.0042 - val_msle: 0.0042\n",
      "Epoch 42/70\n",
      " - 1s - loss: 0.0024 - msle: 0.0024 - val_loss: 0.0041 - val_msle: 0.0041\n",
      "Epoch 43/70\n",
      " - 1s - loss: 0.0024 - msle: 0.0024 - val_loss: 0.0041 - val_msle: 0.0041\n",
      "Epoch 44/70\n",
      " - 1s - loss: 0.0023 - msle: 0.0023 - val_loss: 0.0042 - val_msle: 0.0042\n",
      "Epoch 45/70\n",
      " - 1s - loss: 0.0022 - msle: 0.0022 - val_loss: 0.0041 - val_msle: 0.0041\n",
      "Epoch 46/70\n",
      " - 1s - loss: 0.0024 - msle: 0.0024 - val_loss: 0.0041 - val_msle: 0.0041\n",
      "Epoch 47/70\n",
      " - 1s - loss: 0.0024 - msle: 0.0024 - val_loss: 0.0041 - val_msle: 0.0041\n",
      "Epoch 48/70\n",
      " - 1s - loss: 0.0022 - msle: 0.0022 - val_loss: 0.0040 - val_msle: 0.0040\n",
      "Epoch 49/70\n",
      " - 1s - loss: 0.0025 - msle: 0.0025 - val_loss: 0.0042 - val_msle: 0.0042\n",
      "Epoch 50/70\n",
      " - 1s - loss: 0.0022 - msle: 0.0022 - val_loss: 0.0040 - val_msle: 0.0040\n",
      "Epoch 51/70\n",
      " - 1s - loss: 0.0023 - msle: 0.0023 - val_loss: 0.0041 - val_msle: 0.0041\n",
      "Epoch 52/70\n",
      " - 1s - loss: 0.0021 - msle: 0.0021 - val_loss: 0.0040 - val_msle: 0.0040\n",
      "Epoch 53/70\n",
      " - 1s - loss: 0.0022 - msle: 0.0022 - val_loss: 0.0040 - val_msle: 0.0040\n",
      "Epoch 54/70\n",
      " - 1s - loss: 0.0022 - msle: 0.0022 - val_loss: 0.0040 - val_msle: 0.0040\n",
      "Epoch 55/70\n",
      " - 1s - loss: 0.0023 - msle: 0.0023 - val_loss: 0.0040 - val_msle: 0.0040\n",
      "Epoch 56/70\n",
      " - 1s - loss: 0.0023 - msle: 0.0023 - val_loss: 0.0040 - val_msle: 0.0040\n",
      "Epoch 57/70\n",
      " - 1s - loss: 0.0022 - msle: 0.0022 - val_loss: 0.0040 - val_msle: 0.0040\n",
      "Epoch 58/70\n",
      " - 1s - loss: 0.0021 - msle: 0.0021 - val_loss: 0.0040 - val_msle: 0.0040\n",
      "Epoch 59/70\n",
      " - 1s - loss: 0.0022 - msle: 0.0022 - val_loss: 0.0040 - val_msle: 0.0040\n",
      "Epoch 60/70\n",
      " - 1s - loss: 0.0022 - msle: 0.0022 - val_loss: 0.0040 - val_msle: 0.0040\n",
      "Epoch 61/70\n",
      " - 1s - loss: 0.0021 - msle: 0.0021 - val_loss: 0.0040 - val_msle: 0.0040\n",
      "Epoch 62/70\n",
      " - 1s - loss: 0.0022 - msle: 0.0022 - val_loss: 0.0040 - val_msle: 0.0040\n",
      "Epoch 63/70\n",
      " - 1s - loss: 0.0022 - msle: 0.0022 - val_loss: 0.0041 - val_msle: 0.0041\n",
      "Epoch 64/70\n",
      " - 1s - loss: 0.0022 - msle: 0.0022 - val_loss: 0.0040 - val_msle: 0.0040\n",
      "Epoch 65/70\n",
      " - 1s - loss: 0.0023 - msle: 0.0023 - val_loss: 0.0040 - val_msle: 0.0040\n",
      "Epoch 66/70\n",
      " - 1s - loss: 0.0022 - msle: 0.0022 - val_loss: 0.0040 - val_msle: 0.0040\n",
      "Epoch 67/70\n",
      " - 1s - loss: 0.0022 - msle: 0.0022 - val_loss: 0.0040 - val_msle: 0.0040\n",
      "Epoch 68/70\n",
      " - 1s - loss: 0.0022 - msle: 0.0022 - val_loss: 0.0040 - val_msle: 0.0040\n",
      "Epoch 69/70\n",
      " - 1s - loss: 0.0020 - msle: 0.0020 - val_loss: 0.0039 - val_msle: 0.0039\n",
      "Epoch 70/70\n",
      " - 1s - loss: 0.0021 - msle: 0.0021 - val_loss: 0.0039 - val_msle: 0.0039\n",
      "real [[41761.89]]\n",
      "Test RMSE: 3479.463\n",
      "Diff [[-3479.46254515]]\n",
      "% Diff [[-8.33166924]] %\n",
      "Predictions [[45241.35254515]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "activation = LeakyReLU(alpha=0.05)\n",
    "\n",
    "crypto = crypto\n",
    "execute_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading... BTC\n",
      "Extracting columns columns for BTC\n",
      "Proccessing and arranging columns for LSTM model\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>close_19</th>\n",
       "      <th>close_diff_20_19</th>\n",
       "      <th>close_18</th>\n",
       "      <th>close_diff_20_18</th>\n",
       "      <th>close_17</th>\n",
       "      <th>close_diff_20_17</th>\n",
       "      <th>close_16</th>\n",
       "      <th>close_diff_20_16</th>\n",
       "      <th>close_15</th>\n",
       "      <th>close_diff_20_15</th>\n",
       "      <th>...</th>\n",
       "      <th>close_diff_20_4</th>\n",
       "      <th>close_3</th>\n",
       "      <th>close_diff_20_3</th>\n",
       "      <th>close_2</th>\n",
       "      <th>close_diff_20_2</th>\n",
       "      <th>close_1</th>\n",
       "      <th>close_diff_20_1</th>\n",
       "      <th>close_0</th>\n",
       "      <th>close_diff_20_0</th>\n",
       "      <th>close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>16150.03</td>\n",
       "      <td>-2706.22</td>\n",
       "      <td>14902.54</td>\n",
       "      <td>-2392.66</td>\n",
       "      <td>14400.00</td>\n",
       "      <td>-2088.98</td>\n",
       "      <td>14907.09</td>\n",
       "      <td>-585.55</td>\n",
       "      <td>13238.78</td>\n",
       "      <td>-87.83</td>\n",
       "      <td>...</td>\n",
       "      <td>-3915.06</td>\n",
       "      <td>10799.18</td>\n",
       "      <td>-4120.33</td>\n",
       "      <td>11349.99</td>\n",
       "      <td>-3709.55</td>\n",
       "      <td>11175.27</td>\n",
       "      <td>-5785.12</td>\n",
       "      <td>11089.00</td>\n",
       "      <td>-5980.79</td>\n",
       "      <td>10000.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>14902.54</td>\n",
       "      <td>-2392.66</td>\n",
       "      <td>14400.00</td>\n",
       "      <td>-2088.98</td>\n",
       "      <td>14907.09</td>\n",
       "      <td>-585.55</td>\n",
       "      <td>13238.78</td>\n",
       "      <td>-87.83</td>\n",
       "      <td>13740.01</td>\n",
       "      <td>440.01</td>\n",
       "      <td>...</td>\n",
       "      <td>-4120.33</td>\n",
       "      <td>11349.99</td>\n",
       "      <td>-3709.55</td>\n",
       "      <td>11175.27</td>\n",
       "      <td>-5785.12</td>\n",
       "      <td>11089.00</td>\n",
       "      <td>-5980.79</td>\n",
       "      <td>11491.00</td>\n",
       "      <td>-4659.03</td>\n",
       "      <td>10159.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>14400.00</td>\n",
       "      <td>-2088.98</td>\n",
       "      <td>14907.09</td>\n",
       "      <td>-585.55</td>\n",
       "      <td>13238.78</td>\n",
       "      <td>-87.83</td>\n",
       "      <td>13740.01</td>\n",
       "      <td>440.01</td>\n",
       "      <td>14210.00</td>\n",
       "      <td>710.00</td>\n",
       "      <td>...</td>\n",
       "      <td>-3709.55</td>\n",
       "      <td>11175.27</td>\n",
       "      <td>-5785.12</td>\n",
       "      <td>11089.00</td>\n",
       "      <td>-5980.79</td>\n",
       "      <td>11491.00</td>\n",
       "      <td>-4659.03</td>\n",
       "      <td>11879.95</td>\n",
       "      <td>-3022.59</td>\n",
       "      <td>11039.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>14907.09</td>\n",
       "      <td>-585.55</td>\n",
       "      <td>13238.78</td>\n",
       "      <td>-87.83</td>\n",
       "      <td>13740.01</td>\n",
       "      <td>440.01</td>\n",
       "      <td>14210.00</td>\n",
       "      <td>710.00</td>\n",
       "      <td>13474.99</td>\n",
       "      <td>-224.35</td>\n",
       "      <td>...</td>\n",
       "      <td>-5785.12</td>\n",
       "      <td>11089.00</td>\n",
       "      <td>-5980.79</td>\n",
       "      <td>11491.00</td>\n",
       "      <td>-4659.03</td>\n",
       "      <td>11879.95</td>\n",
       "      <td>-3022.59</td>\n",
       "      <td>11251.00</td>\n",
       "      <td>-3149.00</td>\n",
       "      <td>10383.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>13238.78</td>\n",
       "      <td>-87.83</td>\n",
       "      <td>13740.01</td>\n",
       "      <td>440.01</td>\n",
       "      <td>14210.00</td>\n",
       "      <td>710.00</td>\n",
       "      <td>13474.99</td>\n",
       "      <td>-224.35</td>\n",
       "      <td>13539.93</td>\n",
       "      <td>-2149.08</td>\n",
       "      <td>...</td>\n",
       "      <td>-5980.79</td>\n",
       "      <td>11491.00</td>\n",
       "      <td>-4659.03</td>\n",
       "      <td>11879.95</td>\n",
       "      <td>-3022.59</td>\n",
       "      <td>11251.00</td>\n",
       "      <td>-3149.00</td>\n",
       "      <td>10237.51</td>\n",
       "      <td>-4669.58</td>\n",
       "      <td>11153.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1593</th>\n",
       "      <td>50588.95</td>\n",
       "      <td>-9755.92</td>\n",
       "      <td>50471.19</td>\n",
       "      <td>-6420.43</td>\n",
       "      <td>47545.59</td>\n",
       "      <td>-10506.65</td>\n",
       "      <td>47140.54</td>\n",
       "      <td>-12566.97</td>\n",
       "      <td>49389.99</td>\n",
       "      <td>-9232.03</td>\n",
       "      <td>...</td>\n",
       "      <td>-7892.18</td>\n",
       "      <td>50838.81</td>\n",
       "      <td>-2762.24</td>\n",
       "      <td>50820.00</td>\n",
       "      <td>1667.53</td>\n",
       "      <td>50399.66</td>\n",
       "      <td>1003.33</td>\n",
       "      <td>50775.49</td>\n",
       "      <td>333.57</td>\n",
       "      <td>43084.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1594</th>\n",
       "      <td>50471.19</td>\n",
       "      <td>-6420.43</td>\n",
       "      <td>47545.59</td>\n",
       "      <td>-10506.65</td>\n",
       "      <td>47140.54</td>\n",
       "      <td>-12566.97</td>\n",
       "      <td>49389.99</td>\n",
       "      <td>-9232.03</td>\n",
       "      <td>50053.90</td>\n",
       "      <td>-6193.28</td>\n",
       "      <td>...</td>\n",
       "      <td>-2762.24</td>\n",
       "      <td>50820.00</td>\n",
       "      <td>1667.53</td>\n",
       "      <td>50399.66</td>\n",
       "      <td>1003.33</td>\n",
       "      <td>50775.49</td>\n",
       "      <td>333.57</td>\n",
       "      <td>50701.44</td>\n",
       "      <td>112.49</td>\n",
       "      <td>43071.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1595</th>\n",
       "      <td>47545.59</td>\n",
       "      <td>-10506.65</td>\n",
       "      <td>47140.54</td>\n",
       "      <td>-12566.97</td>\n",
       "      <td>49389.99</td>\n",
       "      <td>-9232.03</td>\n",
       "      <td>50053.90</td>\n",
       "      <td>-6193.28</td>\n",
       "      <td>46702.75</td>\n",
       "      <td>-10838.52</td>\n",
       "      <td>...</td>\n",
       "      <td>1667.53</td>\n",
       "      <td>50399.66</td>\n",
       "      <td>1003.33</td>\n",
       "      <td>50775.49</td>\n",
       "      <td>333.57</td>\n",
       "      <td>50701.44</td>\n",
       "      <td>112.49</td>\n",
       "      <td>47543.74</td>\n",
       "      <td>-2927.45</td>\n",
       "      <td>42201.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1596</th>\n",
       "      <td>47140.54</td>\n",
       "      <td>-12566.97</td>\n",
       "      <td>49389.99</td>\n",
       "      <td>-9232.03</td>\n",
       "      <td>50053.90</td>\n",
       "      <td>-6193.28</td>\n",
       "      <td>46702.75</td>\n",
       "      <td>-10838.52</td>\n",
       "      <td>48343.28</td>\n",
       "      <td>-8795.01</td>\n",
       "      <td>...</td>\n",
       "      <td>1003.33</td>\n",
       "      <td>50775.49</td>\n",
       "      <td>333.57</td>\n",
       "      <td>50701.44</td>\n",
       "      <td>112.49</td>\n",
       "      <td>47543.74</td>\n",
       "      <td>-2927.45</td>\n",
       "      <td>46464.66</td>\n",
       "      <td>-1080.93</td>\n",
       "      <td>42352.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1597</th>\n",
       "      <td>49389.99</td>\n",
       "      <td>-9232.03</td>\n",
       "      <td>50053.90</td>\n",
       "      <td>-6193.28</td>\n",
       "      <td>46702.75</td>\n",
       "      <td>-10838.52</td>\n",
       "      <td>48343.28</td>\n",
       "      <td>-8795.01</td>\n",
       "      <td>48864.98</td>\n",
       "      <td>-10095.38</td>\n",
       "      <td>...</td>\n",
       "      <td>333.57</td>\n",
       "      <td>50701.44</td>\n",
       "      <td>112.49</td>\n",
       "      <td>47543.74</td>\n",
       "      <td>-2927.45</td>\n",
       "      <td>46464.66</td>\n",
       "      <td>-1080.93</td>\n",
       "      <td>47120.87</td>\n",
       "      <td>-19.67</td>\n",
       "      <td>41660.01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1435 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      close_19  close_diff_20_19  close_18  close_diff_20_18  close_17  \\\n",
       "163   16150.03          -2706.22  14902.54          -2392.66  14400.00   \n",
       "164   14902.54          -2392.66  14400.00          -2088.98  14907.09   \n",
       "165   14400.00          -2088.98  14907.09           -585.55  13238.78   \n",
       "166   14907.09           -585.55  13238.78            -87.83  13740.01   \n",
       "167   13238.78            -87.83  13740.01            440.01  14210.00   \n",
       "...        ...               ...       ...               ...       ...   \n",
       "1593  50588.95          -9755.92  50471.19          -6420.43  47545.59   \n",
       "1594  50471.19          -6420.43  47545.59         -10506.65  47140.54   \n",
       "1595  47545.59         -10506.65  47140.54         -12566.97  49389.99   \n",
       "1596  47140.54         -12566.97  49389.99          -9232.03  50053.90   \n",
       "1597  49389.99          -9232.03  50053.90          -6193.28  46702.75   \n",
       "\n",
       "      close_diff_20_17  close_16  close_diff_20_16  close_15  \\\n",
       "163           -2088.98  14907.09           -585.55  13238.78   \n",
       "164            -585.55  13238.78            -87.83  13740.01   \n",
       "165             -87.83  13740.01            440.01  14210.00   \n",
       "166             440.01  14210.00            710.00  13474.99   \n",
       "167             710.00  13474.99           -224.35  13539.93   \n",
       "...                ...       ...               ...       ...   \n",
       "1593         -10506.65  47140.54         -12566.97  49389.99   \n",
       "1594         -12566.97  49389.99          -9232.03  50053.90   \n",
       "1595          -9232.03  50053.90          -6193.28  46702.75   \n",
       "1596          -6193.28  46702.75         -10838.52  48343.28   \n",
       "1597         -10838.52  48343.28          -8795.01  48864.98   \n",
       "\n",
       "      close_diff_20_15  ...  close_diff_20_4   close_3  close_diff_20_3  \\\n",
       "163             -87.83  ...         -3915.06  10799.18         -4120.33   \n",
       "164             440.01  ...         -4120.33  11349.99         -3709.55   \n",
       "165             710.00  ...         -3709.55  11175.27         -5785.12   \n",
       "166            -224.35  ...         -5785.12  11089.00         -5980.79   \n",
       "167           -2149.08  ...         -5980.79  11491.00         -4659.03   \n",
       "...                ...  ...              ...       ...              ...   \n",
       "1593          -9232.03  ...         -7892.18  50838.81         -2762.24   \n",
       "1594          -6193.28  ...         -2762.24  50820.00          1667.53   \n",
       "1595         -10838.52  ...          1667.53  50399.66          1003.33   \n",
       "1596          -8795.01  ...          1003.33  50775.49           333.57   \n",
       "1597         -10095.38  ...           333.57  50701.44           112.49   \n",
       "\n",
       "       close_2  close_diff_20_2   close_1  close_diff_20_1   close_0  \\\n",
       "163   11349.99         -3709.55  11175.27         -5785.12  11089.00   \n",
       "164   11175.27         -5785.12  11089.00         -5980.79  11491.00   \n",
       "165   11089.00         -5980.79  11491.00         -4659.03  11879.95   \n",
       "166   11491.00         -4659.03  11879.95         -3022.59  11251.00   \n",
       "167   11879.95         -3022.59  11251.00         -3149.00  10237.51   \n",
       "...        ...              ...       ...              ...       ...   \n",
       "1593  50820.00          1667.53  50399.66          1003.33  50775.49   \n",
       "1594  50399.66          1003.33  50775.49           333.57  50701.44   \n",
       "1595  50775.49           333.57  50701.44           112.49  47543.74   \n",
       "1596  50701.44           112.49  47543.74         -2927.45  46464.66   \n",
       "1597  47543.74         -2927.45  46464.66         -1080.93  47120.87   \n",
       "\n",
       "      close_diff_20_0     close  \n",
       "163          -5980.79  10000.09  \n",
       "164          -4659.03  10159.98  \n",
       "165          -3022.59  11039.55  \n",
       "166          -3149.00  10383.43  \n",
       "167          -4669.58  11153.00  \n",
       "...               ...       ...  \n",
       "1593           333.57  43084.29  \n",
       "1594           112.49  43071.66  \n",
       "1595         -2927.45  42201.62  \n",
       "1596         -1080.93  42352.12  \n",
       "1597           -19.67  41660.01  \n",
       "\n",
       "[1435 rows x 41 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>close_19</th>\n",
       "      <th>close_diff_20_19</th>\n",
       "      <th>close_18</th>\n",
       "      <th>close_diff_20_18</th>\n",
       "      <th>close_17</th>\n",
       "      <th>close_diff_20_17</th>\n",
       "      <th>close_16</th>\n",
       "      <th>close_diff_20_16</th>\n",
       "      <th>close_15</th>\n",
       "      <th>close_diff_20_15</th>\n",
       "      <th>...</th>\n",
       "      <th>close_diff_20_4</th>\n",
       "      <th>close_3</th>\n",
       "      <th>close_diff_20_3</th>\n",
       "      <th>close_2</th>\n",
       "      <th>close_diff_20_2</th>\n",
       "      <th>close_1</th>\n",
       "      <th>close_diff_20_1</th>\n",
       "      <th>close_0</th>\n",
       "      <th>close_diff_20_0</th>\n",
       "      <th>close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1598</th>\n",
       "      <td>50053.9</td>\n",
       "      <td>-6193.28</td>\n",
       "      <td>46702.75</td>\n",
       "      <td>-10838.52</td>\n",
       "      <td>48343.28</td>\n",
       "      <td>-8795.01</td>\n",
       "      <td>48864.98</td>\n",
       "      <td>-10095.38</td>\n",
       "      <td>47632.38</td>\n",
       "      <td>-6094.15</td>\n",
       "      <td>...</td>\n",
       "      <td>112.49</td>\n",
       "      <td>47543.74</td>\n",
       "      <td>-2927.45</td>\n",
       "      <td>46464.66</td>\n",
       "      <td>-1080.93</td>\n",
       "      <td>47120.87</td>\n",
       "      <td>-19.67</td>\n",
       "      <td>46216.93</td>\n",
       "      <td>-3173.06</td>\n",
       "      <td>41761.89</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      close_19  close_diff_20_19  close_18  close_diff_20_18  close_17  \\\n",
       "1598   50053.9          -6193.28  46702.75         -10838.52  48343.28   \n",
       "\n",
       "      close_diff_20_17  close_16  close_diff_20_16  close_15  \\\n",
       "1598          -8795.01  48864.98         -10095.38  47632.38   \n",
       "\n",
       "      close_diff_20_15  ...  close_diff_20_4   close_3  close_diff_20_3  \\\n",
       "1598          -6094.15  ...           112.49  47543.74         -2927.45   \n",
       "\n",
       "       close_2  close_diff_20_2   close_1  close_diff_20_1   close_0  \\\n",
       "1598  46464.66         -1080.93  47120.87           -19.67  46216.93   \n",
       "\n",
       "      close_diff_20_0     close  \n",
       "1598         -3173.06  41761.89  \n",
       "\n",
       "[1 rows x 41 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (1435, 1, 40) (1435, 1)\n",
      "Model: \"sequential_22\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_58 (LSTM)               (None, 1, 100)            56400     \n",
      "_________________________________________________________________\n",
      "lstm_59 (LSTM)               (None, 1, 50)             30200     \n",
      "_________________________________________________________________\n",
      "dropout_37 (Dropout)         (None, 1, 50)             0         \n",
      "_________________________________________________________________\n",
      "lstm_60 (LSTM)               (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_38 (Dropout)         (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 1)                 51        \n",
      "_________________________________________________________________\n",
      "Swish (Activation)           (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 106,851\n",
      "Trainable params: 106,851\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Y shape (1435, 1)\n",
      "Train on 1435 samples, validate on 287 samples\n",
      "Epoch 1/70\n",
      " - 7s - loss: 0.0091 - msle: 0.0091 - val_loss: 0.0050 - val_msle: 0.0050\n",
      "Epoch 2/70\n",
      " - 1s - loss: 0.0586 - msle: 0.0586 - val_loss: 0.0933 - val_msle: 0.0933\n",
      "Epoch 3/70\n",
      " - 1s - loss: 0.0201 - msle: 0.0201 - val_loss: 0.0151 - val_msle: 0.0151\n",
      "Epoch 4/70\n",
      " - 1s - loss: 0.0104 - msle: 0.0104 - val_loss: 0.0156 - val_msle: 0.0156\n",
      "Epoch 5/70\n",
      " - 1s - loss: 0.0079 - msle: 0.0079 - val_loss: 0.0060 - val_msle: 0.0060\n",
      "Epoch 6/70\n",
      " - 1s - loss: 0.0060 - msle: 0.0060 - val_loss: 0.0064 - val_msle: 0.0064\n",
      "Epoch 7/70\n",
      " - 1s - loss: 0.0054 - msle: 0.0054 - val_loss: 0.0059 - val_msle: 0.0059\n",
      "Epoch 8/70\n",
      " - 1s - loss: 0.0043 - msle: 0.0043 - val_loss: 0.0059 - val_msle: 0.0059\n",
      "Epoch 9/70\n",
      " - 1s - loss: 0.0038 - msle: 0.0038 - val_loss: 0.0060 - val_msle: 0.0060\n",
      "Epoch 10/70\n",
      " - 1s - loss: 0.0037 - msle: 0.0037 - val_loss: 0.0059 - val_msle: 0.0059\n",
      "Epoch 11/70\n",
      " - 1s - loss: 0.0032 - msle: 0.0032 - val_loss: 0.0059 - val_msle: 0.0059\n",
      "Epoch 12/70\n",
      " - 1s - loss: 0.0034 - msle: 0.0034 - val_loss: 0.0060 - val_msle: 0.0060\n",
      "Epoch 13/70\n",
      " - 1s - loss: 0.0029 - msle: 0.0029 - val_loss: 0.0059 - val_msle: 0.0059\n",
      "Epoch 14/70\n",
      " - 1s - loss: 0.0030 - msle: 0.0030 - val_loss: 0.0058 - val_msle: 0.0058\n",
      "Epoch 15/70\n",
      " - 1s - loss: 0.0029 - msle: 0.0029 - val_loss: 0.0059 - val_msle: 0.0059\n",
      "Epoch 16/70\n",
      " - 1s - loss: 0.0030 - msle: 0.0030 - val_loss: 0.0060 - val_msle: 0.0060\n",
      "Epoch 17/70\n",
      " - 1s - loss: 0.0029 - msle: 0.0029 - val_loss: 0.0057 - val_msle: 0.0057\n",
      "Epoch 18/70\n",
      " - 1s - loss: 0.0031 - msle: 0.0031 - val_loss: 0.0058 - val_msle: 0.0058\n",
      "Epoch 19/70\n",
      " - 1s - loss: 0.0029 - msle: 0.0029 - val_loss: 0.0057 - val_msle: 0.0057\n",
      "Epoch 20/70\n",
      " - 1s - loss: 0.0028 - msle: 0.0028 - val_loss: 0.0057 - val_msle: 0.0057\n",
      "Epoch 21/70\n",
      " - 1s - loss: 0.0030 - msle: 0.0030 - val_loss: 0.0056 - val_msle: 0.0056\n",
      "Epoch 22/70\n",
      " - 1s - loss: 0.0027 - msle: 0.0027 - val_loss: 0.0056 - val_msle: 0.0056\n",
      "Epoch 23/70\n",
      " - 1s - loss: 0.0029 - msle: 0.0029 - val_loss: 0.0055 - val_msle: 0.0055\n",
      "Epoch 24/70\n",
      " - 1s - loss: 0.0025 - msle: 0.0025 - val_loss: 0.0054 - val_msle: 0.0054\n",
      "Epoch 25/70\n",
      " - 1s - loss: 0.0028 - msle: 0.0028 - val_loss: 0.0054 - val_msle: 0.0054\n",
      "Epoch 26/70\n",
      " - 1s - loss: 0.0028 - msle: 0.0028 - val_loss: 0.0053 - val_msle: 0.0053\n",
      "Epoch 27/70\n",
      " - 1s - loss: 0.0025 - msle: 0.0025 - val_loss: 0.0053 - val_msle: 0.0053\n",
      "Epoch 28/70\n",
      " - 1s - loss: 0.0026 - msle: 0.0026 - val_loss: 0.0052 - val_msle: 0.0052\n",
      "Epoch 29/70\n",
      " - 1s - loss: 0.0027 - msle: 0.0027 - val_loss: 0.0052 - val_msle: 0.0052\n",
      "Epoch 30/70\n",
      " - 1s - loss: 0.0027 - msle: 0.0027 - val_loss: 0.0051 - val_msle: 0.0051\n",
      "Epoch 31/70\n",
      " - 1s - loss: 0.0027 - msle: 0.0027 - val_loss: 0.0052 - val_msle: 0.0052\n",
      "Epoch 32/70\n",
      " - 1s - loss: 0.0027 - msle: 0.0027 - val_loss: 0.0049 - val_msle: 0.0049\n",
      "Epoch 33/70\n",
      " - 1s - loss: 0.0025 - msle: 0.0025 - val_loss: 0.0049 - val_msle: 0.0049\n",
      "Epoch 34/70\n",
      " - 1s - loss: 0.0029 - msle: 0.0029 - val_loss: 0.0047 - val_msle: 0.0047\n",
      "Epoch 35/70\n",
      " - 1s - loss: 0.0024 - msle: 0.0024 - val_loss: 0.0047 - val_msle: 0.0047\n",
      "Epoch 36/70\n",
      " - 1s - loss: 0.0024 - msle: 0.0024 - val_loss: 0.0046 - val_msle: 0.0046\n",
      "Epoch 37/70\n",
      " - 1s - loss: 0.0025 - msle: 0.0025 - val_loss: 0.0046 - val_msle: 0.0046\n",
      "Epoch 38/70\n",
      " - 1s - loss: 0.0027 - msle: 0.0027 - val_loss: 0.0045 - val_msle: 0.0045\n",
      "Epoch 39/70\n",
      " - 1s - loss: 0.0024 - msle: 0.0024 - val_loss: 0.0045 - val_msle: 0.0045\n",
      "Epoch 40/70\n",
      " - 1s - loss: 0.0026 - msle: 0.0026 - val_loss: 0.0044 - val_msle: 0.0044\n",
      "Epoch 41/70\n",
      " - 1s - loss: 0.0025 - msle: 0.0025 - val_loss: 0.0044 - val_msle: 0.0044\n",
      "Epoch 42/70\n",
      " - 1s - loss: 0.0027 - msle: 0.0027 - val_loss: 0.0044 - val_msle: 0.0044\n",
      "Epoch 43/70\n",
      " - 1s - loss: 0.0025 - msle: 0.0025 - val_loss: 0.0044 - val_msle: 0.0044\n",
      "Epoch 44/70\n",
      " - 1s - loss: 0.0025 - msle: 0.0025 - val_loss: 0.0042 - val_msle: 0.0042\n",
      "Epoch 45/70\n",
      " - 1s - loss: 0.0025 - msle: 0.0025 - val_loss: 0.0042 - val_msle: 0.0042\n",
      "Epoch 46/70\n",
      " - 1s - loss: 0.0024 - msle: 0.0024 - val_loss: 0.0042 - val_msle: 0.0042\n",
      "Epoch 47/70\n",
      " - 1s - loss: 0.0023 - msle: 0.0023 - val_loss: 0.0042 - val_msle: 0.0042\n",
      "Epoch 48/70\n",
      " - 1s - loss: 0.0024 - msle: 0.0024 - val_loss: 0.0041 - val_msle: 0.0041\n",
      "Epoch 49/70\n",
      " - 1s - loss: 0.0024 - msle: 0.0024 - val_loss: 0.0041 - val_msle: 0.0041\n",
      "Epoch 50/70\n",
      " - 1s - loss: 0.0024 - msle: 0.0024 - val_loss: 0.0042 - val_msle: 0.0042\n",
      "Epoch 51/70\n",
      " - 1s - loss: 0.0022 - msle: 0.0022 - val_loss: 0.0041 - val_msle: 0.0041\n",
      "Epoch 52/70\n",
      " - 1s - loss: 0.0024 - msle: 0.0024 - val_loss: 0.0041 - val_msle: 0.0041\n",
      "Epoch 53/70\n",
      " - 1s - loss: 0.0023 - msle: 0.0023 - val_loss: 0.0041 - val_msle: 0.0041\n",
      "Epoch 54/70\n",
      " - 1s - loss: 0.0023 - msle: 0.0023 - val_loss: 0.0041 - val_msle: 0.0041\n",
      "Epoch 55/70\n",
      " - 1s - loss: 0.0025 - msle: 0.0025 - val_loss: 0.0041 - val_msle: 0.0041\n",
      "Epoch 56/70\n",
      " - 1s - loss: 0.0025 - msle: 0.0025 - val_loss: 0.0040 - val_msle: 0.0040\n",
      "Epoch 57/70\n",
      " - 1s - loss: 0.0023 - msle: 0.0023 - val_loss: 0.0040 - val_msle: 0.0040\n",
      "Epoch 58/70\n",
      " - 1s - loss: 0.0022 - msle: 0.0022 - val_loss: 0.0040 - val_msle: 0.0040\n",
      "Epoch 59/70\n",
      " - 1s - loss: 0.0021 - msle: 0.0021 - val_loss: 0.0041 - val_msle: 0.0041\n",
      "Epoch 60/70\n",
      " - 1s - loss: 0.0024 - msle: 0.0024 - val_loss: 0.0040 - val_msle: 0.0040\n",
      "Epoch 61/70\n",
      " - 1s - loss: 0.0023 - msle: 0.0023 - val_loss: 0.0040 - val_msle: 0.0040\n",
      "Epoch 62/70\n",
      " - 1s - loss: 0.0024 - msle: 0.0024 - val_loss: 0.0040 - val_msle: 0.0040\n",
      "Epoch 63/70\n",
      " - 1s - loss: 0.0023 - msle: 0.0023 - val_loss: 0.0040 - val_msle: 0.0040\n",
      "Epoch 64/70\n",
      " - 1s - loss: 0.0024 - msle: 0.0024 - val_loss: 0.0040 - val_msle: 0.0040\n",
      "Epoch 65/70\n",
      " - 1s - loss: 0.0023 - msle: 0.0023 - val_loss: 0.0040 - val_msle: 0.0040\n",
      "Epoch 66/70\n",
      " - 1s - loss: 0.0022 - msle: 0.0022 - val_loss: 0.0040 - val_msle: 0.0040\n",
      "Epoch 67/70\n",
      " - 1s - loss: 0.0023 - msle: 0.0023 - val_loss: 0.0041 - val_msle: 0.0041\n",
      "Epoch 68/70\n",
      " - 1s - loss: 0.0021 - msle: 0.0021 - val_loss: 0.0041 - val_msle: 0.0041\n",
      "Epoch 69/70\n",
      " - 1s - loss: 0.0021 - msle: 0.0021 - val_loss: 0.0040 - val_msle: 0.0040\n",
      "Epoch 70/70\n",
      " - 1s - loss: 0.0023 - msle: 0.0023 - val_loss: 0.0040 - val_msle: 0.0040\n",
      "real [[41761.89]]\n",
      "Test RMSE: 3470.071\n",
      "Diff [[-3470.07066693]]\n",
      "% Diff [[-8.30918013]] %\n",
      "Predictions [[45231.96066693]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "activation = Activation(custom_activation,name = \"Swish\")\n",
    "\n",
    "crypto = crypto\n",
    "execute_test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nos quedaremos con activación ReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "activation = LeakyReLU(alpha=0.05)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente usaremos la diferencia de precio y el precio pero aumentando a 40 los dias previos usados y bajando a 10 los dias a predecir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### PERIODS ####\n",
    "prev_periods = 40\n",
    "pred_periods = 10\n",
    "\n",
    "\n",
    "columns_12 = ['close', 'close_diff_10']\n",
    "columns = columns_12\n",
    "\n",
    "for crypto in cryptos:\n",
    "    crypto = crypto\n",
    "    execute_test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mejora considerable al subir prev peridos y bajar pred periods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se ha probado a mover el numero de dias previos usados. Parece no afectar mucho al comportamiento del modelo "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Haremos backtesting para probar a añadir varias caracteristicas y sacar como target la diferencia de precio y el precio. Obtendremos mejor resultado una vez aplicado el modelado de red y los hiperparametros mas eficiantes segun hemos analizado?\n",
    "\n",
    "Caracteristicas a probar:\n",
    "\n",
    "- Resistance and support levels 50\n",
    "\n",
    "Target a probar:\n",
    "\n",
    "- close\n",
    "- close_diff_10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cambiaremos a mse porque no vimos mejoras relevantes en la diferencia de precio usando msle.\n",
    "\n",
    "Se ha probado en este modelado de datos con mse y no ofrece buenos resultados. Se vuelve a mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = 'mse'\n",
    "metrics = ['mse']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'close'\n",
    "\n",
    "columns_13 = ['Sup 50', 'Res 50', 'close']\n",
    "columns_14 = ['Sup 50', 'Res 50', 'close_diff_10']\n",
    "\n",
    "columns = columns_13\n",
    "num_features = len(columns)\n",
    "\n",
    "for crypto in cryptos:\n",
    "    crypto = crypto\n",
    "    execute_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'close_diff_10'\n",
    "\n",
    "columns = columns_14\n",
    "num_features = len(columns)\n",
    "\n",
    "for crypto in cryptos:\n",
    "    crypto = crypto\n",
    "    execute_test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seguiremos usando el modelado anterior"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probemos con volumen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### PERIODS ####\n",
    "prev_periods = 40\n",
    "pred_periods = 10\n",
    "\n",
    "#GRU\n",
    "model_sel = 1\n",
    "\n",
    "# Cryptos\n",
    "cryptos = ['ETH']\n",
    "\n",
    "#### NORM AND FEATURES CONFIGURATION ####\n",
    "target = 'close'\n",
    "norm_strat = 2\n",
    "\n",
    "#### COLUMNS ####\n",
    "columns_12 = ['close', 'Volume ETH']\n",
    "\n",
    "\n",
    "#### Hyper params ####\n",
    "\n",
    "#activations = ['relu', 'sigmoid', 'softmax']\n",
    "#losses = ['mse', 'binary_crossentropy', 'categorical_crossentropy']\n",
    "#metrics_opt = ['mse', 'accuracy']\n",
    "activation = 'relu'\n",
    "loss = 'msle'\n",
    "metrics = ['msle']\n",
    "initial_learning_rate = 0.01\n",
    "\n",
    "optimizer = optimizers.Adam(learning_rate=0.0005)\n",
    "\n",
    "callbacks = ['mc', 'es']\n",
    "batch_size = 32\n",
    "epochs = 70\n",
    "\n",
    "layers = 2\n",
    "neurons = [100, 50, 50]\n",
    "\n",
    "columns = columns_12\n",
    "num_features = len(columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por ultimo, antes de probar el modelo GRU haremos una ultima prueba con softmax y la operacion a realizar usando los parametros y modelado ya analizado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 70\n",
    "\n",
    "target = None\n",
    "columns_11 = ['op_buy', 'op_sell', 'op_hold'] # Usar softmax\n",
    "\n",
    "columns = columns_11\n",
    "num_features = len(columns)\n",
    "\n",
    "activation = 'softmax'\n",
    "loss = 'categorical_crossentropy'\n",
    "metrics = ['accuracy', 'categorical_crossentropy']\n",
    "\n",
    "crypto = 'ETH'\n",
    "\n",
    "split_indexes = [-7, -9, -15, -19]\n",
    "\n",
    "for split_index in split_indexes:\n",
    "    execute_test(split_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for crypto in cryptos:\n",
    "    crypto = crypto\n",
    "    execute_test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No conseguimos buenos resultados. Seguimos sin ser capaces de identificar los puntos de compra y venta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GRU\n",
    "\n",
    "Probaremos el mejor modelado e hiperparametros ya vistos pero con GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### PERIODS ####\n",
    "prev_periods = 20\n",
    "pred_periods = 20\n",
    "\n",
    "#GRU\n",
    "model_sel = 1\n",
    "\n",
    "# Cryptos\n",
    "cryptos = ['ETH', 'ADA', 'BTC', 'LNK', 'LTC']\n",
    "\n",
    "#### NORM AND FEATURES CONFIGURATION ####\n",
    "target = 'close'\n",
    "norm_strat = 2\n",
    "\n",
    "#### COLUMNS ####\n",
    "columns_12 = ['close', 'close_diff_20']\n",
    "\n",
    "\n",
    "#### Hyper params ####\n",
    "\n",
    "#activations = ['relu', 'sigmoid', 'softmax']\n",
    "#losses = ['mse', 'binary_crossentropy', 'categorical_crossentropy']\n",
    "#metrics_opt = ['mse', 'accuracy']\n",
    "activation = LeakyReLU(alpha=0.05)\n",
    "loss = 'msle'\n",
    "metrics = ['msle']\n",
    "initial_learning_rate = 0.01\n",
    "\n",
    "optimizer = optimizers.Adam(learning_rate=0.0005)\n",
    "\n",
    "callbacks = ['mc', 'es']\n",
    "batch_size = 32\n",
    "epochs = 70\n",
    "\n",
    "layers = 2\n",
    "neurons = [100, 50, 50]\n",
    "\n",
    "columns = columns_12\n",
    "num_features = len(columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading... BTC\n",
      "Extracting columns columns for BTC\n",
      "Proccessing and arranging columns for LSTM model\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>close_19</th>\n",
       "      <th>close_diff_20_19</th>\n",
       "      <th>close_18</th>\n",
       "      <th>close_diff_20_18</th>\n",
       "      <th>close_17</th>\n",
       "      <th>close_diff_20_17</th>\n",
       "      <th>close_16</th>\n",
       "      <th>close_diff_20_16</th>\n",
       "      <th>close_15</th>\n",
       "      <th>close_diff_20_15</th>\n",
       "      <th>...</th>\n",
       "      <th>close_diff_20_4</th>\n",
       "      <th>close_3</th>\n",
       "      <th>close_diff_20_3</th>\n",
       "      <th>close_2</th>\n",
       "      <th>close_diff_20_2</th>\n",
       "      <th>close_1</th>\n",
       "      <th>close_diff_20_1</th>\n",
       "      <th>close_0</th>\n",
       "      <th>close_diff_20_0</th>\n",
       "      <th>close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>16150.03</td>\n",
       "      <td>-2706.22</td>\n",
       "      <td>14902.54</td>\n",
       "      <td>-2392.66</td>\n",
       "      <td>14400.00</td>\n",
       "      <td>-2088.98</td>\n",
       "      <td>14907.09</td>\n",
       "      <td>-585.55</td>\n",
       "      <td>13238.78</td>\n",
       "      <td>-87.83</td>\n",
       "      <td>...</td>\n",
       "      <td>-3915.06</td>\n",
       "      <td>10799.18</td>\n",
       "      <td>-4120.33</td>\n",
       "      <td>11349.99</td>\n",
       "      <td>-3709.55</td>\n",
       "      <td>11175.27</td>\n",
       "      <td>-5785.12</td>\n",
       "      <td>11089.00</td>\n",
       "      <td>-5980.79</td>\n",
       "      <td>10000.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>14902.54</td>\n",
       "      <td>-2392.66</td>\n",
       "      <td>14400.00</td>\n",
       "      <td>-2088.98</td>\n",
       "      <td>14907.09</td>\n",
       "      <td>-585.55</td>\n",
       "      <td>13238.78</td>\n",
       "      <td>-87.83</td>\n",
       "      <td>13740.01</td>\n",
       "      <td>440.01</td>\n",
       "      <td>...</td>\n",
       "      <td>-4120.33</td>\n",
       "      <td>11349.99</td>\n",
       "      <td>-3709.55</td>\n",
       "      <td>11175.27</td>\n",
       "      <td>-5785.12</td>\n",
       "      <td>11089.00</td>\n",
       "      <td>-5980.79</td>\n",
       "      <td>11491.00</td>\n",
       "      <td>-4659.03</td>\n",
       "      <td>10159.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>14400.00</td>\n",
       "      <td>-2088.98</td>\n",
       "      <td>14907.09</td>\n",
       "      <td>-585.55</td>\n",
       "      <td>13238.78</td>\n",
       "      <td>-87.83</td>\n",
       "      <td>13740.01</td>\n",
       "      <td>440.01</td>\n",
       "      <td>14210.00</td>\n",
       "      <td>710.00</td>\n",
       "      <td>...</td>\n",
       "      <td>-3709.55</td>\n",
       "      <td>11175.27</td>\n",
       "      <td>-5785.12</td>\n",
       "      <td>11089.00</td>\n",
       "      <td>-5980.79</td>\n",
       "      <td>11491.00</td>\n",
       "      <td>-4659.03</td>\n",
       "      <td>11879.95</td>\n",
       "      <td>-3022.59</td>\n",
       "      <td>11039.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>14907.09</td>\n",
       "      <td>-585.55</td>\n",
       "      <td>13238.78</td>\n",
       "      <td>-87.83</td>\n",
       "      <td>13740.01</td>\n",
       "      <td>440.01</td>\n",
       "      <td>14210.00</td>\n",
       "      <td>710.00</td>\n",
       "      <td>13474.99</td>\n",
       "      <td>-224.35</td>\n",
       "      <td>...</td>\n",
       "      <td>-5785.12</td>\n",
       "      <td>11089.00</td>\n",
       "      <td>-5980.79</td>\n",
       "      <td>11491.00</td>\n",
       "      <td>-4659.03</td>\n",
       "      <td>11879.95</td>\n",
       "      <td>-3022.59</td>\n",
       "      <td>11251.00</td>\n",
       "      <td>-3149.00</td>\n",
       "      <td>10383.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>13238.78</td>\n",
       "      <td>-87.83</td>\n",
       "      <td>13740.01</td>\n",
       "      <td>440.01</td>\n",
       "      <td>14210.00</td>\n",
       "      <td>710.00</td>\n",
       "      <td>13474.99</td>\n",
       "      <td>-224.35</td>\n",
       "      <td>13539.93</td>\n",
       "      <td>-2149.08</td>\n",
       "      <td>...</td>\n",
       "      <td>-5980.79</td>\n",
       "      <td>11491.00</td>\n",
       "      <td>-4659.03</td>\n",
       "      <td>11879.95</td>\n",
       "      <td>-3022.59</td>\n",
       "      <td>11251.00</td>\n",
       "      <td>-3149.00</td>\n",
       "      <td>10237.51</td>\n",
       "      <td>-4669.58</td>\n",
       "      <td>11153.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1593</th>\n",
       "      <td>50588.95</td>\n",
       "      <td>-9755.92</td>\n",
       "      <td>50471.19</td>\n",
       "      <td>-6420.43</td>\n",
       "      <td>47545.59</td>\n",
       "      <td>-10506.65</td>\n",
       "      <td>47140.54</td>\n",
       "      <td>-12566.97</td>\n",
       "      <td>49389.99</td>\n",
       "      <td>-9232.03</td>\n",
       "      <td>...</td>\n",
       "      <td>-7892.18</td>\n",
       "      <td>50838.81</td>\n",
       "      <td>-2762.24</td>\n",
       "      <td>50820.00</td>\n",
       "      <td>1667.53</td>\n",
       "      <td>50399.66</td>\n",
       "      <td>1003.33</td>\n",
       "      <td>50775.49</td>\n",
       "      <td>333.57</td>\n",
       "      <td>43084.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1594</th>\n",
       "      <td>50471.19</td>\n",
       "      <td>-6420.43</td>\n",
       "      <td>47545.59</td>\n",
       "      <td>-10506.65</td>\n",
       "      <td>47140.54</td>\n",
       "      <td>-12566.97</td>\n",
       "      <td>49389.99</td>\n",
       "      <td>-9232.03</td>\n",
       "      <td>50053.90</td>\n",
       "      <td>-6193.28</td>\n",
       "      <td>...</td>\n",
       "      <td>-2762.24</td>\n",
       "      <td>50820.00</td>\n",
       "      <td>1667.53</td>\n",
       "      <td>50399.66</td>\n",
       "      <td>1003.33</td>\n",
       "      <td>50775.49</td>\n",
       "      <td>333.57</td>\n",
       "      <td>50701.44</td>\n",
       "      <td>112.49</td>\n",
       "      <td>43071.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1595</th>\n",
       "      <td>47545.59</td>\n",
       "      <td>-10506.65</td>\n",
       "      <td>47140.54</td>\n",
       "      <td>-12566.97</td>\n",
       "      <td>49389.99</td>\n",
       "      <td>-9232.03</td>\n",
       "      <td>50053.90</td>\n",
       "      <td>-6193.28</td>\n",
       "      <td>46702.75</td>\n",
       "      <td>-10838.52</td>\n",
       "      <td>...</td>\n",
       "      <td>1667.53</td>\n",
       "      <td>50399.66</td>\n",
       "      <td>1003.33</td>\n",
       "      <td>50775.49</td>\n",
       "      <td>333.57</td>\n",
       "      <td>50701.44</td>\n",
       "      <td>112.49</td>\n",
       "      <td>47543.74</td>\n",
       "      <td>-2927.45</td>\n",
       "      <td>42201.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1596</th>\n",
       "      <td>47140.54</td>\n",
       "      <td>-12566.97</td>\n",
       "      <td>49389.99</td>\n",
       "      <td>-9232.03</td>\n",
       "      <td>50053.90</td>\n",
       "      <td>-6193.28</td>\n",
       "      <td>46702.75</td>\n",
       "      <td>-10838.52</td>\n",
       "      <td>48343.28</td>\n",
       "      <td>-8795.01</td>\n",
       "      <td>...</td>\n",
       "      <td>1003.33</td>\n",
       "      <td>50775.49</td>\n",
       "      <td>333.57</td>\n",
       "      <td>50701.44</td>\n",
       "      <td>112.49</td>\n",
       "      <td>47543.74</td>\n",
       "      <td>-2927.45</td>\n",
       "      <td>46464.66</td>\n",
       "      <td>-1080.93</td>\n",
       "      <td>42352.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1597</th>\n",
       "      <td>49389.99</td>\n",
       "      <td>-9232.03</td>\n",
       "      <td>50053.90</td>\n",
       "      <td>-6193.28</td>\n",
       "      <td>46702.75</td>\n",
       "      <td>-10838.52</td>\n",
       "      <td>48343.28</td>\n",
       "      <td>-8795.01</td>\n",
       "      <td>48864.98</td>\n",
       "      <td>-10095.38</td>\n",
       "      <td>...</td>\n",
       "      <td>333.57</td>\n",
       "      <td>50701.44</td>\n",
       "      <td>112.49</td>\n",
       "      <td>47543.74</td>\n",
       "      <td>-2927.45</td>\n",
       "      <td>46464.66</td>\n",
       "      <td>-1080.93</td>\n",
       "      <td>47120.87</td>\n",
       "      <td>-19.67</td>\n",
       "      <td>41660.01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1435 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      close_19  close_diff_20_19  close_18  close_diff_20_18  close_17  \\\n",
       "163   16150.03          -2706.22  14902.54          -2392.66  14400.00   \n",
       "164   14902.54          -2392.66  14400.00          -2088.98  14907.09   \n",
       "165   14400.00          -2088.98  14907.09           -585.55  13238.78   \n",
       "166   14907.09           -585.55  13238.78            -87.83  13740.01   \n",
       "167   13238.78            -87.83  13740.01            440.01  14210.00   \n",
       "...        ...               ...       ...               ...       ...   \n",
       "1593  50588.95          -9755.92  50471.19          -6420.43  47545.59   \n",
       "1594  50471.19          -6420.43  47545.59         -10506.65  47140.54   \n",
       "1595  47545.59         -10506.65  47140.54         -12566.97  49389.99   \n",
       "1596  47140.54         -12566.97  49389.99          -9232.03  50053.90   \n",
       "1597  49389.99          -9232.03  50053.90          -6193.28  46702.75   \n",
       "\n",
       "      close_diff_20_17  close_16  close_diff_20_16  close_15  \\\n",
       "163           -2088.98  14907.09           -585.55  13238.78   \n",
       "164            -585.55  13238.78            -87.83  13740.01   \n",
       "165             -87.83  13740.01            440.01  14210.00   \n",
       "166             440.01  14210.00            710.00  13474.99   \n",
       "167             710.00  13474.99           -224.35  13539.93   \n",
       "...                ...       ...               ...       ...   \n",
       "1593         -10506.65  47140.54         -12566.97  49389.99   \n",
       "1594         -12566.97  49389.99          -9232.03  50053.90   \n",
       "1595          -9232.03  50053.90          -6193.28  46702.75   \n",
       "1596          -6193.28  46702.75         -10838.52  48343.28   \n",
       "1597         -10838.52  48343.28          -8795.01  48864.98   \n",
       "\n",
       "      close_diff_20_15  ...  close_diff_20_4   close_3  close_diff_20_3  \\\n",
       "163             -87.83  ...         -3915.06  10799.18         -4120.33   \n",
       "164             440.01  ...         -4120.33  11349.99         -3709.55   \n",
       "165             710.00  ...         -3709.55  11175.27         -5785.12   \n",
       "166            -224.35  ...         -5785.12  11089.00         -5980.79   \n",
       "167           -2149.08  ...         -5980.79  11491.00         -4659.03   \n",
       "...                ...  ...              ...       ...              ...   \n",
       "1593          -9232.03  ...         -7892.18  50838.81         -2762.24   \n",
       "1594          -6193.28  ...         -2762.24  50820.00          1667.53   \n",
       "1595         -10838.52  ...          1667.53  50399.66          1003.33   \n",
       "1596          -8795.01  ...          1003.33  50775.49           333.57   \n",
       "1597         -10095.38  ...           333.57  50701.44           112.49   \n",
       "\n",
       "       close_2  close_diff_20_2   close_1  close_diff_20_1   close_0  \\\n",
       "163   11349.99         -3709.55  11175.27         -5785.12  11089.00   \n",
       "164   11175.27         -5785.12  11089.00         -5980.79  11491.00   \n",
       "165   11089.00         -5980.79  11491.00         -4659.03  11879.95   \n",
       "166   11491.00         -4659.03  11879.95         -3022.59  11251.00   \n",
       "167   11879.95         -3022.59  11251.00         -3149.00  10237.51   \n",
       "...        ...              ...       ...              ...       ...   \n",
       "1593  50820.00          1667.53  50399.66          1003.33  50775.49   \n",
       "1594  50399.66          1003.33  50775.49           333.57  50701.44   \n",
       "1595  50775.49           333.57  50701.44           112.49  47543.74   \n",
       "1596  50701.44           112.49  47543.74         -2927.45  46464.66   \n",
       "1597  47543.74         -2927.45  46464.66         -1080.93  47120.87   \n",
       "\n",
       "      close_diff_20_0     close  \n",
       "163          -5980.79  10000.09  \n",
       "164          -4659.03  10159.98  \n",
       "165          -3022.59  11039.55  \n",
       "166          -3149.00  10383.43  \n",
       "167          -4669.58  11153.00  \n",
       "...               ...       ...  \n",
       "1593           333.57  43084.29  \n",
       "1594           112.49  43071.66  \n",
       "1595         -2927.45  42201.62  \n",
       "1596         -1080.93  42352.12  \n",
       "1597           -19.67  41660.01  \n",
       "\n",
       "[1435 rows x 41 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>close_19</th>\n",
       "      <th>close_diff_20_19</th>\n",
       "      <th>close_18</th>\n",
       "      <th>close_diff_20_18</th>\n",
       "      <th>close_17</th>\n",
       "      <th>close_diff_20_17</th>\n",
       "      <th>close_16</th>\n",
       "      <th>close_diff_20_16</th>\n",
       "      <th>close_15</th>\n",
       "      <th>close_diff_20_15</th>\n",
       "      <th>...</th>\n",
       "      <th>close_diff_20_4</th>\n",
       "      <th>close_3</th>\n",
       "      <th>close_diff_20_3</th>\n",
       "      <th>close_2</th>\n",
       "      <th>close_diff_20_2</th>\n",
       "      <th>close_1</th>\n",
       "      <th>close_diff_20_1</th>\n",
       "      <th>close_0</th>\n",
       "      <th>close_diff_20_0</th>\n",
       "      <th>close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1598</th>\n",
       "      <td>50053.9</td>\n",
       "      <td>-6193.28</td>\n",
       "      <td>46702.75</td>\n",
       "      <td>-10838.52</td>\n",
       "      <td>48343.28</td>\n",
       "      <td>-8795.01</td>\n",
       "      <td>48864.98</td>\n",
       "      <td>-10095.38</td>\n",
       "      <td>47632.38</td>\n",
       "      <td>-6094.15</td>\n",
       "      <td>...</td>\n",
       "      <td>112.49</td>\n",
       "      <td>47543.74</td>\n",
       "      <td>-2927.45</td>\n",
       "      <td>46464.66</td>\n",
       "      <td>-1080.93</td>\n",
       "      <td>47120.87</td>\n",
       "      <td>-19.67</td>\n",
       "      <td>46216.93</td>\n",
       "      <td>-3173.06</td>\n",
       "      <td>41761.89</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      close_19  close_diff_20_19  close_18  close_diff_20_18  close_17  \\\n",
       "1598   50053.9          -6193.28  46702.75         -10838.52  48343.28   \n",
       "\n",
       "      close_diff_20_17  close_16  close_diff_20_16  close_15  \\\n",
       "1598          -8795.01  48864.98         -10095.38  47632.38   \n",
       "\n",
       "      close_diff_20_15  ...  close_diff_20_4   close_3  close_diff_20_3  \\\n",
       "1598          -6094.15  ...           112.49  47543.74         -2927.45   \n",
       "\n",
       "       close_2  close_diff_20_2   close_1  close_diff_20_1   close_0  \\\n",
       "1598  46464.66         -1080.93  47120.87           -19.67  46216.93   \n",
       "\n",
       "      close_diff_20_0     close  \n",
       "1598         -3173.06  41761.89  \n",
       "\n",
       "[1 rows x 41 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (1435, 1, 40) (1435, 1)\n",
      "Model: \"sequential_24\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_4 (GRU)                  (None, 1, 100)            42300     \n",
      "_________________________________________________________________\n",
      "gru_5 (GRU)                  (None, 1, 50)             22650     \n",
      "_________________________________________________________________\n",
      "dropout_41 (Dropout)         (None, 1, 50)             0         \n",
      "_________________________________________________________________\n",
      "gru_6 (GRU)                  (None, 50)                15150     \n",
      "_________________________________________________________________\n",
      "dropout_42 (Dropout)         (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 1)                 51        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 80,151\n",
      "Trainable params: 80,151\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Y shape (1435, 1)\n",
      "Train on 1435 samples, validate on 287 samples\n",
      "Epoch 1/70\n",
      " - 7s - loss: 0.0125 - msle: 0.0125 - val_loss: 0.0072 - val_msle: 0.0072\n",
      "Epoch 2/70\n",
      " - 1s - loss: 0.0267 - msle: 0.0267 - val_loss: 0.0068 - val_msle: 0.0068\n",
      "Epoch 3/70\n",
      " - 1s - loss: 0.0075 - msle: 0.0075 - val_loss: 0.0068 - val_msle: 0.0068\n",
      "Epoch 4/70\n",
      " - 1s - loss: 0.0041 - msle: 0.0041 - val_loss: 0.0068 - val_msle: 0.0068\n",
      "Epoch 5/70\n",
      " - 1s - loss: 0.0044 - msle: 0.0044 - val_loss: 0.0070 - val_msle: 0.0070\n",
      "Epoch 6/70\n",
      " - 1s - loss: 0.0041 - msle: 0.0041 - val_loss: 0.0064 - val_msle: 0.0064\n",
      "Epoch 7/70\n",
      " - 1s - loss: 0.0041 - msle: 0.0041 - val_loss: 0.0064 - val_msle: 0.0064\n",
      "Epoch 8/70\n",
      " - 1s - loss: 0.0041 - msle: 0.0041 - val_loss: 0.0057 - val_msle: 0.0057\n",
      "Epoch 9/70\n",
      " - 1s - loss: 0.0039 - msle: 0.0039 - val_loss: 0.0071 - val_msle: 0.0071\n",
      "Epoch 10/70\n",
      " - 1s - loss: 0.0040 - msle: 0.0040 - val_loss: 0.0054 - val_msle: 0.0054\n",
      "Epoch 11/70\n",
      " - 1s - loss: 0.0037 - msle: 0.0037 - val_loss: 0.0062 - val_msle: 0.0062\n",
      "Epoch 12/70\n",
      " - 1s - loss: 0.0038 - msle: 0.0038 - val_loss: 0.0059 - val_msle: 0.0059\n",
      "Epoch 13/70\n",
      " - 1s - loss: 0.0037 - msle: 0.0037 - val_loss: 0.0053 - val_msle: 0.0053\n",
      "Epoch 14/70\n",
      " - 2s - loss: 0.0039 - msle: 0.0039 - val_loss: 0.0058 - val_msle: 0.0058\n",
      "Epoch 15/70\n",
      " - 2s - loss: 0.0036 - msle: 0.0036 - val_loss: 0.0057 - val_msle: 0.0057\n",
      "Epoch 16/70\n",
      " - 1s - loss: 0.0037 - msle: 0.0037 - val_loss: 0.0056 - val_msle: 0.0056\n",
      "Epoch 17/70\n",
      " - 1s - loss: 0.0037 - msle: 0.0037 - val_loss: 0.0049 - val_msle: 0.0049\n",
      "Epoch 18/70\n",
      " - 1s - loss: 0.0033 - msle: 0.0033 - val_loss: 0.0054 - val_msle: 0.0054\n",
      "Epoch 19/70\n",
      " - 1s - loss: 0.0035 - msle: 0.0035 - val_loss: 0.0049 - val_msle: 0.0049\n",
      "Epoch 20/70\n",
      " - 1s - loss: 0.0035 - msle: 0.0035 - val_loss: 0.0056 - val_msle: 0.0056\n",
      "Epoch 21/70\n",
      " - 1s - loss: 0.0035 - msle: 0.0035 - val_loss: 0.0046 - val_msle: 0.0046\n",
      "Epoch 22/70\n",
      " - 1s - loss: 0.0032 - msle: 0.0032 - val_loss: 0.0050 - val_msle: 0.0050\n",
      "Epoch 23/70\n",
      " - 1s - loss: 0.0032 - msle: 0.0032 - val_loss: 0.0052 - val_msle: 0.0052\n",
      "Epoch 24/70\n",
      " - 1s - loss: 0.0032 - msle: 0.0032 - val_loss: 0.0046 - val_msle: 0.0046\n",
      "Epoch 25/70\n",
      " - 1s - loss: 0.0029 - msle: 0.0029 - val_loss: 0.0043 - val_msle: 0.0043\n",
      "Epoch 26/70\n",
      " - 1s - loss: 0.0031 - msle: 0.0031 - val_loss: 0.0050 - val_msle: 0.0050\n",
      "Epoch 27/70\n",
      " - 1s - loss: 0.0030 - msle: 0.0030 - val_loss: 0.0047 - val_msle: 0.0047\n",
      "Epoch 28/70\n",
      " - 1s - loss: 0.0028 - msle: 0.0028 - val_loss: 0.0048 - val_msle: 0.0048\n",
      "Epoch 29/70\n",
      " - 1s - loss: 0.0028 - msle: 0.0028 - val_loss: 0.0041 - val_msle: 0.0041\n",
      "Epoch 30/70\n",
      " - 1s - loss: 0.0027 - msle: 0.0027 - val_loss: 0.0043 - val_msle: 0.0043\n",
      "Epoch 31/70\n",
      " - 1s - loss: 0.0028 - msle: 0.0028 - val_loss: 0.0046 - val_msle: 0.0046\n",
      "Epoch 32/70\n",
      " - 1s - loss: 0.0030 - msle: 0.0030 - val_loss: 0.0048 - val_msle: 0.0048\n",
      "Epoch 33/70\n",
      " - 1s - loss: 0.0031 - msle: 0.0031 - val_loss: 0.0041 - val_msle: 0.0041\n",
      "Epoch 34/70\n",
      " - 1s - loss: 0.0028 - msle: 0.0028 - val_loss: 0.0040 - val_msle: 0.0040\n",
      "Epoch 35/70\n",
      " - 1s - loss: 0.0027 - msle: 0.0027 - val_loss: 0.0040 - val_msle: 0.0040\n",
      "Epoch 36/70\n",
      " - 1s - loss: 0.0025 - msle: 0.0025 - val_loss: 0.0040 - val_msle: 0.0040\n",
      "Epoch 37/70\n",
      " - 1s - loss: 0.0025 - msle: 0.0025 - val_loss: 0.0039 - val_msle: 0.0039\n",
      "Epoch 38/70\n",
      " - 1s - loss: 0.0024 - msle: 0.0024 - val_loss: 0.0040 - val_msle: 0.0040\n",
      "Epoch 39/70\n",
      " - 1s - loss: 0.0028 - msle: 0.0028 - val_loss: 0.0039 - val_msle: 0.0039\n",
      "Epoch 40/70\n",
      " - 1s - loss: 0.0028 - msle: 0.0028 - val_loss: 0.0041 - val_msle: 0.0041\n",
      "Epoch 41/70\n",
      " - 1s - loss: 0.0028 - msle: 0.0028 - val_loss: 0.0039 - val_msle: 0.0039\n",
      "Epoch 42/70\n",
      " - 1s - loss: 0.0027 - msle: 0.0027 - val_loss: 0.0042 - val_msle: 0.0042\n",
      "Epoch 43/70\n",
      " - 1s - loss: 0.0029 - msle: 0.0029 - val_loss: 0.0039 - val_msle: 0.0039\n",
      "Epoch 44/70\n",
      " - 1s - loss: 0.0028 - msle: 0.0028 - val_loss: 0.0040 - val_msle: 0.0040\n",
      "Epoch 45/70\n",
      " - 1s - loss: 0.0025 - msle: 0.0025 - val_loss: 0.0040 - val_msle: 0.0040\n",
      "Epoch 46/70\n",
      " - 1s - loss: 0.0027 - msle: 0.0027 - val_loss: 0.0040 - val_msle: 0.0040\n",
      "Epoch 47/70\n",
      " - 1s - loss: 0.0025 - msle: 0.0025 - val_loss: 0.0040 - val_msle: 0.0040\n",
      "Epoch 48/70\n",
      " - 1s - loss: 0.0027 - msle: 0.0027 - val_loss: 0.0038 - val_msle: 0.0038\n",
      "Epoch 49/70\n",
      " - 1s - loss: 0.0026 - msle: 0.0026 - val_loss: 0.0038 - val_msle: 0.0038\n",
      "Epoch 50/70\n",
      " - 1s - loss: 0.0024 - msle: 0.0024 - val_loss: 0.0040 - val_msle: 0.0040\n",
      "Epoch 51/70\n",
      " - 1s - loss: 0.0024 - msle: 0.0024 - val_loss: 0.0038 - val_msle: 0.0038\n",
      "Epoch 52/70\n",
      " - 1s - loss: 0.0025 - msle: 0.0025 - val_loss: 0.0038 - val_msle: 0.0038\n",
      "Epoch 53/70\n",
      " - 1s - loss: 0.0025 - msle: 0.0025 - val_loss: 0.0039 - val_msle: 0.0039\n",
      "Epoch 54/70\n",
      " - 1s - loss: 0.0025 - msle: 0.0025 - val_loss: 0.0039 - val_msle: 0.0039\n",
      "Epoch 55/70\n",
      " - 1s - loss: 0.0026 - msle: 0.0026 - val_loss: 0.0042 - val_msle: 0.0042\n",
      "Epoch 56/70\n",
      " - 1s - loss: 0.0028 - msle: 0.0028 - val_loss: 0.0046 - val_msle: 0.0046\n",
      "Epoch 57/70\n",
      " - 1s - loss: 0.0027 - msle: 0.0027 - val_loss: 0.0039 - val_msle: 0.0039\n",
      "Epoch 58/70\n",
      " - 1s - loss: 0.0027 - msle: 0.0027 - val_loss: 0.0038 - val_msle: 0.0038\n",
      "Epoch 59/70\n",
      " - 1s - loss: 0.0025 - msle: 0.0025 - val_loss: 0.0038 - val_msle: 0.0038\n",
      "Epoch 60/70\n",
      " - 1s - loss: 0.0024 - msle: 0.0024 - val_loss: 0.0037 - val_msle: 0.0037\n",
      "Epoch 61/70\n",
      " - 1s - loss: 0.0024 - msle: 0.0024 - val_loss: 0.0037 - val_msle: 0.0037\n",
      "Epoch 62/70\n",
      " - 1s - loss: 0.0025 - msle: 0.0025 - val_loss: 0.0039 - val_msle: 0.0039\n",
      "Epoch 63/70\n",
      " - 1s - loss: 0.0024 - msle: 0.0024 - val_loss: 0.0041 - val_msle: 0.0041\n",
      "Epoch 64/70\n",
      " - 1s - loss: 0.0023 - msle: 0.0023 - val_loss: 0.0038 - val_msle: 0.0038\n",
      "Epoch 65/70\n",
      " - 1s - loss: 0.0025 - msle: 0.0025 - val_loss: 0.0040 - val_msle: 0.0040\n",
      "Epoch 66/70\n",
      " - 1s - loss: 0.0023 - msle: 0.0023 - val_loss: 0.0038 - val_msle: 0.0038\n",
      "Epoch 67/70\n",
      " - 1s - loss: 0.0022 - msle: 0.0022 - val_loss: 0.0038 - val_msle: 0.0038\n",
      "Epoch 68/70\n",
      " - 1s - loss: 0.0022 - msle: 0.0022 - val_loss: 0.0038 - val_msle: 0.0038\n",
      "Epoch 69/70\n",
      " - 1s - loss: 0.0021 - msle: 0.0021 - val_loss: 0.0039 - val_msle: 0.0039\n",
      "Epoch 70/70\n",
      " - 1s - loss: 0.0025 - msle: 0.0025 - val_loss: 0.0038 - val_msle: 0.0038\n",
      "real [[41761.89]]\n",
      "Test RMSE: 3712.101\n",
      "Diff [[-3712.1012853]]\n",
      "% Diff [[-8.88872914]] %\n",
      "Predictions [[45473.9912853]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "crypto = crypto\n",
    "execute_test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Final models to use\n",
    "\n",
    "Despues de todo el analisis usaremos este diccionario de parametros para nuestros modelos. Bajamos aun mas los dias a predecir y los dias previos usados para mayor precisión y rapidez de entrenamiento.\n",
    "\n",
    "Se ha observaod ademas estancamientos en algunos entrenamiento y para evitarlo hemos cambiado de msle a mse\n",
    "\n",
    "Se ha probado con diferentes funciones de lr scheduler por no solucionaba el problema.\n",
    "\n",
    "Otra solucion es obtener mas datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### PERIODS ####\n",
    "prev_periods = 40\n",
    "pred_periods = 5\n",
    "\n",
    "#LSTM\n",
    "model_sel = 1\n",
    "\n",
    "# Cryptos\n",
    "cryptos = ['ETH', 'ADA', 'BTC', 'LNK', 'LTC']\n",
    "\n",
    "#### NORM AND FEATURES CONFIGURATION ####\n",
    "target = 'close'\n",
    "norm_strat = 2\n",
    "\n",
    "#### Hyper params ####\n",
    "activation = LeakyReLU(alpha=0.05)\n",
    "loss = 'msle'\n",
    "metrics = ['msle']\n",
    "initial_learning_rate = 0.01\n",
    "\n",
    "optimizer = optimizers.Adam(learning_rate=0.0005)\n",
    "\n",
    "callbacks = ['mc', 'es']\n",
    "batch_size = 16\n",
    "epochs = 70\n",
    "\n",
    "layers = 2\n",
    "neurons = [100, 50, 50]\n",
    "\n",
    "columns = ['RSI', 'ADX', 'close']\n",
    "num_features = len(columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading... BTC\n",
      "Extracting columns columns for BTC\n",
      "Proccessing and arranging columns for LSTM model\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>close_39</th>\n",
       "      <th>ADX_39</th>\n",
       "      <th>RSI_39</th>\n",
       "      <th>close_38</th>\n",
       "      <th>ADX_38</th>\n",
       "      <th>RSI_38</th>\n",
       "      <th>close_37</th>\n",
       "      <th>ADX_37</th>\n",
       "      <th>RSI_37</th>\n",
       "      <th>close_36</th>\n",
       "      <th>...</th>\n",
       "      <th>close_2</th>\n",
       "      <th>ADX_2</th>\n",
       "      <th>RSI_2</th>\n",
       "      <th>close_1</th>\n",
       "      <th>ADX_1</th>\n",
       "      <th>RSI_1</th>\n",
       "      <th>close_0</th>\n",
       "      <th>ADX_0</th>\n",
       "      <th>RSI_0</th>\n",
       "      <th>close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>13380.00</td>\n",
       "      <td>55.667336</td>\n",
       "      <td>33.988305</td>\n",
       "      <td>14675.11</td>\n",
       "      <td>54.588856</td>\n",
       "      <td>43.409602</td>\n",
       "      <td>14919.51</td>\n",
       "      <td>44.541440</td>\n",
       "      <td>45.004726</td>\n",
       "      <td>15059.54</td>\n",
       "      <td>...</td>\n",
       "      <td>7599.00</td>\n",
       "      <td>50.304212</td>\n",
       "      <td>31.164405</td>\n",
       "      <td>7784.02</td>\n",
       "      <td>50.571974</td>\n",
       "      <td>32.713437</td>\n",
       "      <td>8683.92</td>\n",
       "      <td>50.731941</td>\n",
       "      <td>39.808302</td>\n",
       "      <td>9449.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>14675.11</td>\n",
       "      <td>54.588856</td>\n",
       "      <td>43.409602</td>\n",
       "      <td>14919.51</td>\n",
       "      <td>44.541440</td>\n",
       "      <td>45.004726</td>\n",
       "      <td>15059.54</td>\n",
       "      <td>39.574604</td>\n",
       "      <td>45.944867</td>\n",
       "      <td>16960.39</td>\n",
       "      <td>...</td>\n",
       "      <td>7784.02</td>\n",
       "      <td>50.571974</td>\n",
       "      <td>32.713437</td>\n",
       "      <td>8683.92</td>\n",
       "      <td>50.731941</td>\n",
       "      <td>39.808302</td>\n",
       "      <td>8533.98</td>\n",
       "      <td>49.729774</td>\n",
       "      <td>39.069110</td>\n",
       "      <td>10000.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>14919.51</td>\n",
       "      <td>44.541440</td>\n",
       "      <td>45.004726</td>\n",
       "      <td>15059.54</td>\n",
       "      <td>39.574604</td>\n",
       "      <td>45.944867</td>\n",
       "      <td>16960.39</td>\n",
       "      <td>36.632306</td>\n",
       "      <td>56.752693</td>\n",
       "      <td>17069.79</td>\n",
       "      <td>...</td>\n",
       "      <td>8683.92</td>\n",
       "      <td>50.731941</td>\n",
       "      <td>39.808302</td>\n",
       "      <td>8533.98</td>\n",
       "      <td>49.729774</td>\n",
       "      <td>39.069110</td>\n",
       "      <td>8063.88</td>\n",
       "      <td>48.444698</td>\n",
       "      <td>36.764139</td>\n",
       "      <td>10159.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>15059.54</td>\n",
       "      <td>39.574604</td>\n",
       "      <td>45.944867</td>\n",
       "      <td>16960.39</td>\n",
       "      <td>36.632306</td>\n",
       "      <td>56.752693</td>\n",
       "      <td>17069.79</td>\n",
       "      <td>29.774929</td>\n",
       "      <td>57.282071</td>\n",
       "      <td>16150.03</td>\n",
       "      <td>...</td>\n",
       "      <td>8533.98</td>\n",
       "      <td>49.729774</td>\n",
       "      <td>39.069110</td>\n",
       "      <td>8063.88</td>\n",
       "      <td>48.444698</td>\n",
       "      <td>36.764139</td>\n",
       "      <td>8903.00</td>\n",
       "      <td>47.447901</td>\n",
       "      <td>43.205221</td>\n",
       "      <td>11039.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>16960.39</td>\n",
       "      <td>36.632306</td>\n",
       "      <td>56.752693</td>\n",
       "      <td>17069.79</td>\n",
       "      <td>29.774929</td>\n",
       "      <td>57.282071</td>\n",
       "      <td>16150.03</td>\n",
       "      <td>24.962937</td>\n",
       "      <td>51.567014</td>\n",
       "      <td>14902.54</td>\n",
       "      <td>...</td>\n",
       "      <td>8063.88</td>\n",
       "      <td>48.444698</td>\n",
       "      <td>36.764139</td>\n",
       "      <td>8903.00</td>\n",
       "      <td>47.447901</td>\n",
       "      <td>43.205221</td>\n",
       "      <td>8539.90</td>\n",
       "      <td>46.009643</td>\n",
       "      <td>41.247375</td>\n",
       "      <td>10383.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1608</th>\n",
       "      <td>56480.34</td>\n",
       "      <td>20.055789</td>\n",
       "      <td>44.283082</td>\n",
       "      <td>53601.05</td>\n",
       "      <td>19.681954</td>\n",
       "      <td>38.415831</td>\n",
       "      <td>49152.47</td>\n",
       "      <td>20.522635</td>\n",
       "      <td>31.476679</td>\n",
       "      <td>49396.33</td>\n",
       "      <td>...</td>\n",
       "      <td>41679.74</td>\n",
       "      <td>34.682549</td>\n",
       "      <td>29.550724</td>\n",
       "      <td>41864.62</td>\n",
       "      <td>36.062684</td>\n",
       "      <td>30.496427</td>\n",
       "      <td>41822.49</td>\n",
       "      <td>37.005191</td>\n",
       "      <td>30.396292</td>\n",
       "      <td>43084.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1609</th>\n",
       "      <td>53601.05</td>\n",
       "      <td>19.681954</td>\n",
       "      <td>38.415831</td>\n",
       "      <td>49152.47</td>\n",
       "      <td>20.522635</td>\n",
       "      <td>31.476679</td>\n",
       "      <td>49396.33</td>\n",
       "      <td>22.878406</td>\n",
       "      <td>32.199668</td>\n",
       "      <td>50441.92</td>\n",
       "      <td>...</td>\n",
       "      <td>41864.62</td>\n",
       "      <td>36.062684</td>\n",
       "      <td>30.496427</td>\n",
       "      <td>41822.49</td>\n",
       "      <td>37.005191</td>\n",
       "      <td>30.396292</td>\n",
       "      <td>42729.29</td>\n",
       "      <td>38.204257</td>\n",
       "      <td>35.319142</td>\n",
       "      <td>43071.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1610</th>\n",
       "      <td>49152.47</td>\n",
       "      <td>20.522635</td>\n",
       "      <td>31.476679</td>\n",
       "      <td>49396.33</td>\n",
       "      <td>22.878406</td>\n",
       "      <td>32.199668</td>\n",
       "      <td>50441.92</td>\n",
       "      <td>25.036301</td>\n",
       "      <td>35.349386</td>\n",
       "      <td>50588.95</td>\n",
       "      <td>...</td>\n",
       "      <td>41822.49</td>\n",
       "      <td>37.005191</td>\n",
       "      <td>30.396292</td>\n",
       "      <td>42729.29</td>\n",
       "      <td>38.204257</td>\n",
       "      <td>35.319142</td>\n",
       "      <td>43902.66</td>\n",
       "      <td>38.629996</td>\n",
       "      <td>41.122043</td>\n",
       "      <td>42201.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1611</th>\n",
       "      <td>49396.33</td>\n",
       "      <td>22.878406</td>\n",
       "      <td>32.199668</td>\n",
       "      <td>50441.92</td>\n",
       "      <td>25.036301</td>\n",
       "      <td>35.349386</td>\n",
       "      <td>50588.95</td>\n",
       "      <td>26.624459</td>\n",
       "      <td>35.801031</td>\n",
       "      <td>50471.19</td>\n",
       "      <td>...</td>\n",
       "      <td>42729.29</td>\n",
       "      <td>38.204257</td>\n",
       "      <td>35.319142</td>\n",
       "      <td>43902.66</td>\n",
       "      <td>38.629996</td>\n",
       "      <td>41.122043</td>\n",
       "      <td>42560.11</td>\n",
       "      <td>38.192198</td>\n",
       "      <td>37.028616</td>\n",
       "      <td>42352.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1612</th>\n",
       "      <td>50441.92</td>\n",
       "      <td>25.036301</td>\n",
       "      <td>35.349386</td>\n",
       "      <td>50588.95</td>\n",
       "      <td>26.624459</td>\n",
       "      <td>35.801031</td>\n",
       "      <td>50471.19</td>\n",
       "      <td>27.717067</td>\n",
       "      <td>35.586600</td>\n",
       "      <td>47545.59</td>\n",
       "      <td>...</td>\n",
       "      <td>43902.66</td>\n",
       "      <td>38.629996</td>\n",
       "      <td>41.122043</td>\n",
       "      <td>42560.11</td>\n",
       "      <td>38.192198</td>\n",
       "      <td>37.028616</td>\n",
       "      <td>43059.96</td>\n",
       "      <td>37.731310</td>\n",
       "      <td>39.445484</td>\n",
       "      <td>41660.01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1436 rows × 121 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      close_39     ADX_39     RSI_39  close_38     ADX_38     RSI_38  \\\n",
       "177   13380.00  55.667336  33.988305  14675.11  54.588856  43.409602   \n",
       "178   14675.11  54.588856  43.409602  14919.51  44.541440  45.004726   \n",
       "179   14919.51  44.541440  45.004726  15059.54  39.574604  45.944867   \n",
       "180   15059.54  39.574604  45.944867  16960.39  36.632306  56.752693   \n",
       "181   16960.39  36.632306  56.752693  17069.79  29.774929  57.282071   \n",
       "...        ...        ...        ...       ...        ...        ...   \n",
       "1608  56480.34  20.055789  44.283082  53601.05  19.681954  38.415831   \n",
       "1609  53601.05  19.681954  38.415831  49152.47  20.522635  31.476679   \n",
       "1610  49152.47  20.522635  31.476679  49396.33  22.878406  32.199668   \n",
       "1611  49396.33  22.878406  32.199668  50441.92  25.036301  35.349386   \n",
       "1612  50441.92  25.036301  35.349386  50588.95  26.624459  35.801031   \n",
       "\n",
       "      close_37     ADX_37     RSI_37  close_36  ...   close_2      ADX_2  \\\n",
       "177   14919.51  44.541440  45.004726  15059.54  ...   7599.00  50.304212   \n",
       "178   15059.54  39.574604  45.944867  16960.39  ...   7784.02  50.571974   \n",
       "179   16960.39  36.632306  56.752693  17069.79  ...   8683.92  50.731941   \n",
       "180   17069.79  29.774929  57.282071  16150.03  ...   8533.98  49.729774   \n",
       "181   16150.03  24.962937  51.567014  14902.54  ...   8063.88  48.444698   \n",
       "...        ...        ...        ...       ...  ...       ...        ...   \n",
       "1608  49152.47  20.522635  31.476679  49396.33  ...  41679.74  34.682549   \n",
       "1609  49396.33  22.878406  32.199668  50441.92  ...  41864.62  36.062684   \n",
       "1610  50441.92  25.036301  35.349386  50588.95  ...  41822.49  37.005191   \n",
       "1611  50588.95  26.624459  35.801031  50471.19  ...  42729.29  38.204257   \n",
       "1612  50471.19  27.717067  35.586600  47545.59  ...  43902.66  38.629996   \n",
       "\n",
       "          RSI_2   close_1      ADX_1      RSI_1   close_0      ADX_0  \\\n",
       "177   31.164405   7784.02  50.571974  32.713437   8683.92  50.731941   \n",
       "178   32.713437   8683.92  50.731941  39.808302   8533.98  49.729774   \n",
       "179   39.808302   8533.98  49.729774  39.069110   8063.88  48.444698   \n",
       "180   39.069110   8063.88  48.444698  36.764139   8903.00  47.447901   \n",
       "181   36.764139   8903.00  47.447901  43.205221   8539.90  46.009643   \n",
       "...         ...       ...        ...        ...       ...        ...   \n",
       "1608  29.550724  41864.62  36.062684  30.496427  41822.49  37.005191   \n",
       "1609  30.496427  41822.49  37.005191  30.396292  42729.29  38.204257   \n",
       "1610  30.396292  42729.29  38.204257  35.319142  43902.66  38.629996   \n",
       "1611  35.319142  43902.66  38.629996  41.122043  42560.11  38.192198   \n",
       "1612  41.122043  42560.11  38.192198  37.028616  43059.96  37.731310   \n",
       "\n",
       "          RSI_0     close  \n",
       "177   39.808302   9449.99  \n",
       "178   39.069110  10000.09  \n",
       "179   36.764139  10159.98  \n",
       "180   43.205221  11039.55  \n",
       "181   41.247375  10383.43  \n",
       "...         ...       ...  \n",
       "1608  30.396292  43084.29  \n",
       "1609  35.319142  43071.66  \n",
       "1610  41.122043  42201.62  \n",
       "1611  37.028616  42352.12  \n",
       "1612  39.445484  41660.01  \n",
       "\n",
       "[1436 rows x 121 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>close_39</th>\n",
       "      <th>ADX_39</th>\n",
       "      <th>RSI_39</th>\n",
       "      <th>close_38</th>\n",
       "      <th>ADX_38</th>\n",
       "      <th>RSI_38</th>\n",
       "      <th>close_37</th>\n",
       "      <th>ADX_37</th>\n",
       "      <th>RSI_37</th>\n",
       "      <th>close_36</th>\n",
       "      <th>...</th>\n",
       "      <th>close_2</th>\n",
       "      <th>ADX_2</th>\n",
       "      <th>RSI_2</th>\n",
       "      <th>close_1</th>\n",
       "      <th>ADX_1</th>\n",
       "      <th>RSI_1</th>\n",
       "      <th>close_0</th>\n",
       "      <th>ADX_0</th>\n",
       "      <th>RSI_0</th>\n",
       "      <th>close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1613</th>\n",
       "      <td>50588.95</td>\n",
       "      <td>26.624459</td>\n",
       "      <td>35.801031</td>\n",
       "      <td>50471.19</td>\n",
       "      <td>27.717067</td>\n",
       "      <td>35.5866</td>\n",
       "      <td>47545.59</td>\n",
       "      <td>28.966559</td>\n",
       "      <td>30.671535</td>\n",
       "      <td>47140.54</td>\n",
       "      <td>...</td>\n",
       "      <td>42560.11</td>\n",
       "      <td>38.192198</td>\n",
       "      <td>37.028616</td>\n",
       "      <td>43059.96</td>\n",
       "      <td>37.73131</td>\n",
       "      <td>39.445484</td>\n",
       "      <td>43084.29</td>\n",
       "      <td>37.486625</td>\n",
       "      <td>39.567066</td>\n",
       "      <td>41761.89</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 121 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      close_39     ADX_39     RSI_39  close_38     ADX_38   RSI_38  close_37  \\\n",
       "1613  50588.95  26.624459  35.801031  50471.19  27.717067  35.5866  47545.59   \n",
       "\n",
       "         ADX_37     RSI_37  close_36  ...   close_2      ADX_2      RSI_2  \\\n",
       "1613  28.966559  30.671535  47140.54  ...  42560.11  38.192198  37.028616   \n",
       "\n",
       "       close_1     ADX_1      RSI_1   close_0      ADX_0      RSI_0     close  \n",
       "1613  43059.96  37.73131  39.445484  43084.29  37.486625  39.567066  41761.89  \n",
       "\n",
       "[1 rows x 121 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (1436, 1, 120) (1436, 1)\n",
      "Model: \"sequential_28\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_14 (GRU)                 (None, 1, 100)            66300     \n",
      "_________________________________________________________________\n",
      "gru_15 (GRU)                 (None, 1, 50)             22650     \n",
      "_________________________________________________________________\n",
      "dropout_47 (Dropout)         (None, 1, 50)             0         \n",
      "_________________________________________________________________\n",
      "gru_16 (GRU)                 (None, 50)                15150     \n",
      "_________________________________________________________________\n",
      "dropout_48 (Dropout)         (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 1)                 51        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 104,151\n",
      "Trainable params: 104,151\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Y shape (1436, 1)\n",
      "Train on 1436 samples, validate on 288 samples\n",
      "Epoch 1/70\n",
      " - 8s - loss: 0.0096 - msle: 0.0096 - val_loss: 0.0052 - val_msle: 0.0052\n",
      "Epoch 2/70\n",
      " - 1s - loss: 0.0487 - msle: 0.0487 - val_loss: 0.0162 - val_msle: 0.0162\n",
      "Epoch 3/70\n",
      " - 1s - loss: 0.0284 - msle: 0.0284 - val_loss: 0.0113 - val_msle: 0.0113\n",
      "Epoch 4/70\n",
      " - 1s - loss: 0.0050 - msle: 0.0050 - val_loss: 0.0047 - val_msle: 0.0047\n",
      "Epoch 5/70\n",
      " - 2s - loss: 0.0063 - msle: 0.0063 - val_loss: 0.0054 - val_msle: 0.0054\n",
      "Epoch 6/70\n",
      " - 2s - loss: 0.0070 - msle: 0.0070 - val_loss: 0.0046 - val_msle: 0.0046\n",
      "Epoch 7/70\n",
      " - 4s - loss: 0.0068 - msle: 0.0068 - val_loss: 0.0045 - val_msle: 0.0045\n",
      "Epoch 8/70\n",
      " - 3s - loss: 0.0069 - msle: 0.0069 - val_loss: 0.0046 - val_msle: 0.0046\n",
      "Epoch 9/70\n",
      " - 2s - loss: 0.0061 - msle: 0.0061 - val_loss: 0.0041 - val_msle: 0.0041\n",
      "Epoch 10/70\n",
      " - 2s - loss: 0.0054 - msle: 0.0054 - val_loss: 0.0045 - val_msle: 0.0045\n",
      "Epoch 11/70\n",
      " - 1s - loss: 0.0047 - msle: 0.0047 - val_loss: 0.0038 - val_msle: 0.0038\n",
      "Epoch 12/70\n",
      " - 1s - loss: 0.0042 - msle: 0.0042 - val_loss: 0.0034 - val_msle: 0.0034\n",
      "Epoch 13/70\n",
      " - 1s - loss: 0.0037 - msle: 0.0037 - val_loss: 0.0037 - val_msle: 0.0037\n",
      "Epoch 14/70\n",
      " - 1s - loss: 0.0029 - msle: 0.0029 - val_loss: 0.0037 - val_msle: 0.0037\n",
      "Epoch 15/70\n",
      " - 1s - loss: 0.0024 - msle: 0.0024 - val_loss: 0.0030 - val_msle: 0.0030\n",
      "Epoch 16/70\n",
      " - 1s - loss: 0.0022 - msle: 0.0022 - val_loss: 0.0030 - val_msle: 0.0030\n",
      "Epoch 17/70\n",
      " - 1s - loss: 0.0022 - msle: 0.0022 - val_loss: 0.0034 - val_msle: 0.0034\n",
      "Epoch 18/70\n",
      " - 1s - loss: 0.0023 - msle: 0.0023 - val_loss: 0.0032 - val_msle: 0.0032\n",
      "Epoch 19/70\n",
      " - 1s - loss: 0.0025 - msle: 0.0025 - val_loss: 0.0032 - val_msle: 0.0032\n",
      "Epoch 20/70\n",
      " - 2s - loss: 0.0025 - msle: 0.0025 - val_loss: 0.0042 - val_msle: 0.0042\n",
      "Epoch 21/70\n",
      " - 1s - loss: 0.0030 - msle: 0.0030 - val_loss: 0.0033 - val_msle: 0.0033\n",
      "Epoch 22/70\n",
      " - 1s - loss: 0.0023 - msle: 0.0023 - val_loss: 0.0029 - val_msle: 0.0029\n",
      "Epoch 23/70\n",
      " - 1s - loss: 0.0023 - msle: 0.0023 - val_loss: 0.0031 - val_msle: 0.0031\n",
      "Epoch 24/70\n",
      " - 1s - loss: 0.0025 - msle: 0.0025 - val_loss: 0.0031 - val_msle: 0.0031\n",
      "Epoch 25/70\n",
      " - 1s - loss: 0.0020 - msle: 0.0020 - val_loss: 0.0033 - val_msle: 0.0033\n",
      "Epoch 26/70\n",
      " - 1s - loss: 0.0022 - msle: 0.0022 - val_loss: 0.0032 - val_msle: 0.0032\n",
      "Epoch 27/70\n",
      " - 1s - loss: 0.0022 - msle: 0.0022 - val_loss: 0.0026 - val_msle: 0.0026\n",
      "Epoch 28/70\n",
      " - 1s - loss: 0.0020 - msle: 0.0020 - val_loss: 0.0029 - val_msle: 0.0029\n",
      "Epoch 29/70\n",
      " - 1s - loss: 0.0021 - msle: 0.0021 - val_loss: 0.0028 - val_msle: 0.0028\n",
      "Epoch 30/70\n",
      " - 1s - loss: 0.0022 - msle: 0.0022 - val_loss: 0.0028 - val_msle: 0.0028\n",
      "Epoch 31/70\n",
      " - 1s - loss: 0.0021 - msle: 0.0021 - val_loss: 0.0027 - val_msle: 0.0027\n",
      "Epoch 32/70\n",
      " - 1s - loss: 0.0020 - msle: 0.0020 - val_loss: 0.0027 - val_msle: 0.0027\n",
      "Epoch 33/70\n",
      " - 1s - loss: 0.0018 - msle: 0.0018 - val_loss: 0.0028 - val_msle: 0.0028\n",
      "Epoch 34/70\n",
      " - 2s - loss: 0.0020 - msle: 0.0020 - val_loss: 0.0029 - val_msle: 0.0029\n",
      "Epoch 35/70\n",
      " - 1s - loss: 0.0021 - msle: 0.0021 - val_loss: 0.0030 - val_msle: 0.0030\n",
      "Epoch 36/70\n",
      " - 3s - loss: 0.0021 - msle: 0.0021 - val_loss: 0.0030 - val_msle: 0.0030\n",
      "Epoch 37/70\n",
      " - 2s - loss: 0.0022 - msle: 0.0022 - val_loss: 0.0032 - val_msle: 0.0032\n",
      "Epoch 38/70\n",
      " - 1s - loss: 0.0023 - msle: 0.0023 - val_loss: 0.0028 - val_msle: 0.0028\n",
      "Epoch 39/70\n",
      " - 1s - loss: 0.0021 - msle: 0.0021 - val_loss: 0.0028 - val_msle: 0.0028\n",
      "Epoch 40/70\n",
      " - 2s - loss: 0.0021 - msle: 0.0021 - val_loss: 0.0026 - val_msle: 0.0026\n",
      "Epoch 41/70\n",
      " - 2s - loss: 0.0019 - msle: 0.0019 - val_loss: 0.0024 - val_msle: 0.0024\n",
      "Epoch 42/70\n",
      " - 2s - loss: 0.0017 - msle: 0.0017 - val_loss: 0.0022 - val_msle: 0.0022\n",
      "Epoch 43/70\n",
      " - 1s - loss: 0.0016 - msle: 0.0016 - val_loss: 0.0027 - val_msle: 0.0027\n",
      "Epoch 44/70\n",
      " - 1s - loss: 0.0021 - msle: 0.0021 - val_loss: 0.0026 - val_msle: 0.0026\n",
      "Epoch 45/70\n",
      " - 1s - loss: 0.0020 - msle: 0.0020 - val_loss: 0.0025 - val_msle: 0.0025\n",
      "Epoch 46/70\n",
      " - 2s - loss: 0.0021 - msle: 0.0021 - val_loss: 0.0025 - val_msle: 0.0025\n",
      "Epoch 47/70\n",
      " - 2s - loss: 0.0019 - msle: 0.0019 - val_loss: 0.0023 - val_msle: 0.0023\n",
      "Epoch 48/70\n",
      " - 2s - loss: 0.0019 - msle: 0.0019 - val_loss: 0.0022 - val_msle: 0.0022\n",
      "Epoch 49/70\n",
      " - 2s - loss: 0.0018 - msle: 0.0018 - val_loss: 0.0023 - val_msle: 0.0023\n",
      "Epoch 50/70\n",
      " - 2s - loss: 0.0019 - msle: 0.0019 - val_loss: 0.0021 - val_msle: 0.0021\n",
      "Epoch 51/70\n",
      " - 1s - loss: 0.0019 - msle: 0.0019 - val_loss: 0.0021 - val_msle: 0.0021\n",
      "Epoch 52/70\n",
      " - 1s - loss: 0.0020 - msle: 0.0020 - val_loss: 0.0022 - val_msle: 0.0022\n",
      "Epoch 53/70\n",
      " - 1s - loss: 0.0019 - msle: 0.0019 - val_loss: 0.0021 - val_msle: 0.0021\n",
      "Epoch 54/70\n",
      " - 1s - loss: 0.0016 - msle: 0.0016 - val_loss: 0.0022 - val_msle: 0.0022\n",
      "Epoch 55/70\n",
      " - 1s - loss: 0.0017 - msle: 0.0017 - val_loss: 0.0021 - val_msle: 0.0021\n",
      "Epoch 56/70\n",
      " - 1s - loss: 0.0017 - msle: 0.0017 - val_loss: 0.0021 - val_msle: 0.0021\n",
      "Epoch 57/70\n",
      " - 1s - loss: 0.0017 - msle: 0.0017 - val_loss: 0.0021 - val_msle: 0.0021\n",
      "Epoch 58/70\n",
      " - 1s - loss: 0.0017 - msle: 0.0017 - val_loss: 0.0021 - val_msle: 0.0021\n",
      "Epoch 59/70\n",
      " - 1s - loss: 0.0018 - msle: 0.0018 - val_loss: 0.0021 - val_msle: 0.0021\n",
      "Epoch 60/70\n",
      " - 3s - loss: 0.0019 - msle: 0.0019 - val_loss: 0.0021 - val_msle: 0.0021\n",
      "Epoch 61/70\n",
      " - 2s - loss: 0.0018 - msle: 0.0018 - val_loss: 0.0021 - val_msle: 0.0021\n",
      "Epoch 62/70\n",
      " - 4s - loss: 0.0017 - msle: 0.0017 - val_loss: 0.0021 - val_msle: 0.0021\n",
      "Epoch 63/70\n",
      " - 3s - loss: 0.0016 - msle: 0.0016 - val_loss: 0.0020 - val_msle: 0.0020\n",
      "Epoch 64/70\n",
      " - 3s - loss: 0.0017 - msle: 0.0017 - val_loss: 0.0021 - val_msle: 0.0021\n",
      "Epoch 65/70\n",
      " - 3s - loss: 0.0015 - msle: 0.0015 - val_loss: 0.0021 - val_msle: 0.0021\n",
      "Epoch 66/70\n",
      " - 2s - loss: 0.0016 - msle: 0.0016 - val_loss: 0.0021 - val_msle: 0.0021\n",
      "Epoch 67/70\n",
      " - 2s - loss: 0.0016 - msle: 0.0016 - val_loss: 0.0020 - val_msle: 0.0020\n",
      "Epoch 68/70\n",
      " - 2s - loss: 0.0015 - msle: 0.0015 - val_loss: 0.0020 - val_msle: 0.0020\n",
      "Epoch 69/70\n",
      " - 1s - loss: 0.0014 - msle: 0.0014 - val_loss: 0.0019 - val_msle: 0.0019\n",
      "Epoch 70/70\n",
      " - 2s - loss: 0.0015 - msle: 0.0015 - val_loss: 0.0019 - val_msle: 0.0019\n",
      "real [[41761.89]]\n",
      "Test RMSE: 110.293\n",
      "Diff [[110.29348029]]\n",
      "% Diff [[0.26410079]] %\n",
      "Predictions [[41651.59651971]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "crypto = crypto\n",
    "execute_test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hemos probado con un dataset mas grande y vemos una precisión considerablemente más alta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Complete simulation\n",
    "\n",
    "Complete strategy definition. Let the machine work through all the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### PERIODS ####\n",
    "prev_periods = 20\n",
    "pred_periods = 5\n",
    "\n",
    "#LSTM\n",
    "model_sel = 0\n",
    "\n",
    "# Cryptos\n",
    "crypto = 'BTC'\n",
    "\n",
    "#### NORM AND FEATURES CONFIGURATION ####\n",
    "target = 'close'\n",
    "norm_strat = 2\n",
    "\n",
    "#### Hyper params ####\n",
    "activation = LeakyReLU(alpha=0.05)\n",
    "loss = 'msle'\n",
    "metrics = ['msle']\n",
    "initial_learning_rate = 0.01\n",
    "\n",
    "optimizer = optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "callbacks = ['mc', 'es']\n",
    "batch_size = 32\n",
    "epochs = 70\n",
    "\n",
    "layers = 2\n",
    "neurons = [100, 50, 50]\n",
    "\n",
    "columns = ['RSI', 'ADX', 'close']\n",
    "num_features = len(columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading... BTC\n",
      "Extracting columns columns for BTC\n",
      "Proccessing and arranging columns for LSTM model\n"
     ]
    }
   ],
   "source": [
    "sim = DLSimulator(crypto, prev_periods, pred_periods, columns, target,\n",
    "    norm_strat, model_sel, layers, neurons, batch_size, epochs, \n",
    "    activation, loss, metrics, optimizer, initial_learning_rate, callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulation starting...\n",
      "INDEX: 1399\n",
      "CLOSE: 40144.04\n",
      "MODE: buy\n",
      "TRAINING MODEL:\n",
      "Input shape: (1399, 1, 60) (1399, 1)\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 1, 100)            64400     \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 1, 50)             30200     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1, 50)             0         \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 51        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 114,851\n",
      "Trainable params: 114,851\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Y shape (1399, 1)\n",
      "Train on 1399 samples, validate on 280 samples\n",
      "Epoch 1/70\n",
      " - 8s - loss: 0.0251 - msle: 0.0251 - val_loss: 0.0458 - val_msle: 0.0458\n",
      "Epoch 2/70\n",
      " - 1s - loss: 0.0421 - msle: 0.0421 - val_loss: 0.0598 - val_msle: 0.0598\n",
      "Epoch 3/70\n",
      " - 1s - loss: 0.0172 - msle: 0.0172 - val_loss: 0.0098 - val_msle: 0.0098\n",
      "Epoch 4/70\n",
      " - 1s - loss: 0.0063 - msle: 0.0063 - val_loss: 0.0031 - val_msle: 0.0031\n",
      "Epoch 5/70\n",
      " - 1s - loss: 0.0020 - msle: 0.0020 - val_loss: 0.0028 - val_msle: 0.0028\n",
      "Epoch 6/70\n",
      " - 1s - loss: 0.0021 - msle: 0.0021 - val_loss: 0.0026 - val_msle: 0.0026\n",
      "Epoch 7/70\n",
      " - 1s - loss: 0.0019 - msle: 0.0019 - val_loss: 0.0027 - val_msle: 0.0027\n",
      "Epoch 8/70\n",
      " - 1s - loss: 0.0019 - msle: 0.0019 - val_loss: 0.0025 - val_msle: 0.0025\n",
      "Epoch 9/70\n",
      " - 1s - loss: 0.0017 - msle: 0.0017 - val_loss: 0.0025 - val_msle: 0.0025\n",
      "Epoch 10/70\n",
      " - 1s - loss: 0.0018 - msle: 0.0018 - val_loss: 0.0027 - val_msle: 0.0027\n",
      "Epoch 11/70\n",
      " - 1s - loss: 0.0017 - msle: 0.0017 - val_loss: 0.0026 - val_msle: 0.0026\n",
      "Epoch 12/70\n",
      " - 1s - loss: 0.0014 - msle: 0.0014 - val_loss: 0.0024 - val_msle: 0.0024\n",
      "Epoch 13/70\n",
      " - 1s - loss: 0.0015 - msle: 0.0015 - val_loss: 0.0024 - val_msle: 0.0024\n",
      "Epoch 14/70\n",
      " - 1s - loss: 0.0015 - msle: 0.0015 - val_loss: 0.0024 - val_msle: 0.0024\n",
      "Epoch 15/70\n",
      " - 1s - loss: 0.0015 - msle: 0.0015 - val_loss: 0.0024 - val_msle: 0.0024\n",
      "Epoch 16/70\n",
      " - 1s - loss: 0.0014 - msle: 0.0014 - val_loss: 0.0023 - val_msle: 0.0023\n",
      "Epoch 17/70\n",
      " - 1s - loss: 0.0014 - msle: 0.0014 - val_loss: 0.0023 - val_msle: 0.0023\n",
      "Epoch 18/70\n",
      " - 1s - loss: 0.0015 - msle: 0.0015 - val_loss: 0.0026 - val_msle: 0.0026\n",
      "Epoch 19/70\n",
      " - 1s - loss: 0.0014 - msle: 0.0014 - val_loss: 0.0024 - val_msle: 0.0024\n",
      "Epoch 20/70\n",
      " - 1s - loss: 0.0014 - msle: 0.0014 - val_loss: 0.0023 - val_msle: 0.0023\n",
      "Epoch 21/70\n",
      " - 1s - loss: 0.0013 - msle: 0.0013 - val_loss: 0.0029 - val_msle: 0.0029\n",
      "Epoch 22/70\n",
      " - 1s - loss: 0.0013 - msle: 0.0013 - val_loss: 0.0022 - val_msle: 0.0022\n",
      "Epoch 23/70\n",
      " - 1s - loss: 0.0013 - msle: 0.0013 - val_loss: 0.0021 - val_msle: 0.0021\n",
      "Epoch 24/70\n",
      " - 1s - loss: 0.0014 - msle: 0.0014 - val_loss: 0.0026 - val_msle: 0.0026\n",
      "Epoch 25/70\n",
      " - 1s - loss: 0.0013 - msle: 0.0013 - val_loss: 0.0023 - val_msle: 0.0023\n",
      "Epoch 26/70\n",
      " - 1s - loss: 0.0011 - msle: 0.0011 - val_loss: 0.0023 - val_msle: 0.0023\n",
      "Epoch 27/70\n",
      " - 1s - loss: 0.0012 - msle: 0.0012 - val_loss: 0.0020 - val_msle: 0.0020\n",
      "Epoch 28/70\n",
      " - 1s - loss: 0.0013 - msle: 0.0013 - val_loss: 0.0025 - val_msle: 0.0025\n",
      "Epoch 29/70\n",
      " - 1s - loss: 0.0013 - msle: 0.0013 - val_loss: 0.0025 - val_msle: 0.0025\n",
      "Epoch 30/70\n",
      " - 1s - loss: 0.0011 - msle: 0.0011 - val_loss: 0.0022 - val_msle: 0.0022\n",
      "Epoch 31/70\n",
      " - 1s - loss: 0.0012 - msle: 0.0012 - val_loss: 0.0020 - val_msle: 0.0020\n",
      "Epoch 32/70\n",
      " - 1s - loss: 0.0012 - msle: 0.0012 - val_loss: 0.0020 - val_msle: 0.0020\n",
      "Epoch 33/70\n",
      " - 1s - loss: 0.0012 - msle: 0.0012 - val_loss: 0.0022 - val_msle: 0.0022\n",
      "Epoch 34/70\n",
      " - 1s - loss: 0.0013 - msle: 0.0013 - val_loss: 0.0023 - val_msle: 0.0023\n",
      "Epoch 35/70\n",
      " - 1s - loss: 0.0015 - msle: 0.0015 - val_loss: 0.0031 - val_msle: 0.0031\n",
      "Epoch 36/70\n",
      " - 1s - loss: 0.0015 - msle: 0.0015 - val_loss: 0.0034 - val_msle: 0.0034\n",
      "Epoch 37/70\n",
      " - 1s - loss: 0.0011 - msle: 0.0011 - val_loss: 0.0020 - val_msle: 0.0020\n",
      "Epoch 38/70\n",
      " - 1s - loss: 0.0011 - msle: 0.0011 - val_loss: 0.0019 - val_msle: 0.0019\n",
      "Epoch 39/70\n",
      " - 1s - loss: 0.0012 - msle: 0.0012 - val_loss: 0.0021 - val_msle: 0.0021\n",
      "Epoch 40/70\n",
      " - 1s - loss: 0.0010 - msle: 0.0010 - val_loss: 0.0020 - val_msle: 0.0020\n",
      "Epoch 41/70\n",
      " - 1s - loss: 0.0013 - msle: 0.0013 - val_loss: 0.0021 - val_msle: 0.0021\n",
      "Epoch 42/70\n",
      " - 1s - loss: 0.0013 - msle: 0.0013 - val_loss: 0.0028 - val_msle: 0.0028\n",
      "Epoch 43/70\n",
      " - 1s - loss: 0.0013 - msle: 0.0013 - val_loss: 0.0032 - val_msle: 0.0032\n",
      "Epoch 44/70\n",
      " - 1s - loss: 0.0011 - msle: 0.0011 - val_loss: 0.0027 - val_msle: 0.0027\n",
      "Epoch 45/70\n",
      " - 1s - loss: 0.0011 - msle: 0.0011 - val_loss: 0.0021 - val_msle: 0.0021\n",
      "Epoch 46/70\n",
      " - 1s - loss: 0.0012 - msle: 0.0012 - val_loss: 0.0019 - val_msle: 0.0019\n",
      "Epoch 47/70\n",
      " - 1s - loss: 0.0011 - msle: 0.0011 - val_loss: 0.0018 - val_msle: 0.0018\n",
      "Epoch 48/70\n",
      " - 1s - loss: 0.0010 - msle: 0.0010 - val_loss: 0.0018 - val_msle: 0.0018\n",
      "Epoch 49/70\n",
      " - 1s - loss: 0.0011 - msle: 0.0011 - val_loss: 0.0020 - val_msle: 0.0020\n",
      "Epoch 50/70\n",
      " - 1s - loss: 0.0010 - msle: 0.0010 - val_loss: 0.0025 - val_msle: 0.0025\n",
      "Epoch 51/70\n",
      " - 1s - loss: 0.0012 - msle: 0.0012 - val_loss: 0.0024 - val_msle: 0.0024\n",
      "Epoch 52/70\n",
      " - 1s - loss: 0.0012 - msle: 0.0012 - val_loss: 0.0025 - val_msle: 0.0025\n",
      "Epoch 53/70\n",
      " - 1s - loss: 0.0012 - msle: 0.0012 - val_loss: 0.0025 - val_msle: 0.0025\n",
      "Epoch 54/70\n",
      " - 1s - loss: 0.0010 - msle: 0.0010 - val_loss: 0.0023 - val_msle: 0.0023\n",
      "Epoch 55/70\n",
      " - 1s - loss: 9.7615e-04 - msle: 9.7615e-04 - val_loss: 0.0018 - val_msle: 0.0018\n",
      "Epoch 56/70\n",
      " - 1s - loss: 0.0011 - msle: 0.0011 - val_loss: 0.0018 - val_msle: 0.0018\n",
      "Epoch 57/70\n",
      " - 1s - loss: 9.3200e-04 - msle: 9.3200e-04 - val_loss: 0.0018 - val_msle: 0.0018\n",
      "Epoch 58/70\n",
      " - 1s - loss: 8.7563e-04 - msle: 8.7563e-04 - val_loss: 0.0022 - val_msle: 0.0022\n",
      "Epoch 59/70\n",
      " - 1s - loss: 0.0012 - msle: 0.0012 - val_loss: 0.0021 - val_msle: 0.0021\n",
      "Epoch 60/70\n",
      " - 1s - loss: 0.0010 - msle: 0.0010 - val_loss: 0.0026 - val_msle: 0.0026\n",
      "Epoch 61/70\n",
      " - 1s - loss: 0.0011 - msle: 0.0011 - val_loss: 0.0026 - val_msle: 0.0026\n",
      "Epoch 62/70\n",
      " - 1s - loss: 0.0011 - msle: 0.0011 - val_loss: 0.0026 - val_msle: 0.0026\n",
      "Epoch 63/70\n",
      " - 1s - loss: 0.0010 - msle: 0.0010 - val_loss: 0.0022 - val_msle: 0.0022\n",
      "Epoch 64/70\n",
      " - 1s - loss: 0.0012 - msle: 0.0012 - val_loss: 0.0025 - val_msle: 0.0025\n",
      "Epoch 65/70\n",
      " - 1s - loss: 8.7762e-04 - msle: 8.7762e-04 - val_loss: 0.0018 - val_msle: 0.0018\n",
      "Epoch 66/70\n",
      " - 1s - loss: 8.9983e-04 - msle: 8.9983e-04 - val_loss: 0.0021 - val_msle: 0.0021\n",
      "Epoch 67/70\n",
      " - 1s - loss: 8.0567e-04 - msle: 8.0567e-04 - val_loss: 0.0019 - val_msle: 0.0019\n",
      "Epoch 68/70\n",
      " - 1s - loss: 8.9229e-04 - msle: 8.9229e-04 - val_loss: 0.0018 - val_msle: 0.0018\n",
      "Epoch 69/70\n",
      " - 1s - loss: 9.0423e-04 - msle: 9.0423e-04 - val_loss: 0.0018 - val_msle: 0.0018\n",
      "Epoch 70/70\n",
      " - 1s - loss: 9.2686e-04 - msle: 9.2686e-04 - val_loss: 0.0018 - val_msle: 0.0018\n",
      "PREDICTING VALUE FOR       close_19     ADX_19     RSI_19  close_18     ADX_18     RSI_18  \\\n",
      "1556   61299.8  33.582115  57.110128  60911.11  32.473445  56.003554   \n",
      "\n",
      "      close_17     ADX_17     RSI_17  close_16  ...   close_2      ADX_2  \\\n",
      "1556  63219.99  31.226523  60.855548  62896.48  ...  60344.87  24.430115   \n",
      "\n",
      "          RSI_2   close_1      ADX_1      RSI_1   close_0      ADX_0  \\\n",
      "1556  45.565723  56891.62  23.576312  38.249876  58052.24  23.321307   \n",
      "\n",
      "          RSI_0     close  \n",
      "1556  41.641275  57138.29  \n",
      "\n",
      "[1 rows x 61 columns]\n",
      "real [[57138.29]]\n",
      "Test RMSE: 836.061\n",
      "Diff [[-836.06118756]]\n",
      "% Diff [[-1.46322403]] %\n",
      "### BUY OPERATION ###\n",
      "VALUE TODAY: 40144.04\n",
      "VALUE PREDICTED IN 5 DAYS: [[57974.35118756]]\n",
      "||||----|||| Current Orders: [] \n",
      "\n",
      "\n",
      "\n",
      "INDEX: 1400\n",
      "CLOSE: 38349.01\n",
      "MODE: sell\n",
      "CHECKING ORDERS...\n",
      "TRAINING MODEL:\n",
      "Input shape: (1400, 1, 60) (1400, 1)\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_4 (LSTM)                (None, 1, 100)            64400     \n",
      "_________________________________________________________________\n",
      "lstm_5 (LSTM)                (None, 1, 50)             30200     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 1, 50)             0         \n",
      "_________________________________________________________________\n",
      "lstm_6 (LSTM)                (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 51        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 114,851\n",
      "Trainable params: 114,851\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Y shape (1400, 1)\n",
      "Train on 1400 samples, validate on 280 samples\n",
      "Epoch 1/70\n",
      " - 6s - loss: 0.0108 - msle: 0.0108 - val_loss: 0.0147 - val_msle: 0.0147\n",
      "Epoch 2/70\n",
      " - 1s - loss: 0.0568 - msle: 0.0568 - val_loss: 0.0738 - val_msle: 0.0738\n",
      "Epoch 3/70\n",
      " - 1s - loss: 0.0455 - msle: 0.0455 - val_loss: 0.0749 - val_msle: 0.0749\n",
      "Epoch 4/70\n",
      " - 1s - loss: 0.0186 - msle: 0.0186 - val_loss: 0.0069 - val_msle: 0.0069\n",
      "Epoch 5/70\n",
      " - 1s - loss: 0.0079 - msle: 0.0079 - val_loss: 0.0054 - val_msle: 0.0054\n",
      "Epoch 6/70\n",
      " - 1s - loss: 0.0071 - msle: 0.0071 - val_loss: 0.0066 - val_msle: 0.0066\n",
      "Epoch 7/70\n",
      " - 1s - loss: 0.0042 - msle: 0.0042 - val_loss: 0.0036 - val_msle: 0.0036\n",
      "Epoch 8/70\n",
      " - 1s - loss: 0.0026 - msle: 0.0026 - val_loss: 0.0040 - val_msle: 0.0040\n",
      "Epoch 9/70\n",
      " - 1s - loss: 0.0024 - msle: 0.0024 - val_loss: 0.0035 - val_msle: 0.0035\n",
      "Epoch 10/70\n",
      " - 1s - loss: 0.0018 - msle: 0.0018 - val_loss: 0.0037 - val_msle: 0.0037\n",
      "Epoch 11/70\n",
      " - 1s - loss: 0.0019 - msle: 0.0019 - val_loss: 0.0034 - val_msle: 0.0034\n",
      "Epoch 12/70\n",
      " - 1s - loss: 0.0015 - msle: 0.0015 - val_loss: 0.0034 - val_msle: 0.0034\n",
      "Epoch 13/70\n",
      " - 1s - loss: 0.0017 - msle: 0.0017 - val_loss: 0.0033 - val_msle: 0.0033\n",
      "Epoch 14/70\n",
      " - 1s - loss: 0.0015 - msle: 0.0015 - val_loss: 0.0033 - val_msle: 0.0033\n",
      "Epoch 15/70\n",
      " - 1s - loss: 0.0016 - msle: 0.0016 - val_loss: 0.0031 - val_msle: 0.0031\n",
      "Epoch 16/70\n",
      " - 1s - loss: 0.0015 - msle: 0.0015 - val_loss: 0.0030 - val_msle: 0.0030\n",
      "Epoch 17/70\n",
      " - 1s - loss: 0.0013 - msle: 0.0013 - val_loss: 0.0030 - val_msle: 0.0030\n",
      "Epoch 18/70\n",
      " - 1s - loss: 0.0016 - msle: 0.0016 - val_loss: 0.0030 - val_msle: 0.0030\n",
      "Epoch 19/70\n",
      " - 1s - loss: 0.0015 - msle: 0.0015 - val_loss: 0.0030 - val_msle: 0.0030\n",
      "Epoch 20/70\n",
      " - 1s - loss: 0.0015 - msle: 0.0015 - val_loss: 0.0029 - val_msle: 0.0029\n",
      "Epoch 21/70\n",
      " - 1s - loss: 0.0015 - msle: 0.0015 - val_loss: 0.0029 - val_msle: 0.0029\n",
      "Epoch 22/70\n",
      " - 1s - loss: 0.0013 - msle: 0.0013 - val_loss: 0.0028 - val_msle: 0.0028\n",
      "Epoch 23/70\n",
      " - 1s - loss: 0.0014 - msle: 0.0014 - val_loss: 0.0028 - val_msle: 0.0028\n",
      "Epoch 24/70\n",
      " - 1s - loss: 0.0014 - msle: 0.0014 - val_loss: 0.0028 - val_msle: 0.0028\n",
      "Epoch 25/70\n",
      " - 1s - loss: 0.0013 - msle: 0.0013 - val_loss: 0.0027 - val_msle: 0.0027\n",
      "Epoch 26/70\n",
      " - 1s - loss: 0.0014 - msle: 0.0014 - val_loss: 0.0027 - val_msle: 0.0027\n",
      "Epoch 27/70\n",
      " - 1s - loss: 0.0012 - msle: 0.0012 - val_loss: 0.0026 - val_msle: 0.0026\n",
      "Epoch 28/70\n",
      " - 1s - loss: 0.0015 - msle: 0.0015 - val_loss: 0.0025 - val_msle: 0.0025\n",
      "Epoch 29/70\n",
      " - 1s - loss: 0.0013 - msle: 0.0013 - val_loss: 0.0025 - val_msle: 0.0025\n",
      "Epoch 30/70\n",
      " - 1s - loss: 0.0014 - msle: 0.0014 - val_loss: 0.0026 - val_msle: 0.0026\n",
      "Epoch 31/70\n",
      " - 1s - loss: 0.0013 - msle: 0.0013 - val_loss: 0.0024 - val_msle: 0.0024\n",
      "Epoch 32/70\n",
      " - 1s - loss: 0.0013 - msle: 0.0013 - val_loss: 0.0024 - val_msle: 0.0024\n",
      "Epoch 33/70\n",
      " - 1s - loss: 0.0014 - msle: 0.0014 - val_loss: 0.0025 - val_msle: 0.0025\n",
      "Epoch 34/70\n",
      " - 1s - loss: 0.0012 - msle: 0.0012 - val_loss: 0.0024 - val_msle: 0.0024\n",
      "Epoch 35/70\n",
      " - 1s - loss: 0.0012 - msle: 0.0012 - val_loss: 0.0023 - val_msle: 0.0023\n",
      "Epoch 36/70\n",
      " - 1s - loss: 0.0012 - msle: 0.0012 - val_loss: 0.0024 - val_msle: 0.0024\n",
      "Epoch 37/70\n",
      " - 1s - loss: 0.0012 - msle: 0.0012 - val_loss: 0.0023 - val_msle: 0.0023\n",
      "Epoch 38/70\n",
      " - 1s - loss: 0.0012 - msle: 0.0012 - val_loss: 0.0023 - val_msle: 0.0023\n",
      "Epoch 39/70\n",
      " - 1s - loss: 0.0012 - msle: 0.0012 - val_loss: 0.0021 - val_msle: 0.0021\n",
      "Epoch 40/70\n",
      " - 1s - loss: 0.0011 - msle: 0.0011 - val_loss: 0.0021 - val_msle: 0.0021\n",
      "Epoch 41/70\n",
      " - 1s - loss: 0.0011 - msle: 0.0011 - val_loss: 0.0021 - val_msle: 0.0021\n",
      "Epoch 42/70\n",
      " - 1s - loss: 0.0012 - msle: 0.0012 - val_loss: 0.0024 - val_msle: 0.0024\n",
      "Epoch 43/70\n",
      " - 1s - loss: 0.0011 - msle: 0.0011 - val_loss: 0.0020 - val_msle: 0.0020\n",
      "Epoch 44/70\n",
      " - 1s - loss: 0.0012 - msle: 0.0012 - val_loss: 0.0020 - val_msle: 0.0020\n",
      "Epoch 45/70\n",
      " - 1s - loss: 0.0011 - msle: 0.0011 - val_loss: 0.0024 - val_msle: 0.0024\n",
      "Epoch 46/70\n",
      " - 1s - loss: 0.0010 - msle: 0.0010 - val_loss: 0.0021 - val_msle: 0.0021\n",
      "Epoch 47/70\n",
      " - 1s - loss: 0.0011 - msle: 0.0011 - val_loss: 0.0019 - val_msle: 0.0019\n",
      "Epoch 48/70\n",
      " - 1s - loss: 0.0012 - msle: 0.0012 - val_loss: 0.0024 - val_msle: 0.0024\n",
      "Epoch 49/70\n",
      " - 1s - loss: 0.0010 - msle: 0.0010 - val_loss: 0.0019 - val_msle: 0.0019\n",
      "Epoch 50/70\n",
      " - 1s - loss: 0.0010 - msle: 0.0010 - val_loss: 0.0020 - val_msle: 0.0020\n",
      "Epoch 51/70\n",
      " - 1s - loss: 0.0011 - msle: 0.0011 - val_loss: 0.0020 - val_msle: 0.0020\n",
      "Epoch 52/70\n",
      " - 1s - loss: 0.0010 - msle: 0.0010 - val_loss: 0.0020 - val_msle: 0.0020\n",
      "Epoch 53/70\n",
      " - 1s - loss: 0.0011 - msle: 0.0011 - val_loss: 0.0019 - val_msle: 0.0019\n",
      "Epoch 54/70\n",
      " - 1s - loss: 0.0011 - msle: 0.0011 - val_loss: 0.0019 - val_msle: 0.0019\n",
      "Epoch 55/70\n",
      " - 1s - loss: 0.0011 - msle: 0.0011 - val_loss: 0.0022 - val_msle: 0.0022\n",
      "Epoch 56/70\n",
      " - 1s - loss: 0.0011 - msle: 0.0011 - val_loss: 0.0026 - val_msle: 0.0026\n",
      "Epoch 57/70\n",
      " - 1s - loss: 0.0010 - msle: 0.0010 - val_loss: 0.0018 - val_msle: 0.0018\n",
      "Epoch 58/70\n",
      " - 1s - loss: 0.0010 - msle: 0.0010 - val_loss: 0.0018 - val_msle: 0.0018\n",
      "Epoch 59/70\n",
      " - 1s - loss: 9.9352e-04 - msle: 9.9352e-04 - val_loss: 0.0024 - val_msle: 0.0024\n",
      "Epoch 60/70\n",
      " - 1s - loss: 0.0010 - msle: 0.0010 - val_loss: 0.0017 - val_msle: 0.0017\n",
      "Epoch 61/70\n",
      " - 1s - loss: 0.0011 - msle: 0.0011 - val_loss: 0.0019 - val_msle: 0.0019\n",
      "Epoch 62/70\n",
      " - 1s - loss: 9.8023e-04 - msle: 9.8023e-04 - val_loss: 0.0017 - val_msle: 0.0017\n",
      "Epoch 63/70\n",
      " - 1s - loss: 9.7422e-04 - msle: 9.7422e-04 - val_loss: 0.0018 - val_msle: 0.0018\n",
      "Epoch 64/70\n",
      " - 1s - loss: 9.5325e-04 - msle: 9.5324e-04 - val_loss: 0.0020 - val_msle: 0.0020\n",
      "Epoch 65/70\n",
      " - 1s - loss: 9.8103e-04 - msle: 9.8103e-04 - val_loss: 0.0020 - val_msle: 0.0020\n",
      "Epoch 66/70\n",
      " - 1s - loss: 0.0011 - msle: 0.0011 - val_loss: 0.0027 - val_msle: 0.0027\n",
      "Epoch 67/70\n",
      " - 1s - loss: 9.1949e-04 - msle: 9.1949e-04 - val_loss: 0.0020 - val_msle: 0.0020\n",
      "Epoch 68/70\n",
      " - 1s - loss: 0.0010 - msle: 0.0010 - val_loss: 0.0017 - val_msle: 0.0017\n",
      "Epoch 69/70\n",
      " - 1s - loss: 0.0010 - msle: 0.0010 - val_loss: 0.0017 - val_msle: 0.0017\n",
      "Epoch 70/70\n",
      " - 1s - loss: 9.2773e-04 - msle: 9.2773e-04 - val_loss: 0.0017 - val_msle: 0.0017\n",
      "PREDICTING VALUE FOR       close_19     ADX_19     RSI_19  close_18     ADX_18     RSI_18  \\\n",
      "1557  60911.11  32.473445  56.003554  63219.99  31.226523  60.855548   \n",
      "\n",
      "      close_17    ADX_17    RSI_17  close_16  ...   close_2      ADX_2  \\\n",
      "1557  62896.48  30.71195  59.85944  61395.01  ...  56891.62  23.576312   \n",
      "\n",
      "          RSI_2   close_1      ADX_1      RSI_1   close_0      ADX_0  \\\n",
      "1557  38.249876  58052.24  23.321307  41.641275  59707.51  23.280175   \n",
      "\n",
      "          RSI_0     close  \n",
      "1557  46.181102  58960.36  \n",
      "\n",
      "[1 rows x 61 columns]\n",
      "real [[58960.36]]\n",
      "Test RMSE: 3396.321\n",
      "Diff [[3396.32127107]]\n",
      "% Diff [[5.7603469]] %\n",
      "||||----|||| Current Orders: [] \n",
      "\n",
      "\n",
      "\n",
      "INDEX: 1401\n",
      "CLOSE: 38092.97\n",
      "MODE: sell\n",
      "CHECKING ORDERS...\n",
      "TRAINING MODEL:\n",
      "Input shape: (1401, 1, 60) (1401, 1)\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_7 (LSTM)                (None, 1, 100)            64400     \n",
      "_________________________________________________________________\n",
      "lstm_8 (LSTM)                (None, 1, 50)             30200     \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 1, 50)             0         \n",
      "_________________________________________________________________\n",
      "lstm_9 (LSTM)                (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 51        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 114,851\n",
      "Trainable params: 114,851\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Y shape (1401, 1)\n",
      "Train on 1401 samples, validate on 281 samples\n",
      "Epoch 1/70\n",
      " - 6s - loss: 0.0117 - msle: 0.0117 - val_loss: 0.0181 - val_msle: 0.0181\n",
      "Epoch 2/70\n",
      " - 1s - loss: 0.0629 - msle: 0.0629 - val_loss: 0.1088 - val_msle: 0.1088\n",
      "Epoch 3/70\n",
      " - 1s - loss: 0.0417 - msle: 0.0417 - val_loss: 0.0833 - val_msle: 0.0833\n",
      "Epoch 4/70\n",
      " - 1s - loss: 0.0229 - msle: 0.0229 - val_loss: 0.0201 - val_msle: 0.0201\n",
      "Epoch 5/70\n",
      " - 1s - loss: 0.0055 - msle: 0.0055 - val_loss: 0.0044 - val_msle: 0.0044\n",
      "Epoch 6/70\n",
      " - 1s - loss: 0.0043 - msle: 0.0043 - val_loss: 0.0043 - val_msle: 0.0043\n",
      "Epoch 7/70\n",
      " - 1s - loss: 0.0037 - msle: 0.0037 - val_loss: 0.0040 - val_msle: 0.0040\n",
      "Epoch 8/70\n",
      " - 1s - loss: 0.0023 - msle: 0.0023 - val_loss: 0.0039 - val_msle: 0.0039\n",
      "Epoch 9/70\n",
      " - 1s - loss: 0.0024 - msle: 0.0024 - val_loss: 0.0034 - val_msle: 0.0034\n",
      "Epoch 10/70\n",
      " - 1s - loss: 0.0019 - msle: 0.0019 - val_loss: 0.0036 - val_msle: 0.0036\n",
      "Epoch 11/70\n",
      " - 1s - loss: 0.0024 - msle: 0.0024 - val_loss: 0.0033 - val_msle: 0.0033\n",
      "Epoch 12/70\n",
      " - 1s - loss: 0.0020 - msle: 0.0020 - val_loss: 0.0032 - val_msle: 0.0032\n",
      "Epoch 13/70\n",
      " - 1s - loss: 0.0022 - msle: 0.0022 - val_loss: 0.0030 - val_msle: 0.0030\n",
      "Epoch 14/70\n",
      " - 1s - loss: 0.0015 - msle: 0.0015 - val_loss: 0.0031 - val_msle: 0.0031\n",
      "Epoch 15/70\n",
      " - 1s - loss: 0.0017 - msle: 0.0017 - val_loss: 0.0030 - val_msle: 0.0030\n",
      "Epoch 16/70\n",
      " - 1s - loss: 0.0014 - msle: 0.0014 - val_loss: 0.0030 - val_msle: 0.0030\n",
      "Epoch 17/70\n",
      " - 1s - loss: 0.0016 - msle: 0.0016 - val_loss: 0.0028 - val_msle: 0.0028\n",
      "Epoch 18/70\n",
      " - 1s - loss: 0.0015 - msle: 0.0015 - val_loss: 0.0029 - val_msle: 0.0029\n",
      "Epoch 19/70\n",
      " - 1s - loss: 0.0015 - msle: 0.0015 - val_loss: 0.0029 - val_msle: 0.0029\n",
      "Epoch 20/70\n",
      " - 1s - loss: 0.0014 - msle: 0.0014 - val_loss: 0.0028 - val_msle: 0.0028\n",
      "Epoch 21/70\n",
      " - 1s - loss: 0.0015 - msle: 0.0015 - val_loss: 0.0028 - val_msle: 0.0028\n",
      "Epoch 22/70\n",
      " - 1s - loss: 0.0013 - msle: 0.0013 - val_loss: 0.0027 - val_msle: 0.0027\n",
      "Epoch 23/70\n",
      " - 1s - loss: 0.0015 - msle: 0.0015 - val_loss: 0.0027 - val_msle: 0.0027\n",
      "Epoch 24/70\n",
      " - 1s - loss: 0.0014 - msle: 0.0014 - val_loss: 0.0026 - val_msle: 0.0026\n",
      "Epoch 25/70\n",
      " - 1s - loss: 0.0015 - msle: 0.0015 - val_loss: 0.0026 - val_msle: 0.0026\n",
      "Epoch 26/70\n",
      " - 1s - loss: 0.0014 - msle: 0.0014 - val_loss: 0.0026 - val_msle: 0.0026\n",
      "Epoch 27/70\n",
      " - 1s - loss: 0.0015 - msle: 0.0015 - val_loss: 0.0027 - val_msle: 0.0027\n",
      "Epoch 28/70\n",
      " - 1s - loss: 0.0014 - msle: 0.0014 - val_loss: 0.0025 - val_msle: 0.0025\n",
      "Epoch 29/70\n",
      " - 1s - loss: 0.0014 - msle: 0.0014 - val_loss: 0.0025 - val_msle: 0.0025\n",
      "Epoch 30/70\n",
      " - 1s - loss: 0.0014 - msle: 0.0014 - val_loss: 0.0024 - val_msle: 0.0024\n",
      "Epoch 31/70\n",
      " - 1s - loss: 0.0014 - msle: 0.0014 - val_loss: 0.0025 - val_msle: 0.0025\n",
      "Epoch 32/70\n",
      " - 1s - loss: 0.0012 - msle: 0.0012 - val_loss: 0.0024 - val_msle: 0.0024\n",
      "Epoch 33/70\n",
      " - 1s - loss: 0.0013 - msle: 0.0013 - val_loss: 0.0023 - val_msle: 0.0023\n",
      "Epoch 34/70\n",
      " - 1s - loss: 0.0012 - msle: 0.0012 - val_loss: 0.0024 - val_msle: 0.0024\n",
      "Epoch 35/70\n",
      " - 1s - loss: 0.0013 - msle: 0.0013 - val_loss: 0.0022 - val_msle: 0.0022\n",
      "Epoch 36/70\n",
      " - 1s - loss: 0.0013 - msle: 0.0013 - val_loss: 0.0024 - val_msle: 0.0024\n",
      "Epoch 37/70\n",
      " - 1s - loss: 0.0014 - msle: 0.0014 - val_loss: 0.0022 - val_msle: 0.0022\n",
      "Epoch 38/70\n",
      " - 1s - loss: 0.0013 - msle: 0.0013 - val_loss: 0.0023 - val_msle: 0.0023\n",
      "Epoch 39/70\n",
      " - 1s - loss: 0.0012 - msle: 0.0012 - val_loss: 0.0022 - val_msle: 0.0022\n",
      "Epoch 40/70\n",
      " - 1s - loss: 0.0012 - msle: 0.0012 - val_loss: 0.0022 - val_msle: 0.0022\n",
      "Epoch 41/70\n",
      " - 1s - loss: 0.0011 - msle: 0.0011 - val_loss: 0.0023 - val_msle: 0.0023\n",
      "Epoch 42/70\n",
      " - 1s - loss: 0.0011 - msle: 0.0011 - val_loss: 0.0022 - val_msle: 0.0022\n",
      "Epoch 43/70\n",
      " - 1s - loss: 0.0011 - msle: 0.0011 - val_loss: 0.0021 - val_msle: 0.0021\n",
      "Epoch 44/70\n",
      " - 1s - loss: 0.0011 - msle: 0.0011 - val_loss: 0.0020 - val_msle: 0.0020\n",
      "Epoch 45/70\n",
      " - 1s - loss: 0.0011 - msle: 0.0011 - val_loss: 0.0020 - val_msle: 0.0020\n",
      "Epoch 46/70\n",
      " - 1s - loss: 0.0011 - msle: 0.0011 - val_loss: 0.0019 - val_msle: 0.0019\n",
      "Epoch 47/70\n",
      " - 1s - loss: 0.0011 - msle: 0.0011 - val_loss: 0.0020 - val_msle: 0.0020\n",
      "Epoch 48/70\n",
      " - 1s - loss: 0.0011 - msle: 0.0011 - val_loss: 0.0024 - val_msle: 0.0024\n",
      "Epoch 49/70\n",
      " - 1s - loss: 0.0011 - msle: 0.0011 - val_loss: 0.0019 - val_msle: 0.0019\n",
      "Epoch 50/70\n",
      " - 1s - loss: 0.0011 - msle: 0.0011 - val_loss: 0.0019 - val_msle: 0.0019\n",
      "Epoch 51/70\n",
      " - 1s - loss: 0.0011 - msle: 0.0011 - val_loss: 0.0018 - val_msle: 0.0018\n",
      "Epoch 52/70\n",
      " - 1s - loss: 0.0010 - msle: 0.0010 - val_loss: 0.0018 - val_msle: 0.0018\n",
      "Epoch 53/70\n",
      " - 1s - loss: 0.0010 - msle: 0.0010 - val_loss: 0.0020 - val_msle: 0.0020\n",
      "Epoch 54/70\n",
      " - 1s - loss: 8.7673e-04 - msle: 8.7673e-04 - val_loss: 0.0018 - val_msle: 0.0018\n",
      "Epoch 55/70\n",
      " - 1s - loss: 9.9299e-04 - msle: 9.9299e-04 - val_loss: 0.0021 - val_msle: 0.0021\n",
      "Epoch 56/70\n",
      " - 1s - loss: 0.0010 - msle: 0.0010 - val_loss: 0.0019 - val_msle: 0.0019\n",
      "Epoch 57/70\n",
      " - 1s - loss: 0.0010 - msle: 0.0010 - val_loss: 0.0017 - val_msle: 0.0017\n",
      "Epoch 58/70\n",
      " - 1s - loss: 0.0010 - msle: 0.0010 - val_loss: 0.0018 - val_msle: 0.0018\n",
      "Epoch 59/70\n",
      " - 1s - loss: 9.4688e-04 - msle: 9.4688e-04 - val_loss: 0.0021 - val_msle: 0.0021\n",
      "Epoch 60/70\n",
      " - 1s - loss: 9.7908e-04 - msle: 9.7908e-04 - val_loss: 0.0019 - val_msle: 0.0019\n",
      "Epoch 61/70\n",
      " - 1s - loss: 9.9996e-04 - msle: 9.9996e-04 - val_loss: 0.0017 - val_msle: 0.0017\n",
      "Epoch 62/70\n",
      " - 1s - loss: 9.8945e-04 - msle: 9.8945e-04 - val_loss: 0.0020 - val_msle: 0.0020\n",
      "Epoch 63/70\n",
      " - 1s - loss: 9.8711e-04 - msle: 9.8711e-04 - val_loss: 0.0020 - val_msle: 0.0020\n",
      "Epoch 64/70\n",
      " - 1s - loss: 9.8577e-04 - msle: 9.8577e-04 - val_loss: 0.0018 - val_msle: 0.0018\n",
      "Epoch 65/70\n",
      " - 1s - loss: 9.9792e-04 - msle: 9.9792e-04 - val_loss: 0.0017 - val_msle: 0.0017\n",
      "Epoch 66/70\n",
      " - 1s - loss: 9.0651e-04 - msle: 9.0651e-04 - val_loss: 0.0016 - val_msle: 0.0016\n",
      "Epoch 67/70\n",
      " - 1s - loss: 8.8794e-04 - msle: 8.8794e-04 - val_loss: 0.0020 - val_msle: 0.0020\n",
      "Epoch 68/70\n",
      " - 1s - loss: 9.3645e-04 - msle: 9.3645e-04 - val_loss: 0.0016 - val_msle: 0.0016\n",
      "Epoch 69/70\n",
      " - 1s - loss: 9.8483e-04 - msle: 9.8483e-04 - val_loss: 0.0018 - val_msle: 0.0018\n",
      "Epoch 70/70\n",
      " - 1s - loss: 9.8537e-04 - msle: 9.8537e-04 - val_loss: 0.0020 - val_msle: 0.0020\n",
      "PREDICTING VALUE FOR       close_19     ADX_19     RSI_19  close_18    ADX_18    RSI_18  close_17  \\\n",
      "1558  63219.99  31.226523  60.855548  62896.48  30.71195  59.85944  61395.01   \n",
      "\n",
      "         ADX_17     RSI_17  close_16  ...   close_2      ADX_2      RSI_2  \\\n",
      "1558  30.101656  55.332545  60937.12  ...  58052.24  23.321307  41.641275   \n",
      "\n",
      "       close_1      ADX_1      RSI_1   close_0      ADX_0      RSI_0     close  \n",
      "1558  59707.51  23.280175  46.181102  58622.02  22.582078  43.776117  53726.53  \n",
      "\n",
      "[1 rows x 61 columns]\n",
      "real [[53726.53]]\n",
      "Test RMSE: 2563.888\n",
      "Diff [[-2563.88809053]]\n",
      "% Diff [[-4.7721081]] %\n",
      "||||----|||| Current Orders: [] \n",
      "\n",
      "\n",
      "\n",
      "INDEX: 1402\n",
      "CLOSE: 35819.84\n",
      "MODE: sell\n",
      "CHECKING ORDERS...\n",
      "TRAINING MODEL:\n",
      "Input shape: (1402, 1, 60) (1402, 1)\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_10 (LSTM)               (None, 1, 100)            64400     \n",
      "_________________________________________________________________\n",
      "lstm_11 (LSTM)               (None, 1, 50)             30200     \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 1, 50)             0         \n",
      "_________________________________________________________________\n",
      "lstm_12 (LSTM)               (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 51        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 114,851\n",
      "Trainable params: 114,851\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Y shape (1402, 1)\n",
      "Train on 1402 samples, validate on 281 samples\n",
      "Epoch 1/70\n",
      " - 7s - loss: 0.0108 - msle: 0.0108 - val_loss: 0.0109 - val_msle: 0.0109\n",
      "Epoch 2/70\n",
      " - 1s - loss: 0.0603 - msle: 0.0603 - val_loss: 0.1105 - val_msle: 0.1105\n",
      "Epoch 3/70\n",
      " - 1s - loss: 0.0416 - msle: 0.0416 - val_loss: 0.0797 - val_msle: 0.0797\n",
      "Epoch 4/70\n",
      " - 1s - loss: 0.0165 - msle: 0.0165 - val_loss: 0.0040 - val_msle: 0.0040\n",
      "Epoch 5/70\n",
      " - 1s - loss: 0.0092 - msle: 0.0092 - val_loss: 0.0070 - val_msle: 0.0070\n",
      "Epoch 6/70\n",
      " - 1s - loss: 0.0077 - msle: 0.0077 - val_loss: 0.0057 - val_msle: 0.0057\n",
      "Epoch 7/70\n",
      " - 1s - loss: 0.0047 - msle: 0.0047 - val_loss: 0.0038 - val_msle: 0.0038\n",
      "Epoch 8/70\n",
      " - 1s - loss: 0.0039 - msle: 0.0039 - val_loss: 0.0045 - val_msle: 0.0045\n",
      "Epoch 9/70\n",
      " - 1s - loss: 0.0032 - msle: 0.0032 - val_loss: 0.0034 - val_msle: 0.0034\n",
      "Epoch 10/70\n",
      " - 1s - loss: 0.0021 - msle: 0.0021 - val_loss: 0.0037 - val_msle: 0.0037\n",
      "Epoch 11/70\n",
      " - 1s - loss: 0.0024 - msle: 0.0024 - val_loss: 0.0033 - val_msle: 0.0033\n",
      "Epoch 12/70\n",
      " - 1s - loss: 0.0018 - msle: 0.0018 - val_loss: 0.0034 - val_msle: 0.0034\n",
      "Epoch 13/70\n",
      " - 1s - loss: 0.0020 - msle: 0.0020 - val_loss: 0.0032 - val_msle: 0.0032\n",
      "Epoch 14/70\n",
      " - 1s - loss: 0.0016 - msle: 0.0016 - val_loss: 0.0032 - val_msle: 0.0032\n",
      "Epoch 15/70\n",
      " - 1s - loss: 0.0019 - msle: 0.0019 - val_loss: 0.0031 - val_msle: 0.0031\n",
      "Epoch 16/70\n",
      " - 1s - loss: 0.0014 - msle: 0.0014 - val_loss: 0.0031 - val_msle: 0.0031\n",
      "Epoch 17/70\n",
      " - 1s - loss: 0.0016 - msle: 0.0016 - val_loss: 0.0030 - val_msle: 0.0030\n",
      "Epoch 18/70\n",
      " - 1s - loss: 0.0014 - msle: 0.0014 - val_loss: 0.0031 - val_msle: 0.0031\n",
      "Epoch 19/70\n",
      " - 1s - loss: 0.0017 - msle: 0.0017 - val_loss: 0.0030 - val_msle: 0.0030\n",
      "Epoch 20/70\n",
      " - 1s - loss: 0.0016 - msle: 0.0016 - val_loss: 0.0029 - val_msle: 0.0029\n",
      "Epoch 21/70\n",
      " - 1s - loss: 0.0017 - msle: 0.0017 - val_loss: 0.0029 - val_msle: 0.0029\n",
      "Epoch 22/70\n",
      " - 1s - loss: 0.0014 - msle: 0.0014 - val_loss: 0.0029 - val_msle: 0.0029\n",
      "Epoch 23/70\n",
      " - 1s - loss: 0.0015 - msle: 0.0015 - val_loss: 0.0028 - val_msle: 0.0028\n",
      "Epoch 24/70\n",
      " - 1s - loss: 0.0014 - msle: 0.0014 - val_loss: 0.0028 - val_msle: 0.0028\n",
      "Epoch 25/70\n",
      " - 1s - loss: 0.0014 - msle: 0.0014 - val_loss: 0.0027 - val_msle: 0.0027\n",
      "Epoch 26/70\n",
      " - 1s - loss: 0.0013 - msle: 0.0013 - val_loss: 0.0027 - val_msle: 0.0027\n",
      "Epoch 27/70\n",
      " - 1s - loss: 0.0014 - msle: 0.0014 - val_loss: 0.0026 - val_msle: 0.0026\n",
      "Epoch 28/70\n",
      " - 1s - loss: 0.0015 - msle: 0.0015 - val_loss: 0.0026 - val_msle: 0.0026\n",
      "Epoch 29/70\n",
      " - 1s - loss: 0.0014 - msle: 0.0014 - val_loss: 0.0025 - val_msle: 0.0025\n",
      "Epoch 30/70\n",
      " - 1s - loss: 0.0013 - msle: 0.0013 - val_loss: 0.0025 - val_msle: 0.0025\n",
      "Epoch 31/70\n",
      " - 1s - loss: 0.0013 - msle: 0.0013 - val_loss: 0.0025 - val_msle: 0.0025\n",
      "Epoch 32/70\n",
      " - 1s - loss: 0.0011 - msle: 0.0011 - val_loss: 0.0024 - val_msle: 0.0024\n",
      "Epoch 33/70\n",
      " - 1s - loss: 0.0013 - msle: 0.0013 - val_loss: 0.0025 - val_msle: 0.0025\n",
      "Epoch 34/70\n",
      " - 1s - loss: 0.0012 - msle: 0.0012 - val_loss: 0.0023 - val_msle: 0.0023\n",
      "Epoch 35/70\n",
      " - 1s - loss: 0.0014 - msle: 0.0014 - val_loss: 0.0025 - val_msle: 0.0025\n",
      "Epoch 36/70\n",
      " - 1s - loss: 0.0010 - msle: 0.0010 - val_loss: 0.0022 - val_msle: 0.0022\n",
      "Epoch 37/70\n",
      " - 1s - loss: 0.0013 - msle: 0.0013 - val_loss: 0.0023 - val_msle: 0.0023\n",
      "Epoch 38/70\n",
      " - 1s - loss: 0.0011 - msle: 0.0011 - val_loss: 0.0022 - val_msle: 0.0022\n",
      "Epoch 39/70\n",
      " - 1s - loss: 0.0012 - msle: 0.0012 - val_loss: 0.0024 - val_msle: 0.0024\n",
      "Epoch 40/70\n",
      " - 1s - loss: 0.0012 - msle: 0.0012 - val_loss: 0.0021 - val_msle: 0.0021\n",
      "Epoch 41/70\n",
      " - 1s - loss: 0.0012 - msle: 0.0012 - val_loss: 0.0023 - val_msle: 0.0023\n",
      "Epoch 42/70\n",
      " - 1s - loss: 9.4948e-04 - msle: 9.4948e-04 - val_loss: 0.0020 - val_msle: 0.0020\n",
      "Epoch 43/70\n",
      " - 1s - loss: 0.0010 - msle: 0.0010 - val_loss: 0.0020 - val_msle: 0.0020\n",
      "Epoch 44/70\n",
      " - 1s - loss: 0.0011 - msle: 0.0011 - val_loss: 0.0023 - val_msle: 0.0023\n",
      "Epoch 45/70\n",
      " - 1s - loss: 0.0011 - msle: 0.0011 - val_loss: 0.0020 - val_msle: 0.0020\n",
      "Epoch 46/70\n",
      " - 1s - loss: 0.0011 - msle: 0.0011 - val_loss: 0.0021 - val_msle: 0.0021\n",
      "Epoch 47/70\n",
      " - 1s - loss: 9.9825e-04 - msle: 9.9825e-04 - val_loss: 0.0019 - val_msle: 0.0019\n",
      "Epoch 48/70\n",
      " - 1s - loss: 0.0010 - msle: 0.0010 - val_loss: 0.0022 - val_msle: 0.0022\n",
      "Epoch 49/70\n",
      " - 1s - loss: 9.7076e-04 - msle: 9.7076e-04 - val_loss: 0.0018 - val_msle: 0.0018\n",
      "Epoch 50/70\n",
      " - 1s - loss: 9.6988e-04 - msle: 9.6988e-04 - val_loss: 0.0021 - val_msle: 0.0021\n",
      "Epoch 51/70\n",
      " - 1s - loss: 9.7396e-04 - msle: 9.7396e-04 - val_loss: 0.0019 - val_msle: 0.0019\n",
      "Epoch 52/70\n",
      " - 1s - loss: 9.8586e-04 - msle: 9.8586e-04 - val_loss: 0.0018 - val_msle: 0.0018\n",
      "Epoch 53/70\n",
      " - 1s - loss: 0.0010 - msle: 0.0010 - val_loss: 0.0020 - val_msle: 0.0020\n",
      "Epoch 54/70\n",
      " - 1s - loss: 0.0010 - msle: 0.0010 - val_loss: 0.0020 - val_msle: 0.0020\n",
      "Epoch 55/70\n",
      " - 1s - loss: 9.6620e-04 - msle: 9.6620e-04 - val_loss: 0.0017 - val_msle: 0.0017\n",
      "Epoch 56/70\n",
      " - 1s - loss: 9.5857e-04 - msle: 9.5857e-04 - val_loss: 0.0018 - val_msle: 0.0018\n",
      "Epoch 57/70\n",
      " - 1s - loss: 0.0011 - msle: 0.0011 - val_loss: 0.0026 - val_msle: 0.0026\n",
      "Epoch 58/70\n",
      " - 1s - loss: 0.0010 - msle: 0.0010 - val_loss: 0.0020 - val_msle: 0.0020\n",
      "Epoch 59/70\n",
      " - 1s - loss: 9.5035e-04 - msle: 9.5035e-04 - val_loss: 0.0020 - val_msle: 0.0020\n",
      "Epoch 60/70\n",
      " - 1s - loss: 9.5174e-04 - msle: 9.5174e-04 - val_loss: 0.0022 - val_msle: 0.0022\n",
      "Epoch 61/70\n",
      " - 1s - loss: 9.9926e-04 - msle: 9.9926e-04 - val_loss: 0.0018 - val_msle: 0.0018\n",
      "Epoch 62/70\n",
      " - 1s - loss: 9.2684e-04 - msle: 9.2684e-04 - val_loss: 0.0019 - val_msle: 0.0019\n",
      "Epoch 63/70\n",
      " - 1s - loss: 9.0215e-04 - msle: 9.0215e-04 - val_loss: 0.0018 - val_msle: 0.0018\n",
      "Epoch 64/70\n",
      " - 1s - loss: 9.7234e-04 - msle: 9.7234e-04 - val_loss: 0.0018 - val_msle: 0.0018\n",
      "Epoch 65/70\n",
      " - 1s - loss: 9.5516e-04 - msle: 9.5516e-04 - val_loss: 0.0017 - val_msle: 0.0017\n",
      "Epoch 66/70\n",
      " - 1s - loss: 8.7282e-04 - msle: 8.7282e-04 - val_loss: 0.0019 - val_msle: 0.0019\n",
      "Epoch 67/70\n",
      " - 1s - loss: 8.5700e-04 - msle: 8.5700e-04 - val_loss: 0.0017 - val_msle: 0.0017\n",
      "Epoch 68/70\n",
      " - 1s - loss: 9.2105e-04 - msle: 9.2105e-04 - val_loss: 0.0018 - val_msle: 0.0018\n",
      "Epoch 69/70\n",
      " - 1s - loss: 9.3834e-04 - msle: 9.3834e-04 - val_loss: 0.0021 - val_msle: 0.0021\n",
      "Epoch 70/70\n",
      " - 1s - loss: 8.6995e-04 - msle: 8.6995e-04 - val_loss: 0.0017 - val_msle: 0.0017\n",
      "PREDICTING VALUE FOR       close_19    ADX_19    RSI_19  close_18     ADX_18     RSI_18  close_17  \\\n",
      "1559  62896.48  30.71195  59.85944  61395.01  30.101656  55.332545  60937.12   \n",
      "\n",
      "         ADX_17     RSI_17  close_16  ...   close_2      ADX_2      RSI_2  \\\n",
      "1559  29.534954  53.991563  61470.61  ...  59707.51  23.280175  46.181102   \n",
      "\n",
      "       close_1      ADX_1      RSI_1   close_0      ADX_0      RSI_0     close  \n",
      "1559  58622.02  22.582078  43.776117  56247.18  21.922024  38.991852  54721.03  \n",
      "\n",
      "[1 rows x 61 columns]\n",
      "real [[54721.03]]\n",
      "Test RMSE: 1183.379\n",
      "Diff [[1183.37908185]]\n",
      "% Diff [[2.16256726]] %\n",
      "||||----|||| Current Orders: [] \n",
      "\n",
      "\n",
      "\n",
      "INDEX: 1403\n",
      "CLOSE: 35483.72\n",
      "MODE: sell\n",
      "CHECKING ORDERS...\n",
      "TRAINING MODEL:\n",
      "Input shape: (1403, 1, 60) (1403, 1)\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_13 (LSTM)               (None, 1, 100)            64400     \n",
      "_________________________________________________________________\n",
      "lstm_14 (LSTM)               (None, 1, 50)             30200     \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 1, 50)             0         \n",
      "_________________________________________________________________\n",
      "lstm_15 (LSTM)               (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 51        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 114,851\n",
      "Trainable params: 114,851\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Y shape (1403, 1)\n",
      "Train on 1403 samples, validate on 281 samples\n",
      "Epoch 1/70\n",
      " - 7s - loss: 0.0098 - msle: 0.0098 - val_loss: 0.0062 - val_msle: 0.0062\n",
      "Epoch 2/70\n",
      " - 1s - loss: 0.0531 - msle: 0.0531 - val_loss: 0.0730 - val_msle: 0.0730\n",
      "Epoch 3/70\n",
      " - 1s - loss: 0.0470 - msle: 0.0470 - val_loss: 0.0788 - val_msle: 0.0788\n",
      "Epoch 4/70\n",
      " - 1s - loss: 0.0119 - msle: 0.0119 - val_loss: 0.0040 - val_msle: 0.0040\n",
      "Epoch 5/70\n",
      " - 1s - loss: 0.0067 - msle: 0.0067 - val_loss: 0.0048 - val_msle: 0.0048\n",
      "Epoch 6/70\n",
      " - 1s - loss: 0.0054 - msle: 0.0054 - val_loss: 0.0037 - val_msle: 0.0037\n",
      "Epoch 7/70\n",
      " - 1s - loss: 0.0045 - msle: 0.0045 - val_loss: 0.0041 - val_msle: 0.0041\n",
      "Epoch 8/70\n",
      " - 1s - loss: 0.0033 - msle: 0.0033 - val_loss: 0.0038 - val_msle: 0.0038\n",
      "Epoch 9/70\n",
      " - 1s - loss: 0.0030 - msle: 0.0030 - val_loss: 0.0033 - val_msle: 0.0033\n",
      "Epoch 10/70\n",
      " - 1s - loss: 0.0021 - msle: 0.0021 - val_loss: 0.0034 - val_msle: 0.0034\n",
      "Epoch 11/70\n",
      " - 1s - loss: 0.0024 - msle: 0.0024 - val_loss: 0.0032 - val_msle: 0.0032\n",
      "Epoch 12/70\n",
      " - 1s - loss: 0.0017 - msle: 0.0017 - val_loss: 0.0033 - val_msle: 0.0033\n",
      "Epoch 13/70\n",
      " - 1s - loss: 0.0022 - msle: 0.0022 - val_loss: 0.0031 - val_msle: 0.0031\n",
      "Epoch 14/70\n",
      " - 1s - loss: 0.0016 - msle: 0.0016 - val_loss: 0.0032 - val_msle: 0.0032\n",
      "Epoch 15/70\n",
      " - 1s - loss: 0.0019 - msle: 0.0019 - val_loss: 0.0030 - val_msle: 0.0030\n",
      "Epoch 16/70\n",
      " - 1s - loss: 0.0015 - msle: 0.0015 - val_loss: 0.0031 - val_msle: 0.0031\n",
      "Epoch 17/70\n",
      " - 1s - loss: 0.0017 - msle: 0.0017 - val_loss: 0.0029 - val_msle: 0.0029\n",
      "Epoch 18/70\n",
      " - 1s - loss: 0.0014 - msle: 0.0014 - val_loss: 0.0029 - val_msle: 0.0029\n",
      "Epoch 19/70\n",
      " - 1s - loss: 0.0016 - msle: 0.0016 - val_loss: 0.0028 - val_msle: 0.0028\n",
      "Epoch 20/70\n",
      " - 1s - loss: 0.0013 - msle: 0.0013 - val_loss: 0.0028 - val_msle: 0.0028\n",
      "Epoch 21/70\n",
      " - 1s - loss: 0.0014 - msle: 0.0014 - val_loss: 0.0027 - val_msle: 0.0027\n",
      "Epoch 22/70\n",
      " - 1s - loss: 0.0014 - msle: 0.0014 - val_loss: 0.0028 - val_msle: 0.0028\n",
      "Epoch 23/70\n",
      " - 1s - loss: 0.0016 - msle: 0.0016 - val_loss: 0.0027 - val_msle: 0.0027\n",
      "Epoch 24/70\n",
      " - 1s - loss: 0.0012 - msle: 0.0012 - val_loss: 0.0027 - val_msle: 0.0027\n",
      "Epoch 25/70\n",
      " - 1s - loss: 0.0014 - msle: 0.0014 - val_loss: 0.0027 - val_msle: 0.0027\n",
      "Epoch 26/70\n",
      " - 1s - loss: 0.0013 - msle: 0.0013 - val_loss: 0.0026 - val_msle: 0.0026\n",
      "Epoch 27/70\n",
      " - 1s - loss: 0.0014 - msle: 0.0014 - val_loss: 0.0027 - val_msle: 0.0027\n",
      "Epoch 28/70\n",
      " - 1s - loss: 0.0013 - msle: 0.0013 - val_loss: 0.0026 - val_msle: 0.0026\n",
      "Epoch 29/70\n",
      " - 1s - loss: 0.0014 - msle: 0.0014 - val_loss: 0.0025 - val_msle: 0.0025\n",
      "Epoch 30/70\n",
      " - 1s - loss: 0.0013 - msle: 0.0013 - val_loss: 0.0025 - val_msle: 0.0025\n",
      "Epoch 31/70\n",
      " - 1s - loss: 0.0012 - msle: 0.0012 - val_loss: 0.0025 - val_msle: 0.0025\n",
      "Epoch 32/70\n",
      " - 1s - loss: 0.0012 - msle: 0.0012 - val_loss: 0.0024 - val_msle: 0.0024\n",
      "Epoch 33/70\n",
      " - 1s - loss: 0.0012 - msle: 0.0012 - val_loss: 0.0023 - val_msle: 0.0023\n",
      "Epoch 34/70\n",
      " - 1s - loss: 0.0011 - msle: 0.0011 - val_loss: 0.0024 - val_msle: 0.0024\n",
      "Epoch 35/70\n",
      " - 1s - loss: 0.0013 - msle: 0.0013 - val_loss: 0.0022 - val_msle: 0.0022\n",
      "Epoch 36/70\n",
      " - 1s - loss: 0.0013 - msle: 0.0013 - val_loss: 0.0024 - val_msle: 0.0024\n",
      "Epoch 37/70\n",
      " - 1s - loss: 0.0012 - msle: 0.0012 - val_loss: 0.0022 - val_msle: 0.0022\n",
      "Epoch 38/70\n",
      " - 1s - loss: 0.0012 - msle: 0.0012 - val_loss: 0.0022 - val_msle: 0.0022\n",
      "Epoch 39/70\n",
      " - 1s - loss: 0.0010 - msle: 0.0010 - val_loss: 0.0022 - val_msle: 0.0022\n",
      "Epoch 40/70\n",
      " - 1s - loss: 0.0012 - msle: 0.0012 - val_loss: 0.0021 - val_msle: 0.0021\n",
      "Epoch 41/70\n",
      " - 1s - loss: 0.0012 - msle: 0.0012 - val_loss: 0.0022 - val_msle: 0.0022\n",
      "Epoch 42/70\n",
      " - 1s - loss: 0.0012 - msle: 0.0012 - val_loss: 0.0022 - val_msle: 0.0022\n",
      "Epoch 43/70\n",
      " - 1s - loss: 0.0010 - msle: 0.0010 - val_loss: 0.0020 - val_msle: 0.0020\n",
      "Epoch 44/70\n",
      " - 1s - loss: 9.7805e-04 - msle: 9.7805e-04 - val_loss: 0.0020 - val_msle: 0.0020\n",
      "Epoch 45/70\n",
      " - 1s - loss: 0.0010 - msle: 0.0010 - val_loss: 0.0019 - val_msle: 0.0019\n",
      "Epoch 46/70\n",
      " - 1s - loss: 0.0011 - msle: 0.0011 - val_loss: 0.0021 - val_msle: 0.0021\n",
      "Epoch 47/70\n",
      " - 1s - loss: 0.0010 - msle: 0.0010 - val_loss: 0.0022 - val_msle: 0.0022\n",
      "Epoch 48/70\n",
      " - 1s - loss: 9.5886e-04 - msle: 9.5886e-04 - val_loss: 0.0019 - val_msle: 0.0019\n",
      "Epoch 49/70\n",
      " - 1s - loss: 0.0011 - msle: 0.0011 - val_loss: 0.0022 - val_msle: 0.0022\n",
      "Epoch 50/70\n",
      " - 1s - loss: 9.9476e-04 - msle: 9.9476e-04 - val_loss: 0.0018 - val_msle: 0.0018\n",
      "Epoch 51/70\n",
      " - 1s - loss: 0.0011 - msle: 0.0011 - val_loss: 0.0021 - val_msle: 0.0021\n",
      "Epoch 52/70\n",
      " - 1s - loss: 9.9164e-04 - msle: 9.9164e-04 - val_loss: 0.0020 - val_msle: 0.0020\n",
      "Epoch 53/70\n",
      " - 1s - loss: 9.9088e-04 - msle: 9.9088e-04 - val_loss: 0.0018 - val_msle: 0.0018\n",
      "Epoch 54/70\n",
      " - 1s - loss: 0.0010 - msle: 0.0010 - val_loss: 0.0020 - val_msle: 0.0020\n",
      "Epoch 55/70\n",
      " - 1s - loss: 0.0011 - msle: 0.0011 - val_loss: 0.0022 - val_msle: 0.0022\n",
      "Epoch 56/70\n",
      " - 1s - loss: 0.0011 - msle: 0.0011 - val_loss: 0.0018 - val_msle: 0.0018\n",
      "Epoch 57/70\n",
      " - 1s - loss: 9.6563e-04 - msle: 9.6563e-04 - val_loss: 0.0021 - val_msle: 0.0021\n",
      "Epoch 58/70\n",
      " - 1s - loss: 9.6397e-04 - msle: 9.6397e-04 - val_loss: 0.0020 - val_msle: 0.0020\n",
      "Epoch 59/70\n",
      " - 1s - loss: 0.0010 - msle: 0.0010 - val_loss: 0.0021 - val_msle: 0.0021\n",
      "Epoch 60/70\n",
      " - 1s - loss: 9.9011e-04 - msle: 9.9011e-04 - val_loss: 0.0020 - val_msle: 0.0020\n",
      "Epoch 61/70\n",
      " - 1s - loss: 9.3384e-04 - msle: 9.3384e-04 - val_loss: 0.0016 - val_msle: 0.0016\n",
      "Epoch 62/70\n",
      " - 1s - loss: 9.7089e-04 - msle: 9.7089e-04 - val_loss: 0.0018 - val_msle: 0.0018\n",
      "Epoch 63/70\n",
      " - 1s - loss: 9.2894e-04 - msle: 9.2894e-04 - val_loss: 0.0019 - val_msle: 0.0019\n",
      "Epoch 64/70\n",
      " - 1s - loss: 9.8242e-04 - msle: 9.8242e-04 - val_loss: 0.0021 - val_msle: 0.0021\n",
      "Epoch 65/70\n",
      " - 1s - loss: 9.6326e-04 - msle: 9.6326e-04 - val_loss: 0.0018 - val_msle: 0.0018\n",
      "Epoch 66/70\n",
      " - 1s - loss: 9.8811e-04 - msle: 9.8811e-04 - val_loss: 0.0024 - val_msle: 0.0024\n",
      "Epoch 67/70\n",
      " - 1s - loss: 8.8453e-04 - msle: 8.8453e-04 - val_loss: 0.0017 - val_msle: 0.0017\n",
      "Epoch 68/70\n",
      " - 1s - loss: 0.0010 - msle: 0.0010 - val_loss: 0.0016 - val_msle: 0.0016\n",
      "Epoch 69/70\n",
      " - 1s - loss: 0.0010 - msle: 0.0010 - val_loss: 0.0016 - val_msle: 0.0016\n",
      "Epoch 70/70\n",
      " - 1s - loss: 9.1630e-04 - msle: 9.1630e-04 - val_loss: 0.0016 - val_msle: 0.0016\n",
      "PREDICTING VALUE FOR       close_19     ADX_19     RSI_19  close_18     ADX_18     RSI_18  \\\n",
      "1560  61395.01  30.101656  55.332545  60937.12  29.534954  53.991563   \n",
      "\n",
      "      close_17     ADX_17     RSI_17  close_16  ...   close_2      ADX_2  \\\n",
      "1560  61470.61  28.975831  55.349314  63273.59  ...  58622.02  22.582078   \n",
      "\n",
      "          RSI_2   close_1      ADX_1      RSI_1   close_0      ADX_0  \\\n",
      "1560  43.776117  56247.18  21.922024  38.991852  57541.27  22.171558   \n",
      "\n",
      "          RSI_0     close  \n",
      "1560  42.668771  57274.88  \n",
      "\n",
      "[1 rows x 61 columns]\n",
      "real [[57274.88]]\n",
      "Test RMSE: 3313.870\n",
      "Diff [[3313.87004574]]\n",
      "% Diff [[5.78590483]] %\n",
      "||||----|||| Current Orders: [] \n",
      "\n",
      "\n",
      "\n",
      "INDEX: 1404\n",
      "CLOSE: 35600.16\n",
      "MODE: sell\n",
      "CHECKING ORDERS...\n",
      "TRAINING MODEL:\n",
      "Input shape: (1404, 1, 60) (1404, 1)\n",
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_16 (LSTM)               (None, 1, 100)            64400     \n",
      "_________________________________________________________________\n",
      "lstm_17 (LSTM)               (None, 1, 50)             30200     \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 1, 50)             0         \n",
      "_________________________________________________________________\n",
      "lstm_18 (LSTM)               (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 51        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 114,851\n",
      "Trainable params: 114,851\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Y shape (1404, 1)\n",
      "Train on 1404 samples, validate on 281 samples\n",
      "Epoch 1/70\n",
      " - 7s - loss: 0.0714 - msle: 0.0714 - val_loss: 0.2899 - val_msle: 0.2899\n",
      "Epoch 2/70\n",
      " - 1s - loss: 0.0718 - msle: 0.0718 - val_loss: 0.2899 - val_msle: 0.2899\n",
      "Epoch 3/70\n",
      " - 1s - loss: 0.0718 - msle: 0.0718 - val_loss: 0.2899 - val_msle: 0.2899\n",
      "Epoch 4/70\n",
      " - 1s - loss: 0.0718 - msle: 0.0718 - val_loss: 0.2899 - val_msle: 0.2899\n",
      "Epoch 5/70\n",
      " - 1s - loss: 0.0718 - msle: 0.0718 - val_loss: 0.2899 - val_msle: 0.2899\n",
      "Epoch 6/70\n",
      " - 1s - loss: 0.0718 - msle: 0.0718 - val_loss: 0.2899 - val_msle: 0.2899\n",
      "Epoch 7/70\n",
      " - 1s - loss: 0.0718 - msle: 0.0718 - val_loss: 0.2899 - val_msle: 0.2899\n",
      "Epoch 8/70\n",
      " - 1s - loss: 0.0718 - msle: 0.0718 - val_loss: 0.2899 - val_msle: 0.2899\n",
      "Epoch 9/70\n",
      " - 1s - loss: 0.0718 - msle: 0.0718 - val_loss: 0.2899 - val_msle: 0.2899\n",
      "Epoch 10/70\n",
      " - 1s - loss: 0.0718 - msle: 0.0718 - val_loss: 0.2899 - val_msle: 0.2899\n",
      "Epoch 11/70\n",
      " - 1s - loss: 0.0718 - msle: 0.0718 - val_loss: 0.2899 - val_msle: 0.2899\n",
      "Epoch 12/70\n",
      " - 1s - loss: 0.0718 - msle: 0.0718 - val_loss: 0.2899 - val_msle: 0.2899\n",
      "Epoch 13/70\n",
      " - 1s - loss: 0.0718 - msle: 0.0718 - val_loss: 0.2899 - val_msle: 0.2899\n",
      "Epoch 14/70\n",
      " - 1s - loss: 0.0718 - msle: 0.0718 - val_loss: 0.2899 - val_msle: 0.2899\n",
      "Epoch 15/70\n",
      " - 1s - loss: 0.0718 - msle: 0.0718 - val_loss: 0.2899 - val_msle: 0.2899\n",
      "Epoch 16/70\n",
      " - 1s - loss: 0.0718 - msle: 0.0718 - val_loss: 0.2899 - val_msle: 0.2899\n",
      "Epoch 17/70\n",
      " - 1s - loss: 0.0718 - msle: 0.0718 - val_loss: 0.2899 - val_msle: 0.2899\n",
      "Epoch 18/70\n",
      " - 1s - loss: 0.0718 - msle: 0.0718 - val_loss: 0.2899 - val_msle: 0.2899\n",
      "Epoch 19/70\n",
      " - 1s - loss: 0.0718 - msle: 0.0718 - val_loss: 0.2899 - val_msle: 0.2899\n",
      "Epoch 20/70\n",
      " - 1s - loss: 0.0718 - msle: 0.0718 - val_loss: 0.2899 - val_msle: 0.2899\n",
      "Epoch 21/70\n",
      " - 1s - loss: 0.0718 - msle: 0.0718 - val_loss: 0.2899 - val_msle: 0.2899\n",
      "Epoch 22/70\n",
      " - 1s - loss: 0.0718 - msle: 0.0718 - val_loss: 0.2899 - val_msle: 0.2899\n",
      "Epoch 23/70\n",
      " - 1s - loss: 0.0718 - msle: 0.0718 - val_loss: 0.2899 - val_msle: 0.2899\n",
      "Epoch 24/70\n",
      " - 1s - loss: 0.0718 - msle: 0.0718 - val_loss: 0.2899 - val_msle: 0.2899\n",
      "Epoch 25/70\n",
      " - 1s - loss: 0.0718 - msle: 0.0718 - val_loss: 0.2899 - val_msle: 0.2899\n",
      "Epoch 26/70\n",
      " - 1s - loss: 0.0718 - msle: 0.0718 - val_loss: 0.2899 - val_msle: 0.2899\n",
      "PREDICTING VALUE FOR       close_19     ADX_19     RSI_19  close_18     ADX_18     RSI_18  \\\n",
      "1561  60937.12  29.534954  53.991563  61470.61  28.975831  55.349314   \n",
      "\n",
      "      close_17     ADX_17     RSI_17  close_16  ...   close_2      ADX_2  \\\n",
      "1561  63273.59  28.083785  59.679963  67525.83  ...  56247.18  21.922024   \n",
      "\n",
      "          RSI_2   close_1      ADX_1      RSI_1   close_0     ADX_0  \\\n",
      "1561  38.991852  57541.27  22.171558  42.668771  57138.29  22.48208   \n",
      "\n",
      "          RSI_0     close  \n",
      "1561  41.823453  57776.25  \n",
      "\n",
      "[1 rows x 61 columns]\n",
      "real [[57776.25]]\n",
      "Test RMSE: 54840.362\n",
      "Diff [[54840.36155682]]\n",
      "% Diff [[94.91852025]] %\n",
      "||||----|||| Current Orders: [] \n",
      "\n",
      "\n",
      "\n",
      "INDEX: 1405\n",
      "CLOSE: 31608.93\n",
      "MODE: sell\n",
      "CHECKING ORDERS...\n",
      "TRAINING MODEL:\n",
      "Input shape: (1405, 1, 60) (1405, 1)\n",
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_19 (LSTM)               (None, 1, 100)            64400     \n",
      "_________________________________________________________________\n",
      "lstm_20 (LSTM)               (None, 1, 50)             30200     \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 1, 50)             0         \n",
      "_________________________________________________________________\n",
      "lstm_21 (LSTM)               (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 51        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 114,851\n",
      "Trainable params: 114,851\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Y shape (1405, 1)\n",
      "Train on 1405 samples, validate on 281 samples\n",
      "Epoch 1/70\n",
      " - 6s - loss: 0.0717 - msle: 0.0717 - val_loss: 0.2900 - val_msle: 0.2900\n",
      "Epoch 2/70\n",
      " - 1s - loss: 0.0720 - msle: 0.0720 - val_loss: 0.2900 - val_msle: 0.2900\n",
      "Epoch 3/70\n",
      " - 1s - loss: 0.0720 - msle: 0.0720 - val_loss: 0.2900 - val_msle: 0.2900\n",
      "Epoch 4/70\n",
      " - 1s - loss: 0.0720 - msle: 0.0720 - val_loss: 0.2900 - val_msle: 0.2900\n",
      "Epoch 5/70\n",
      " - 1s - loss: 0.0720 - msle: 0.0720 - val_loss: 0.2900 - val_msle: 0.2900\n",
      "Epoch 6/70\n",
      " - 1s - loss: 0.0720 - msle: 0.0720 - val_loss: 0.2900 - val_msle: 0.2900\n",
      "Epoch 7/70\n",
      " - 1s - loss: 0.0720 - msle: 0.0720 - val_loss: 0.2900 - val_msle: 0.2900\n",
      "Epoch 8/70\n",
      " - 1s - loss: 0.0720 - msle: 0.0720 - val_loss: 0.2900 - val_msle: 0.2900\n",
      "Epoch 9/70\n",
      " - 1s - loss: 0.0720 - msle: 0.0720 - val_loss: 0.2900 - val_msle: 0.2900\n",
      "Epoch 10/70\n",
      " - 1s - loss: 0.0720 - msle: 0.0720 - val_loss: 0.2900 - val_msle: 0.2900\n",
      "Epoch 11/70\n",
      " - 1s - loss: 0.0720 - msle: 0.0720 - val_loss: 0.2900 - val_msle: 0.2900\n",
      "Epoch 12/70\n",
      " - 1s - loss: 0.0720 - msle: 0.0720 - val_loss: 0.2900 - val_msle: 0.2900\n",
      "Epoch 13/70\n",
      " - 1s - loss: 0.0720 - msle: 0.0720 - val_loss: 0.2900 - val_msle: 0.2900\n",
      "Epoch 14/70\n",
      " - 1s - loss: 0.0720 - msle: 0.0720 - val_loss: 0.2900 - val_msle: 0.2900\n",
      "Epoch 15/70\n",
      " - 1s - loss: 0.0720 - msle: 0.0720 - val_loss: 0.2900 - val_msle: 0.2900\n",
      "Epoch 16/70\n",
      " - 1s - loss: 0.0720 - msle: 0.0720 - val_loss: 0.2900 - val_msle: 0.2900\n",
      "Epoch 17/70\n",
      " - 1s - loss: 0.0720 - msle: 0.0720 - val_loss: 0.2900 - val_msle: 0.2900\n",
      "Epoch 18/70\n",
      " - 1s - loss: 0.0720 - msle: 0.0720 - val_loss: 0.2900 - val_msle: 0.2900\n",
      "Epoch 19/70\n",
      " - 1s - loss: 0.0720 - msle: 0.0720 - val_loss: 0.2900 - val_msle: 0.2900\n",
      "Epoch 20/70\n",
      " - 1s - loss: 0.0720 - msle: 0.0720 - val_loss: 0.2900 - val_msle: 0.2900\n",
      "Epoch 21/70\n",
      " - 1s - loss: 0.0720 - msle: 0.0720 - val_loss: 0.2900 - val_msle: 0.2900\n",
      "Epoch 22/70\n",
      " - 1s - loss: 0.0720 - msle: 0.0720 - val_loss: 0.2900 - val_msle: 0.2900\n",
      "Epoch 23/70\n",
      " - 1s - loss: 0.0720 - msle: 0.0720 - val_loss: 0.2900 - val_msle: 0.2900\n",
      "Epoch 24/70\n",
      " - 1s - loss: 0.0720 - msle: 0.0720 - val_loss: 0.2900 - val_msle: 0.2900\n",
      "Epoch 25/70\n",
      " - 1s - loss: 0.0720 - msle: 0.0720 - val_loss: 0.2900 - val_msle: 0.2900\n",
      "Epoch 26/70\n",
      " - 1s - loss: 0.0720 - msle: 0.0720 - val_loss: 0.2900 - val_msle: 0.2900\n",
      "PREDICTING VALUE FOR       close_19     ADX_19     RSI_19  close_18     ADX_18     RSI_18  \\\n",
      "1562  61470.61  28.975831  55.349314  63273.59  28.083785  59.679963   \n",
      "\n",
      "      close_17     ADX_17     RSI_17  close_16  ...   close_2      ADX_2  \\\n",
      "1562  67525.83  28.067493  67.649268  66947.66  ...  57541.27  22.171558   \n",
      "\n",
      "          RSI_2   close_1     ADX_1      RSI_1   close_0      ADX_0  \\\n",
      "1562  42.668771  57138.29  22.48208  41.823453  58960.36  22.709187   \n",
      "\n",
      "          RSI_0     close  \n",
      "1562  46.941786  56950.56  \n",
      "\n",
      "[1 rows x 61 columns]\n",
      "real [[56950.56]]\n",
      "Test RMSE: 53891.649\n",
      "Diff [[53891.64862884]]\n",
      "% Diff [[94.62883004]] %\n",
      "||||----|||| Current Orders: [] \n",
      "\n",
      "\n",
      "\n",
      "INDEX: 1406\n",
      "CLOSE: 32509.56\n",
      "MODE: sell\n",
      "CHECKING ORDERS...\n",
      "TRAINING MODEL:\n",
      "Input shape: (1406, 1, 60) (1406, 1)\n",
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_22 (LSTM)               (None, 1, 100)            64400     \n",
      "_________________________________________________________________\n",
      "lstm_23 (LSTM)               (None, 1, 50)             30200     \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 1, 50)             0         \n",
      "_________________________________________________________________\n",
      "lstm_24 (LSTM)               (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1)                 51        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 114,851\n",
      "Trainable params: 114,851\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Y shape (1406, 1)\n",
      "Train on 1406 samples, validate on 282 samples\n",
      "Epoch 1/70\n",
      " - 6s - loss: 0.0719 - msle: 0.0719 - val_loss: 0.2902 - val_msle: 0.2902\n",
      "Epoch 2/70\n",
      " - 1s - loss: 0.0722 - msle: 0.0722 - val_loss: 0.2902 - val_msle: 0.2902\n",
      "Epoch 3/70\n",
      " - 1s - loss: 0.0722 - msle: 0.0722 - val_loss: 0.2902 - val_msle: 0.2902\n",
      "Epoch 4/70\n",
      " - 1s - loss: 0.0722 - msle: 0.0722 - val_loss: 0.2902 - val_msle: 0.2902\n",
      "Epoch 5/70\n",
      " - 1s - loss: 0.0722 - msle: 0.0722 - val_loss: 0.2902 - val_msle: 0.2902\n",
      "Epoch 6/70\n",
      " - 1s - loss: 0.0722 - msle: 0.0722 - val_loss: 0.2902 - val_msle: 0.2902\n",
      "Epoch 7/70\n",
      " - 1s - loss: 0.0722 - msle: 0.0722 - val_loss: 0.2902 - val_msle: 0.2902\n",
      "Epoch 8/70\n",
      " - 1s - loss: 0.0722 - msle: 0.0722 - val_loss: 0.2902 - val_msle: 0.2902\n",
      "Epoch 9/70\n",
      " - 1s - loss: 0.0722 - msle: 0.0722 - val_loss: 0.2902 - val_msle: 0.2902\n",
      "Epoch 10/70\n",
      " - 1s - loss: 0.0722 - msle: 0.0722 - val_loss: 0.2902 - val_msle: 0.2902\n",
      "Epoch 11/70\n",
      " - 1s - loss: 0.0722 - msle: 0.0722 - val_loss: 0.2902 - val_msle: 0.2902\n",
      "Epoch 12/70\n",
      " - 1s - loss: 0.0722 - msle: 0.0722 - val_loss: 0.2902 - val_msle: 0.2902\n",
      "Epoch 13/70\n",
      " - 1s - loss: 0.0722 - msle: 0.0722 - val_loss: 0.2902 - val_msle: 0.2902\n",
      "Epoch 14/70\n",
      " - 1s - loss: 0.0722 - msle: 0.0722 - val_loss: 0.2902 - val_msle: 0.2902\n",
      "Epoch 15/70\n",
      " - 1s - loss: 0.0722 - msle: 0.0722 - val_loss: 0.2902 - val_msle: 0.2902\n",
      "Epoch 16/70\n",
      " - 1s - loss: 0.0722 - msle: 0.0722 - val_loss: 0.2902 - val_msle: 0.2902\n",
      "Epoch 17/70\n",
      " - 1s - loss: 0.0722 - msle: 0.0722 - val_loss: 0.2902 - val_msle: 0.2902\n",
      "Epoch 18/70\n",
      " - 1s - loss: 0.0722 - msle: 0.0722 - val_loss: 0.2902 - val_msle: 0.2902\n",
      "Epoch 19/70\n",
      " - 1s - loss: 0.0722 - msle: 0.0722 - val_loss: 0.2902 - val_msle: 0.2902\n",
      "Epoch 20/70\n",
      " - 1s - loss: 0.0722 - msle: 0.0722 - val_loss: 0.2902 - val_msle: 0.2902\n",
      "Epoch 21/70\n",
      " - 1s - loss: 0.0722 - msle: 0.0722 - val_loss: 0.2902 - val_msle: 0.2902\n",
      "Epoch 22/70\n",
      " - 1s - loss: 0.0722 - msle: 0.0722 - val_loss: 0.2902 - val_msle: 0.2902\n",
      "Epoch 23/70\n",
      " - 1s - loss: 0.0722 - msle: 0.0722 - val_loss: 0.2902 - val_msle: 0.2902\n",
      "Epoch 24/70\n",
      " - 1s - loss: 0.0722 - msle: 0.0722 - val_loss: 0.2902 - val_msle: 0.2902\n",
      "Epoch 25/70\n",
      " - 1s - loss: 0.0722 - msle: 0.0722 - val_loss: 0.2902 - val_msle: 0.2902\n",
      "Epoch 26/70\n",
      " - 1s - loss: 0.0722 - msle: 0.0722 - val_loss: 0.2902 - val_msle: 0.2902\n",
      "PREDICTING VALUE FOR       close_19     ADX_19     RSI_19  close_18     ADX_18     RSI_18  \\\n",
      "1563  63273.59  28.083785  59.679963  67525.83  28.067493  67.649268   \n",
      "\n",
      "      close_17    ADX_17     RSI_17  close_16  ...   close_2     ADX_2  \\\n",
      "1563  66947.66  29.35133  65.746463  64882.43  ...  57138.29  22.48208   \n",
      "\n",
      "          RSI_2   close_1      ADX_1      RSI_1   close_0      ADX_0  \\\n",
      "1563  41.823453  58960.36  22.709187  46.941786  53726.53  22.201147   \n",
      "\n",
      "         RSI_0     close  \n",
      "1563  36.89936  57184.07  \n",
      "\n",
      "[1 rows x 61 columns]\n",
      "real [[57184.07]]\n",
      "Test RMSE: 54172.545\n",
      "Diff [[54172.54508684]]\n",
      "% Diff [[94.73362964]] %\n",
      "||||----|||| Current Orders: [] \n",
      "\n",
      "\n",
      "\n",
      "INDEX: 1407\n",
      "CLOSE: 33678.07\n",
      "MODE: sell\n",
      "CHECKING ORDERS...\n",
      "TRAINING MODEL:\n",
      "Input shape: (1407, 1, 60) (1407, 1)\n",
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_25 (LSTM)               (None, 1, 100)            64400     \n",
      "_________________________________________________________________\n",
      "lstm_26 (LSTM)               (None, 1, 50)             30200     \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 1, 50)             0         \n",
      "_________________________________________________________________\n",
      "lstm_27 (LSTM)               (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1)                 51        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 114,851\n",
      "Trainable params: 114,851\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Y shape (1407, 1)\n",
      "Train on 1407 samples, validate on 282 samples\n",
      "Epoch 1/70\n",
      " - 7s - loss: 0.0102 - msle: 0.0102 - val_loss: 0.0113 - val_msle: 0.0113\n",
      "Epoch 2/70\n",
      " - 1s - loss: 0.0611 - msle: 0.0611 - val_loss: 0.1024 - val_msle: 0.1024\n",
      "Epoch 3/70\n",
      " - 1s - loss: 0.0369 - msle: 0.0369 - val_loss: 0.0504 - val_msle: 0.0504\n",
      "Epoch 4/70\n",
      " - 1s - loss: 0.0110 - msle: 0.0110 - val_loss: 0.0035 - val_msle: 0.0035\n",
      "Epoch 5/70\n",
      " - 1s - loss: 0.0054 - msle: 0.0054 - val_loss: 0.0056 - val_msle: 0.0056\n",
      "Epoch 6/70\n",
      " - 1s - loss: 0.0045 - msle: 0.0045 - val_loss: 0.0034 - val_msle: 0.0034\n",
      "Epoch 7/70\n",
      " - 1s - loss: 0.0042 - msle: 0.0042 - val_loss: 0.0048 - val_msle: 0.0048\n",
      "Epoch 8/70\n",
      " - 1s - loss: 0.0037 - msle: 0.0037 - val_loss: 0.0035 - val_msle: 0.0035\n",
      "Epoch 9/70\n",
      " - 1s - loss: 0.0039 - msle: 0.0039 - val_loss: 0.0039 - val_msle: 0.0039\n",
      "Epoch 10/70\n",
      " - 1s - loss: 0.0032 - msle: 0.0032 - val_loss: 0.0036 - val_msle: 0.0036\n",
      "Epoch 11/70\n",
      " - 1s - loss: 0.0034 - msle: 0.0034 - val_loss: 0.0034 - val_msle: 0.0034\n",
      "Epoch 12/70\n",
      " - 1s - loss: 0.0022 - msle: 0.0022 - val_loss: 0.0034 - val_msle: 0.0034\n",
      "Epoch 13/70\n",
      " - 1s - loss: 0.0023 - msle: 0.0023 - val_loss: 0.0030 - val_msle: 0.0030\n",
      "Epoch 14/70\n",
      " - 1s - loss: 0.0017 - msle: 0.0017 - val_loss: 0.0031 - val_msle: 0.0031\n",
      "Epoch 15/70\n",
      " - 1s - loss: 0.0021 - msle: 0.0021 - val_loss: 0.0029 - val_msle: 0.0029\n",
      "Epoch 16/70\n",
      " - 1s - loss: 0.0016 - msle: 0.0016 - val_loss: 0.0030 - val_msle: 0.0030\n",
      "Epoch 17/70\n",
      " - 1s - loss: 0.0017 - msle: 0.0017 - val_loss: 0.0029 - val_msle: 0.0029\n",
      "Epoch 18/70\n",
      " - 1s - loss: 0.0015 - msle: 0.0015 - val_loss: 0.0029 - val_msle: 0.0029\n",
      "Epoch 19/70\n",
      " - 1s - loss: 0.0017 - msle: 0.0017 - val_loss: 0.0030 - val_msle: 0.0030\n",
      "Epoch 20/70\n",
      " - 1s - loss: 0.0016 - msle: 0.0016 - val_loss: 0.0029 - val_msle: 0.0029\n",
      "Epoch 21/70\n",
      " - 1s - loss: 0.0017 - msle: 0.0017 - val_loss: 0.0027 - val_msle: 0.0027\n",
      "Epoch 22/70\n",
      " - 1s - loss: 0.0016 - msle: 0.0016 - val_loss: 0.0027 - val_msle: 0.0027\n",
      "Epoch 23/70\n",
      " - 1s - loss: 0.0014 - msle: 0.0014 - val_loss: 0.0027 - val_msle: 0.0027\n",
      "Epoch 24/70\n",
      " - 1s - loss: 0.0014 - msle: 0.0014 - val_loss: 0.0027 - val_msle: 0.0027\n",
      "Epoch 25/70\n",
      " - 1s - loss: 0.0016 - msle: 0.0016 - val_loss: 0.0026 - val_msle: 0.0026\n",
      "Epoch 26/70\n",
      " - 1s - loss: 0.0014 - msle: 0.0014 - val_loss: 0.0026 - val_msle: 0.0026\n",
      "Epoch 27/70\n",
      " - 1s - loss: 0.0014 - msle: 0.0014 - val_loss: 0.0025 - val_msle: 0.0025\n",
      "Epoch 28/70\n",
      " - 1s - loss: 0.0013 - msle: 0.0013 - val_loss: 0.0025 - val_msle: 0.0025\n",
      "Epoch 29/70\n",
      " - 1s - loss: 0.0014 - msle: 0.0014 - val_loss: 0.0026 - val_msle: 0.0026\n",
      "Epoch 30/70\n",
      " - 1s - loss: 0.0014 - msle: 0.0014 - val_loss: 0.0024 - val_msle: 0.0024\n",
      "Epoch 31/70\n",
      " - 1s - loss: 0.0012 - msle: 0.0012 - val_loss: 0.0024 - val_msle: 0.0024\n",
      "Epoch 32/70\n",
      " - 1s - loss: 0.0012 - msle: 0.0012 - val_loss: 0.0024 - val_msle: 0.0024\n",
      "Epoch 33/70\n",
      " - 1s - loss: 0.0014 - msle: 0.0014 - val_loss: 0.0024 - val_msle: 0.0024\n",
      "Epoch 34/70\n",
      " - 1s - loss: 0.0012 - msle: 0.0012 - val_loss: 0.0023 - val_msle: 0.0023\n",
      "Epoch 35/70\n",
      " - 1s - loss: 0.0013 - msle: 0.0013 - val_loss: 0.0023 - val_msle: 0.0023\n",
      "Epoch 36/70\n",
      " - 1s - loss: 0.0013 - msle: 0.0013 - val_loss: 0.0022 - val_msle: 0.0022\n",
      "Epoch 37/70\n",
      " - 1s - loss: 0.0012 - msle: 0.0012 - val_loss: 0.0022 - val_msle: 0.0022\n",
      "Epoch 38/70\n",
      " - 1s - loss: 0.0011 - msle: 0.0011 - val_loss: 0.0022 - val_msle: 0.0022\n",
      "Epoch 39/70\n",
      " - 1s - loss: 0.0012 - msle: 0.0012 - val_loss: 0.0022 - val_msle: 0.0022\n",
      "Epoch 40/70\n",
      " - 1s - loss: 0.0012 - msle: 0.0012 - val_loss: 0.0021 - val_msle: 0.0021\n",
      "Epoch 41/70\n",
      " - 1s - loss: 0.0012 - msle: 0.0012 - val_loss: 0.0021 - val_msle: 0.0021\n",
      "Epoch 42/70\n",
      " - 1s - loss: 0.0011 - msle: 0.0011 - val_loss: 0.0020 - val_msle: 0.0020\n",
      "Epoch 43/70\n",
      " - 1s - loss: 0.0011 - msle: 0.0011 - val_loss: 0.0022 - val_msle: 0.0022\n",
      "Epoch 44/70\n",
      " - 1s - loss: 0.0012 - msle: 0.0012 - val_loss: 0.0020 - val_msle: 0.0020\n",
      "Epoch 45/70\n",
      " - 1s - loss: 0.0012 - msle: 0.0012 - val_loss: 0.0020 - val_msle: 0.0020\n",
      "Epoch 46/70\n",
      " - 1s - loss: 0.0013 - msle: 0.0013 - val_loss: 0.0025 - val_msle: 0.0025\n",
      "Epoch 47/70\n",
      " - 1s - loss: 0.0011 - msle: 0.0011 - val_loss: 0.0019 - val_msle: 0.0019\n",
      "Epoch 48/70\n",
      " - 1s - loss: 0.0011 - msle: 0.0011 - val_loss: 0.0021 - val_msle: 0.0021\n",
      "Epoch 49/70\n",
      " - 1s - loss: 0.0011 - msle: 0.0011 - val_loss: 0.0022 - val_msle: 0.0022\n",
      "Epoch 50/70\n",
      " - 1s - loss: 9.7440e-04 - msle: 9.7440e-04 - val_loss: 0.0018 - val_msle: 0.0018\n",
      "Epoch 51/70\n",
      " - 1s - loss: 0.0011 - msle: 0.0011 - val_loss: 0.0020 - val_msle: 0.0020\n",
      "Epoch 52/70\n",
      " - 1s - loss: 9.6878e-04 - msle: 9.6878e-04 - val_loss: 0.0019 - val_msle: 0.0019\n",
      "Epoch 53/70\n",
      " - 1s - loss: 0.0010 - msle: 0.0010 - val_loss: 0.0020 - val_msle: 0.0020\n",
      "Epoch 54/70\n",
      " - 1s - loss: 9.6981e-04 - msle: 9.6981e-04 - val_loss: 0.0019 - val_msle: 0.0019\n",
      "Epoch 55/70\n",
      " - 1s - loss: 0.0010 - msle: 0.0010 - val_loss: 0.0018 - val_msle: 0.0018\n",
      "Epoch 56/70\n",
      " - 1s - loss: 9.7136e-04 - msle: 9.7136e-04 - val_loss: 0.0018 - val_msle: 0.0018\n",
      "Epoch 57/70\n",
      " - 1s - loss: 9.1968e-04 - msle: 9.1968e-04 - val_loss: 0.0018 - val_msle: 0.0018\n",
      "Epoch 58/70\n",
      " - 1s - loss: 0.0010 - msle: 0.0010 - val_loss: 0.0020 - val_msle: 0.0020\n",
      "Epoch 59/70\n",
      " - 1s - loss: 9.6965e-04 - msle: 9.6965e-04 - val_loss: 0.0018 - val_msle: 0.0018\n",
      "Epoch 60/70\n",
      " - 1s - loss: 8.9233e-04 - msle: 8.9233e-04 - val_loss: 0.0018 - val_msle: 0.0018\n",
      "Epoch 61/70\n",
      " - 1s - loss: 9.8836e-04 - msle: 9.8836e-04 - val_loss: 0.0017 - val_msle: 0.0017\n",
      "Epoch 62/70\n",
      " - 1s - loss: 9.8020e-04 - msle: 9.8020e-04 - val_loss: 0.0019 - val_msle: 0.0019\n",
      "Epoch 63/70\n",
      " - 1s - loss: 9.1566e-04 - msle: 9.1566e-04 - val_loss: 0.0017 - val_msle: 0.0017\n",
      "Epoch 64/70\n",
      " - 1s - loss: 9.5083e-04 - msle: 9.5083e-04 - val_loss: 0.0018 - val_msle: 0.0018\n",
      "Epoch 65/70\n",
      " - 1s - loss: 9.4556e-04 - msle: 9.4556e-04 - val_loss: 0.0022 - val_msle: 0.0022\n",
      "Epoch 66/70\n",
      " - 1s - loss: 8.9447e-04 - msle: 8.9447e-04 - val_loss: 0.0018 - val_msle: 0.0018\n",
      "Epoch 67/70\n",
      " - 1s - loss: 9.4034e-04 - msle: 9.4034e-04 - val_loss: 0.0016 - val_msle: 0.0016\n",
      "Epoch 68/70\n",
      " - 1s - loss: 8.9361e-04 - msle: 8.9361e-04 - val_loss: 0.0016 - val_msle: 0.0016\n",
      "Epoch 69/70\n",
      " - 1s - loss: 8.8111e-04 - msle: 8.8111e-04 - val_loss: 0.0017 - val_msle: 0.0017\n",
      "Epoch 70/70\n",
      " - 1s - loss: 9.2811e-04 - msle: 9.2811e-04 - val_loss: 0.0022 - val_msle: 0.0022\n",
      "PREDICTING VALUE FOR       close_19     ADX_19     RSI_19  close_18    ADX_18     RSI_18  close_17  \\\n",
      "1564  67525.83  28.067493  67.649268  66947.66  29.35133  65.746463  64882.43   \n",
      "\n",
      "         ADX_17     RSI_17  close_16  ...   close_2      ADX_2      RSI_2  \\\n",
      "1564  30.575737  59.327232  64774.26  ...  58960.36  22.709187  46.941786   \n",
      "\n",
      "       close_1      ADX_1     RSI_1   close_0     ADX_0      RSI_0     close  \n",
      "1564  53726.53  22.201147  36.89936  54721.03  22.73231  39.545878  56480.34  \n",
      "\n",
      "[1 rows x 61 columns]\n",
      "real [[56480.34]]\n",
      "Test RMSE: 3254.783\n",
      "Diff [[3254.78311173]]\n",
      "% Diff [[5.76268328]] %\n",
      "||||----|||| Current Orders: [] \n",
      "\n",
      "\n",
      "\n",
      "INDEX: 1408\n",
      "CLOSE: 34663.09\n",
      "MODE: sell\n",
      "CHECKING ORDERS...\n",
      "TRAINING MODEL:\n",
      "Input shape: (1408, 1, 60) (1408, 1)\n",
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_28 (LSTM)               (None, 1, 100)            64400     \n",
      "_________________________________________________________________\n",
      "lstm_29 (LSTM)               (None, 1, 50)             30200     \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 1, 50)             0         \n",
      "_________________________________________________________________\n",
      "lstm_30 (LSTM)               (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 1)                 51        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 114,851\n",
      "Trainable params: 114,851\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Y shape (1408, 1)\n",
      "Train on 1408 samples, validate on 282 samples\n",
      "Epoch 1/70\n",
      " - 7s - loss: 0.0112 - msle: 0.0112 - val_loss: 0.0114 - val_msle: 0.0114\n",
      "Epoch 2/70\n",
      " - 1s - loss: 0.0540 - msle: 0.0540 - val_loss: 0.0652 - val_msle: 0.0652\n",
      "Epoch 3/70\n",
      " - 1s - loss: 0.0503 - msle: 0.0503 - val_loss: 0.0896 - val_msle: 0.0896\n",
      "Epoch 4/70\n",
      " - 1s - loss: 0.0162 - msle: 0.0162 - val_loss: 0.0059 - val_msle: 0.0059\n",
      "Epoch 5/70\n",
      " - 1s - loss: 0.0071 - msle: 0.0071 - val_loss: 0.0056 - val_msle: 0.0056\n",
      "Epoch 6/70\n",
      " - 1s - loss: 0.0059 - msle: 0.0059 - val_loss: 0.0055 - val_msle: 0.0055\n",
      "Epoch 7/70\n",
      " - 1s - loss: 0.0043 - msle: 0.0043 - val_loss: 0.0033 - val_msle: 0.0033\n",
      "Epoch 8/70\n",
      " - 1s - loss: 0.0026 - msle: 0.0026 - val_loss: 0.0037 - val_msle: 0.0037\n",
      "Epoch 9/70\n",
      " - 1s - loss: 0.0025 - msle: 0.0025 - val_loss: 0.0033 - val_msle: 0.0033\n",
      "Epoch 10/70\n",
      " - 1s - loss: 0.0019 - msle: 0.0019 - val_loss: 0.0034 - val_msle: 0.0034\n",
      "Epoch 11/70\n",
      " - 1s - loss: 0.0021 - msle: 0.0021 - val_loss: 0.0032 - val_msle: 0.0032\n",
      "Epoch 12/70\n",
      " - 1s - loss: 0.0017 - msle: 0.0017 - val_loss: 0.0033 - val_msle: 0.0033\n",
      "Epoch 13/70\n",
      " - 1s - loss: 0.0015 - msle: 0.0015 - val_loss: 0.0031 - val_msle: 0.0031\n",
      "Epoch 14/70\n",
      " - 1s - loss: 0.0016 - msle: 0.0016 - val_loss: 0.0031 - val_msle: 0.0031\n",
      "Epoch 15/70\n",
      " - 1s - loss: 0.0016 - msle: 0.0016 - val_loss: 0.0030 - val_msle: 0.0030\n",
      "Epoch 16/70\n",
      " - 1s - loss: 0.0015 - msle: 0.0015 - val_loss: 0.0031 - val_msle: 0.0031\n",
      "Epoch 17/70\n",
      " - 1s - loss: 0.0015 - msle: 0.0015 - val_loss: 0.0030 - val_msle: 0.0030\n",
      "Epoch 18/70\n",
      " - 1s - loss: 0.0015 - msle: 0.0015 - val_loss: 0.0029 - val_msle: 0.0029\n",
      "Epoch 19/70\n",
      " - 1s - loss: 0.0015 - msle: 0.0015 - val_loss: 0.0029 - val_msle: 0.0029\n",
      "Epoch 20/70\n",
      " - 1s - loss: 0.0016 - msle: 0.0016 - val_loss: 0.0029 - val_msle: 0.0029\n",
      "Epoch 21/70\n",
      " - 1s - loss: 0.0014 - msle: 0.0014 - val_loss: 0.0028 - val_msle: 0.0028\n",
      "Epoch 22/70\n",
      " - 1s - loss: 0.0016 - msle: 0.0016 - val_loss: 0.0027 - val_msle: 0.0027\n",
      "Epoch 23/70\n",
      " - 1s - loss: 0.0013 - msle: 0.0013 - val_loss: 0.0027 - val_msle: 0.0027\n",
      "Epoch 24/70\n",
      " - 1s - loss: 0.0014 - msle: 0.0014 - val_loss: 0.0027 - val_msle: 0.0027\n",
      "Epoch 25/70\n",
      " - 1s - loss: 0.0013 - msle: 0.0013 - val_loss: 0.0027 - val_msle: 0.0027\n",
      "Epoch 26/70\n",
      " - 1s - loss: 0.0014 - msle: 0.0014 - val_loss: 0.0027 - val_msle: 0.0027\n",
      "Epoch 27/70\n",
      " - 1s - loss: 0.0013 - msle: 0.0013 - val_loss: 0.0026 - val_msle: 0.0026\n",
      "Epoch 28/70\n",
      " - 1s - loss: 0.0014 - msle: 0.0014 - val_loss: 0.0026 - val_msle: 0.0026\n",
      "Epoch 29/70\n",
      " - 1s - loss: 0.0013 - msle: 0.0013 - val_loss: 0.0026 - val_msle: 0.0026\n",
      "Epoch 30/70\n",
      " - 1s - loss: 0.0012 - msle: 0.0012 - val_loss: 0.0025 - val_msle: 0.0025\n",
      "Epoch 31/70\n",
      " - 1s - loss: 0.0014 - msle: 0.0014 - val_loss: 0.0026 - val_msle: 0.0026\n",
      "Epoch 32/70\n",
      " - 1s - loss: 0.0012 - msle: 0.0012 - val_loss: 0.0024 - val_msle: 0.0024\n",
      "Epoch 33/70\n",
      " - 1s - loss: 0.0013 - msle: 0.0013 - val_loss: 0.0024 - val_msle: 0.0024\n",
      "Epoch 34/70\n",
      " - 1s - loss: 0.0012 - msle: 0.0012 - val_loss: 0.0023 - val_msle: 0.0023\n",
      "Epoch 35/70\n",
      " - 1s - loss: 0.0012 - msle: 0.0012 - val_loss: 0.0024 - val_msle: 0.0024\n",
      "Epoch 36/70\n",
      " - 1s - loss: 0.0011 - msle: 0.0011 - val_loss: 0.0023 - val_msle: 0.0023\n",
      "Epoch 37/70\n",
      " - 1s - loss: 0.0013 - msle: 0.0013 - val_loss: 0.0022 - val_msle: 0.0022\n",
      "Epoch 38/70\n",
      " - 1s - loss: 0.0013 - msle: 0.0013 - val_loss: 0.0023 - val_msle: 0.0023\n",
      "Epoch 39/70\n",
      " - 1s - loss: 0.0013 - msle: 0.0013 - val_loss: 0.0023 - val_msle: 0.0023\n",
      "Epoch 40/70\n",
      " - 1s - loss: 0.0010 - msle: 0.0010 - val_loss: 0.0022 - val_msle: 0.0022\n",
      "Epoch 41/70\n",
      " - 1s - loss: 0.0012 - msle: 0.0012 - val_loss: 0.0021 - val_msle: 0.0021\n",
      "Epoch 42/70\n",
      " - 1s - loss: 0.0012 - msle: 0.0012 - val_loss: 0.0021 - val_msle: 0.0021\n",
      "Epoch 43/70\n",
      " - 1s - loss: 0.0011 - msle: 0.0011 - val_loss: 0.0021 - val_msle: 0.0021\n",
      "Epoch 44/70\n",
      " - 1s - loss: 0.0013 - msle: 0.0013 - val_loss: 0.0023 - val_msle: 0.0023\n",
      "Epoch 45/70\n",
      " - 1s - loss: 0.0011 - msle: 0.0011 - val_loss: 0.0021 - val_msle: 0.0021\n",
      "Epoch 46/70\n",
      " - 1s - loss: 0.0011 - msle: 0.0011 - val_loss: 0.0021 - val_msle: 0.0021\n",
      "Epoch 47/70\n",
      " - 1s - loss: 0.0010 - msle: 0.0010 - val_loss: 0.0020 - val_msle: 0.0020\n",
      "Epoch 48/70\n",
      " - 1s - loss: 0.0012 - msle: 0.0012 - val_loss: 0.0025 - val_msle: 0.0025\n",
      "Epoch 49/70\n",
      " - 1s - loss: 0.0011 - msle: 0.0011 - val_loss: 0.0020 - val_msle: 0.0020\n",
      "Epoch 50/70\n",
      " - 1s - loss: 0.0012 - msle: 0.0012 - val_loss: 0.0019 - val_msle: 0.0019\n",
      "Epoch 51/70\n",
      " - 1s - loss: 0.0011 - msle: 0.0011 - val_loss: 0.0021 - val_msle: 0.0021\n",
      "Epoch 52/70\n",
      " - 1s - loss: 0.0010 - msle: 0.0010 - val_loss: 0.0020 - val_msle: 0.0020\n",
      "Epoch 53/70\n",
      " - 1s - loss: 9.9923e-04 - msle: 9.9923e-04 - val_loss: 0.0018 - val_msle: 0.0018\n",
      "Epoch 54/70\n",
      " - 1s - loss: 0.0011 - msle: 0.0011 - val_loss: 0.0021 - val_msle: 0.0021\n",
      "Epoch 55/70\n",
      " - 1s - loss: 0.0012 - msle: 0.0012 - val_loss: 0.0022 - val_msle: 0.0022\n",
      "Epoch 56/70\n",
      " - 1s - loss: 0.0010 - msle: 0.0010 - val_loss: 0.0018 - val_msle: 0.0018\n",
      "Epoch 57/70\n",
      " - 1s - loss: 0.0010 - msle: 0.0010 - val_loss: 0.0021 - val_msle: 0.0021\n",
      "Epoch 58/70\n",
      " - 1s - loss: 0.0010 - msle: 0.0010 - val_loss: 0.0020 - val_msle: 0.0020\n",
      "Epoch 59/70\n",
      " - 1s - loss: 8.8754e-04 - msle: 8.8754e-04 - val_loss: 0.0020 - val_msle: 0.0020\n",
      "Epoch 60/70\n",
      " - 1s - loss: 9.2348e-04 - msle: 9.2348e-04 - val_loss: 0.0020 - val_msle: 0.0020\n",
      "Epoch 61/70\n",
      " - 1s - loss: 9.6194e-04 - msle: 9.6194e-04 - val_loss: 0.0020 - val_msle: 0.0020\n",
      "Epoch 62/70\n",
      " - 1s - loss: 0.0010 - msle: 0.0010 - val_loss: 0.0019 - val_msle: 0.0019\n",
      "Epoch 63/70\n",
      " - 1s - loss: 9.5193e-04 - msle: 9.5193e-04 - val_loss: 0.0017 - val_msle: 0.0017\n",
      "Epoch 64/70\n",
      " - 1s - loss: 9.8676e-04 - msle: 9.8676e-04 - val_loss: 0.0019 - val_msle: 0.0019\n",
      "Epoch 65/70\n",
      " - 1s - loss: 9.4479e-04 - msle: 9.4479e-04 - val_loss: 0.0017 - val_msle: 0.0017\n",
      "Epoch 66/70\n",
      " - 1s - loss: 9.1184e-04 - msle: 9.1184e-04 - val_loss: 0.0018 - val_msle: 0.0018\n",
      "Epoch 67/70\n",
      " - 1s - loss: 9.3042e-04 - msle: 9.3042e-04 - val_loss: 0.0018 - val_msle: 0.0018\n",
      "Epoch 68/70\n",
      " - 1s - loss: 9.1144e-04 - msle: 9.1144e-04 - val_loss: 0.0016 - val_msle: 0.0016\n",
      "Epoch 69/70\n",
      " - 1s - loss: 8.2844e-04 - msle: 8.2844e-04 - val_loss: 0.0016 - val_msle: 0.0016\n",
      "Epoch 70/70\n",
      " - 1s - loss: 0.0010 - msle: 0.0010 - val_loss: 0.0019 - val_msle: 0.0019\n",
      "PREDICTING VALUE FOR       close_19    ADX_19     RSI_19  close_18     ADX_18     RSI_18  close_17  \\\n",
      "1565  66947.66  29.35133  65.746463  64882.43  30.575737  59.327232  64774.26   \n",
      "\n",
      "         ADX_17     RSI_17  close_16  ...   close_2      ADX_2     RSI_2  \\\n",
      "1565  30.062773  59.002293  64122.23  ...  53726.53  22.201147  36.89936   \n",
      "\n",
      "       close_1     ADX_1      RSI_1   close_0      ADX_0    RSI_0     close  \n",
      "1565  54721.03  22.73231  39.545878  57274.88  23.158874  45.8291  53601.05  \n",
      "\n",
      "[1 rows x 61 columns]\n",
      "real [[53601.05]]\n",
      "Test RMSE: 357.273\n",
      "Diff [[357.27286798]]\n",
      "% Diff [[0.6665408]] %\n",
      "||||----|||| Current Orders: [] \n",
      "\n",
      "\n",
      "\n",
      "INDEX: 1409\n",
      "CLOSE: 31584.45\n",
      "MODE: sell\n",
      "CHECKING ORDERS...\n",
      "TRAINING MODEL:\n",
      "Input shape: (1409, 1, 60) (1409, 1)\n",
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_31 (LSTM)               (None, 1, 100)            64400     \n",
      "_________________________________________________________________\n",
      "lstm_32 (LSTM)               (None, 1, 50)             30200     \n",
      "_________________________________________________________________\n",
      "dropout_21 (Dropout)         (None, 1, 50)             0         \n",
      "_________________________________________________________________\n",
      "lstm_33 (LSTM)               (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_22 (Dropout)         (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 1)                 51        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 114,851\n",
      "Trainable params: 114,851\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Y shape (1409, 1)\n",
      "Train on 1409 samples, validate on 282 samples\n",
      "Epoch 1/70\n",
      " - 6s - loss: 0.0724 - msle: 0.0724 - val_loss: 0.2908 - val_msle: 0.2908\n",
      "Epoch 2/70\n",
      " - 1s - loss: 0.0728 - msle: 0.0728 - val_loss: 0.2908 - val_msle: 0.2908\n",
      "Epoch 3/70\n",
      " - 1s - loss: 0.0728 - msle: 0.0728 - val_loss: 0.2908 - val_msle: 0.2908\n",
      "Epoch 4/70\n",
      " - 1s - loss: 0.0728 - msle: 0.0728 - val_loss: 0.2908 - val_msle: 0.2908\n",
      "Epoch 5/70\n",
      " - 1s - loss: 0.0728 - msle: 0.0728 - val_loss: 0.2908 - val_msle: 0.2908\n",
      "Epoch 6/70\n",
      " - 1s - loss: 0.0728 - msle: 0.0728 - val_loss: 0.2908 - val_msle: 0.2908\n",
      "Epoch 7/70\n",
      " - 1s - loss: 0.0728 - msle: 0.0728 - val_loss: 0.2908 - val_msle: 0.2908\n",
      "Epoch 8/70\n",
      " - 1s - loss: 0.0728 - msle: 0.0728 - val_loss: 0.2908 - val_msle: 0.2908\n",
      "Epoch 9/70\n",
      " - 1s - loss: 0.0728 - msle: 0.0728 - val_loss: 0.2908 - val_msle: 0.2908\n",
      "Epoch 10/70\n",
      " - 1s - loss: 0.0728 - msle: 0.0728 - val_loss: 0.2908 - val_msle: 0.2908\n",
      "Epoch 11/70\n",
      " - 1s - loss: 0.0728 - msle: 0.0728 - val_loss: 0.2908 - val_msle: 0.2908\n",
      "Epoch 12/70\n",
      " - 1s - loss: 0.0728 - msle: 0.0728 - val_loss: 0.2908 - val_msle: 0.2908\n",
      "Epoch 13/70\n",
      " - 1s - loss: 0.0728 - msle: 0.0728 - val_loss: 0.2908 - val_msle: 0.2908\n",
      "Epoch 14/70\n",
      " - 1s - loss: 0.0728 - msle: 0.0728 - val_loss: 0.2908 - val_msle: 0.2908\n",
      "Epoch 15/70\n",
      " - 1s - loss: 0.0728 - msle: 0.0728 - val_loss: 0.2908 - val_msle: 0.2908\n",
      "Epoch 16/70\n",
      " - 1s - loss: 0.0728 - msle: 0.0728 - val_loss: 0.2908 - val_msle: 0.2908\n",
      "Epoch 17/70\n",
      " - 1s - loss: 0.0728 - msle: 0.0728 - val_loss: 0.2908 - val_msle: 0.2908\n",
      "Epoch 18/70\n",
      " - 1s - loss: 0.0728 - msle: 0.0728 - val_loss: 0.2908 - val_msle: 0.2908\n",
      "Epoch 19/70\n",
      " - 1s - loss: 0.0728 - msle: 0.0728 - val_loss: 0.2908 - val_msle: 0.2908\n",
      "Epoch 20/70\n",
      " - 1s - loss: 0.0728 - msle: 0.0728 - val_loss: 0.2908 - val_msle: 0.2908\n",
      "Epoch 21/70\n",
      " - 1s - loss: 0.0728 - msle: 0.0728 - val_loss: 0.2908 - val_msle: 0.2908\n",
      "Epoch 22/70\n",
      " - 1s - loss: 0.0728 - msle: 0.0728 - val_loss: 0.2908 - val_msle: 0.2908\n",
      "Epoch 23/70\n",
      " - 1s - loss: 0.0728 - msle: 0.0728 - val_loss: 0.2908 - val_msle: 0.2908\n",
      "Epoch 24/70\n",
      " - 1s - loss: 0.0728 - msle: 0.0728 - val_loss: 0.2908 - val_msle: 0.2908\n",
      "Epoch 25/70\n",
      " - 1s - loss: 0.0728 - msle: 0.0728 - val_loss: 0.2908 - val_msle: 0.2908\n",
      "Epoch 26/70\n",
      " - 1s - loss: 0.0728 - msle: 0.0728 - val_loss: 0.2908 - val_msle: 0.2908\n",
      "PREDICTING VALUE FOR       close_19     ADX_19     RSI_19  close_18     ADX_18     RSI_18  \\\n",
      "1566  64882.43  30.575737  59.327232  64774.26  30.062773  59.002293   \n",
      "\n",
      "      close_17     ADX_17     RSI_17  close_16  ...   close_2     ADX_2  \\\n",
      "1566  64122.23  29.524246  56.976524   64380.0  ...  54721.03  22.73231   \n",
      "\n",
      "          RSI_2   close_1      ADX_1    RSI_1   close_0      ADX_0      RSI_0  \\\n",
      "1566  39.545878  57274.88  23.158874  45.8291  57776.25  22.645288  46.993843   \n",
      "\n",
      "         close  \n",
      "1566  49152.47  \n",
      "\n",
      "[1 rows x 61 columns]\n",
      "real [[49152.47]]\n",
      "Test RMSE: 46093.697\n",
      "Diff [[46093.69747051]]\n",
      "% Diff [[93.77697086]] %\n",
      "||||----|||| Current Orders: [] \n",
      "\n",
      "\n",
      "\n",
      "INDEX: 1410\n",
      "CLOSE: 32283.65\n",
      "MODE: sell\n",
      "CHECKING ORDERS...\n",
      "TRAINING MODEL:\n",
      "Input shape: (1410, 1, 60) (1410, 1)\n",
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_34 (LSTM)               (None, 1, 100)            64400     \n",
      "_________________________________________________________________\n",
      "lstm_35 (LSTM)               (None, 1, 50)             30200     \n",
      "_________________________________________________________________\n",
      "dropout_23 (Dropout)         (None, 1, 50)             0         \n",
      "_________________________________________________________________\n",
      "lstm_36 (LSTM)               (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_24 (Dropout)         (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 1)                 51        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 114,851\n",
      "Trainable params: 114,851\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Y shape (1410, 1)\n",
      "Train on 1410 samples, validate on 282 samples\n",
      "Epoch 1/70\n",
      " - 6s - loss: 0.0726 - msle: 0.0726 - val_loss: 0.2908 - val_msle: 0.2908\n",
      "Epoch 2/70\n",
      " - 1s - loss: 0.0730 - msle: 0.0730 - val_loss: 0.2908 - val_msle: 0.2908\n",
      "Epoch 3/70\n",
      " - 1s - loss: 0.0730 - msle: 0.0730 - val_loss: 0.2908 - val_msle: 0.2908\n",
      "Epoch 4/70\n",
      " - 1s - loss: 0.0730 - msle: 0.0730 - val_loss: 0.2908 - val_msle: 0.2908\n",
      "Epoch 5/70\n",
      " - 1s - loss: 0.0730 - msle: 0.0730 - val_loss: 0.2908 - val_msle: 0.2908\n",
      "Epoch 6/70\n",
      " - 1s - loss: 0.0730 - msle: 0.0730 - val_loss: 0.2908 - val_msle: 0.2908\n",
      "Epoch 7/70\n",
      " - 1s - loss: 0.0730 - msle: 0.0730 - val_loss: 0.2908 - val_msle: 0.2908\n",
      "Epoch 8/70\n",
      " - 1s - loss: 0.0730 - msle: 0.0730 - val_loss: 0.2908 - val_msle: 0.2908\n",
      "Epoch 9/70\n",
      " - 1s - loss: 0.0730 - msle: 0.0730 - val_loss: 0.2908 - val_msle: 0.2908\n",
      "Epoch 10/70\n",
      " - 1s - loss: 0.0730 - msle: 0.0730 - val_loss: 0.2908 - val_msle: 0.2908\n",
      "Epoch 11/70\n",
      " - 1s - loss: 0.0730 - msle: 0.0730 - val_loss: 0.2908 - val_msle: 0.2908\n",
      "Epoch 12/70\n",
      " - 1s - loss: 0.0730 - msle: 0.0730 - val_loss: 0.2908 - val_msle: 0.2908\n",
      "Epoch 13/70\n",
      " - 1s - loss: 0.0730 - msle: 0.0730 - val_loss: 0.2908 - val_msle: 0.2908\n",
      "Epoch 14/70\n",
      " - 1s - loss: 0.0730 - msle: 0.0730 - val_loss: 0.2908 - val_msle: 0.2908\n",
      "Epoch 15/70\n",
      " - 1s - loss: 0.0730 - msle: 0.0730 - val_loss: 0.2908 - val_msle: 0.2908\n",
      "Epoch 16/70\n",
      " - 1s - loss: 0.0730 - msle: 0.0730 - val_loss: 0.2908 - val_msle: 0.2908\n",
      "Epoch 17/70\n",
      " - 1s - loss: 0.0730 - msle: 0.0730 - val_loss: 0.2908 - val_msle: 0.2908\n",
      "Epoch 18/70\n",
      " - 1s - loss: 0.0730 - msle: 0.0730 - val_loss: 0.2908 - val_msle: 0.2908\n",
      "Epoch 19/70\n",
      " - 1s - loss: 0.0730 - msle: 0.0730 - val_loss: 0.2908 - val_msle: 0.2908\n",
      "Epoch 20/70\n",
      " - 1s - loss: 0.0730 - msle: 0.0730 - val_loss: 0.2908 - val_msle: 0.2908\n",
      "Epoch 21/70\n",
      " - 1s - loss: 0.0730 - msle: 0.0730 - val_loss: 0.2908 - val_msle: 0.2908\n",
      "Epoch 22/70\n",
      " - 1s - loss: 0.0730 - msle: 0.0730 - val_loss: 0.2908 - val_msle: 0.2908\n",
      "Epoch 23/70\n",
      " - 1s - loss: 0.0730 - msle: 0.0730 - val_loss: 0.2908 - val_msle: 0.2908\n",
      "Epoch 24/70\n",
      " - 1s - loss: 0.0730 - msle: 0.0730 - val_loss: 0.2908 - val_msle: 0.2908\n",
      "Epoch 25/70\n",
      " - 1s - loss: 0.0730 - msle: 0.0730 - val_loss: 0.2908 - val_msle: 0.2908\n",
      "Epoch 26/70\n",
      " - 1s - loss: 0.0730 - msle: 0.0730 - val_loss: 0.2908 - val_msle: 0.2908\n",
      "PREDICTING VALUE FOR       close_19     ADX_19     RSI_19  close_18     ADX_18     RSI_18  \\\n",
      "1567  64774.26  30.062773  59.002293  64122.23  29.524246  56.976524   \n",
      "\n",
      "      close_17     ADX_17     RSI_17  close_16  ...   close_2      ADX_2  \\\n",
      "1567   64380.0  28.215527  57.596356   65519.1  ...  57274.88  23.158874   \n",
      "\n",
      "        RSI_2   close_1      ADX_1      RSI_1   close_0      ADX_0      RSI_0  \\\n",
      "1567  45.8291  57776.25  22.645288  46.993843  56950.56  21.618234  45.267626   \n",
      "\n",
      "         close  \n",
      "1567  49396.33  \n",
      "\n",
      "[1 rows x 61 columns]\n",
      "real [[49396.33]]\n",
      "Test RMSE: 46387.873\n",
      "Diff [[46387.87291571]]\n",
      "% Diff [[93.90955343]] %\n",
      "||||----|||| Current Orders: [] \n",
      "\n",
      "\n",
      "\n",
      "INDEX: 1411\n",
      "CLOSE: 34700.34\n",
      "MODE: sell\n",
      "CHECKING ORDERS...\n",
      "TRAINING MODEL:\n",
      "Input shape: (1411, 1, 60) (1411, 1)\n",
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_37 (LSTM)               (None, 1, 100)            64400     \n",
      "_________________________________________________________________\n",
      "lstm_38 (LSTM)               (None, 1, 50)             30200     \n",
      "_________________________________________________________________\n",
      "dropout_25 (Dropout)         (None, 1, 50)             0         \n",
      "_________________________________________________________________\n",
      "lstm_39 (LSTM)               (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_26 (Dropout)         (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 1)                 51        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 114,851\n",
      "Trainable params: 114,851\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Y shape (1411, 1)\n",
      "Train on 1411 samples, validate on 283 samples\n",
      "Epoch 1/70\n",
      " - 6s - loss: 0.0727 - msle: 0.0727 - val_loss: 0.2908 - val_msle: 0.2908\n",
      "Epoch 2/70\n",
      " - 1s - loss: 0.0731 - msle: 0.0731 - val_loss: 0.2908 - val_msle: 0.2908\n",
      "Epoch 3/70\n",
      " - 1s - loss: 0.0731 - msle: 0.0731 - val_loss: 0.2908 - val_msle: 0.2908\n",
      "Epoch 4/70\n",
      " - 1s - loss: 0.0731 - msle: 0.0731 - val_loss: 0.2908 - val_msle: 0.2908\n",
      "Epoch 5/70\n",
      " - 1s - loss: 0.0731 - msle: 0.0731 - val_loss: 0.2908 - val_msle: 0.2908\n",
      "Epoch 6/70\n",
      " - 1s - loss: 0.0731 - msle: 0.0731 - val_loss: 0.2908 - val_msle: 0.2908\n",
      "Epoch 7/70\n",
      " - 1s - loss: 0.0731 - msle: 0.0731 - val_loss: 0.2908 - val_msle: 0.2908\n",
      "Epoch 8/70\n",
      " - 1s - loss: 0.0731 - msle: 0.0731 - val_loss: 0.2908 - val_msle: 0.2908\n",
      "Epoch 9/70\n",
      " - 1s - loss: 0.0731 - msle: 0.0731 - val_loss: 0.2908 - val_msle: 0.2908\n",
      "Epoch 10/70\n",
      " - 1s - loss: 0.0731 - msle: 0.0731 - val_loss: 0.2908 - val_msle: 0.2908\n",
      "Epoch 11/70\n",
      " - 1s - loss: 0.0731 - msle: 0.0731 - val_loss: 0.2908 - val_msle: 0.2908\n",
      "Epoch 12/70\n",
      " - 1s - loss: 0.0731 - msle: 0.0731 - val_loss: 0.2908 - val_msle: 0.2908\n",
      "Epoch 13/70\n",
      " - 1s - loss: 0.0731 - msle: 0.0731 - val_loss: 0.2908 - val_msle: 0.2908\n",
      "Epoch 14/70\n",
      " - 1s - loss: 0.0731 - msle: 0.0731 - val_loss: 0.2908 - val_msle: 0.2908\n",
      "Epoch 15/70\n",
      " - 1s - loss: 0.0731 - msle: 0.0731 - val_loss: 0.2908 - val_msle: 0.2908\n",
      "Epoch 16/70\n",
      " - 1s - loss: 0.0731 - msle: 0.0731 - val_loss: 0.2908 - val_msle: 0.2908\n",
      "Epoch 17/70\n",
      " - 1s - loss: 0.0731 - msle: 0.0731 - val_loss: 0.2908 - val_msle: 0.2908\n",
      "Epoch 18/70\n",
      " - 1s - loss: 0.0731 - msle: 0.0731 - val_loss: 0.2908 - val_msle: 0.2908\n",
      "Epoch 19/70\n",
      " - 1s - loss: 0.0731 - msle: 0.0731 - val_loss: 0.2908 - val_msle: 0.2908\n",
      "Epoch 20/70\n",
      " - 1s - loss: 0.0731 - msle: 0.0731 - val_loss: 0.2908 - val_msle: 0.2908\n",
      "Epoch 21/70\n",
      " - 1s - loss: 0.0731 - msle: 0.0731 - val_loss: 0.2908 - val_msle: 0.2908\n",
      "Epoch 22/70\n",
      " - 1s - loss: 0.0731 - msle: 0.0731 - val_loss: 0.2908 - val_msle: 0.2908\n",
      "Epoch 23/70\n",
      " - 1s - loss: 0.0731 - msle: 0.0731 - val_loss: 0.2908 - val_msle: 0.2908\n",
      "Epoch 24/70\n",
      " - 1s - loss: 0.0731 - msle: 0.0731 - val_loss: 0.2908 - val_msle: 0.2908\n",
      "Epoch 25/70\n",
      " - 1s - loss: 0.0731 - msle: 0.0731 - val_loss: 0.2908 - val_msle: 0.2908\n",
      "Epoch 26/70\n",
      " - 1s - loss: 0.0731 - msle: 0.0731 - val_loss: 0.2908 - val_msle: 0.2908\n",
      "PREDICTING VALUE FOR       close_19     ADX_19     RSI_19  close_18     ADX_18     RSI_18  \\\n",
      "1568  64122.23  29.524246  56.976524   64380.0  28.215527  57.596356   \n",
      "\n",
      "      close_17    ADX_17     RSI_17  close_16  ...   close_2      ADX_2  \\\n",
      "1568   65519.1  27.01545  60.317088  63606.74  ...  57776.25  22.645288   \n",
      "\n",
      "          RSI_2   close_1      ADX_1      RSI_1   close_0      ADX_0  \\\n",
      "1568  46.993843  56950.56  21.618234  45.267626  57184.07  20.798744   \n",
      "\n",
      "          RSI_0     close  \n",
      "1568  45.873163  50441.92  \n",
      "\n",
      "[1 rows x 61 columns]\n",
      "real [[50441.92]]\n",
      "Test RMSE: 47446.942\n",
      "Diff [[47446.94217766]]\n",
      "% Diff [[94.06252216]] %\n",
      "||||----|||| Current Orders: [] \n",
      "\n",
      "\n",
      "\n",
      "INDEX: 1412\n",
      "CLOSE: 34494.89\n",
      "MODE: sell\n",
      "CHECKING ORDERS...\n",
      "TRAINING MODEL:\n",
      "Input shape: (1412, 1, 60) (1412, 1)\n",
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_40 (LSTM)               (None, 1, 100)            64400     \n",
      "_________________________________________________________________\n",
      "lstm_41 (LSTM)               (None, 1, 50)             30200     \n",
      "_________________________________________________________________\n",
      "dropout_27 (Dropout)         (None, 1, 50)             0         \n",
      "_________________________________________________________________\n",
      "lstm_42 (LSTM)               (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_28 (Dropout)         (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 1)                 51        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 114,851\n",
      "Trainable params: 114,851\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Y shape (1412, 1)\n",
      "Train on 1412 samples, validate on 283 samples\n",
      "Epoch 1/70\n",
      " - 6s - loss: 0.0729 - msle: 0.0729 - val_loss: 0.2910 - val_msle: 0.2910\n",
      "Epoch 2/70\n",
      " - 1s - loss: 0.0733 - msle: 0.0733 - val_loss: 0.2910 - val_msle: 0.2910\n",
      "Epoch 3/70\n",
      " - 1s - loss: 0.0733 - msle: 0.0733 - val_loss: 0.2910 - val_msle: 0.2910\n",
      "Epoch 4/70\n",
      " - 1s - loss: 0.0733 - msle: 0.0733 - val_loss: 0.2910 - val_msle: 0.2910\n",
      "Epoch 5/70\n",
      " - 1s - loss: 0.0733 - msle: 0.0733 - val_loss: 0.2910 - val_msle: 0.2910\n",
      "Epoch 6/70\n",
      " - 1s - loss: 0.0733 - msle: 0.0733 - val_loss: 0.2910 - val_msle: 0.2910\n",
      "Epoch 7/70\n",
      " - 1s - loss: 0.0733 - msle: 0.0733 - val_loss: 0.2910 - val_msle: 0.2910\n",
      "Epoch 8/70\n",
      " - 1s - loss: 0.0733 - msle: 0.0733 - val_loss: 0.2910 - val_msle: 0.2910\n",
      "Epoch 9/70\n",
      " - 1s - loss: 0.0733 - msle: 0.0733 - val_loss: 0.2910 - val_msle: 0.2910\n",
      "Epoch 10/70\n",
      " - 1s - loss: 0.0521 - msle: 0.0521 - val_loss: 0.0055 - val_msle: 0.0055\n",
      "Epoch 11/70\n",
      " - 1s - loss: 0.0589 - msle: 0.0589 - val_loss: 0.0772 - val_msle: 0.0772\n",
      "Epoch 12/70\n",
      " - 1s - loss: 0.0129 - msle: 0.0129 - val_loss: 0.0050 - val_msle: 0.0050\n",
      "Epoch 13/70\n",
      " - 1s - loss: 0.0067 - msle: 0.0067 - val_loss: 0.0053 - val_msle: 0.0053\n",
      "Epoch 14/70\n",
      " - 1s - loss: 0.0045 - msle: 0.0045 - val_loss: 0.0035 - val_msle: 0.0035\n",
      "Epoch 15/70\n",
      " - 1s - loss: 0.0043 - msle: 0.0043 - val_loss: 0.0048 - val_msle: 0.0048\n",
      "Epoch 16/70\n",
      " - 1s - loss: 0.0037 - msle: 0.0037 - val_loss: 0.0034 - val_msle: 0.0034\n",
      "Epoch 17/70\n",
      " - 1s - loss: 0.0034 - msle: 0.0034 - val_loss: 0.0035 - val_msle: 0.0035\n",
      "Epoch 18/70\n",
      " - 1s - loss: 0.0023 - msle: 0.0023 - val_loss: 0.0033 - val_msle: 0.0033\n",
      "Epoch 19/70\n",
      " - 1s - loss: 0.0024 - msle: 0.0024 - val_loss: 0.0032 - val_msle: 0.0032\n",
      "Epoch 20/70\n",
      " - 1s - loss: 0.0019 - msle: 0.0019 - val_loss: 0.0032 - val_msle: 0.0032\n",
      "Epoch 21/70\n",
      " - 1s - loss: 0.0020 - msle: 0.0020 - val_loss: 0.0031 - val_msle: 0.0031\n",
      "Epoch 22/70\n",
      " - 1s - loss: 0.0017 - msle: 0.0017 - val_loss: 0.0031 - val_msle: 0.0031\n",
      "Epoch 23/70\n",
      " - 1s - loss: 0.0016 - msle: 0.0016 - val_loss: 0.0030 - val_msle: 0.0030\n",
      "Epoch 24/70\n",
      " - 1s - loss: 0.0016 - msle: 0.0016 - val_loss: 0.0030 - val_msle: 0.0030\n",
      "Epoch 25/70\n",
      " - 1s - loss: 0.0016 - msle: 0.0016 - val_loss: 0.0030 - val_msle: 0.0030\n",
      "Epoch 26/70\n",
      " - 1s - loss: 0.0015 - msle: 0.0015 - val_loss: 0.0029 - val_msle: 0.0029\n",
      "Epoch 27/70\n",
      " - 1s - loss: 0.0015 - msle: 0.0015 - val_loss: 0.0030 - val_msle: 0.0030\n",
      "Epoch 28/70\n",
      " - 1s - loss: 0.0016 - msle: 0.0016 - val_loss: 0.0029 - val_msle: 0.0029\n",
      "Epoch 29/70\n",
      " - 1s - loss: 0.0015 - msle: 0.0015 - val_loss: 0.0029 - val_msle: 0.0029\n",
      "Epoch 30/70\n",
      " - 1s - loss: 0.0015 - msle: 0.0015 - val_loss: 0.0028 - val_msle: 0.0028\n",
      "Epoch 31/70\n",
      " - 1s - loss: 0.0013 - msle: 0.0013 - val_loss: 0.0028 - val_msle: 0.0028\n",
      "Epoch 32/70\n",
      " - 1s - loss: 0.0016 - msle: 0.0016 - val_loss: 0.0028 - val_msle: 0.0028\n",
      "Epoch 33/70\n",
      " - 1s - loss: 0.0014 - msle: 0.0014 - val_loss: 0.0028 - val_msle: 0.0028\n",
      "Epoch 34/70\n",
      " - 1s - loss: 0.0014 - msle: 0.0014 - val_loss: 0.0027 - val_msle: 0.0027\n",
      "Epoch 35/70\n",
      " - 1s - loss: 0.0012 - msle: 0.0012 - val_loss: 0.0027 - val_msle: 0.0027\n",
      "Epoch 36/70\n",
      " - 1s - loss: 0.0012 - msle: 0.0012 - val_loss: 0.0027 - val_msle: 0.0027\n",
      "Epoch 37/70\n",
      " - 1s - loss: 0.0013 - msle: 0.0013 - val_loss: 0.0026 - val_msle: 0.0026\n",
      "Epoch 38/70\n",
      " - 1s - loss: 0.0013 - msle: 0.0013 - val_loss: 0.0025 - val_msle: 0.0025\n",
      "Epoch 39/70\n",
      " - 1s - loss: 0.0013 - msle: 0.0013 - val_loss: 0.0025 - val_msle: 0.0025\n",
      "Epoch 40/70\n",
      " - 1s - loss: 0.0013 - msle: 0.0013 - val_loss: 0.0026 - val_msle: 0.0026\n",
      "Epoch 41/70\n",
      " - 1s - loss: 0.0013 - msle: 0.0013 - val_loss: 0.0025 - val_msle: 0.0025\n",
      "Epoch 42/70\n",
      " - 1s - loss: 0.0012 - msle: 0.0012 - val_loss: 0.0025 - val_msle: 0.0025\n",
      "Epoch 43/70\n",
      " - 1s - loss: 0.0012 - msle: 0.0012 - val_loss: 0.0025 - val_msle: 0.0025\n",
      "Epoch 44/70\n",
      " - 1s - loss: 0.0013 - msle: 0.0013 - val_loss: 0.0024 - val_msle: 0.0024\n",
      "Epoch 45/70\n",
      " - 1s - loss: 0.0012 - msle: 0.0012 - val_loss: 0.0024 - val_msle: 0.0024\n",
      "Epoch 46/70\n",
      " - 1s - loss: 0.0013 - msle: 0.0013 - val_loss: 0.0024 - val_msle: 0.0024\n",
      "Epoch 47/70\n",
      " - 1s - loss: 0.0012 - msle: 0.0012 - val_loss: 0.0024 - val_msle: 0.0024\n",
      "Epoch 48/70\n",
      " - 1s - loss: 0.0012 - msle: 0.0012 - val_loss: 0.0023 - val_msle: 0.0023\n",
      "Epoch 49/70\n",
      " - 1s - loss: 0.0010 - msle: 0.0010 - val_loss: 0.0024 - val_msle: 0.0024\n",
      "Epoch 50/70\n",
      " - 1s - loss: 0.0012 - msle: 0.0012 - val_loss: 0.0025 - val_msle: 0.0025\n",
      "Epoch 51/70\n",
      " - 1s - loss: 0.0014 - msle: 0.0014 - val_loss: 0.0026 - val_msle: 0.0026\n",
      "Epoch 52/70\n",
      " - 1s - loss: 0.0011 - msle: 0.0011 - val_loss: 0.0022 - val_msle: 0.0022\n",
      "Epoch 53/70\n",
      " - 1s - loss: 0.0011 - msle: 0.0011 - val_loss: 0.0021 - val_msle: 0.0021\n",
      "Epoch 54/70\n",
      " - 1s - loss: 0.0011 - msle: 0.0011 - val_loss: 0.0022 - val_msle: 0.0022\n",
      "Epoch 55/70\n",
      " - 1s - loss: 0.0011 - msle: 0.0011 - val_loss: 0.0021 - val_msle: 0.0021\n",
      "Epoch 56/70\n",
      " - 1s - loss: 0.0011 - msle: 0.0011 - val_loss: 0.0023 - val_msle: 0.0023\n",
      "Epoch 57/70\n",
      " - 1s - loss: 0.0011 - msle: 0.0011 - val_loss: 0.0021 - val_msle: 0.0021\n",
      "Epoch 58/70\n",
      " - 1s - loss: 0.0012 - msle: 0.0012 - val_loss: 0.0020 - val_msle: 0.0020\n",
      "Epoch 59/70\n",
      " - 1s - loss: 0.0011 - msle: 0.0011 - val_loss: 0.0021 - val_msle: 0.0021\n",
      "Epoch 60/70\n",
      " - 1s - loss: 0.0010 - msle: 0.0010 - val_loss: 0.0020 - val_msle: 0.0020\n",
      "Epoch 61/70\n",
      " - 1s - loss: 0.0012 - msle: 0.0012 - val_loss: 0.0020 - val_msle: 0.0020\n",
      "Epoch 62/70\n",
      " - 1s - loss: 0.0011 - msle: 0.0011 - val_loss: 0.0022 - val_msle: 0.0022\n",
      "Epoch 63/70\n",
      " - 1s - loss: 0.0011 - msle: 0.0011 - val_loss: 0.0021 - val_msle: 0.0021\n",
      "Epoch 64/70\n",
      " - 1s - loss: 0.0010 - msle: 0.0010 - val_loss: 0.0020 - val_msle: 0.0020\n",
      "Epoch 65/70\n",
      " - 1s - loss: 0.0011 - msle: 0.0011 - val_loss: 0.0020 - val_msle: 0.0020\n",
      "Epoch 66/70\n",
      " - 1s - loss: 0.0011 - msle: 0.0011 - val_loss: 0.0020 - val_msle: 0.0020\n",
      "Epoch 67/70\n",
      " - 1s - loss: 8.9637e-04 - msle: 8.9637e-04 - val_loss: 0.0019 - val_msle: 0.0019\n",
      "Epoch 68/70\n",
      " - 1s - loss: 9.4621e-04 - msle: 9.4621e-04 - val_loss: 0.0020 - val_msle: 0.0020\n",
      "Epoch 69/70\n",
      " - 1s - loss: 8.6221e-04 - msle: 8.6221e-04 - val_loss: 0.0018 - val_msle: 0.0018\n",
      "Epoch 70/70\n",
      " - 1s - loss: 0.0010 - msle: 0.0010 - val_loss: 0.0020 - val_msle: 0.0020\n",
      "PREDICTING VALUE FOR       close_19     ADX_19     RSI_19  close_18    ADX_18     RSI_18  close_17  \\\n",
      "1569   64380.0  28.215527  57.596356   65519.1  27.01545  60.317088  63606.74   \n",
      "\n",
      "         ADX_17     RSI_17  close_16  ...   close_2      ADX_2      RSI_2  \\\n",
      "1569  26.114754  54.047349  60058.87  ...  56950.56  21.618234  45.267626   \n",
      "\n",
      "       close_1      ADX_1      RSI_1   close_0      ADX_0      RSI_0     close  \n",
      "1569  57184.07  20.798744  45.873163  56480.34  20.055789  44.283082  50588.95  \n",
      "\n",
      "[1 rows x 61 columns]\n",
      "real [[50588.95]]\n",
      "Test RMSE: 3185.039\n",
      "Diff [[-3185.0389083]]\n",
      "% Diff [[-6.2959182]] %\n",
      "||||----|||| Current Orders: [] \n",
      "\n",
      "\n",
      "\n",
      "INDEX: 1413\n",
      "CLOSE: 35911.73\n",
      "MODE: sell\n",
      "CHECKING ORDERS...\n",
      "TRAINING MODEL:\n",
      "Input shape: (1413, 1, 60) (1413, 1)\n",
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_43 (LSTM)               (None, 1, 100)            64400     \n",
      "_________________________________________________________________\n",
      "lstm_44 (LSTM)               (None, 1, 50)             30200     \n",
      "_________________________________________________________________\n",
      "dropout_29 (Dropout)         (None, 1, 50)             0         \n",
      "_________________________________________________________________\n",
      "lstm_45 (LSTM)               (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_30 (Dropout)         (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 1)                 51        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 114,851\n",
      "Trainable params: 114,851\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Y shape (1413, 1)\n",
      "Train on 1413 samples, validate on 283 samples\n",
      "Epoch 1/70\n",
      " - 7s - loss: 0.0731 - msle: 0.0731 - val_loss: 0.2911 - val_msle: 0.2911\n",
      "Epoch 2/70\n",
      " - 1s - loss: 0.0735 - msle: 0.0735 - val_loss: 0.2911 - val_msle: 0.2911\n",
      "Epoch 3/70\n",
      " - 1s - loss: 0.0735 - msle: 0.0735 - val_loss: 0.2911 - val_msle: 0.2911\n",
      "Epoch 4/70\n",
      " - 1s - loss: 0.0735 - msle: 0.0735 - val_loss: 0.2911 - val_msle: 0.2911\n",
      "Epoch 5/70\n",
      " - 1s - loss: 0.0735 - msle: 0.0735 - val_loss: 0.2911 - val_msle: 0.2911\n",
      "Epoch 6/70\n",
      " - 1s - loss: 0.0735 - msle: 0.0735 - val_loss: 0.2911 - val_msle: 0.2911\n",
      "Epoch 7/70\n",
      " - 1s - loss: 0.0735 - msle: 0.0735 - val_loss: 0.2911 - val_msle: 0.2911\n",
      "Epoch 8/70\n",
      " - 1s - loss: 0.0735 - msle: 0.0735 - val_loss: 0.2911 - val_msle: 0.2911\n",
      "Epoch 9/70\n",
      " - 1s - loss: 0.0124 - msle: 0.0124 - val_loss: 0.0221 - val_msle: 0.0221\n",
      "Epoch 10/70\n",
      " - 1s - loss: 0.0648 - msle: 0.0648 - val_loss: 0.1117 - val_msle: 0.1117\n",
      "Epoch 11/70\n",
      " - 1s - loss: 0.0266 - msle: 0.0266 - val_loss: 0.0198 - val_msle: 0.0198\n",
      "Epoch 12/70\n",
      " - 1s - loss: 0.0080 - msle: 0.0080 - val_loss: 0.0054 - val_msle: 0.0054\n",
      "Epoch 13/70\n",
      " - 1s - loss: 0.0058 - msle: 0.0058 - val_loss: 0.0039 - val_msle: 0.0039\n",
      "Epoch 14/70\n",
      " - 1s - loss: 0.0038 - msle: 0.0038 - val_loss: 0.0041 - val_msle: 0.0041\n",
      "Epoch 15/70\n",
      " - 1s - loss: 0.0029 - msle: 0.0029 - val_loss: 0.0039 - val_msle: 0.0039\n",
      "Epoch 16/70\n",
      " - 1s - loss: 0.0025 - msle: 0.0025 - val_loss: 0.0035 - val_msle: 0.0035\n",
      "Epoch 17/70\n",
      " - 1s - loss: 0.0021 - msle: 0.0021 - val_loss: 0.0036 - val_msle: 0.0036\n",
      "Epoch 18/70\n",
      " - 1s - loss: 0.0022 - msle: 0.0022 - val_loss: 0.0034 - val_msle: 0.0034\n",
      "Epoch 19/70\n",
      " - 1s - loss: 0.0018 - msle: 0.0018 - val_loss: 0.0034 - val_msle: 0.0034\n",
      "Epoch 20/70\n",
      " - 1s - loss: 0.0019 - msle: 0.0019 - val_loss: 0.0033 - val_msle: 0.0033\n",
      "Epoch 21/70\n",
      " - 1s - loss: 0.0016 - msle: 0.0016 - val_loss: 0.0033 - val_msle: 0.0033\n",
      "Epoch 22/70\n",
      " - 1s - loss: 0.0018 - msle: 0.0018 - val_loss: 0.0032 - val_msle: 0.0032\n",
      "Epoch 23/70\n",
      " - 1s - loss: 0.0016 - msle: 0.0016 - val_loss: 0.0032 - val_msle: 0.0032\n",
      "Epoch 24/70\n",
      " - 1s - loss: 0.0016 - msle: 0.0016 - val_loss: 0.0031 - val_msle: 0.0031\n",
      "Epoch 25/70\n",
      " - 1s - loss: 0.0015 - msle: 0.0015 - val_loss: 0.0031 - val_msle: 0.0031\n",
      "Epoch 26/70\n",
      " - 1s - loss: 0.0014 - msle: 0.0014 - val_loss: 0.0030 - val_msle: 0.0030\n",
      "Epoch 27/70\n",
      " - 1s - loss: 0.0016 - msle: 0.0016 - val_loss: 0.0031 - val_msle: 0.0031\n",
      "Epoch 28/70\n",
      " - 1s - loss: 0.0016 - msle: 0.0016 - val_loss: 0.0029 - val_msle: 0.0029\n",
      "Epoch 29/70\n",
      " - 1s - loss: 0.0014 - msle: 0.0014 - val_loss: 0.0030 - val_msle: 0.0030\n",
      "Epoch 30/70\n",
      " - 1s - loss: 0.0014 - msle: 0.0014 - val_loss: 0.0028 - val_msle: 0.0028\n",
      "Epoch 31/70\n",
      " - 1s - loss: 0.0014 - msle: 0.0014 - val_loss: 0.0028 - val_msle: 0.0028\n",
      "Epoch 32/70\n",
      " - 1s - loss: 0.0014 - msle: 0.0014 - val_loss: 0.0028 - val_msle: 0.0028\n",
      "Epoch 33/70\n",
      " - 1s - loss: 0.0013 - msle: 0.0013 - val_loss: 0.0027 - val_msle: 0.0027\n",
      "Epoch 34/70\n",
      " - 1s - loss: 0.0014 - msle: 0.0014 - val_loss: 0.0027 - val_msle: 0.0027\n",
      "Epoch 35/70\n",
      " - 1s - loss: 0.0013 - msle: 0.0013 - val_loss: 0.0026 - val_msle: 0.0026\n",
      "Epoch 36/70\n",
      " - 1s - loss: 0.0013 - msle: 0.0013 - val_loss: 0.0026 - val_msle: 0.0026\n",
      "Epoch 37/70\n",
      " - 1s - loss: 0.0013 - msle: 0.0013 - val_loss: 0.0025 - val_msle: 0.0025\n",
      "Epoch 38/70\n",
      " - 1s - loss: 0.0014 - msle: 0.0014 - val_loss: 0.0025 - val_msle: 0.0025\n",
      "Epoch 39/70\n",
      " - 1s - loss: 0.0012 - msle: 0.0012 - val_loss: 0.0024 - val_msle: 0.0024\n",
      "Epoch 40/70\n",
      " - 1s - loss: 0.0013 - msle: 0.0013 - val_loss: 0.0023 - val_msle: 0.0023\n",
      "Epoch 41/70\n",
      " - 1s - loss: 0.0013 - msle: 0.0013 - val_loss: 0.0024 - val_msle: 0.0024\n",
      "Epoch 42/70\n",
      " - 1s - loss: 0.0013 - msle: 0.0013 - val_loss: 0.0022 - val_msle: 0.0022\n",
      "Epoch 43/70\n",
      " - 1s - loss: 0.0013 - msle: 0.0013 - val_loss: 0.0022 - val_msle: 0.0022\n",
      "Epoch 44/70\n",
      " - 1s - loss: 0.0012 - msle: 0.0012 - val_loss: 0.0021 - val_msle: 0.0021\n",
      "Epoch 45/70\n",
      " - 1s - loss: 0.0012 - msle: 0.0012 - val_loss: 0.0021 - val_msle: 0.0021\n",
      "Epoch 46/70\n",
      " - 1s - loss: 0.0011 - msle: 0.0011 - val_loss: 0.0022 - val_msle: 0.0022\n",
      "Epoch 47/70\n",
      " - 1s - loss: 0.0011 - msle: 0.0011 - val_loss: 0.0020 - val_msle: 0.0020\n",
      "Epoch 48/70\n",
      " - 1s - loss: 0.0011 - msle: 0.0011 - val_loss: 0.0020 - val_msle: 0.0020\n",
      "Epoch 49/70\n",
      " - 1s - loss: 0.0010 - msle: 0.0010 - val_loss: 0.0020 - val_msle: 0.0020\n",
      "Epoch 50/70\n",
      " - 1s - loss: 0.0011 - msle: 0.0011 - val_loss: 0.0019 - val_msle: 0.0019\n",
      "Epoch 51/70\n",
      " - 1s - loss: 0.0010 - msle: 0.0010 - val_loss: 0.0019 - val_msle: 0.0019\n",
      "Epoch 52/70\n",
      " - 1s - loss: 0.0011 - msle: 0.0011 - val_loss: 0.0025 - val_msle: 0.0025\n",
      "Epoch 53/70\n",
      " - 1s - loss: 0.0010 - msle: 0.0010 - val_loss: 0.0019 - val_msle: 0.0019\n",
      "Epoch 54/70\n",
      " - 1s - loss: 0.0011 - msle: 0.0011 - val_loss: 0.0020 - val_msle: 0.0020\n",
      "Epoch 55/70\n",
      " - 1s - loss: 0.0011 - msle: 0.0011 - val_loss: 0.0019 - val_msle: 0.0019\n",
      "Epoch 56/70\n",
      " - 1s - loss: 9.3823e-04 - msle: 9.3823e-04 - val_loss: 0.0018 - val_msle: 0.0018\n",
      "Epoch 57/70\n",
      " - 1s - loss: 0.0010 - msle: 0.0010 - val_loss: 0.0018 - val_msle: 0.0018\n",
      "Epoch 58/70\n",
      " - 1s - loss: 0.0011 - msle: 0.0011 - val_loss: 0.0017 - val_msle: 0.0017\n",
      "Epoch 59/70\n",
      " - 1s - loss: 9.7106e-04 - msle: 9.7106e-04 - val_loss: 0.0017 - val_msle: 0.0017\n",
      "Epoch 60/70\n",
      " - 1s - loss: 9.2653e-04 - msle: 9.2653e-04 - val_loss: 0.0017 - val_msle: 0.0017\n",
      "Epoch 61/70\n",
      " - 1s - loss: 9.4729e-04 - msle: 9.4729e-04 - val_loss: 0.0018 - val_msle: 0.0018\n",
      "Epoch 62/70\n",
      " - 1s - loss: 9.6549e-04 - msle: 9.6549e-04 - val_loss: 0.0018 - val_msle: 0.0018\n",
      "Epoch 63/70\n",
      " - 1s - loss: 0.0010 - msle: 0.0010 - val_loss: 0.0020 - val_msle: 0.0020\n",
      "Epoch 64/70\n",
      " - 1s - loss: 9.7432e-04 - msle: 9.7432e-04 - val_loss: 0.0017 - val_msle: 0.0017\n",
      "Epoch 65/70\n",
      " - 1s - loss: 8.9797e-04 - msle: 8.9797e-04 - val_loss: 0.0017 - val_msle: 0.0017\n",
      "Epoch 66/70\n",
      " - 1s - loss: 9.8341e-04 - msle: 9.8341e-04 - val_loss: 0.0018 - val_msle: 0.0018\n",
      "Epoch 67/70\n",
      " - 1s - loss: 0.0010 - msle: 0.0010 - val_loss: 0.0019 - val_msle: 0.0019\n",
      "Epoch 68/70\n",
      " - 1s - loss: 0.0010 - msle: 0.0010 - val_loss: 0.0017 - val_msle: 0.0017\n",
      "Epoch 69/70\n",
      " - 1s - loss: 0.0010 - msle: 0.0010 - val_loss: 0.0017 - val_msle: 0.0017\n",
      "Epoch 70/70\n",
      " - 1s - loss: 9.7704e-04 - msle: 9.7704e-04 - val_loss: 0.0018 - val_msle: 0.0018\n",
      "PREDICTING VALUE FOR       close_19    ADX_19     RSI_19  close_18     ADX_18     RSI_18  close_17  \\\n",
      "1570   65519.1  27.01545  60.317088  63606.74  26.114754  54.047349  60058.87   \n",
      "\n",
      "        ADX_17     RSI_17  close_16  ...   close_2      ADX_2      RSI_2  \\\n",
      "1570  25.46082  44.753088  60344.87  ...  57184.07  20.798744  45.873163   \n",
      "\n",
      "       close_1      ADX_1      RSI_1   close_0      ADX_0      RSI_0     close  \n",
      "1570  56480.34  20.055789  44.283082  53601.05  19.681954  38.415831  50471.19  \n",
      "\n",
      "[1 rows x 61 columns]\n",
      "real [[50471.19]]\n",
      "Test RMSE: 1501.092\n",
      "Diff [[-1501.09165842]]\n",
      "% Diff [[-2.97415547]] %\n",
      "||||----|||| Current Orders: [] \n",
      "\n",
      "\n",
      "\n",
      "INDEX: 1414\n",
      "CLOSE: 35045.0\n",
      "MODE: sell\n",
      "CHECKING ORDERS...\n",
      "TRAINING MODEL:\n",
      "Input shape: (1414, 1, 60) (1414, 1)\n",
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_46 (LSTM)               (None, 1, 100)            64400     \n",
      "_________________________________________________________________\n",
      "lstm_47 (LSTM)               (None, 1, 50)             30200     \n",
      "_________________________________________________________________\n",
      "dropout_31 (Dropout)         (None, 1, 50)             0         \n",
      "_________________________________________________________________\n",
      "lstm_48 (LSTM)               (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_32 (Dropout)         (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 1)                 51        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 114,851\n",
      "Trainable params: 114,851\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Y shape (1414, 1)\n",
      "Train on 1414 samples, validate on 283 samples\n",
      "Epoch 1/70\n",
      " - 6s - loss: 0.0109 - msle: 0.0109 - val_loss: 0.0119 - val_msle: 0.0119\n",
      "Epoch 2/70\n",
      " - 1s - loss: 0.0645 - msle: 0.0645 - val_loss: 0.0659 - val_msle: 0.0659\n",
      "Epoch 3/70\n",
      " - 1s - loss: 0.0503 - msle: 0.0503 - val_loss: 0.0795 - val_msle: 0.0795\n",
      "Epoch 4/70\n",
      " - 1s - loss: 0.0261 - msle: 0.0261 - val_loss: 0.0158 - val_msle: 0.0158\n",
      "Epoch 5/70\n",
      " - 1s - loss: 0.0068 - msle: 0.0068 - val_loss: 0.0045 - val_msle: 0.0045\n",
      "Epoch 6/70\n",
      " - 1s - loss: 0.0054 - msle: 0.0054 - val_loss: 0.0038 - val_msle: 0.0038\n",
      "Epoch 7/70\n",
      " - 1s - loss: 0.0038 - msle: 0.0038 - val_loss: 0.0037 - val_msle: 0.0037\n",
      "Epoch 8/70\n",
      " - 1s - loss: 0.0028 - msle: 0.0028 - val_loss: 0.0036 - val_msle: 0.0036\n",
      "Epoch 9/70\n",
      " - 1s - loss: 0.0026 - msle: 0.0026 - val_loss: 0.0034 - val_msle: 0.0034\n",
      "Epoch 10/70\n",
      " - 1s - loss: 0.0022 - msle: 0.0022 - val_loss: 0.0033 - val_msle: 0.0033\n",
      "Epoch 11/70\n",
      " - 1s - loss: 0.0021 - msle: 0.0021 - val_loss: 0.0033 - val_msle: 0.0033\n",
      "Epoch 12/70\n",
      " - 1s - loss: 0.0019 - msle: 0.0019 - val_loss: 0.0032 - val_msle: 0.0032\n",
      "Epoch 13/70\n",
      " - 1s - loss: 0.0018 - msle: 0.0018 - val_loss: 0.0031 - val_msle: 0.0031\n",
      "Epoch 14/70\n",
      " - 1s - loss: 0.0016 - msle: 0.0016 - val_loss: 0.0031 - val_msle: 0.0031\n",
      "Epoch 15/70\n",
      " - 1s - loss: 0.0017 - msle: 0.0017 - val_loss: 0.0030 - val_msle: 0.0030\n",
      "Epoch 16/70\n",
      " - 1s - loss: 0.0015 - msle: 0.0015 - val_loss: 0.0030 - val_msle: 0.0030\n",
      "Epoch 17/70\n",
      " - 1s - loss: 0.0016 - msle: 0.0016 - val_loss: 0.0029 - val_msle: 0.0029\n",
      "Epoch 18/70\n",
      " - 1s - loss: 0.0015 - msle: 0.0015 - val_loss: 0.0029 - val_msle: 0.0029\n",
      "Epoch 19/70\n",
      " - 1s - loss: 0.0016 - msle: 0.0016 - val_loss: 0.0028 - val_msle: 0.0028\n",
      "Epoch 20/70\n",
      " - 1s - loss: 0.0015 - msle: 0.0015 - val_loss: 0.0028 - val_msle: 0.0028\n",
      "Epoch 21/70\n",
      " - 1s - loss: 0.0015 - msle: 0.0015 - val_loss: 0.0027 - val_msle: 0.0027\n",
      "Epoch 22/70\n",
      " - 1s - loss: 0.0016 - msle: 0.0016 - val_loss: 0.0027 - val_msle: 0.0027\n",
      "Epoch 23/70\n",
      " - 1s - loss: 0.0013 - msle: 0.0013 - val_loss: 0.0026 - val_msle: 0.0026\n",
      "Epoch 24/70\n",
      " - 1s - loss: 0.0013 - msle: 0.0013 - val_loss: 0.0026 - val_msle: 0.0026\n",
      "Epoch 25/70\n",
      " - 1s - loss: 0.0014 - msle: 0.0014 - val_loss: 0.0026 - val_msle: 0.0026\n",
      "Epoch 26/70\n",
      " - 1s - loss: 0.0015 - msle: 0.0015 - val_loss: 0.0025 - val_msle: 0.0025\n",
      "Epoch 27/70\n",
      " - 1s - loss: 0.0013 - msle: 0.0013 - val_loss: 0.0025 - val_msle: 0.0025\n",
      "Epoch 28/70\n",
      " - 1s - loss: 0.0014 - msle: 0.0014 - val_loss: 0.0025 - val_msle: 0.0025\n",
      "Epoch 29/70\n",
      " - 1s - loss: 0.0013 - msle: 0.0013 - val_loss: 0.0025 - val_msle: 0.0025\n",
      "Epoch 30/70\n",
      " - 1s - loss: 0.0014 - msle: 0.0014 - val_loss: 0.0025 - val_msle: 0.0025\n",
      "Epoch 31/70\n",
      " - 1s - loss: 0.0013 - msle: 0.0013 - val_loss: 0.0024 - val_msle: 0.0024\n",
      "Epoch 32/70\n",
      " - 1s - loss: 0.0013 - msle: 0.0013 - val_loss: 0.0023 - val_msle: 0.0023\n",
      "Epoch 33/70\n",
      " - 1s - loss: 0.0012 - msle: 0.0012 - val_loss: 0.0023 - val_msle: 0.0023\n",
      "Epoch 34/70\n",
      " - 1s - loss: 0.0012 - msle: 0.0012 - val_loss: 0.0022 - val_msle: 0.0022\n",
      "Epoch 35/70\n",
      " - 1s - loss: 0.0011 - msle: 0.0011 - val_loss: 0.0022 - val_msle: 0.0022\n",
      "Epoch 36/70\n",
      " - 1s - loss: 0.0013 - msle: 0.0013 - val_loss: 0.0022 - val_msle: 0.0022\n",
      "Epoch 37/70\n",
      " - 1s - loss: 0.0012 - msle: 0.0012 - val_loss: 0.0021 - val_msle: 0.0021\n",
      "Epoch 38/70\n",
      " - 1s - loss: 0.0013 - msle: 0.0013 - val_loss: 0.0022 - val_msle: 0.0022\n",
      "Epoch 39/70\n",
      " - 1s - loss: 0.0011 - msle: 0.0011 - val_loss: 0.0021 - val_msle: 0.0021\n",
      "Epoch 40/70\n",
      " - 1s - loss: 0.0012 - msle: 0.0012 - val_loss: 0.0021 - val_msle: 0.0021\n",
      "Epoch 41/70\n",
      " - 1s - loss: 0.0012 - msle: 0.0012 - val_loss: 0.0022 - val_msle: 0.0022\n",
      "Epoch 42/70\n",
      " - 1s - loss: 0.0012 - msle: 0.0012 - val_loss: 0.0020 - val_msle: 0.0020\n",
      "Epoch 43/70\n",
      " - 1s - loss: 0.0010 - msle: 0.0010 - val_loss: 0.0019 - val_msle: 0.0019\n",
      "Epoch 44/70\n",
      " - 1s - loss: 0.0010 - msle: 0.0010 - val_loss: 0.0018 - val_msle: 0.0018\n",
      "Epoch 45/70\n",
      " - 1s - loss: 0.0011 - msle: 0.0011 - val_loss: 0.0021 - val_msle: 0.0021\n",
      "Epoch 46/70\n",
      " - 1s - loss: 0.0010 - msle: 0.0010 - val_loss: 0.0018 - val_msle: 0.0018\n",
      "Epoch 47/70\n",
      " - 1s - loss: 0.0010 - msle: 0.0010 - val_loss: 0.0018 - val_msle: 0.0018\n",
      "Epoch 48/70\n",
      " - 1s - loss: 9.9966e-04 - msle: 9.9966e-04 - val_loss: 0.0023 - val_msle: 0.0023\n",
      "Epoch 49/70\n",
      " - 1s - loss: 9.8276e-04 - msle: 9.8276e-04 - val_loss: 0.0019 - val_msle: 0.0019\n",
      "Epoch 50/70\n",
      " - 1s - loss: 0.0013 - msle: 0.0013 - val_loss: 0.0017 - val_msle: 0.0017\n",
      "Epoch 51/70\n",
      " - 1s - loss: 0.0010 - msle: 0.0010 - val_loss: 0.0018 - val_msle: 0.0018\n",
      "Epoch 52/70\n",
      " - 1s - loss: 0.0012 - msle: 0.0012 - val_loss: 0.0018 - val_msle: 0.0018\n",
      "Epoch 53/70\n",
      " - 1s - loss: 0.0013 - msle: 0.0013 - val_loss: 0.0024 - val_msle: 0.0024\n",
      "Epoch 54/70\n",
      " - 1s - loss: 0.0011 - msle: 0.0011 - val_loss: 0.0017 - val_msle: 0.0017\n",
      "Epoch 55/70\n",
      " - 1s - loss: 0.0011 - msle: 0.0011 - val_loss: 0.0018 - val_msle: 0.0018\n",
      "Epoch 56/70\n",
      " - 1s - loss: 9.9228e-04 - msle: 9.9228e-04 - val_loss: 0.0017 - val_msle: 0.0017\n",
      "Epoch 57/70\n",
      " - 1s - loss: 0.0010 - msle: 0.0010 - val_loss: 0.0018 - val_msle: 0.0018\n",
      "Epoch 58/70\n",
      " - 1s - loss: 0.0010 - msle: 0.0010 - val_loss: 0.0017 - val_msle: 0.0017\n",
      "Epoch 59/70\n",
      " - 1s - loss: 9.4225e-04 - msle: 9.4225e-04 - val_loss: 0.0016 - val_msle: 0.0016\n",
      "Epoch 60/70\n",
      " - 1s - loss: 0.0011 - msle: 0.0011 - val_loss: 0.0016 - val_msle: 0.0016\n",
      "Epoch 61/70\n",
      " - 1s - loss: 9.1654e-04 - msle: 9.1654e-04 - val_loss: 0.0018 - val_msle: 0.0018\n",
      "Epoch 62/70\n",
      " - 1s - loss: 0.0010 - msle: 0.0010 - val_loss: 0.0018 - val_msle: 0.0018\n",
      "Epoch 63/70\n",
      " - 1s - loss: 9.9293e-04 - msle: 9.9293e-04 - val_loss: 0.0018 - val_msle: 0.0018\n",
      "Epoch 64/70\n",
      " - 1s - loss: 0.0011 - msle: 0.0011 - val_loss: 0.0017 - val_msle: 0.0017\n",
      "Epoch 65/70\n",
      " - 1s - loss: 8.2240e-04 - msle: 8.2240e-04 - val_loss: 0.0016 - val_msle: 0.0016\n",
      "Epoch 66/70\n",
      " - 1s - loss: 9.3118e-04 - msle: 9.3118e-04 - val_loss: 0.0016 - val_msle: 0.0016\n",
      "Epoch 67/70\n",
      " - 1s - loss: 0.0011 - msle: 0.0011 - val_loss: 0.0019 - val_msle: 0.0019\n",
      "Epoch 68/70\n",
      " - 1s - loss: 9.9037e-04 - msle: 9.9037e-04 - val_loss: 0.0018 - val_msle: 0.0018\n",
      "Epoch 69/70\n",
      " - 1s - loss: 8.6242e-04 - msle: 8.6242e-04 - val_loss: 0.0015 - val_msle: 0.0015\n",
      "Epoch 70/70\n",
      " - 1s - loss: 8.8752e-04 - msle: 8.8752e-04 - val_loss: 0.0015 - val_msle: 0.0015\n",
      "PREDICTING VALUE FOR       close_19     ADX_19     RSI_19  close_18    ADX_18     RSI_18  close_17  \\\n",
      "1571  63606.74  26.114754  54.047349  60058.87  25.46082  44.753088  60344.87   \n",
      "\n",
      "         ADX_17     RSI_17  close_16  ...   close_2      ADX_2      RSI_2  \\\n",
      "1571  24.430115  45.565723  56891.62  ...  56480.34  20.055789  44.283082   \n",
      "\n",
      "       close_1      ADX_1      RSI_1   close_0      ADX_0      RSI_0     close  \n",
      "1571  53601.05  19.681954  38.415831  49152.47  20.522635  31.476679  47545.59  \n",
      "\n",
      "[1 rows x 61 columns]\n",
      "real [[47545.59]]\n",
      "Test RMSE: 2569.032\n",
      "Diff [[-2569.03181488]]\n",
      "% Diff [[-5.403302]] %\n",
      "||||----|||| Current Orders: [] \n",
      "\n",
      "\n",
      "\n",
      "INDEX: 1415\n",
      "CLOSE: 33504.69\n",
      "MODE: sell\n",
      "CHECKING ORDERS...\n",
      "TRAINING MODEL:\n",
      "Input shape: (1415, 1, 60) (1415, 1)\n",
      "Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_49 (LSTM)               (None, 1, 100)            64400     \n",
      "_________________________________________________________________\n",
      "lstm_50 (LSTM)               (None, 1, 50)             30200     \n",
      "_________________________________________________________________\n",
      "dropout_33 (Dropout)         (None, 1, 50)             0         \n",
      "_________________________________________________________________\n",
      "lstm_51 (LSTM)               (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_34 (Dropout)         (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 1)                 51        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 114,851\n",
      "Trainable params: 114,851\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Y shape (1415, 1)\n",
      "Train on 1415 samples, validate on 283 samples\n",
      "Epoch 1/70\n",
      " - 6s - loss: 0.0734 - msle: 0.0734 - val_loss: 0.2912 - val_msle: 0.2912\n",
      "Epoch 2/70\n",
      " - 1s - loss: 0.0738 - msle: 0.0738 - val_loss: 0.2912 - val_msle: 0.2912\n",
      "Epoch 3/70\n",
      " - 1s - loss: 0.0738 - msle: 0.0738 - val_loss: 0.2912 - val_msle: 0.2912\n",
      "Epoch 4/70\n",
      " - 1s - loss: 0.0738 - msle: 0.0738 - val_loss: 0.2912 - val_msle: 0.2912\n",
      "Epoch 5/70\n",
      " - 1s - loss: 0.0738 - msle: 0.0738 - val_loss: 0.2912 - val_msle: 0.2912\n",
      "Epoch 6/70\n",
      " - 1s - loss: 0.0738 - msle: 0.0738 - val_loss: 0.2912 - val_msle: 0.2912\n",
      "Epoch 7/70\n",
      " - 1s - loss: 0.0738 - msle: 0.0738 - val_loss: 0.2912 - val_msle: 0.2912\n",
      "Epoch 8/70\n",
      " - 1s - loss: 0.0738 - msle: 0.0738 - val_loss: 0.2912 - val_msle: 0.2912\n",
      "Epoch 9/70\n",
      " - 1s - loss: 0.0738 - msle: 0.0738 - val_loss: 0.2912 - val_msle: 0.2912\n",
      "Epoch 10/70\n",
      " - 1s - loss: 0.0738 - msle: 0.0738 - val_loss: 0.2912 - val_msle: 0.2912\n",
      "Epoch 11/70\n",
      " - 1s - loss: 0.0738 - msle: 0.0738 - val_loss: 0.2912 - val_msle: 0.2912\n",
      "Epoch 12/70\n",
      " - 1s - loss: 0.0738 - msle: 0.0738 - val_loss: 0.2912 - val_msle: 0.2912\n",
      "Epoch 13/70\n",
      " - 1s - loss: 0.0738 - msle: 0.0738 - val_loss: 0.2912 - val_msle: 0.2912\n",
      "Epoch 14/70\n",
      " - 1s - loss: 0.0738 - msle: 0.0738 - val_loss: 0.2912 - val_msle: 0.2912\n",
      "Epoch 15/70\n",
      " - 1s - loss: 0.0738 - msle: 0.0738 - val_loss: 0.2912 - val_msle: 0.2912\n",
      "Epoch 16/70\n",
      " - 1s - loss: 0.0738 - msle: 0.0738 - val_loss: 0.2912 - val_msle: 0.2912\n",
      "Epoch 17/70\n",
      " - 1s - loss: 0.0738 - msle: 0.0738 - val_loss: 0.2912 - val_msle: 0.2912\n",
      "Epoch 18/70\n",
      " - 1s - loss: 0.0738 - msle: 0.0738 - val_loss: 0.2912 - val_msle: 0.2912\n",
      "Epoch 19/70\n",
      " - 1s - loss: 0.0738 - msle: 0.0738 - val_loss: 0.2912 - val_msle: 0.2912\n",
      "Epoch 20/70\n",
      " - 1s - loss: 0.0738 - msle: 0.0738 - val_loss: 0.2912 - val_msle: 0.2912\n",
      "Epoch 21/70\n",
      " - 1s - loss: 0.0738 - msle: 0.0738 - val_loss: 0.2912 - val_msle: 0.2912\n",
      "Epoch 22/70\n",
      " - 1s - loss: 0.0738 - msle: 0.0738 - val_loss: 0.2912 - val_msle: 0.2912\n",
      "Epoch 23/70\n",
      " - 1s - loss: 0.0738 - msle: 0.0738 - val_loss: 0.2912 - val_msle: 0.2912\n",
      "Epoch 24/70\n",
      " - 1s - loss: 0.0738 - msle: 0.0738 - val_loss: 0.2912 - val_msle: 0.2912\n",
      "Epoch 25/70\n",
      " - 1s - loss: 0.0738 - msle: 0.0738 - val_loss: 0.2912 - val_msle: 0.2912\n",
      "Epoch 26/70\n",
      " - 1s - loss: 0.0738 - msle: 0.0738 - val_loss: 0.2912 - val_msle: 0.2912\n",
      "PREDICTING VALUE FOR       close_19    ADX_19     RSI_19  close_18     ADX_18     RSI_18  close_17  \\\n",
      "1572  60058.87  25.46082  44.753088  60344.87  24.430115  45.565723  56891.62   \n",
      "\n",
      "         ADX_17     RSI_17  close_16  ...   close_2      ADX_2      RSI_2  \\\n",
      "1572  23.576312  38.249876  58052.24  ...  53601.05  19.681954  38.415831   \n",
      "\n",
      "       close_1      ADX_1      RSI_1   close_0      ADX_0      RSI_0     close  \n",
      "1572  49152.47  20.522635  31.476679  49396.33  22.878406  32.199668  47140.54  \n",
      "\n",
      "[1 rows x 61 columns]\n",
      "real [[47140.54]]\n",
      "Test RMSE: 44084.439\n",
      "Diff [[44084.43861531]]\n",
      "% Diff [[93.51704205]] %\n",
      "||||----|||| Current Orders: [] \n",
      "\n",
      "\n",
      "\n",
      "INDEX: 1416\n",
      "CLOSE: 33786.55\n",
      "MODE: sell\n",
      "CHECKING ORDERS...\n",
      "TRAINING MODEL:\n",
      "Input shape: (1416, 1, 60) (1416, 1)\n",
      "Model: \"sequential_18\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_52 (LSTM)               (None, 1, 100)            64400     \n",
      "_________________________________________________________________\n",
      "lstm_53 (LSTM)               (None, 1, 50)             30200     \n",
      "_________________________________________________________________\n",
      "dropout_35 (Dropout)         (None, 1, 50)             0         \n",
      "_________________________________________________________________\n",
      "lstm_54 (LSTM)               (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_36 (Dropout)         (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 1)                 51        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 114,851\n",
      "Trainable params: 114,851\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Y shape (1416, 1)\n",
      "Train on 1416 samples, validate on 284 samples\n",
      "Epoch 1/70\n",
      " - 6s - loss: 0.0631 - msle: 0.0631 - val_loss: 0.0651 - val_msle: 0.0651\n",
      "Epoch 2/70\n",
      " - 1s - loss: 0.0416 - msle: 0.0416 - val_loss: 0.0212 - val_msle: 0.0212\n",
      "Epoch 3/70\n",
      " - 1s - loss: 0.0136 - msle: 0.0136 - val_loss: 0.0032 - val_msle: 0.0032\n",
      "Epoch 4/70\n",
      " - 1s - loss: 0.0085 - msle: 0.0085 - val_loss: 0.0057 - val_msle: 0.0057\n",
      "Epoch 5/70\n",
      " - 1s - loss: 0.0044 - msle: 0.0044 - val_loss: 0.0056 - val_msle: 0.0056\n",
      "Epoch 6/70\n",
      " - 1s - loss: 0.0034 - msle: 0.0034 - val_loss: 0.0036 - val_msle: 0.0036\n",
      "Epoch 7/70\n",
      " - 1s - loss: 0.0030 - msle: 0.0030 - val_loss: 0.0042 - val_msle: 0.0042\n",
      "Epoch 8/70\n",
      " - 1s - loss: 0.0023 - msle: 0.0023 - val_loss: 0.0034 - val_msle: 0.0034\n",
      "Epoch 9/70\n",
      " - 1s - loss: 0.0024 - msle: 0.0024 - val_loss: 0.0033 - val_msle: 0.0033\n",
      "Epoch 10/70\n",
      " - 1s - loss: 0.0021 - msle: 0.0021 - val_loss: 0.0034 - val_msle: 0.0034\n",
      "Epoch 11/70\n",
      " - 1s - loss: 0.0024 - msle: 0.0024 - val_loss: 0.0039 - val_msle: 0.0039\n",
      "Epoch 12/70\n",
      " - 1s - loss: 0.0020 - msle: 0.0020 - val_loss: 0.0032 - val_msle: 0.0032\n",
      "Epoch 13/70\n",
      " - 1s - loss: 0.0023 - msle: 0.0023 - val_loss: 0.0036 - val_msle: 0.0036\n",
      "Epoch 14/70\n",
      " - 1s - loss: 0.0020 - msle: 0.0020 - val_loss: 0.0032 - val_msle: 0.0032\n",
      "Epoch 15/70\n",
      " - 1s - loss: 0.0022 - msle: 0.0022 - val_loss: 0.0032 - val_msle: 0.0032\n",
      "Epoch 16/70\n",
      " - 1s - loss: 0.0018 - msle: 0.0018 - val_loss: 0.0031 - val_msle: 0.0031\n",
      "Epoch 17/70\n",
      " - 1s - loss: 0.0019 - msle: 0.0019 - val_loss: 0.0032 - val_msle: 0.0032\n",
      "Epoch 18/70\n",
      " - 1s - loss: 0.0015 - msle: 0.0015 - val_loss: 0.0030 - val_msle: 0.0030\n",
      "Epoch 19/70\n",
      " - 1s - loss: 0.0018 - msle: 0.0018 - val_loss: 0.0030 - val_msle: 0.0030\n",
      "Epoch 20/70\n",
      " - 1s - loss: 0.0015 - msle: 0.0015 - val_loss: 0.0029 - val_msle: 0.0029\n",
      "Epoch 21/70\n",
      " - 1s - loss: 0.0015 - msle: 0.0015 - val_loss: 0.0028 - val_msle: 0.0028\n",
      "Epoch 22/70\n",
      " - 1s - loss: 0.0013 - msle: 0.0013 - val_loss: 0.0028 - val_msle: 0.0028\n",
      "Epoch 23/70\n",
      " - 1s - loss: 0.0015 - msle: 0.0015 - val_loss: 0.0028 - val_msle: 0.0028\n",
      "Epoch 24/70\n",
      " - 1s - loss: 0.0013 - msle: 0.0013 - val_loss: 0.0028 - val_msle: 0.0028\n",
      "Epoch 25/70\n",
      " - 1s - loss: 0.0015 - msle: 0.0015 - val_loss: 0.0028 - val_msle: 0.0028\n",
      "Epoch 26/70\n",
      " - 1s - loss: 0.0013 - msle: 0.0013 - val_loss: 0.0027 - val_msle: 0.0027\n",
      "Epoch 27/70\n",
      " - 1s - loss: 0.0015 - msle: 0.0015 - val_loss: 0.0028 - val_msle: 0.0028\n",
      "Epoch 28/70\n",
      " - 1s - loss: 0.0013 - msle: 0.0013 - val_loss: 0.0026 - val_msle: 0.0026\n",
      "Epoch 29/70\n",
      " - 1s - loss: 0.0012 - msle: 0.0012 - val_loss: 0.0026 - val_msle: 0.0026\n",
      "Epoch 30/70\n",
      " - 1s - loss: 0.0013 - msle: 0.0013 - val_loss: 0.0026 - val_msle: 0.0026\n",
      "Epoch 31/70\n",
      " - 1s - loss: 0.0013 - msle: 0.0013 - val_loss: 0.0026 - val_msle: 0.0026\n",
      "Epoch 32/70\n",
      " - 1s - loss: 0.0012 - msle: 0.0012 - val_loss: 0.0025 - val_msle: 0.0025\n",
      "Epoch 33/70\n",
      " - 1s - loss: 0.0014 - msle: 0.0014 - val_loss: 0.0024 - val_msle: 0.0024\n",
      "Epoch 34/70\n",
      " - 1s - loss: 0.0012 - msle: 0.0012 - val_loss: 0.0024 - val_msle: 0.0024\n",
      "Epoch 35/70\n",
      " - 1s - loss: 0.0012 - msle: 0.0012 - val_loss: 0.0024 - val_msle: 0.0024\n",
      "Epoch 36/70\n",
      " - 1s - loss: 0.0012 - msle: 0.0012 - val_loss: 0.0024 - val_msle: 0.0024\n",
      "Epoch 37/70\n",
      " - 1s - loss: 0.0012 - msle: 0.0012 - val_loss: 0.0023 - val_msle: 0.0023\n",
      "Epoch 38/70\n",
      " - 1s - loss: 0.0012 - msle: 0.0012 - val_loss: 0.0023 - val_msle: 0.0023\n",
      "Epoch 39/70\n",
      " - 1s - loss: 0.0011 - msle: 0.0011 - val_loss: 0.0022 - val_msle: 0.0022\n",
      "Epoch 40/70\n",
      " - 1s - loss: 0.0012 - msle: 0.0012 - val_loss: 0.0022 - val_msle: 0.0022\n",
      "Epoch 41/70\n",
      " - 1s - loss: 0.0011 - msle: 0.0011 - val_loss: 0.0021 - val_msle: 0.0021\n",
      "Epoch 42/70\n",
      " - 1s - loss: 0.0011 - msle: 0.0011 - val_loss: 0.0021 - val_msle: 0.0021\n",
      "Epoch 43/70\n",
      " - 1s - loss: 0.0011 - msle: 0.0011 - val_loss: 0.0021 - val_msle: 0.0021\n",
      "Epoch 44/70\n",
      " - 1s - loss: 0.0011 - msle: 0.0011 - val_loss: 0.0022 - val_msle: 0.0022\n",
      "Epoch 45/70\n",
      " - 1s - loss: 0.0011 - msle: 0.0011 - val_loss: 0.0021 - val_msle: 0.0021\n",
      "Epoch 46/70\n",
      " - 1s - loss: 0.0011 - msle: 0.0011 - val_loss: 0.0020 - val_msle: 0.0020\n",
      "Epoch 47/70\n",
      " - 1s - loss: 0.0011 - msle: 0.0011 - val_loss: 0.0019 - val_msle: 0.0019\n",
      "Epoch 48/70\n",
      " - 1s - loss: 0.0011 - msle: 0.0011 - val_loss: 0.0020 - val_msle: 0.0020\n",
      "Epoch 49/70\n",
      " - 1s - loss: 0.0011 - msle: 0.0011 - val_loss: 0.0021 - val_msle: 0.0021\n",
      "Epoch 50/70\n",
      " - 1s - loss: 0.0010 - msle: 0.0010 - val_loss: 0.0019 - val_msle: 0.0019\n",
      "Epoch 51/70\n",
      " - 1s - loss: 0.0012 - msle: 0.0012 - val_loss: 0.0019 - val_msle: 0.0019\n",
      "Epoch 52/70\n",
      " - 1s - loss: 0.0011 - msle: 0.0011 - val_loss: 0.0021 - val_msle: 0.0021\n",
      "Epoch 53/70\n",
      " - 1s - loss: 9.8421e-04 - msle: 9.8421e-04 - val_loss: 0.0018 - val_msle: 0.0018\n",
      "Epoch 54/70\n",
      " - 1s - loss: 9.6451e-04 - msle: 9.6451e-04 - val_loss: 0.0018 - val_msle: 0.0018\n",
      "Epoch 55/70\n",
      " - 1s - loss: 0.0010 - msle: 0.0010 - val_loss: 0.0018 - val_msle: 0.0018\n",
      "Epoch 56/70\n",
      " - 1s - loss: 9.6999e-04 - msle: 9.6999e-04 - val_loss: 0.0017 - val_msle: 0.0017\n",
      "Epoch 57/70\n",
      " - 1s - loss: 0.0010 - msle: 0.0010 - val_loss: 0.0021 - val_msle: 0.0021\n",
      "Epoch 58/70\n",
      " - 1s - loss: 9.8751e-04 - msle: 9.8751e-04 - val_loss: 0.0020 - val_msle: 0.0020\n",
      "Epoch 59/70\n",
      " - 1s - loss: 0.0010 - msle: 0.0010 - val_loss: 0.0019 - val_msle: 0.0019\n",
      "Epoch 60/70\n",
      " - 1s - loss: 9.8166e-04 - msle: 9.8166e-04 - val_loss: 0.0017 - val_msle: 0.0017\n",
      "Epoch 61/70\n",
      " - 1s - loss: 9.9392e-04 - msle: 9.9392e-04 - val_loss: 0.0017 - val_msle: 0.0017\n",
      "Epoch 62/70\n",
      " - 1s - loss: 9.8831e-04 - msle: 9.8831e-04 - val_loss: 0.0017 - val_msle: 0.0017\n",
      "Epoch 63/70\n",
      " - 1s - loss: 8.6644e-04 - msle: 8.6644e-04 - val_loss: 0.0017 - val_msle: 0.0017\n",
      "Epoch 64/70\n",
      " - 1s - loss: 9.5030e-04 - msle: 9.5030e-04 - val_loss: 0.0018 - val_msle: 0.0018\n",
      "Epoch 65/70\n",
      " - 1s - loss: 9.8135e-04 - msle: 9.8135e-04 - val_loss: 0.0024 - val_msle: 0.0024\n",
      "Epoch 66/70\n",
      " - 1s - loss: 9.8315e-04 - msle: 9.8315e-04 - val_loss: 0.0017 - val_msle: 0.0017\n",
      "Epoch 67/70\n",
      " - 1s - loss: 0.0010 - msle: 0.0010 - val_loss: 0.0016 - val_msle: 0.0016\n",
      "Epoch 68/70\n",
      " - 1s - loss: 8.4566e-04 - msle: 8.4566e-04 - val_loss: 0.0016 - val_msle: 0.0016\n",
      "Epoch 69/70\n",
      " - 1s - loss: 9.4930e-04 - msle: 9.4930e-04 - val_loss: 0.0020 - val_msle: 0.0020\n",
      "Epoch 70/70\n",
      " - 1s - loss: 9.2908e-04 - msle: 9.2908e-04 - val_loss: 0.0018 - val_msle: 0.0018\n",
      "PREDICTING VALUE FOR       close_19     ADX_19     RSI_19  close_18     ADX_18     RSI_18  \\\n",
      "1573  60344.87  24.430115  45.565723  56891.62  23.576312  38.249876   \n",
      "\n",
      "      close_17     ADX_17     RSI_17  close_16  ...   close_2      ADX_2  \\\n",
      "1573  58052.24  23.321307  41.641275  59707.51  ...  49152.47  20.522635   \n",
      "\n",
      "          RSI_2   close_1      ADX_1      RSI_1   close_0      ADX_0  \\\n",
      "1573  31.476679  49396.33  22.878406  32.199668  50441.92  25.036301   \n",
      "\n",
      "          RSI_0     close  \n",
      "1573  35.349386  49389.99  \n",
      "\n",
      "[1 rows x 61 columns]\n",
      "real [[49389.99]]\n",
      "Test RMSE: 218.332\n",
      "Diff [[218.33192525]]\n",
      "% Diff [[0.44205703]] %\n",
      "||||----|||| Current Orders: [] \n",
      "\n",
      "\n",
      "\n",
      "INDEX: 1417\n",
      "CLOSE: 34669.13\n",
      "MODE: sell\n",
      "CHECKING ORDERS...\n",
      "TRAINING MODEL:\n",
      "Input shape: (1417, 1, 60) (1417, 1)\n",
      "Model: \"sequential_19\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_55 (LSTM)               (None, 1, 100)            64400     \n",
      "_________________________________________________________________\n",
      "lstm_56 (LSTM)               (None, 1, 50)             30200     \n",
      "_________________________________________________________________\n",
      "dropout_37 (Dropout)         (None, 1, 50)             0         \n",
      "_________________________________________________________________\n",
      "lstm_57 (LSTM)               (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_38 (Dropout)         (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 1)                 51        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 114,851\n",
      "Trainable params: 114,851\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Y shape (1417, 1)\n",
      "Train on 1417 samples, validate on 284 samples\n",
      "Epoch 1/70\n",
      " - 7s - loss: 0.0635 - msle: 0.0635 - val_loss: 0.0601 - val_msle: 0.0601\n",
      "Epoch 2/70\n",
      " - 1s - loss: 0.0351 - msle: 0.0351 - val_loss: 0.0069 - val_msle: 0.0069\n",
      "Epoch 3/70\n",
      " - 1s - loss: 0.0156 - msle: 0.0156 - val_loss: 0.0030 - val_msle: 0.0030\n",
      "Epoch 4/70\n",
      " - 1s - loss: 0.0061 - msle: 0.0061 - val_loss: 0.0045 - val_msle: 0.0045\n",
      "Epoch 5/70\n",
      " - 1s - loss: 0.0035 - msle: 0.0035 - val_loss: 0.0045 - val_msle: 0.0045\n",
      "Epoch 6/70\n",
      " - 1s - loss: 0.0026 - msle: 0.0026 - val_loss: 0.0035 - val_msle: 0.0035\n",
      "Epoch 7/70\n",
      " - 1s - loss: 0.0025 - msle: 0.0025 - val_loss: 0.0036 - val_msle: 0.0036\n",
      "Epoch 8/70\n",
      " - 1s - loss: 0.0019 - msle: 0.0019 - val_loss: 0.0033 - val_msle: 0.0033\n",
      "Epoch 9/70\n",
      " - 1s - loss: 0.0022 - msle: 0.0022 - val_loss: 0.0035 - val_msle: 0.0035\n",
      "Epoch 10/70\n",
      " - 1s - loss: 0.0018 - msle: 0.0018 - val_loss: 0.0031 - val_msle: 0.0031\n",
      "Epoch 11/70\n",
      " - 1s - loss: 0.0023 - msle: 0.0023 - val_loss: 0.0033 - val_msle: 0.0033\n",
      "Epoch 12/70\n",
      " - 1s - loss: 0.0018 - msle: 0.0018 - val_loss: 0.0029 - val_msle: 0.0029\n",
      "Epoch 13/70\n",
      " - 1s - loss: 0.0018 - msle: 0.0018 - val_loss: 0.0028 - val_msle: 0.0028\n",
      "Epoch 14/70\n",
      " - 1s - loss: 0.0016 - msle: 0.0016 - val_loss: 0.0027 - val_msle: 0.0027\n",
      "Epoch 15/70\n",
      " - 1s - loss: 0.0015 - msle: 0.0015 - val_loss: 0.0028 - val_msle: 0.0028\n",
      "Epoch 16/70\n",
      " - 1s - loss: 0.0016 - msle: 0.0016 - val_loss: 0.0027 - val_msle: 0.0027\n",
      "Epoch 17/70\n",
      " - 1s - loss: 0.0014 - msle: 0.0014 - val_loss: 0.0026 - val_msle: 0.0026\n",
      "Epoch 18/70\n",
      " - 1s - loss: 0.0015 - msle: 0.0015 - val_loss: 0.0026 - val_msle: 0.0026\n",
      "Epoch 19/70\n",
      " - 1s - loss: 0.0014 - msle: 0.0014 - val_loss: 0.0026 - val_msle: 0.0026\n",
      "Epoch 20/70\n",
      " - 1s - loss: 0.0014 - msle: 0.0014 - val_loss: 0.0025 - val_msle: 0.0025\n",
      "Epoch 21/70\n",
      " - 1s - loss: 0.0014 - msle: 0.0014 - val_loss: 0.0025 - val_msle: 0.0025\n",
      "Epoch 22/70\n",
      " - 1s - loss: 0.0015 - msle: 0.0015 - val_loss: 0.0024 - val_msle: 0.0024\n",
      "Epoch 23/70\n",
      " - 1s - loss: 0.0013 - msle: 0.0013 - val_loss: 0.0024 - val_msle: 0.0024\n",
      "Epoch 24/70\n",
      " - 1s - loss: 0.0013 - msle: 0.0013 - val_loss: 0.0024 - val_msle: 0.0024\n",
      "Epoch 25/70\n",
      " - 1s - loss: 0.0012 - msle: 0.0012 - val_loss: 0.0024 - val_msle: 0.0024\n",
      "Epoch 26/70\n",
      " - 1s - loss: 0.0013 - msle: 0.0013 - val_loss: 0.0023 - val_msle: 0.0023\n",
      "Epoch 27/70\n",
      " - 1s - loss: 0.0014 - msle: 0.0014 - val_loss: 0.0023 - val_msle: 0.0023\n",
      "Epoch 28/70\n",
      " - 1s - loss: 0.0012 - msle: 0.0012 - val_loss: 0.0024 - val_msle: 0.0024\n",
      "Epoch 29/70\n",
      " - 1s - loss: 0.0014 - msle: 0.0014 - val_loss: 0.0024 - val_msle: 0.0024\n",
      "Epoch 30/70\n",
      " - 1s - loss: 0.0011 - msle: 0.0011 - val_loss: 0.0022 - val_msle: 0.0022\n",
      "Epoch 31/70\n",
      " - 1s - loss: 0.0012 - msle: 0.0012 - val_loss: 0.0022 - val_msle: 0.0022\n",
      "Epoch 32/70\n",
      " - 1s - loss: 0.0012 - msle: 0.0012 - val_loss: 0.0022 - val_msle: 0.0022\n",
      "Epoch 33/70\n",
      " - 1s - loss: 0.0011 - msle: 0.0011 - val_loss: 0.0022 - val_msle: 0.0022\n",
      "Epoch 34/70\n",
      " - 1s - loss: 0.0011 - msle: 0.0011 - val_loss: 0.0021 - val_msle: 0.0021\n",
      "Epoch 35/70\n",
      " - 1s - loss: 0.0011 - msle: 0.0011 - val_loss: 0.0021 - val_msle: 0.0021\n",
      "Epoch 36/70\n",
      " - 1s - loss: 0.0010 - msle: 0.0010 - val_loss: 0.0020 - val_msle: 0.0020\n",
      "Epoch 37/70\n",
      " - 1s - loss: 0.0011 - msle: 0.0011 - val_loss: 0.0024 - val_msle: 0.0024\n",
      "Epoch 38/70\n",
      " - 1s - loss: 0.0011 - msle: 0.0011 - val_loss: 0.0020 - val_msle: 0.0020\n",
      "Epoch 39/70\n",
      " - 1s - loss: 0.0011 - msle: 0.0011 - val_loss: 0.0019 - val_msle: 0.0019\n",
      "Epoch 40/70\n",
      " - 1s - loss: 0.0011 - msle: 0.0011 - val_loss: 0.0023 - val_msle: 0.0023\n",
      "Epoch 41/70\n",
      " - 1s - loss: 0.0011 - msle: 0.0011 - val_loss: 0.0019 - val_msle: 0.0019\n",
      "Epoch 42/70\n",
      " - 1s - loss: 0.0010 - msle: 0.0010 - val_loss: 0.0019 - val_msle: 0.0019\n",
      "Epoch 43/70\n",
      " - 1s - loss: 0.0011 - msle: 0.0011 - val_loss: 0.0021 - val_msle: 0.0021\n",
      "Epoch 44/70\n",
      " - 1s - loss: 0.0010 - msle: 0.0010 - val_loss: 0.0019 - val_msle: 0.0019\n",
      "Epoch 45/70\n",
      " - 1s - loss: 0.0010 - msle: 0.0010 - val_loss: 0.0020 - val_msle: 0.0020\n",
      "Epoch 46/70\n",
      " - 1s - loss: 0.0010 - msle: 0.0010 - val_loss: 0.0019 - val_msle: 0.0019\n",
      "Epoch 47/70\n",
      " - 1s - loss: 9.8558e-04 - msle: 9.8558e-04 - val_loss: 0.0018 - val_msle: 0.0018\n",
      "Epoch 48/70\n",
      " - 1s - loss: 0.0011 - msle: 0.0011 - val_loss: 0.0019 - val_msle: 0.0019\n",
      "Epoch 49/70\n",
      " - 1s - loss: 9.6038e-04 - msle: 9.6038e-04 - val_loss: 0.0019 - val_msle: 0.0019\n",
      "Epoch 50/70\n",
      " - 1s - loss: 9.4110e-04 - msle: 9.4110e-04 - val_loss: 0.0017 - val_msle: 0.0017\n",
      "Epoch 51/70\n",
      " - 1s - loss: 0.0011 - msle: 0.0011 - val_loss: 0.0018 - val_msle: 0.0018\n",
      "Epoch 52/70\n",
      " - 1s - loss: 9.5329e-04 - msle: 9.5329e-04 - val_loss: 0.0017 - val_msle: 0.0017\n",
      "Epoch 53/70\n",
      " - 1s - loss: 8.9651e-04 - msle: 8.9651e-04 - val_loss: 0.0017 - val_msle: 0.0017\n",
      "Epoch 54/70\n",
      " - 1s - loss: 9.2674e-04 - msle: 9.2674e-04 - val_loss: 0.0018 - val_msle: 0.0018\n",
      "Epoch 55/70\n",
      " - 1s - loss: 9.0275e-04 - msle: 9.0275e-04 - val_loss: 0.0019 - val_msle: 0.0019\n",
      "Epoch 56/70\n",
      " - 1s - loss: 9.9733e-04 - msle: 9.9733e-04 - val_loss: 0.0020 - val_msle: 0.0020\n",
      "Epoch 57/70\n",
      " - 1s - loss: 9.3493e-04 - msle: 9.3493e-04 - val_loss: 0.0018 - val_msle: 0.0018\n",
      "Epoch 58/70\n",
      " - 1s - loss: 8.2465e-04 - msle: 8.2465e-04 - val_loss: 0.0017 - val_msle: 0.0017\n",
      "Epoch 59/70\n",
      " - 1s - loss: 9.2348e-04 - msle: 9.2348e-04 - val_loss: 0.0016 - val_msle: 0.0016\n",
      "Epoch 60/70\n",
      " - 1s - loss: 0.0010 - msle: 0.0010 - val_loss: 0.0020 - val_msle: 0.0020\n",
      "Epoch 61/70\n",
      " - 1s - loss: 8.4226e-04 - msle: 8.4226e-04 - val_loss: 0.0016 - val_msle: 0.0016\n",
      "Epoch 62/70\n",
      " - 1s - loss: 0.0010 - msle: 0.0010 - val_loss: 0.0017 - val_msle: 0.0017\n",
      "Epoch 63/70\n",
      " - 1s - loss: 8.8781e-04 - msle: 8.8781e-04 - val_loss: 0.0023 - val_msle: 0.0023\n",
      "Epoch 64/70\n",
      " - 1s - loss: 8.9310e-04 - msle: 8.9309e-04 - val_loss: 0.0016 - val_msle: 0.0016\n",
      "Epoch 65/70\n",
      " - 1s - loss: 9.7251e-04 - msle: 9.7251e-04 - val_loss: 0.0015 - val_msle: 0.0015\n",
      "Epoch 66/70\n",
      " - 1s - loss: 9.7979e-04 - msle: 9.7979e-04 - val_loss: 0.0016 - val_msle: 0.0016\n",
      "Epoch 67/70\n",
      " - 1s - loss: 8.9276e-04 - msle: 8.9276e-04 - val_loss: 0.0015 - val_msle: 0.0015\n",
      "Epoch 68/70\n",
      " - 1s - loss: 9.0259e-04 - msle: 9.0259e-04 - val_loss: 0.0019 - val_msle: 0.0019\n",
      "Epoch 69/70\n",
      " - 1s - loss: 9.2344e-04 - msle: 9.2344e-04 - val_loss: 0.0020 - val_msle: 0.0020\n",
      "Epoch 70/70\n",
      " - 1s - loss: 0.0010 - msle: 0.0010 - val_loss: 0.0020 - val_msle: 0.0020\n",
      "PREDICTING VALUE FOR       close_19     ADX_19     RSI_19  close_18     ADX_18     RSI_18  \\\n",
      "1574  56891.62  23.576312  38.249876  58052.24  23.321307  41.641275   \n",
      "\n",
      "      close_17     ADX_17     RSI_17  close_16  ...   close_2      ADX_2  \\\n",
      "1574  59707.51  23.280175  46.181102  58622.02  ...  49396.33  22.878406   \n",
      "\n",
      "          RSI_2   close_1      ADX_1      RSI_1   close_0      ADX_0  \\\n",
      "1574  32.199668  50441.92  25.036301  35.349386  50588.95  26.624459   \n",
      "\n",
      "          RSI_0    close  \n",
      "1574  35.801031  50053.9  \n",
      "\n",
      "[1 rows x 61 columns]\n",
      "real [[50053.9]]\n",
      "Test RMSE: 1228.975\n",
      "Diff [[1228.97473536]]\n",
      "% Diff [[2.45530265]] %\n",
      "||||----|||| Current Orders: [] \n",
      "\n",
      "\n",
      "\n",
      "INDEX: 1418\n",
      "CLOSE: 35286.51\n",
      "MODE: sell\n",
      "CHECKING ORDERS...\n",
      "TRAINING MODEL:\n",
      "Input shape: (1418, 1, 60) (1418, 1)\n",
      "Model: \"sequential_20\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_58 (LSTM)               (None, 1, 100)            64400     \n",
      "_________________________________________________________________\n",
      "lstm_59 (LSTM)               (None, 1, 50)             30200     \n",
      "_________________________________________________________________\n",
      "dropout_39 (Dropout)         (None, 1, 50)             0         \n",
      "_________________________________________________________________\n",
      "lstm_60 (LSTM)               (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_40 (Dropout)         (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 1)                 51        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 114,851\n",
      "Trainable params: 114,851\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Y shape (1418, 1)\n",
      "Train on 1418 samples, validate on 284 samples\n",
      "Epoch 1/70\n",
      " - 6s - loss: 0.0739 - msle: 0.0739 - val_loss: 0.2912 - val_msle: 0.2912\n",
      "Epoch 2/70\n",
      " - 1s - loss: 0.0742 - msle: 0.0742 - val_loss: 0.2912 - val_msle: 0.2912\n",
      "Epoch 3/70\n",
      " - 1s - loss: 0.0742 - msle: 0.0742 - val_loss: 0.2912 - val_msle: 0.2912\n",
      "Epoch 4/70\n",
      " - 1s - loss: 0.0742 - msle: 0.0742 - val_loss: 0.2912 - val_msle: 0.2912\n",
      "Epoch 5/70\n",
      " - 1s - loss: 0.0742 - msle: 0.0742 - val_loss: 0.2912 - val_msle: 0.2912\n",
      "Epoch 6/70\n",
      " - 1s - loss: 0.0742 - msle: 0.0742 - val_loss: 0.2912 - val_msle: 0.2912\n",
      "Epoch 7/70\n",
      " - 1s - loss: 0.0742 - msle: 0.0742 - val_loss: 0.2912 - val_msle: 0.2912\n",
      "Epoch 8/70\n",
      " - 1s - loss: 0.0742 - msle: 0.0742 - val_loss: 0.2912 - val_msle: 0.2912\n",
      "Epoch 9/70\n",
      " - 1s - loss: 0.0742 - msle: 0.0742 - val_loss: 0.2912 - val_msle: 0.2912\n",
      "Epoch 10/70\n",
      " - 1s - loss: 0.0742 - msle: 0.0742 - val_loss: 0.2912 - val_msle: 0.2912\n",
      "Epoch 11/70\n",
      " - 1s - loss: 0.0742 - msle: 0.0742 - val_loss: 0.2912 - val_msle: 0.2912\n",
      "Epoch 12/70\n",
      " - 1s - loss: 0.0742 - msle: 0.0742 - val_loss: 0.2912 - val_msle: 0.2912\n",
      "Epoch 13/70\n",
      " - 1s - loss: 0.0742 - msle: 0.0742 - val_loss: 0.2912 - val_msle: 0.2912\n",
      "Epoch 14/70\n",
      " - 1s - loss: 0.0742 - msle: 0.0742 - val_loss: 0.2912 - val_msle: 0.2912\n",
      "Epoch 15/70\n",
      " - 1s - loss: 0.0742 - msle: 0.0742 - val_loss: 0.2912 - val_msle: 0.2912\n",
      "Epoch 16/70\n",
      " - 1s - loss: 0.0742 - msle: 0.0742 - val_loss: 0.2912 - val_msle: 0.2912\n",
      "Epoch 17/70\n",
      " - 1s - loss: 0.0742 - msle: 0.0742 - val_loss: 0.2912 - val_msle: 0.2912\n",
      "Epoch 18/70\n",
      " - 1s - loss: 0.0742 - msle: 0.0742 - val_loss: 0.2912 - val_msle: 0.2912\n",
      "Epoch 19/70\n",
      " - 1s - loss: 0.0742 - msle: 0.0742 - val_loss: 0.2912 - val_msle: 0.2912\n",
      "Epoch 20/70\n",
      " - 1s - loss: 0.0742 - msle: 0.0742 - val_loss: 0.2912 - val_msle: 0.2912\n",
      "Epoch 21/70\n",
      " - 1s - loss: 0.0742 - msle: 0.0742 - val_loss: 0.2912 - val_msle: 0.2912\n",
      "Epoch 22/70\n",
      " - 1s - loss: 0.0742 - msle: 0.0742 - val_loss: 0.2912 - val_msle: 0.2912\n",
      "Epoch 23/70\n",
      " - 1s - loss: 0.0742 - msle: 0.0742 - val_loss: 0.2912 - val_msle: 0.2912\n",
      "Epoch 24/70\n",
      " - 1s - loss: 0.0742 - msle: 0.0742 - val_loss: 0.2912 - val_msle: 0.2912\n",
      "Epoch 25/70\n",
      " - 1s - loss: 0.0742 - msle: 0.0742 - val_loss: 0.2912 - val_msle: 0.2912\n",
      "Epoch 26/70\n",
      " - 1s - loss: 0.0742 - msle: 0.0742 - val_loss: 0.2912 - val_msle: 0.2912\n",
      "PREDICTING VALUE FOR       close_19     ADX_19     RSI_19  close_18     ADX_18     RSI_18  \\\n",
      "1575  58052.24  23.321307  41.641275  59707.51  23.280175  46.181102   \n",
      "\n",
      "      close_17     ADX_17     RSI_17  close_16  ...   close_2      ADX_2  \\\n",
      "1575  58622.02  22.582078  43.776117  56247.18  ...  50441.92  25.036301   \n",
      "\n",
      "          RSI_2   close_1      ADX_1      RSI_1   close_0      ADX_0    RSI_0  \\\n",
      "1575  35.349386  50588.95  26.624459  35.801031  50471.19  27.717067  35.5866   \n",
      "\n",
      "         close  \n",
      "1575  46702.75  \n",
      "\n",
      "[1 rows x 61 columns]\n",
      "real [[46702.75]]\n",
      "Test RMSE: 43785.503\n",
      "Diff [[43785.50254832]]\n",
      "% Diff [[93.75358528]] %\n",
      "||||----|||| Current Orders: [] \n",
      "\n",
      "\n",
      "\n",
      "INDEX: 1419\n",
      "CLOSE: 33690.14\n",
      "MODE: sell\n",
      "CHECKING ORDERS...\n",
      "TRAINING MODEL:\n",
      "Input shape: (1419, 1, 60) (1419, 1)\n",
      "Model: \"sequential_21\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_61 (LSTM)               (None, 1, 100)            64400     \n",
      "_________________________________________________________________\n",
      "lstm_62 (LSTM)               (None, 1, 50)             30200     \n",
      "_________________________________________________________________\n",
      "dropout_41 (Dropout)         (None, 1, 50)             0         \n",
      "_________________________________________________________________\n",
      "lstm_63 (LSTM)               (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_42 (Dropout)         (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 1)                 51        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 114,851\n",
      "Trainable params: 114,851\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Y shape (1419, 1)\n",
      "Train on 1419 samples, validate on 284 samples\n",
      "Epoch 1/70\n",
      " - 6s - loss: 0.0108 - msle: 0.0108 - val_loss: 0.0112 - val_msle: 0.0112\n",
      "Epoch 2/70\n",
      " - 1s - loss: 0.0632 - msle: 0.0632 - val_loss: 0.0923 - val_msle: 0.0923\n",
      "Epoch 3/70\n",
      " - 1s - loss: 0.0380 - msle: 0.0380 - val_loss: 0.0469 - val_msle: 0.0469\n",
      "Epoch 4/70\n",
      " - 1s - loss: 0.0193 - msle: 0.0193 - val_loss: 0.0034 - val_msle: 0.0034\n",
      "Epoch 5/70\n",
      " - 1s - loss: 0.0071 - msle: 0.0071 - val_loss: 0.0062 - val_msle: 0.0062\n",
      "Epoch 6/70\n",
      " - 1s - loss: 0.0070 - msle: 0.0070 - val_loss: 0.0043 - val_msle: 0.0043\n",
      "Epoch 7/70\n",
      " - 1s - loss: 0.0041 - msle: 0.0041 - val_loss: 0.0039 - val_msle: 0.0039\n",
      "Epoch 8/70\n",
      " - 1s - loss: 0.0037 - msle: 0.0037 - val_loss: 0.0038 - val_msle: 0.0038\n",
      "Epoch 9/70\n",
      " - 1s - loss: 0.0031 - msle: 0.0031 - val_loss: 0.0036 - val_msle: 0.0036\n",
      "Epoch 10/70\n",
      " - 1s - loss: 0.0024 - msle: 0.0024 - val_loss: 0.0037 - val_msle: 0.0037\n",
      "Epoch 11/70\n",
      " - 1s - loss: 0.0021 - msle: 0.0021 - val_loss: 0.0033 - val_msle: 0.0033\n",
      "Epoch 12/70\n",
      " - 1s - loss: 0.0016 - msle: 0.0016 - val_loss: 0.0034 - val_msle: 0.0034\n",
      "Epoch 13/70\n",
      " - 1s - loss: 0.0019 - msle: 0.0019 - val_loss: 0.0032 - val_msle: 0.0032\n",
      "Epoch 14/70\n",
      " - 1s - loss: 0.0017 - msle: 0.0017 - val_loss: 0.0032 - val_msle: 0.0032\n",
      "Epoch 15/70\n",
      " - 1s - loss: 0.0018 - msle: 0.0018 - val_loss: 0.0031 - val_msle: 0.0031\n",
      "Epoch 16/70\n",
      " - 1s - loss: 0.0014 - msle: 0.0014 - val_loss: 0.0031 - val_msle: 0.0031\n",
      "Epoch 17/70\n",
      " - 1s - loss: 0.0015 - msle: 0.0015 - val_loss: 0.0030 - val_msle: 0.0030\n",
      "Epoch 18/70\n",
      " - 1s - loss: 0.0015 - msle: 0.0015 - val_loss: 0.0030 - val_msle: 0.0030\n",
      "Epoch 19/70\n",
      " - 1s - loss: 0.0015 - msle: 0.0015 - val_loss: 0.0029 - val_msle: 0.0029\n",
      "Epoch 20/70\n",
      " - 1s - loss: 0.0014 - msle: 0.0014 - val_loss: 0.0029 - val_msle: 0.0029\n",
      "Epoch 21/70\n",
      " - 1s - loss: 0.0014 - msle: 0.0014 - val_loss: 0.0029 - val_msle: 0.0029\n",
      "Epoch 22/70\n",
      " - 1s - loss: 0.0013 - msle: 0.0013 - val_loss: 0.0028 - val_msle: 0.0028\n",
      "Epoch 23/70\n",
      " - 1s - loss: 0.0014 - msle: 0.0014 - val_loss: 0.0028 - val_msle: 0.0028\n",
      "Epoch 24/70\n",
      " - 1s - loss: 0.0014 - msle: 0.0014 - val_loss: 0.0028 - val_msle: 0.0028\n",
      "Epoch 25/70\n",
      " - 1s - loss: 0.0014 - msle: 0.0014 - val_loss: 0.0027 - val_msle: 0.0027\n",
      "Epoch 26/70\n",
      " - 1s - loss: 0.0014 - msle: 0.0014 - val_loss: 0.0027 - val_msle: 0.0027\n",
      "Epoch 27/70\n",
      " - 1s - loss: 0.0013 - msle: 0.0013 - val_loss: 0.0026 - val_msle: 0.0026\n",
      "Epoch 28/70\n",
      " - 1s - loss: 0.0014 - msle: 0.0014 - val_loss: 0.0026 - val_msle: 0.0026\n",
      "Epoch 29/70\n",
      " - 1s - loss: 0.0013 - msle: 0.0013 - val_loss: 0.0025 - val_msle: 0.0025\n",
      "Epoch 30/70\n",
      " - 1s - loss: 0.0011 - msle: 0.0011 - val_loss: 0.0024 - val_msle: 0.0024\n",
      "Epoch 31/70\n",
      " - 1s - loss: 0.0013 - msle: 0.0013 - val_loss: 0.0024 - val_msle: 0.0024\n",
      "Epoch 32/70\n",
      " - 1s - loss: 0.0011 - msle: 0.0011 - val_loss: 0.0023 - val_msle: 0.0023\n",
      "Epoch 33/70\n",
      " - 1s - loss: 0.0011 - msle: 0.0011 - val_loss: 0.0023 - val_msle: 0.0023\n",
      "Epoch 34/70\n",
      " - 1s - loss: 0.0013 - msle: 0.0013 - val_loss: 0.0023 - val_msle: 0.0023\n",
      "Epoch 35/70\n",
      " - 1s - loss: 0.0013 - msle: 0.0013 - val_loss: 0.0022 - val_msle: 0.0022\n",
      "Epoch 36/70\n",
      " - 1s - loss: 0.0013 - msle: 0.0013 - val_loss: 0.0022 - val_msle: 0.0022\n",
      "Epoch 37/70\n",
      " - 1s - loss: 0.0012 - msle: 0.0012 - val_loss: 0.0023 - val_msle: 0.0023\n",
      "Epoch 38/70\n",
      " - 1s - loss: 0.0011 - msle: 0.0011 - val_loss: 0.0021 - val_msle: 0.0021\n",
      "Epoch 39/70\n",
      " - 1s - loss: 0.0012 - msle: 0.0012 - val_loss: 0.0022 - val_msle: 0.0022\n",
      "Epoch 40/70\n",
      " - 1s - loss: 0.0011 - msle: 0.0011 - val_loss: 0.0020 - val_msle: 0.0020\n",
      "Epoch 41/70\n",
      " - 1s - loss: 0.0011 - msle: 0.0011 - val_loss: 0.0022 - val_msle: 0.0022\n",
      "Epoch 42/70\n",
      " - 1s - loss: 0.0011 - msle: 0.0011 - val_loss: 0.0020 - val_msle: 0.0020\n",
      "Epoch 43/70\n",
      " - 1s - loss: 0.0011 - msle: 0.0011 - val_loss: 0.0019 - val_msle: 0.0019\n",
      "Epoch 44/70\n",
      " - 1s - loss: 0.0011 - msle: 0.0011 - val_loss: 0.0019 - val_msle: 0.0019\n",
      "Epoch 45/70\n",
      " - 1s - loss: 0.0010 - msle: 0.0010 - val_loss: 0.0019 - val_msle: 0.0019\n",
      "Epoch 46/70\n",
      " - 1s - loss: 9.9552e-04 - msle: 9.9552e-04 - val_loss: 0.0019 - val_msle: 0.0019\n",
      "Epoch 47/70\n",
      " - 1s - loss: 9.9806e-04 - msle: 9.9806e-04 - val_loss: 0.0018 - val_msle: 0.0018\n",
      "Epoch 48/70\n",
      " - 1s - loss: 0.0010 - msle: 0.0010 - val_loss: 0.0023 - val_msle: 0.0023\n",
      "Epoch 49/70\n",
      " - 1s - loss: 0.0011 - msle: 0.0011 - val_loss: 0.0018 - val_msle: 0.0018\n",
      "Epoch 50/70\n",
      " - 1s - loss: 0.0012 - msle: 0.0012 - val_loss: 0.0019 - val_msle: 0.0019\n",
      "Epoch 51/70\n",
      " - 1s - loss: 9.0315e-04 - msle: 9.0315e-04 - val_loss: 0.0017 - val_msle: 0.0017\n",
      "Epoch 52/70\n",
      " - 1s - loss: 9.8123e-04 - msle: 9.8123e-04 - val_loss: 0.0017 - val_msle: 0.0017\n",
      "Epoch 53/70\n",
      " - 1s - loss: 0.0011 - msle: 0.0011 - val_loss: 0.0018 - val_msle: 0.0018\n",
      "Epoch 54/70\n",
      " - 1s - loss: 9.9750e-04 - msle: 9.9750e-04 - val_loss: 0.0017 - val_msle: 0.0017\n",
      "Epoch 55/70\n",
      " - 1s - loss: 0.0010 - msle: 0.0010 - val_loss: 0.0017 - val_msle: 0.0017\n",
      "Epoch 56/70\n",
      " - 1s - loss: 0.0010 - msle: 0.0010 - val_loss: 0.0016 - val_msle: 0.0016\n",
      "Epoch 57/70\n",
      " - 1s - loss: 9.6374e-04 - msle: 9.6374e-04 - val_loss: 0.0016 - val_msle: 0.0016\n",
      "Epoch 58/70\n",
      " - 1s - loss: 9.5151e-04 - msle: 9.5151e-04 - val_loss: 0.0019 - val_msle: 0.0019\n",
      "Epoch 59/70\n",
      " - 1s - loss: 8.8104e-04 - msle: 8.8104e-04 - val_loss: 0.0017 - val_msle: 0.0017\n",
      "Epoch 60/70\n",
      " - 1s - loss: 9.9065e-04 - msle: 9.9065e-04 - val_loss: 0.0016 - val_msle: 0.0016\n",
      "Epoch 61/70\n",
      " - 1s - loss: 8.2286e-04 - msle: 8.2286e-04 - val_loss: 0.0016 - val_msle: 0.0016\n",
      "Epoch 62/70\n",
      " - 1s - loss: 0.0010 - msle: 0.0010 - val_loss: 0.0017 - val_msle: 0.0017\n",
      "Epoch 63/70\n",
      " - 1s - loss: 0.0012 - msle: 0.0012 - val_loss: 0.0023 - val_msle: 0.0023\n",
      "Epoch 64/70\n",
      " - 1s - loss: 0.0011 - msle: 0.0011 - val_loss: 0.0020 - val_msle: 0.0020\n",
      "Epoch 65/70\n",
      " - 1s - loss: 0.0011 - msle: 0.0011 - val_loss: 0.0017 - val_msle: 0.0017\n",
      "Epoch 66/70\n",
      " - 1s - loss: 9.1305e-04 - msle: 9.1305e-04 - val_loss: 0.0016 - val_msle: 0.0016\n",
      "Epoch 67/70\n",
      " - 1s - loss: 9.2678e-04 - msle: 9.2678e-04 - val_loss: 0.0016 - val_msle: 0.0016\n",
      "Epoch 68/70\n",
      " - 1s - loss: 0.0011 - msle: 0.0011 - val_loss: 0.0015 - val_msle: 0.0015\n",
      "Epoch 69/70\n",
      " - 1s - loss: 9.1727e-04 - msle: 9.1727e-04 - val_loss: 0.0017 - val_msle: 0.0017\n",
      "Epoch 70/70\n",
      " - 1s - loss: 8.5192e-04 - msle: 8.5192e-04 - val_loss: 0.0019 - val_msle: 0.0019\n",
      "PREDICTING VALUE FOR       close_19     ADX_19     RSI_19  close_18     ADX_18     RSI_18  \\\n",
      "1576  59707.51  23.280175  46.181102  58622.02  22.582078  43.776117   \n",
      "\n",
      "      close_17     ADX_17     RSI_17  close_16  ...   close_2      ADX_2  \\\n",
      "1576  56247.18  21.922024  38.991852  57541.27  ...  50588.95  26.624459   \n",
      "\n",
      "          RSI_2   close_1      ADX_1    RSI_1   close_0      ADX_0      RSI_0  \\\n",
      "1576  35.801031  50471.19  27.717067  35.5866  47545.59  28.966559  30.671535   \n",
      "\n",
      "         close  \n",
      "1576  48343.28  \n",
      "\n",
      "[1 rows x 61 columns]\n",
      "real [[48343.28]]\n",
      "Test RMSE: 1047.744\n",
      "Diff [[1047.74351797]]\n",
      "% Diff [[2.16729919]] %\n",
      "||||----|||| Current Orders: [] \n",
      "\n",
      "\n",
      "\n",
      "INDEX: 1420\n",
      "CLOSE: 34220.01\n",
      "MODE: sell\n",
      "CHECKING ORDERS...\n",
      "TRAINING MODEL:\n",
      "Input shape: (1420, 1, 60) (1420, 1)\n",
      "Model: \"sequential_22\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_64 (LSTM)               (None, 1, 100)            64400     \n",
      "_________________________________________________________________\n",
      "lstm_65 (LSTM)               (None, 1, 50)             30200     \n",
      "_________________________________________________________________\n",
      "dropout_43 (Dropout)         (None, 1, 50)             0         \n",
      "_________________________________________________________________\n",
      "lstm_66 (LSTM)               (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_44 (Dropout)         (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 1)                 51        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 114,851\n",
      "Trainable params: 114,851\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Y shape (1420, 1)\n",
      "Train on 1420 samples, validate on 284 samples\n",
      "Epoch 1/70\n",
      " - 7s - loss: 0.0103 - msle: 0.0103 - val_loss: 0.0088 - val_msle: 0.0088\n",
      "Epoch 2/70\n",
      " - 1s - loss: 0.0529 - msle: 0.0529 - val_loss: 0.0266 - val_msle: 0.0266\n",
      "Epoch 3/70\n",
      " - 1s - loss: 0.0576 - msle: 0.0576 - val_loss: 0.0827 - val_msle: 0.0827\n",
      "Epoch 4/70\n",
      " - 1s - loss: 0.0163 - msle: 0.0163 - val_loss: 0.0034 - val_msle: 0.0034\n",
      "Epoch 5/70\n",
      " - 1s - loss: 0.0076 - msle: 0.0076 - val_loss: 0.0071 - val_msle: 0.0071\n",
      "Epoch 6/70\n",
      " - 1s - loss: 0.0077 - msle: 0.0077 - val_loss: 0.0041 - val_msle: 0.0041\n",
      "Epoch 7/70\n",
      " - 1s - loss: 0.0049 - msle: 0.0049 - val_loss: 0.0038 - val_msle: 0.0038\n",
      "Epoch 8/70\n",
      " - 1s - loss: 0.0036 - msle: 0.0036 - val_loss: 0.0037 - val_msle: 0.0037\n",
      "Epoch 9/70\n",
      " - 1s - loss: 0.0029 - msle: 0.0029 - val_loss: 0.0033 - val_msle: 0.0033\n",
      "Epoch 10/70\n",
      " - 1s - loss: 0.0020 - msle: 0.0020 - val_loss: 0.0034 - val_msle: 0.0034\n",
      "Epoch 11/70\n",
      " - 1s - loss: 0.0023 - msle: 0.0023 - val_loss: 0.0034 - val_msle: 0.0034\n",
      "Epoch 12/70\n",
      " - 1s - loss: 0.0020 - msle: 0.0020 - val_loss: 0.0033 - val_msle: 0.0033\n",
      "Epoch 13/70\n",
      " - 1s - loss: 0.0021 - msle: 0.0021 - val_loss: 0.0032 - val_msle: 0.0032\n",
      "Epoch 14/70\n",
      " - 1s - loss: 0.0017 - msle: 0.0017 - val_loss: 0.0032 - val_msle: 0.0032\n",
      "Epoch 15/70\n",
      " - 1s - loss: 0.0017 - msle: 0.0017 - val_loss: 0.0030 - val_msle: 0.0030\n",
      "Epoch 16/70\n",
      " - 1s - loss: 0.0015 - msle: 0.0015 - val_loss: 0.0031 - val_msle: 0.0031\n",
      "Epoch 17/70\n",
      " - 1s - loss: 0.0015 - msle: 0.0015 - val_loss: 0.0030 - val_msle: 0.0030\n",
      "Epoch 18/70\n",
      " - 1s - loss: 0.0016 - msle: 0.0016 - val_loss: 0.0030 - val_msle: 0.0030\n",
      "Epoch 19/70\n",
      " - 1s - loss: 0.0015 - msle: 0.0015 - val_loss: 0.0029 - val_msle: 0.0029\n",
      "Epoch 20/70\n",
      " - 1s - loss: 0.0014 - msle: 0.0014 - val_loss: 0.0029 - val_msle: 0.0029\n",
      "Epoch 21/70\n",
      " - 1s - loss: 0.0015 - msle: 0.0015 - val_loss: 0.0028 - val_msle: 0.0028\n",
      "Epoch 22/70\n",
      " - 1s - loss: 0.0015 - msle: 0.0015 - val_loss: 0.0028 - val_msle: 0.0028\n",
      "Epoch 23/70\n",
      " - 1s - loss: 0.0014 - msle: 0.0014 - val_loss: 0.0027 - val_msle: 0.0027\n",
      "Epoch 24/70\n",
      " - 1s - loss: 0.0015 - msle: 0.0015 - val_loss: 0.0027 - val_msle: 0.0027\n",
      "Epoch 25/70\n",
      " - 1s - loss: 0.0013 - msle: 0.0013 - val_loss: 0.0027 - val_msle: 0.0027\n",
      "Epoch 26/70\n",
      " - 1s - loss: 0.0014 - msle: 0.0014 - val_loss: 0.0027 - val_msle: 0.0027\n",
      "Epoch 27/70\n",
      " - 1s - loss: 0.0013 - msle: 0.0013 - val_loss: 0.0026 - val_msle: 0.0026\n",
      "Epoch 28/70\n",
      " - 1s - loss: 0.0013 - msle: 0.0013 - val_loss: 0.0025 - val_msle: 0.0025\n",
      "Epoch 29/70\n",
      " - 1s - loss: 0.0013 - msle: 0.0013 - val_loss: 0.0024 - val_msle: 0.0024\n",
      "Epoch 30/70\n",
      " - 1s - loss: 0.0013 - msle: 0.0013 - val_loss: 0.0024 - val_msle: 0.0024\n",
      "Epoch 31/70\n",
      " - 1s - loss: 0.0013 - msle: 0.0013 - val_loss: 0.0024 - val_msle: 0.0024\n",
      "Epoch 32/70\n",
      " - 1s - loss: 0.0012 - msle: 0.0012 - val_loss: 0.0024 - val_msle: 0.0024\n",
      "Epoch 33/70\n",
      " - 1s - loss: 0.0013 - msle: 0.0013 - val_loss: 0.0022 - val_msle: 0.0022\n",
      "Epoch 34/70\n",
      " - 1s - loss: 0.0011 - msle: 0.0011 - val_loss: 0.0022 - val_msle: 0.0022\n",
      "Epoch 35/70\n",
      " - 1s - loss: 0.0012 - msle: 0.0012 - val_loss: 0.0022 - val_msle: 0.0022\n",
      "Epoch 36/70\n",
      " - 1s - loss: 0.0012 - msle: 0.0012 - val_loss: 0.0021 - val_msle: 0.0021\n",
      "Epoch 37/70\n",
      " - 1s - loss: 0.0012 - msle: 0.0012 - val_loss: 0.0021 - val_msle: 0.0021\n",
      "Epoch 38/70\n",
      " - 1s - loss: 0.0011 - msle: 0.0011 - val_loss: 0.0021 - val_msle: 0.0021\n",
      "Epoch 39/70\n",
      " - 1s - loss: 0.0011 - msle: 0.0011 - val_loss: 0.0021 - val_msle: 0.0021\n",
      "Epoch 40/70\n",
      " - 1s - loss: 0.0010 - msle: 0.0010 - val_loss: 0.0019 - val_msle: 0.0019\n",
      "Epoch 41/70\n",
      " - 1s - loss: 0.0011 - msle: 0.0011 - val_loss: 0.0019 - val_msle: 0.0019\n",
      "Epoch 42/70\n",
      " - 1s - loss: 0.0011 - msle: 0.0011 - val_loss: 0.0020 - val_msle: 0.0020\n",
      "Epoch 43/70\n",
      " - 1s - loss: 0.0010 - msle: 0.0010 - val_loss: 0.0018 - val_msle: 0.0018\n",
      "Epoch 44/70\n",
      " - 1s - loss: 0.0011 - msle: 0.0011 - val_loss: 0.0018 - val_msle: 0.0018\n",
      "Epoch 45/70\n",
      " - 1s - loss: 0.0011 - msle: 0.0011 - val_loss: 0.0019 - val_msle: 0.0019\n",
      "Epoch 46/70\n",
      " - 1s - loss: 0.0011 - msle: 0.0011 - val_loss: 0.0020 - val_msle: 0.0020\n",
      "Epoch 47/70\n",
      " - 1s - loss: 0.0010 - msle: 0.0010 - val_loss: 0.0018 - val_msle: 0.0018\n",
      "Epoch 48/70\n",
      " - 1s - loss: 9.5525e-04 - msle: 9.5525e-04 - val_loss: 0.0017 - val_msle: 0.0017\n",
      "Epoch 49/70\n",
      " - 1s - loss: 0.0011 - msle: 0.0011 - val_loss: 0.0018 - val_msle: 0.0018\n",
      "Epoch 50/70\n",
      " - 1s - loss: 9.4752e-04 - msle: 9.4752e-04 - val_loss: 0.0017 - val_msle: 0.0017\n",
      "Epoch 51/70\n",
      " - 1s - loss: 0.0011 - msle: 0.0011 - val_loss: 0.0017 - val_msle: 0.0017\n",
      "Epoch 52/70\n",
      " - 1s - loss: 0.0011 - msle: 0.0011 - val_loss: 0.0025 - val_msle: 0.0025\n",
      "Epoch 53/70\n",
      " - 1s - loss: 0.0011 - msle: 0.0011 - val_loss: 0.0017 - val_msle: 0.0017\n",
      "Epoch 54/70\n",
      " - 1s - loss: 0.0010 - msle: 0.0010 - val_loss: 0.0017 - val_msle: 0.0017\n",
      "Epoch 55/70\n",
      " - 1s - loss: 9.8785e-04 - msle: 9.8785e-04 - val_loss: 0.0016 - val_msle: 0.0016\n",
      "Epoch 56/70\n",
      " - 1s - loss: 9.6014e-04 - msle: 9.6014e-04 - val_loss: 0.0020 - val_msle: 0.0020\n",
      "Epoch 57/70\n",
      " - 1s - loss: 0.0011 - msle: 0.0011 - val_loss: 0.0017 - val_msle: 0.0017\n",
      "Epoch 58/70\n",
      " - 1s - loss: 0.0011 - msle: 0.0011 - val_loss: 0.0019 - val_msle: 0.0019\n",
      "Epoch 59/70\n",
      " - 1s - loss: 0.0010 - msle: 0.0010 - val_loss: 0.0018 - val_msle: 0.0018\n",
      "Epoch 60/70\n",
      " - 1s - loss: 9.1479e-04 - msle: 9.1479e-04 - val_loss: 0.0016 - val_msle: 0.0016\n",
      "Epoch 61/70\n",
      " - 1s - loss: 0.0011 - msle: 0.0011 - val_loss: 0.0016 - val_msle: 0.0016\n",
      "Epoch 62/70\n",
      " - 1s - loss: 0.0011 - msle: 0.0011 - val_loss: 0.0018 - val_msle: 0.0018\n",
      "Epoch 63/70\n",
      " - 1s - loss: 0.0010 - msle: 0.0010 - val_loss: 0.0020 - val_msle: 0.0020\n",
      "Epoch 64/70\n",
      " - 1s - loss: 0.0013 - msle: 0.0013 - val_loss: 0.0025 - val_msle: 0.0025\n",
      "Epoch 65/70\n",
      " - 1s - loss: 9.8604e-04 - msle: 9.8604e-04 - val_loss: 0.0017 - val_msle: 0.0017\n",
      "Epoch 66/70\n",
      " - 1s - loss: 0.0010 - msle: 0.0010 - val_loss: 0.0017 - val_msle: 0.0017\n",
      "Epoch 67/70\n",
      " - 1s - loss: 0.0012 - msle: 0.0012 - val_loss: 0.0017 - val_msle: 0.0017\n",
      "Epoch 68/70\n",
      " - 1s - loss: 9.1856e-04 - msle: 9.1856e-04 - val_loss: 0.0015 - val_msle: 0.0015\n",
      "Epoch 69/70\n",
      " - 1s - loss: 9.7880e-04 - msle: 9.7880e-04 - val_loss: 0.0019 - val_msle: 0.0019\n",
      "Epoch 70/70\n",
      " - 1s - loss: 9.3830e-04 - msle: 9.3830e-04 - val_loss: 0.0015 - val_msle: 0.0015\n",
      "PREDICTING VALUE FOR       close_19     ADX_19     RSI_19  close_18     ADX_18     RSI_18  \\\n",
      "1577  58622.02  22.582078  43.776117  56247.18  21.922024  38.991852   \n",
      "\n",
      "      close_17     ADX_17     RSI_17  close_16  ...   close_2      ADX_2  \\\n",
      "1577  57541.27  22.171558  42.668771  57138.29  ...  50471.19  27.717067   \n",
      "\n",
      "        RSI_2   close_1      ADX_1      RSI_1   close_0      ADX_0      RSI_0  \\\n",
      "1577  35.5866  47545.59  28.966559  30.671535  47140.54  30.320821  30.052658   \n",
      "\n",
      "         close  \n",
      "1577  48864.98  \n",
      "\n",
      "[1 rows x 61 columns]\n",
      "real [[48864.98]]\n",
      "Test RMSE: 2755.162\n",
      "Diff [[2755.1623928]]\n",
      "% Diff [[5.63831683]] %\n",
      "||||----|||| Current Orders: [] \n",
      "\n",
      "\n",
      "\n",
      "INDEX: 1421\n",
      "CLOSE: 33862.12\n",
      "MODE: sell\n",
      "CHECKING ORDERS...\n",
      "TRAINING MODEL:\n",
      "Input shape: (1421, 1, 60) (1421, 1)\n",
      "Model: \"sequential_23\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_67 (LSTM)               (None, 1, 100)            64400     \n",
      "_________________________________________________________________\n",
      "lstm_68 (LSTM)               (None, 1, 50)             30200     \n",
      "_________________________________________________________________\n",
      "dropout_45 (Dropout)         (None, 1, 50)             0         \n",
      "_________________________________________________________________\n",
      "lstm_69 (LSTM)               (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_46 (Dropout)         (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 1)                 51        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 114,851\n",
      "Trainable params: 114,851\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Y shape (1421, 1)\n",
      "Train on 1421 samples, validate on 285 samples\n",
      "Epoch 1/70\n",
      " - 6s - loss: 0.0743 - msle: 0.0743 - val_loss: 0.2911 - val_msle: 0.2911\n",
      "Epoch 2/70\n",
      " - 1s - loss: 0.0746 - msle: 0.0746 - val_loss: 0.2911 - val_msle: 0.2911\n",
      "Epoch 3/70\n",
      " - 1s - loss: 0.0746 - msle: 0.0746 - val_loss: 0.2911 - val_msle: 0.2911\n",
      "Epoch 4/70\n",
      " - 1s - loss: 0.0746 - msle: 0.0746 - val_loss: 0.2911 - val_msle: 0.2911\n",
      "Epoch 5/70\n",
      " - 1s - loss: 0.0746 - msle: 0.0746 - val_loss: 0.2911 - val_msle: 0.2911\n",
      "Epoch 6/70\n",
      " - 1s - loss: 0.0746 - msle: 0.0746 - val_loss: 0.2911 - val_msle: 0.2911\n",
      "Epoch 7/70\n",
      " - 1s - loss: 0.0746 - msle: 0.0746 - val_loss: 0.2911 - val_msle: 0.2911\n",
      "Epoch 8/70\n",
      " - 1s - loss: 0.0746 - msle: 0.0746 - val_loss: 0.2911 - val_msle: 0.2911\n",
      "Epoch 9/70\n",
      " - 1s - loss: 0.0746 - msle: 0.0746 - val_loss: 0.2911 - val_msle: 0.2911\n",
      "Epoch 10/70\n",
      " - 1s - loss: 0.0746 - msle: 0.0746 - val_loss: 0.2911 - val_msle: 0.2911\n",
      "Epoch 11/70\n",
      " - 1s - loss: 0.0746 - msle: 0.0746 - val_loss: 0.2911 - val_msle: 0.2911\n",
      "Epoch 12/70\n",
      " - 1s - loss: 0.0746 - msle: 0.0746 - val_loss: 0.2911 - val_msle: 0.2911\n",
      "Epoch 13/70\n",
      " - 1s - loss: 0.0746 - msle: 0.0746 - val_loss: 0.2911 - val_msle: 0.2911\n",
      "Epoch 14/70\n",
      " - 1s - loss: 0.0746 - msle: 0.0746 - val_loss: 0.2911 - val_msle: 0.2911\n",
      "Epoch 15/70\n",
      " - 1s - loss: 0.0746 - msle: 0.0746 - val_loss: 0.2911 - val_msle: 0.2911\n",
      "Epoch 16/70\n",
      " - 1s - loss: 0.0746 - msle: 0.0746 - val_loss: 0.2911 - val_msle: 0.2911\n",
      "Epoch 17/70\n",
      " - 1s - loss: 0.0746 - msle: 0.0746 - val_loss: 0.2911 - val_msle: 0.2911\n",
      "Epoch 18/70\n",
      " - 1s - loss: 0.0746 - msle: 0.0746 - val_loss: 0.2911 - val_msle: 0.2911\n",
      "Epoch 19/70\n",
      " - 1s - loss: 0.0746 - msle: 0.0746 - val_loss: 0.2911 - val_msle: 0.2911\n",
      "Epoch 20/70\n",
      " - 1s - loss: 0.0746 - msle: 0.0746 - val_loss: 0.2911 - val_msle: 0.2911\n",
      "Epoch 21/70\n",
      " - 1s - loss: 0.0746 - msle: 0.0746 - val_loss: 0.2911 - val_msle: 0.2911\n",
      "Epoch 22/70\n",
      " - 1s - loss: 0.0746 - msle: 0.0746 - val_loss: 0.2911 - val_msle: 0.2911\n",
      "Epoch 23/70\n",
      " - 1s - loss: 0.0746 - msle: 0.0746 - val_loss: 0.2911 - val_msle: 0.2911\n",
      "Epoch 24/70\n",
      " - 1s - loss: 0.0746 - msle: 0.0746 - val_loss: 0.2911 - val_msle: 0.2911\n",
      "Epoch 25/70\n",
      " - 1s - loss: 0.0746 - msle: 0.0746 - val_loss: 0.2911 - val_msle: 0.2911\n",
      "Epoch 26/70\n",
      " - 1s - loss: 0.0746 - msle: 0.0746 - val_loss: 0.2911 - val_msle: 0.2911\n",
      "PREDICTING VALUE FOR       close_19     ADX_19     RSI_19  close_18     ADX_18     RSI_18  \\\n",
      "1578  56247.18  21.922024  38.991852  57541.27  22.171558  42.668771   \n",
      "\n",
      "      close_17    ADX_17     RSI_17  close_16  ...   close_2      ADX_2  \\\n",
      "1578  57138.29  22.48208  41.823453  58960.36  ...  47545.59  28.966559   \n",
      "\n",
      "          RSI_2   close_1      ADX_1      RSI_1   close_0      ADX_0  \\\n",
      "1578  30.671535  47140.54  30.320821  30.052658  49389.99  31.648609   \n",
      "\n",
      "          RSI_0     close  \n",
      "1578  37.584688  47632.38  \n",
      "\n",
      "[1 rows x 61 columns]\n",
      "real [[47632.38]]\n",
      "Test RMSE: 44642.941\n",
      "Diff [[44642.9408851]]\n",
      "% Diff [[93.72393503]] %\n",
      "||||----|||| Current Orders: [] \n",
      "\n",
      "\n",
      "\n",
      "INDEX: 1422\n",
      "CLOSE: 32875.71\n",
      "MODE: sell\n",
      "CHECKING ORDERS...\n",
      "TRAINING MODEL:\n",
      "Input shape: (1422, 1, 60) (1422, 1)\n",
      "Model: \"sequential_24\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_70 (LSTM)               (None, 1, 100)            64400     \n",
      "_________________________________________________________________\n",
      "lstm_71 (LSTM)               (None, 1, 50)             30200     \n",
      "_________________________________________________________________\n",
      "dropout_47 (Dropout)         (None, 1, 50)             0         \n",
      "_________________________________________________________________\n",
      "lstm_72 (LSTM)               (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_48 (Dropout)         (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 1)                 51        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 114,851\n",
      "Trainable params: 114,851\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Y shape (1422, 1)\n",
      "Train on 1422 samples, validate on 285 samples\n",
      "Epoch 1/70\n",
      " - 6s - loss: 0.0744 - msle: 0.0744 - val_loss: 0.2911 - val_msle: 0.2911\n",
      "Epoch 2/70\n",
      " - 1s - loss: 0.0748 - msle: 0.0748 - val_loss: 0.2911 - val_msle: 0.2911\n",
      "Epoch 3/70\n",
      " - 1s - loss: 0.0748 - msle: 0.0748 - val_loss: 0.2911 - val_msle: 0.2911\n",
      "Epoch 4/70\n",
      " - 1s - loss: 0.0748 - msle: 0.0748 - val_loss: 0.2911 - val_msle: 0.2911\n",
      "Epoch 5/70\n",
      " - 1s - loss: 0.0748 - msle: 0.0748 - val_loss: 0.2911 - val_msle: 0.2911\n",
      "Epoch 6/70\n",
      " - 1s - loss: 0.0748 - msle: 0.0748 - val_loss: 0.2911 - val_msle: 0.2911\n",
      "Epoch 7/70\n",
      " - 1s - loss: 0.0748 - msle: 0.0748 - val_loss: 0.2911 - val_msle: 0.2911\n",
      "Epoch 8/70\n",
      " - 1s - loss: 0.0748 - msle: 0.0748 - val_loss: 0.2911 - val_msle: 0.2911\n",
      "Epoch 9/70\n",
      " - 1s - loss: 0.0748 - msle: 0.0748 - val_loss: 0.2911 - val_msle: 0.2911\n",
      "Epoch 10/70\n",
      " - 1s - loss: 0.0748 - msle: 0.0748 - val_loss: 0.2911 - val_msle: 0.2911\n",
      "Epoch 11/70\n",
      " - 1s - loss: 0.0748 - msle: 0.0748 - val_loss: 0.2911 - val_msle: 0.2911\n",
      "Epoch 12/70\n",
      " - 1s - loss: 0.0748 - msle: 0.0748 - val_loss: 0.2911 - val_msle: 0.2911\n",
      "Epoch 13/70\n",
      " - 1s - loss: 0.0748 - msle: 0.0748 - val_loss: 0.2911 - val_msle: 0.2911\n",
      "Epoch 14/70\n",
      " - 1s - loss: 0.0748 - msle: 0.0748 - val_loss: 0.2911 - val_msle: 0.2911\n",
      "Epoch 15/70\n",
      " - 1s - loss: 0.0748 - msle: 0.0748 - val_loss: 0.2911 - val_msle: 0.2911\n",
      "Epoch 16/70\n",
      " - 1s - loss: 0.0748 - msle: 0.0748 - val_loss: 0.2911 - val_msle: 0.2911\n",
      "Epoch 17/70\n",
      " - 1s - loss: 0.0748 - msle: 0.0748 - val_loss: 0.2911 - val_msle: 0.2911\n",
      "Epoch 18/70\n",
      " - 1s - loss: 0.0748 - msle: 0.0748 - val_loss: 0.2911 - val_msle: 0.2911\n",
      "Epoch 19/70\n",
      " - 1s - loss: 0.0748 - msle: 0.0748 - val_loss: 0.2911 - val_msle: 0.2911\n",
      "Epoch 20/70\n",
      " - 1s - loss: 0.0748 - msle: 0.0748 - val_loss: 0.2911 - val_msle: 0.2911\n",
      "Epoch 21/70\n",
      " - 1s - loss: 0.0748 - msle: 0.0748 - val_loss: 0.2911 - val_msle: 0.2911\n",
      "Epoch 22/70\n",
      " - 1s - loss: 0.0748 - msle: 0.0748 - val_loss: 0.2911 - val_msle: 0.2911\n",
      "Epoch 23/70\n",
      " - 1s - loss: 0.0748 - msle: 0.0748 - val_loss: 0.2911 - val_msle: 0.2911\n",
      "Epoch 24/70\n",
      " - 1s - loss: 0.0748 - msle: 0.0748 - val_loss: 0.2911 - val_msle: 0.2911\n",
      "Epoch 25/70\n",
      " - 1s - loss: 0.0748 - msle: 0.0748 - val_loss: 0.2911 - val_msle: 0.2911\n",
      "Epoch 26/70\n",
      " - 1s - loss: 0.0748 - msle: 0.0748 - val_loss: 0.2911 - val_msle: 0.2911\n",
      "PREDICTING VALUE FOR       close_19     ADX_19     RSI_19  close_18    ADX_18     RSI_18  close_17  \\\n",
      "1579  57541.27  22.171558  42.668771  57138.29  22.48208  41.823453  58960.36   \n",
      "\n",
      "         ADX_17     RSI_17  close_16  ...   close_2      ADX_2      RSI_2  \\\n",
      "1579  22.709187  46.941786  53726.53  ...  47140.54  30.320821  30.052658   \n",
      "\n",
      "       close_1      ADX_1      RSI_1  close_0      ADX_0     RSI_0    close  \n",
      "1579  49389.99  31.648609  37.584688  50053.9  32.851719  39.65023  46131.2  \n",
      "\n",
      "[1 rows x 61 columns]\n",
      "real [[46131.2]]\n",
      "Test RMSE: 43145.410\n",
      "Diff [[43145.40988136]]\n",
      "% Diff [[93.52761229]] %\n",
      "||||----|||| Current Orders: [] \n",
      "\n",
      "\n",
      "\n",
      "INDEX: 1423\n",
      "CLOSE: 33815.81\n",
      "MODE: sell\n",
      "CHECKING ORDERS...\n",
      "TRAINING MODEL:\n",
      "Input shape: (1423, 1, 60) (1423, 1)\n",
      "Model: \"sequential_25\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_73 (LSTM)               (None, 1, 100)            64400     \n",
      "_________________________________________________________________\n",
      "lstm_74 (LSTM)               (None, 1, 50)             30200     \n",
      "_________________________________________________________________\n",
      "dropout_49 (Dropout)         (None, 1, 50)             0         \n",
      "_________________________________________________________________\n",
      "lstm_75 (LSTM)               (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_50 (Dropout)         (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 1)                 51        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 114,851\n",
      "Trainable params: 114,851\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Y shape (1423, 1)\n",
      "Train on 1423 samples, validate on 285 samples\n",
      "Epoch 1/70\n",
      " - 6s - loss: 0.0114 - msle: 0.0114 - val_loss: 0.0126 - val_msle: 0.0126\n",
      "Epoch 2/70\n",
      " - 1s - loss: 0.0583 - msle: 0.0583 - val_loss: 0.0691 - val_msle: 0.0691\n",
      "Epoch 3/70\n",
      " - 1s - loss: 0.0491 - msle: 0.0491 - val_loss: 0.0754 - val_msle: 0.0754\n",
      "Epoch 4/70\n",
      " - 1s - loss: 0.0204 - msle: 0.0204 - val_loss: 0.0071 - val_msle: 0.0071\n",
      "Epoch 5/70\n",
      " - 1s - loss: 0.0067 - msle: 0.0067 - val_loss: 0.0053 - val_msle: 0.0053\n",
      "Epoch 6/70\n",
      " - 1s - loss: 0.0059 - msle: 0.0059 - val_loss: 0.0044 - val_msle: 0.0044\n",
      "Epoch 7/70\n",
      " - 1s - loss: 0.0040 - msle: 0.0040 - val_loss: 0.0037 - val_msle: 0.0037\n",
      "Epoch 8/70\n",
      " - 1s - loss: 0.0026 - msle: 0.0026 - val_loss: 0.0039 - val_msle: 0.0039\n",
      "Epoch 9/70\n",
      " - 1s - loss: 0.0024 - msle: 0.0024 - val_loss: 0.0035 - val_msle: 0.0035\n",
      "Epoch 10/70\n",
      " - 1s - loss: 0.0019 - msle: 0.0019 - val_loss: 0.0035 - val_msle: 0.0035\n",
      "Epoch 11/70\n",
      " - 1s - loss: 0.0020 - msle: 0.0020 - val_loss: 0.0034 - val_msle: 0.0034\n",
      "Epoch 12/70\n",
      " - 1s - loss: 0.0017 - msle: 0.0017 - val_loss: 0.0033 - val_msle: 0.0033\n",
      "Epoch 13/70\n",
      " - 1s - loss: 0.0018 - msle: 0.0018 - val_loss: 0.0032 - val_msle: 0.0032\n",
      "Epoch 14/70\n",
      " - 1s - loss: 0.0017 - msle: 0.0017 - val_loss: 0.0032 - val_msle: 0.0032\n",
      "Epoch 15/70\n",
      " - 1s - loss: 0.0017 - msle: 0.0017 - val_loss: 0.0031 - val_msle: 0.0031\n",
      "Epoch 16/70\n",
      " - 1s - loss: 0.0016 - msle: 0.0016 - val_loss: 0.0031 - val_msle: 0.0031\n",
      "Epoch 17/70\n",
      " - 1s - loss: 0.0016 - msle: 0.0016 - val_loss: 0.0030 - val_msle: 0.0030\n",
      "Epoch 18/70\n",
      " - 1s - loss: 0.0015 - msle: 0.0015 - val_loss: 0.0030 - val_msle: 0.0030\n",
      "Epoch 19/70\n",
      " - 1s - loss: 0.0015 - msle: 0.0015 - val_loss: 0.0029 - val_msle: 0.0029\n",
      "Epoch 20/70\n",
      " - 1s - loss: 0.0016 - msle: 0.0016 - val_loss: 0.0029 - val_msle: 0.0029\n",
      "Epoch 21/70\n",
      " - 1s - loss: 0.0016 - msle: 0.0016 - val_loss: 0.0029 - val_msle: 0.0029\n",
      "Epoch 22/70\n",
      " - 1s - loss: 0.0014 - msle: 0.0014 - val_loss: 0.0028 - val_msle: 0.0028\n",
      "Epoch 23/70\n",
      " - 1s - loss: 0.0017 - msle: 0.0017 - val_loss: 0.0027 - val_msle: 0.0027\n",
      "Epoch 24/70\n",
      " - 1s - loss: 0.0013 - msle: 0.0013 - val_loss: 0.0027 - val_msle: 0.0027\n",
      "Epoch 25/70\n",
      " - 1s - loss: 0.0014 - msle: 0.0014 - val_loss: 0.0026 - val_msle: 0.0026\n",
      "Epoch 26/70\n",
      " - 1s - loss: 0.0014 - msle: 0.0014 - val_loss: 0.0026 - val_msle: 0.0026\n",
      "Epoch 27/70\n",
      " - 1s - loss: 0.0014 - msle: 0.0014 - val_loss: 0.0026 - val_msle: 0.0026\n",
      "Epoch 28/70\n",
      " - 1s - loss: 0.0014 - msle: 0.0014 - val_loss: 0.0025 - val_msle: 0.0025\n",
      "Epoch 29/70\n",
      " - 1s - loss: 0.0014 - msle: 0.0014 - val_loss: 0.0025 - val_msle: 0.0025\n",
      "Epoch 30/70\n",
      " - 1s - loss: 0.0013 - msle: 0.0013 - val_loss: 0.0025 - val_msle: 0.0025\n",
      "Epoch 31/70\n",
      " - 1s - loss: 0.0012 - msle: 0.0012 - val_loss: 0.0024 - val_msle: 0.0024\n",
      "Epoch 32/70\n",
      " - 1s - loss: 0.0013 - msle: 0.0013 - val_loss: 0.0024 - val_msle: 0.0024\n",
      "Epoch 33/70\n",
      " - 1s - loss: 0.0013 - msle: 0.0013 - val_loss: 0.0023 - val_msle: 0.0023\n",
      "Epoch 34/70\n",
      " - 1s - loss: 0.0013 - msle: 0.0013 - val_loss: 0.0024 - val_msle: 0.0024\n",
      "Epoch 35/70\n",
      " - 1s - loss: 0.0012 - msle: 0.0012 - val_loss: 0.0022 - val_msle: 0.0022\n",
      "Epoch 36/70\n",
      " - 1s - loss: 0.0012 - msle: 0.0012 - val_loss: 0.0022 - val_msle: 0.0022\n",
      "Epoch 37/70\n",
      " - 1s - loss: 0.0012 - msle: 0.0012 - val_loss: 0.0021 - val_msle: 0.0021\n",
      "Epoch 38/70\n",
      " - 1s - loss: 0.0011 - msle: 0.0011 - val_loss: 0.0021 - val_msle: 0.0021\n",
      "Epoch 39/70\n",
      " - 1s - loss: 0.0012 - msle: 0.0012 - val_loss: 0.0021 - val_msle: 0.0021\n",
      "Epoch 40/70\n",
      " - 1s - loss: 0.0011 - msle: 0.0011 - val_loss: 0.0020 - val_msle: 0.0020\n",
      "Epoch 41/70\n",
      " - 1s - loss: 0.0011 - msle: 0.0011 - val_loss: 0.0019 - val_msle: 0.0019\n",
      "Epoch 42/70\n",
      " - 1s - loss: 0.0012 - msle: 0.0012 - val_loss: 0.0019 - val_msle: 0.0019\n",
      "Epoch 43/70\n",
      " - 1s - loss: 0.0011 - msle: 0.0011 - val_loss: 0.0020 - val_msle: 0.0020\n",
      "Epoch 44/70\n",
      " - 1s - loss: 0.0011 - msle: 0.0011 - val_loss: 0.0019 - val_msle: 0.0019\n",
      "Epoch 45/70\n",
      " - 1s - loss: 0.0011 - msle: 0.0011 - val_loss: 0.0020 - val_msle: 0.0020\n",
      "Epoch 46/70\n",
      " - 1s - loss: 0.0010 - msle: 0.0010 - val_loss: 0.0018 - val_msle: 0.0018\n",
      "Epoch 47/70\n",
      " - 1s - loss: 0.0010 - msle: 0.0010 - val_loss: 0.0018 - val_msle: 0.0018\n",
      "Epoch 48/70\n",
      " - 1s - loss: 0.0011 - msle: 0.0011 - val_loss: 0.0018 - val_msle: 0.0018\n",
      "Epoch 49/70\n",
      " - 1s - loss: 9.6007e-04 - msle: 9.6007e-04 - val_loss: 0.0018 - val_msle: 0.0018\n",
      "Epoch 50/70\n",
      " - 1s - loss: 0.0011 - msle: 0.0011 - val_loss: 0.0019 - val_msle: 0.0019\n",
      "Epoch 51/70\n",
      " - 1s - loss: 0.0010 - msle: 0.0010 - val_loss: 0.0018 - val_msle: 0.0018\n",
      "Epoch 52/70\n",
      " - 1s - loss: 0.0011 - msle: 0.0011 - val_loss: 0.0021 - val_msle: 0.0021\n",
      "Epoch 53/70\n",
      " - 1s - loss: 0.0010 - msle: 0.0010 - val_loss: 0.0017 - val_msle: 0.0017\n",
      "Epoch 54/70\n",
      " - 1s - loss: 9.1277e-04 - msle: 9.1277e-04 - val_loss: 0.0016 - val_msle: 0.0016\n",
      "Epoch 55/70\n",
      " - 1s - loss: 0.0010 - msle: 0.0010 - val_loss: 0.0016 - val_msle: 0.0016\n",
      "Epoch 56/70\n",
      " - 1s - loss: 9.7174e-04 - msle: 9.7174e-04 - val_loss: 0.0017 - val_msle: 0.0017\n",
      "Epoch 57/70\n",
      " - 1s - loss: 0.0011 - msle: 0.0011 - val_loss: 0.0019 - val_msle: 0.0019\n",
      "Epoch 58/70\n",
      " - 1s - loss: 0.0010 - msle: 0.0010 - val_loss: 0.0017 - val_msle: 0.0017\n",
      "Epoch 59/70\n",
      " - 1s - loss: 9.4055e-04 - msle: 9.4055e-04 - val_loss: 0.0020 - val_msle: 0.0020\n",
      "Epoch 60/70\n",
      " - 1s - loss: 0.0010 - msle: 0.0010 - val_loss: 0.0019 - val_msle: 0.0019\n",
      "Epoch 61/70\n",
      " - 1s - loss: 9.8187e-04 - msle: 9.8187e-04 - val_loss: 0.0016 - val_msle: 0.0016\n",
      "Epoch 62/70\n",
      " - 1s - loss: 9.8751e-04 - msle: 9.8751e-04 - val_loss: 0.0015 - val_msle: 0.0015\n",
      "Epoch 63/70\n",
      " - 1s - loss: 9.8932e-04 - msle: 9.8932e-04 - val_loss: 0.0016 - val_msle: 0.0016\n",
      "Epoch 64/70\n",
      " - 1s - loss: 0.0012 - msle: 0.0012 - val_loss: 0.0020 - val_msle: 0.0020\n",
      "Epoch 65/70\n",
      " - 1s - loss: 9.1851e-04 - msle: 9.1851e-04 - val_loss: 0.0017 - val_msle: 0.0017\n",
      "Epoch 66/70\n",
      " - 1s - loss: 8.5651e-04 - msle: 8.5651e-04 - val_loss: 0.0016 - val_msle: 0.0016\n",
      "Epoch 67/70\n",
      " - 1s - loss: 8.7261e-04 - msle: 8.7261e-04 - val_loss: 0.0017 - val_msle: 0.0017\n",
      "Epoch 68/70\n",
      " - 1s - loss: 9.2962e-04 - msle: 9.2962e-04 - val_loss: 0.0015 - val_msle: 0.0015\n",
      "Epoch 69/70\n",
      " - 1s - loss: 9.4037e-04 - msle: 9.4037e-04 - val_loss: 0.0016 - val_msle: 0.0016\n",
      "Epoch 70/70\n",
      " - 1s - loss: 0.0010 - msle: 0.0010 - val_loss: 0.0015 - val_msle: 0.0015\n",
      "PREDICTING VALUE FOR       close_19    ADX_19     RSI_19  close_18     ADX_18     RSI_18  close_17  \\\n",
      "1580  57138.29  22.48208  41.823453  58960.36  22.709187  46.941786  53726.53   \n",
      "\n",
      "         ADX_17    RSI_17  close_16  ...   close_2      ADX_2      RSI_2  \\\n",
      "1580  22.201147  36.89936  54721.03  ...  49389.99  31.648609  37.584688   \n",
      "\n",
      "      close_1      ADX_1     RSI_1   close_0      ADX_0      RSI_0     close  \n",
      "1580  50053.9  32.851719  39.65023  46702.75  33.416801  33.604962  46834.48  \n",
      "\n",
      "[1 rows x 61 columns]\n",
      "real [[46834.48]]\n",
      "Test RMSE: 757.802\n",
      "Diff [[757.80230593]]\n",
      "% Diff [[1.6180436]] %\n",
      "||||----|||| Current Orders: [] \n",
      "\n",
      "\n",
      "\n",
      "INDEX: 1424\n",
      "CLOSE: 33502.87\n",
      "MODE: sell\n",
      "CHECKING ORDERS...\n",
      "TRAINING MODEL:\n",
      "Input shape: (1424, 1, 60) (1424, 1)\n",
      "Model: \"sequential_26\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_76 (LSTM)               (None, 1, 100)            64400     \n",
      "_________________________________________________________________\n",
      "lstm_77 (LSTM)               (None, 1, 50)             30200     \n",
      "_________________________________________________________________\n",
      "dropout_51 (Dropout)         (None, 1, 50)             0         \n",
      "_________________________________________________________________\n",
      "lstm_78 (LSTM)               (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_52 (Dropout)         (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 1)                 51        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 114,851\n",
      "Trainable params: 114,851\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Y shape (1424, 1)\n",
      "Train on 1424 samples, validate on 285 samples\n",
      "Epoch 1/70\n",
      " - 6s - loss: 0.0103 - msle: 0.0103 - val_loss: 0.0060 - val_msle: 0.0060\n",
      "Epoch 2/70\n",
      " - 1s - loss: 0.0588 - msle: 0.0588 - val_loss: 0.1130 - val_msle: 0.1130\n",
      "Epoch 3/70\n",
      " - 1s - loss: 0.0382 - msle: 0.0382 - val_loss: 0.0533 - val_msle: 0.0533\n",
      "Epoch 4/70\n",
      " - 1s - loss: 0.0118 - msle: 0.0118 - val_loss: 0.0039 - val_msle: 0.0039\n",
      "Epoch 5/70\n",
      " - 1s - loss: 0.0053 - msle: 0.0053 - val_loss: 0.0038 - val_msle: 0.0038\n",
      "Epoch 6/70\n",
      " - 1s - loss: 0.0039 - msle: 0.0039 - val_loss: 0.0039 - val_msle: 0.0039\n",
      "Epoch 7/70\n",
      " - 1s - loss: 0.0029 - msle: 0.0029 - val_loss: 0.0038 - val_msle: 0.0038\n",
      "Epoch 8/70\n",
      " - 1s - loss: 0.0024 - msle: 0.0024 - val_loss: 0.0036 - val_msle: 0.0036\n",
      "Epoch 9/70\n",
      " - 1s - loss: 0.0021 - msle: 0.0021 - val_loss: 0.0034 - val_msle: 0.0034\n",
      "Epoch 10/70\n",
      " - 1s - loss: 0.0018 - msle: 0.0018 - val_loss: 0.0033 - val_msle: 0.0033\n",
      "Epoch 11/70\n",
      " - 1s - loss: 0.0019 - msle: 0.0019 - val_loss: 0.0033 - val_msle: 0.0033\n",
      "Epoch 12/70\n",
      " - 1s - loss: 0.0015 - msle: 0.0015 - val_loss: 0.0032 - val_msle: 0.0032\n",
      "Epoch 13/70\n",
      " - 1s - loss: 0.0017 - msle: 0.0017 - val_loss: 0.0031 - val_msle: 0.0031\n",
      "Epoch 14/70\n",
      " - 1s - loss: 0.0014 - msle: 0.0014 - val_loss: 0.0031 - val_msle: 0.0031\n",
      "Epoch 15/70\n",
      " - 1s - loss: 0.0016 - msle: 0.0016 - val_loss: 0.0031 - val_msle: 0.0031\n",
      "Epoch 16/70\n",
      " - 1s - loss: 0.0015 - msle: 0.0015 - val_loss: 0.0029 - val_msle: 0.0029\n",
      "Epoch 17/70\n",
      " - 1s - loss: 0.0015 - msle: 0.0015 - val_loss: 0.0028 - val_msle: 0.0028\n",
      "Epoch 18/70\n",
      " - 1s - loss: 0.0015 - msle: 0.0015 - val_loss: 0.0028 - val_msle: 0.0028\n",
      "Epoch 19/70\n",
      " - 1s - loss: 0.0014 - msle: 0.0014 - val_loss: 0.0028 - val_msle: 0.0028\n",
      "Epoch 20/70\n",
      " - 1s - loss: 0.0015 - msle: 0.0015 - val_loss: 0.0028 - val_msle: 0.0028\n",
      "Epoch 21/70\n",
      " - 1s - loss: 0.0015 - msle: 0.0015 - val_loss: 0.0027 - val_msle: 0.0027\n",
      "Epoch 22/70\n",
      " - 1s - loss: 0.0013 - msle: 0.0013 - val_loss: 0.0027 - val_msle: 0.0027\n",
      "Epoch 23/70\n",
      " - 1s - loss: 0.0013 - msle: 0.0013 - val_loss: 0.0026 - val_msle: 0.0026\n",
      "Epoch 24/70\n",
      " - 1s - loss: 0.0014 - msle: 0.0014 - val_loss: 0.0026 - val_msle: 0.0026\n",
      "Epoch 25/70\n",
      " - 1s - loss: 0.0013 - msle: 0.0013 - val_loss: 0.0025 - val_msle: 0.0025\n",
      "Epoch 26/70\n",
      " - 1s - loss: 0.0014 - msle: 0.0014 - val_loss: 0.0025 - val_msle: 0.0025\n",
      "Epoch 27/70\n",
      " - 1s - loss: 0.0013 - msle: 0.0013 - val_loss: 0.0024 - val_msle: 0.0024\n",
      "Epoch 28/70\n",
      " - 1s - loss: 0.0013 - msle: 0.0013 - val_loss: 0.0023 - val_msle: 0.0023\n",
      "Epoch 29/70\n",
      " - 1s - loss: 0.0013 - msle: 0.0013 - val_loss: 0.0024 - val_msle: 0.0024\n",
      "Epoch 30/70\n",
      " - 1s - loss: 0.0012 - msle: 0.0012 - val_loss: 0.0023 - val_msle: 0.0023\n",
      "Epoch 31/70\n",
      " - 1s - loss: 0.0011 - msle: 0.0011 - val_loss: 0.0022 - val_msle: 0.0022\n",
      "Epoch 32/70\n",
      " - 1s - loss: 0.0012 - msle: 0.0012 - val_loss: 0.0023 - val_msle: 0.0023\n",
      "Epoch 33/70\n",
      " - 1s - loss: 0.0011 - msle: 0.0011 - val_loss: 0.0021 - val_msle: 0.0021\n",
      "Epoch 34/70\n",
      " - 1s - loss: 0.0011 - msle: 0.0011 - val_loss: 0.0021 - val_msle: 0.0021\n",
      "Epoch 35/70\n",
      " - 1s - loss: 0.0012 - msle: 0.0012 - val_loss: 0.0021 - val_msle: 0.0021\n",
      "Epoch 36/70\n",
      " - 1s - loss: 0.0011 - msle: 0.0011 - val_loss: 0.0020 - val_msle: 0.0020\n",
      "Epoch 37/70\n",
      " - 1s - loss: 0.0011 - msle: 0.0011 - val_loss: 0.0020 - val_msle: 0.0020\n",
      "Epoch 38/70\n",
      " - 1s - loss: 0.0011 - msle: 0.0011 - val_loss: 0.0023 - val_msle: 0.0023\n",
      "Epoch 39/70\n",
      " - 1s - loss: 0.0010 - msle: 0.0010 - val_loss: 0.0019 - val_msle: 0.0019\n",
      "Epoch 40/70\n",
      " - 1s - loss: 0.0011 - msle: 0.0011 - val_loss: 0.0019 - val_msle: 0.0019\n",
      "Epoch 41/70\n",
      " - 1s - loss: 0.0011 - msle: 0.0011 - val_loss: 0.0020 - val_msle: 0.0020\n",
      "Epoch 42/70\n",
      " - 1s - loss: 0.0013 - msle: 0.0013 - val_loss: 0.0025 - val_msle: 0.0025\n",
      "Epoch 43/70\n",
      " - 1s - loss: 0.0010 - msle: 0.0010 - val_loss: 0.0020 - val_msle: 0.0020\n",
      "Epoch 44/70\n",
      " - 1s - loss: 0.0011 - msle: 0.0011 - val_loss: 0.0020 - val_msle: 0.0020\n",
      "Epoch 45/70\n",
      " - 1s - loss: 0.0011 - msle: 0.0011 - val_loss: 0.0020 - val_msle: 0.0020\n",
      "Epoch 46/70\n",
      " - 1s - loss: 0.0010 - msle: 0.0010 - val_loss: 0.0019 - val_msle: 0.0019\n",
      "Epoch 47/70\n",
      " - 1s - loss: 0.0011 - msle: 0.0011 - val_loss: 0.0020 - val_msle: 0.0020\n",
      "Epoch 48/70\n",
      " - 1s - loss: 0.0010 - msle: 0.0010 - val_loss: 0.0020 - val_msle: 0.0020\n",
      "Epoch 49/70\n",
      " - 1s - loss: 0.0011 - msle: 0.0011 - val_loss: 0.0020 - val_msle: 0.0020\n",
      "Epoch 50/70\n",
      " - 1s - loss: 0.0013 - msle: 0.0013 - val_loss: 0.0023 - val_msle: 0.0023\n",
      "Epoch 51/70\n",
      " - 1s - loss: 0.0013 - msle: 0.0013 - val_loss: 0.0025 - val_msle: 0.0025\n",
      "Epoch 52/70\n",
      " - 1s - loss: 0.0010 - msle: 0.0010 - val_loss: 0.0017 - val_msle: 0.0017\n",
      "Epoch 53/70\n",
      " - 1s - loss: 0.0010 - msle: 0.0010 - val_loss: 0.0017 - val_msle: 0.0017\n",
      "Epoch 54/70\n",
      " - 1s - loss: 9.5057e-04 - msle: 9.5057e-04 - val_loss: 0.0018 - val_msle: 0.0018\n",
      "Epoch 55/70\n",
      " - 1s - loss: 9.9150e-04 - msle: 9.9150e-04 - val_loss: 0.0017 - val_msle: 0.0017\n",
      "Epoch 56/70\n",
      " - 1s - loss: 0.0010 - msle: 0.0010 - val_loss: 0.0017 - val_msle: 0.0017\n",
      "Epoch 57/70\n",
      " - 1s - loss: 9.8008e-04 - msle: 9.8008e-04 - val_loss: 0.0018 - val_msle: 0.0018\n",
      "Epoch 58/70\n",
      " - 1s - loss: 0.0010 - msle: 0.0010 - val_loss: 0.0018 - val_msle: 0.0018\n",
      "Epoch 59/70\n",
      " - 1s - loss: 0.0010 - msle: 0.0010 - val_loss: 0.0022 - val_msle: 0.0022\n",
      "Epoch 60/70\n",
      " - 1s - loss: 0.0011 - msle: 0.0011 - val_loss: 0.0022 - val_msle: 0.0022\n",
      "Epoch 61/70\n",
      " - 1s - loss: 8.0567e-04 - msle: 8.0567e-04 - val_loss: 0.0017 - val_msle: 0.0017\n",
      "Epoch 62/70\n",
      " - 1s - loss: 9.6010e-04 - msle: 9.6010e-04 - val_loss: 0.0017 - val_msle: 0.0017\n",
      "Epoch 63/70\n",
      " - 1s - loss: 0.0011 - msle: 0.0011 - val_loss: 0.0017 - val_msle: 0.0017\n",
      "Epoch 64/70\n",
      " - 1s - loss: 9.3789e-04 - msle: 9.3789e-04 - val_loss: 0.0018 - val_msle: 0.0018\n",
      "Epoch 65/70\n",
      " - 1s - loss: 9.6230e-04 - msle: 9.6230e-04 - val_loss: 0.0018 - val_msle: 0.0018\n",
      "Epoch 66/70\n",
      " - 1s - loss: 9.7177e-04 - msle: 9.7177e-04 - val_loss: 0.0020 - val_msle: 0.0020\n",
      "Epoch 67/70\n",
      " - 1s - loss: 0.0010 - msle: 0.0010 - val_loss: 0.0018 - val_msle: 0.0018\n",
      "Epoch 68/70\n",
      " - 1s - loss: 0.0010 - msle: 0.0010 - val_loss: 0.0016 - val_msle: 0.0016\n",
      "Epoch 69/70\n",
      " - 1s - loss: 9.7345e-04 - msle: 9.7345e-04 - val_loss: 0.0015 - val_msle: 0.0015\n",
      "Epoch 70/70\n",
      " - 1s - loss: 9.2811e-04 - msle: 9.2811e-04 - val_loss: 0.0016 - val_msle: 0.0016\n",
      "PREDICTING VALUE FOR       close_19     ADX_19     RSI_19  close_18     ADX_18    RSI_18  close_17  \\\n",
      "1581  58960.36  22.709187  46.941786  53726.53  22.201147  36.89936  54721.03   \n",
      "\n",
      "        ADX_17     RSI_17  close_16  ...  close_2      ADX_2     RSI_2  \\\n",
      "1581  22.73231  39.545878  57274.88  ...  50053.9  32.851719  39.65023   \n",
      "\n",
      "       close_1      ADX_1      RSI_1   close_0      ADX_0      RSI_0     close  \n",
      "1581  46702.75  33.416801  33.604962  48343.28  34.452319  38.544703  46681.23  \n",
      "\n",
      "[1 rows x 61 columns]\n",
      "real [[46681.23]]\n",
      "Test RMSE: 498.347\n",
      "Diff [[498.34741368]]\n",
      "% Diff [[1.06755416]] %\n",
      "||||----|||| Current Orders: [] \n",
      "\n",
      "\n",
      "\n",
      "INDEX: 1425\n",
      "CLOSE: 34258.99\n",
      "MODE: sell\n",
      "CHECKING ORDERS...\n",
      "TRAINING MODEL:\n",
      "Input shape: (1425, 1, 60) (1425, 1)\n",
      "Model: \"sequential_27\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_79 (LSTM)               (None, 1, 100)            64400     \n",
      "_________________________________________________________________\n",
      "lstm_80 (LSTM)               (None, 1, 50)             30200     \n",
      "_________________________________________________________________\n",
      "dropout_53 (Dropout)         (None, 1, 50)             0         \n",
      "_________________________________________________________________\n",
      "lstm_81 (LSTM)               (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_54 (Dropout)         (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 1)                 51        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 114,851\n",
      "Trainable params: 114,851\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Y shape (1425, 1)\n",
      "Train on 1425 samples, validate on 285 samples\n",
      "Epoch 1/70\n",
      " - 6s - loss: 0.0748 - msle: 0.0748 - val_loss: 0.2904 - val_msle: 0.2904\n",
      "Epoch 2/70\n",
      " - 1s - loss: 0.0752 - msle: 0.0752 - val_loss: 0.2904 - val_msle: 0.2904\n",
      "Epoch 3/70\n",
      " - 1s - loss: 0.0752 - msle: 0.0752 - val_loss: 0.2904 - val_msle: 0.2904\n",
      "Epoch 4/70\n",
      " - 1s - loss: 0.0752 - msle: 0.0752 - val_loss: 0.2904 - val_msle: 0.2904\n",
      "Epoch 5/70\n",
      " - 1s - loss: 0.0752 - msle: 0.0752 - val_loss: 0.2904 - val_msle: 0.2904\n",
      "Epoch 6/70\n",
      " - 1s - loss: 0.0752 - msle: 0.0752 - val_loss: 0.2904 - val_msle: 0.2904\n",
      "Epoch 7/70\n",
      " - 1s - loss: 0.0752 - msle: 0.0752 - val_loss: 0.2904 - val_msle: 0.2904\n",
      "Epoch 8/70\n",
      " - 1s - loss: 0.0752 - msle: 0.0752 - val_loss: 0.2904 - val_msle: 0.2904\n",
      "Epoch 9/70\n",
      " - 1s - loss: 0.0752 - msle: 0.0752 - val_loss: 0.2904 - val_msle: 0.2904\n",
      "Epoch 10/70\n",
      " - 1s - loss: 0.0100 - msle: 0.0100 - val_loss: 0.0062 - val_msle: 0.0062\n",
      "Epoch 11/70\n",
      " - 1s - loss: 0.0718 - msle: 0.0718 - val_loss: 0.1454 - val_msle: 0.1454\n",
      "Epoch 12/70\n",
      " - 1s - loss: 0.0336 - msle: 0.0336 - val_loss: 0.0367 - val_msle: 0.0367\n",
      "Epoch 13/70\n",
      " - 1s - loss: 0.0108 - msle: 0.0108 - val_loss: 0.0040 - val_msle: 0.0040\n",
      "Epoch 14/70\n",
      " - 1s - loss: 0.0057 - msle: 0.0057 - val_loss: 0.0037 - val_msle: 0.0037\n",
      "Epoch 15/70\n",
      " - 1s - loss: 0.0031 - msle: 0.0031 - val_loss: 0.0035 - val_msle: 0.0035\n",
      "Epoch 16/70\n",
      " - 1s - loss: 0.0024 - msle: 0.0024 - val_loss: 0.0036 - val_msle: 0.0036\n",
      "Epoch 17/70\n",
      " - 1s - loss: 0.0020 - msle: 0.0020 - val_loss: 0.0034 - val_msle: 0.0034\n",
      "Epoch 18/70\n",
      " - 1s - loss: 0.0019 - msle: 0.0019 - val_loss: 0.0034 - val_msle: 0.0034\n",
      "Epoch 19/70\n",
      " - 1s - loss: 0.0020 - msle: 0.0020 - val_loss: 0.0036 - val_msle: 0.0036\n",
      "Epoch 20/70\n",
      " - 1s - loss: 0.0018 - msle: 0.0018 - val_loss: 0.0033 - val_msle: 0.0033\n",
      "Epoch 21/70\n",
      " - 1s - loss: 0.0018 - msle: 0.0018 - val_loss: 0.0032 - val_msle: 0.0032\n",
      "Epoch 22/70\n",
      " - 1s - loss: 0.0017 - msle: 0.0017 - val_loss: 0.0031 - val_msle: 0.0031\n",
      "Epoch 23/70\n",
      " - 1s - loss: 0.0015 - msle: 0.0015 - val_loss: 0.0029 - val_msle: 0.0029\n",
      "Epoch 24/70\n",
      " - 1s - loss: 0.0015 - msle: 0.0015 - val_loss: 0.0029 - val_msle: 0.0029\n",
      "Epoch 25/70\n",
      " - 1s - loss: 0.0015 - msle: 0.0015 - val_loss: 0.0030 - val_msle: 0.0030\n",
      "Epoch 26/70\n",
      " - 1s - loss: 0.0016 - msle: 0.0016 - val_loss: 0.0027 - val_msle: 0.0027\n",
      "Epoch 27/70\n",
      " - 1s - loss: 0.0015 - msle: 0.0015 - val_loss: 0.0027 - val_msle: 0.0027\n",
      "Epoch 28/70\n",
      " - 1s - loss: 0.0014 - msle: 0.0014 - val_loss: 0.0027 - val_msle: 0.0027\n",
      "Epoch 29/70\n",
      " - 1s - loss: 0.0014 - msle: 0.0014 - val_loss: 0.0026 - val_msle: 0.0026\n",
      "Epoch 30/70\n",
      " - 1s - loss: 0.0012 - msle: 0.0012 - val_loss: 0.0026 - val_msle: 0.0026\n",
      "Epoch 31/70\n",
      " - 1s - loss: 0.0013 - msle: 0.0013 - val_loss: 0.0025 - val_msle: 0.0025\n",
      "Epoch 32/70\n",
      " - 1s - loss: 0.0013 - msle: 0.0013 - val_loss: 0.0025 - val_msle: 0.0025\n",
      "Epoch 33/70\n",
      " - 1s - loss: 0.0013 - msle: 0.0013 - val_loss: 0.0024 - val_msle: 0.0024\n",
      "Epoch 34/70\n",
      " - 1s - loss: 0.0012 - msle: 0.0012 - val_loss: 0.0024 - val_msle: 0.0024\n",
      "Epoch 35/70\n",
      " - 1s - loss: 0.0012 - msle: 0.0012 - val_loss: 0.0023 - val_msle: 0.0023\n",
      "Epoch 36/70\n",
      " - 1s - loss: 0.0012 - msle: 0.0012 - val_loss: 0.0023 - val_msle: 0.0023\n",
      "Epoch 37/70\n",
      " - 1s - loss: 0.0013 - msle: 0.0013 - val_loss: 0.0023 - val_msle: 0.0023\n",
      "Epoch 38/70\n",
      " - 1s - loss: 0.0013 - msle: 0.0013 - val_loss: 0.0024 - val_msle: 0.0024\n",
      "Epoch 39/70\n",
      " - 1s - loss: 0.0012 - msle: 0.0012 - val_loss: 0.0023 - val_msle: 0.0023\n",
      "Epoch 40/70\n",
      " - 1s - loss: 0.0013 - msle: 0.0013 - val_loss: 0.0021 - val_msle: 0.0021\n",
      "Epoch 41/70\n",
      " - 1s - loss: 0.0011 - msle: 0.0011 - val_loss: 0.0021 - val_msle: 0.0021\n",
      "Epoch 42/70\n",
      " - 1s - loss: 0.0012 - msle: 0.0012 - val_loss: 0.0022 - val_msle: 0.0022\n",
      "Epoch 43/70\n",
      " - 1s - loss: 0.0012 - msle: 0.0012 - val_loss: 0.0020 - val_msle: 0.0020\n",
      "Epoch 44/70\n",
      " - 1s - loss: 0.0011 - msle: 0.0011 - val_loss: 0.0020 - val_msle: 0.0020\n",
      "Epoch 45/70\n",
      " - 1s - loss: 0.0012 - msle: 0.0012 - val_loss: 0.0019 - val_msle: 0.0019\n",
      "Epoch 46/70\n",
      " - 1s - loss: 0.0011 - msle: 0.0011 - val_loss: 0.0021 - val_msle: 0.0021\n",
      "Epoch 47/70\n",
      " - 1s - loss: 0.0011 - msle: 0.0011 - val_loss: 0.0019 - val_msle: 0.0019\n",
      "Epoch 48/70\n",
      " - 1s - loss: 0.0010 - msle: 0.0010 - val_loss: 0.0018 - val_msle: 0.0018\n",
      "Epoch 49/70\n",
      " - 1s - loss: 0.0010 - msle: 0.0010 - val_loss: 0.0020 - val_msle: 0.0020\n",
      "Epoch 50/70\n",
      " - 1s - loss: 0.0012 - msle: 0.0012 - val_loss: 0.0022 - val_msle: 0.0022\n",
      "Epoch 51/70\n",
      " - 1s - loss: 0.0011 - msle: 0.0011 - val_loss: 0.0021 - val_msle: 0.0021\n",
      "Epoch 52/70\n",
      " - 1s - loss: 0.0010 - msle: 0.0010 - val_loss: 0.0020 - val_msle: 0.0020\n",
      "Epoch 53/70\n",
      " - 1s - loss: 9.4647e-04 - msle: 9.4647e-04 - val_loss: 0.0018 - val_msle: 0.0018\n",
      "Epoch 54/70\n",
      " - 1s - loss: 0.0010 - msle: 0.0010 - val_loss: 0.0018 - val_msle: 0.0018\n",
      "Epoch 55/70\n",
      " - 1s - loss: 0.0011 - msle: 0.0011 - val_loss: 0.0021 - val_msle: 0.0021\n",
      "Epoch 56/70\n",
      " - 1s - loss: 9.8877e-04 - msle: 9.8877e-04 - val_loss: 0.0019 - val_msle: 0.0019\n",
      "Epoch 57/70\n",
      " - 1s - loss: 9.5379e-04 - msle: 9.5379e-04 - val_loss: 0.0019 - val_msle: 0.0019\n",
      "Epoch 58/70\n",
      " - 1s - loss: 0.0011 - msle: 0.0011 - val_loss: 0.0018 - val_msle: 0.0018\n",
      "Epoch 59/70\n",
      " - 1s - loss: 0.0010 - msle: 0.0010 - val_loss: 0.0018 - val_msle: 0.0018\n",
      "Epoch 60/70\n",
      " - 1s - loss: 0.0012 - msle: 0.0012 - val_loss: 0.0020 - val_msle: 0.0020\n",
      "Epoch 61/70\n",
      " - 1s - loss: 9.1647e-04 - msle: 9.1647e-04 - val_loss: 0.0018 - val_msle: 0.0018\n",
      "Epoch 62/70\n",
      " - 1s - loss: 0.0011 - msle: 0.0011 - val_loss: 0.0018 - val_msle: 0.0018\n",
      "Epoch 63/70\n",
      " - 1s - loss: 8.8899e-04 - msle: 8.8899e-04 - val_loss: 0.0018 - val_msle: 0.0018\n",
      "Epoch 64/70\n",
      " - 1s - loss: 9.4245e-04 - msle: 9.4245e-04 - val_loss: 0.0016 - val_msle: 0.0016\n",
      "Epoch 65/70\n",
      " - 1s - loss: 0.0010 - msle: 0.0010 - val_loss: 0.0018 - val_msle: 0.0018\n",
      "Epoch 66/70\n",
      " - 1s - loss: 9.6831e-04 - msle: 9.6831e-04 - val_loss: 0.0017 - val_msle: 0.0017\n",
      "Epoch 67/70\n",
      " - 1s - loss: 0.0010 - msle: 0.0010 - val_loss: 0.0019 - val_msle: 0.0019\n",
      "Epoch 68/70\n",
      " - 1s - loss: 8.8548e-04 - msle: 8.8548e-04 - val_loss: 0.0016 - val_msle: 0.0016\n",
      "Epoch 69/70\n",
      " - 1s - loss: 9.5379e-04 - msle: 9.5379e-04 - val_loss: 0.0020 - val_msle: 0.0020\n",
      "Epoch 70/70\n",
      " - 1s - loss: 0.0010 - msle: 0.0010 - val_loss: 0.0020 - val_msle: 0.0020\n",
      "PREDICTING VALUE FOR       close_19     ADX_19    RSI_19  close_18    ADX_18     RSI_18  close_17  \\\n",
      "1582  53726.53  22.201147  36.89936  54721.03  22.73231  39.545878  57274.88   \n",
      "\n",
      "         ADX_17   RSI_17  close_16  ...   close_2      ADX_2      RSI_2  \\\n",
      "1582  23.158874  45.8291  57776.25  ...  46702.75  33.416801  33.604962   \n",
      "\n",
      "       close_1      ADX_1      RSI_1   close_0      ADX_0      RSI_0     close  \n",
      "1582  48343.28  34.452319  38.544703  48864.98  35.384648  40.071644  46914.16  \n",
      "\n",
      "[1 rows x 61 columns]\n",
      "real [[46914.16]]\n",
      "Test RMSE: 131.876\n",
      "Diff [[131.87624559]]\n",
      "% Diff [[0.28110115]] %\n",
      "||||----|||| Current Orders: [] \n",
      "\n",
      "\n",
      "\n",
      "INDEX: 1426\n",
      "CLOSE: 33086.63\n",
      "MODE: sell\n",
      "CHECKING ORDERS...\n",
      "TRAINING MODEL:\n",
      "Input shape: (1426, 1, 60) (1426, 1)\n",
      "Model: \"sequential_28\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_82 (LSTM)               (None, 1, 100)            64400     \n",
      "_________________________________________________________________\n",
      "lstm_83 (LSTM)               (None, 1, 50)             30200     \n",
      "_________________________________________________________________\n",
      "dropout_55 (Dropout)         (None, 1, 50)             0         \n",
      "_________________________________________________________________\n",
      "lstm_84 (LSTM)               (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_56 (Dropout)         (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 1)                 51        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 114,851\n",
      "Trainable params: 114,851\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Y shape (1426, 1)\n",
      "Train on 1426 samples, validate on 286 samples\n",
      "Epoch 1/70\n",
      " - 7s - loss: 0.0750 - msle: 0.0750 - val_loss: 0.2904 - val_msle: 0.2904\n",
      "Epoch 2/70\n",
      " - 1s - loss: 0.0753 - msle: 0.0753 - val_loss: 0.2904 - val_msle: 0.2904\n",
      "Epoch 3/70\n",
      " - 1s - loss: 0.0753 - msle: 0.0753 - val_loss: 0.2904 - val_msle: 0.2904\n",
      "Epoch 4/70\n",
      " - 1s - loss: 0.0753 - msle: 0.0753 - val_loss: 0.2904 - val_msle: 0.2904\n",
      "Epoch 5/70\n",
      " - 1s - loss: 0.0753 - msle: 0.0753 - val_loss: 0.2904 - val_msle: 0.2904\n",
      "Epoch 6/70\n",
      " - 1s - loss: 0.0753 - msle: 0.0753 - val_loss: 0.2904 - val_msle: 0.2904\n",
      "Epoch 7/70\n",
      " - 1s - loss: 0.0753 - msle: 0.0753 - val_loss: 0.2904 - val_msle: 0.2904\n",
      "Epoch 8/70\n",
      " - 1s - loss: 0.0753 - msle: 0.0753 - val_loss: 0.2904 - val_msle: 0.2904\n",
      "Epoch 9/70\n",
      " - 1s - loss: 0.0753 - msle: 0.0753 - val_loss: 0.2904 - val_msle: 0.2904\n",
      "Epoch 10/70\n",
      " - 1s - loss: 0.0753 - msle: 0.0753 - val_loss: 0.2904 - val_msle: 0.2904\n",
      "Epoch 11/70\n",
      " - 1s - loss: 0.0753 - msle: 0.0753 - val_loss: 0.2904 - val_msle: 0.2904\n",
      "Epoch 12/70\n",
      " - 1s - loss: 0.0753 - msle: 0.0753 - val_loss: 0.2904 - val_msle: 0.2904\n",
      "Epoch 13/70\n",
      " - 1s - loss: 0.0753 - msle: 0.0753 - val_loss: 0.2904 - val_msle: 0.2904\n",
      "Epoch 14/70\n",
      " - 1s - loss: 0.0753 - msle: 0.0753 - val_loss: 0.2904 - val_msle: 0.2904\n",
      "Epoch 15/70\n",
      " - 1s - loss: 0.0753 - msle: 0.0753 - val_loss: 0.2904 - val_msle: 0.2904\n",
      "Epoch 16/70\n",
      " - 1s - loss: 0.0753 - msle: 0.0753 - val_loss: 0.2904 - val_msle: 0.2904\n",
      "Epoch 17/70\n",
      " - 1s - loss: 0.0753 - msle: 0.0753 - val_loss: 0.2904 - val_msle: 0.2904\n",
      "Epoch 18/70\n",
      " - 1s - loss: 0.0753 - msle: 0.0753 - val_loss: 0.2904 - val_msle: 0.2904\n",
      "Epoch 19/70\n",
      " - 1s - loss: 0.0753 - msle: 0.0753 - val_loss: 0.2904 - val_msle: 0.2904\n",
      "Epoch 20/70\n",
      " - 1s - loss: 0.0753 - msle: 0.0753 - val_loss: 0.2904 - val_msle: 0.2904\n",
      "Epoch 21/70\n",
      " - 1s - loss: 0.0753 - msle: 0.0753 - val_loss: 0.2904 - val_msle: 0.2904\n",
      "Epoch 22/70\n",
      " - 1s - loss: 0.0127 - msle: 0.0127 - val_loss: 0.0251 - val_msle: 0.0251\n",
      "Epoch 23/70\n",
      " - 1s - loss: 0.0690 - msle: 0.0690 - val_loss: 0.1148 - val_msle: 0.1148\n",
      "Epoch 24/70\n",
      " - 1s - loss: 0.0340 - msle: 0.0340 - val_loss: 0.0478 - val_msle: 0.0478\n",
      "Epoch 25/70\n",
      " - 1s - loss: 0.0108 - msle: 0.0108 - val_loss: 0.0041 - val_msle: 0.0041\n",
      "Epoch 26/70\n",
      " - 1s - loss: 0.0052 - msle: 0.0052 - val_loss: 0.0041 - val_msle: 0.0041\n",
      "Epoch 27/70\n",
      " - 1s - loss: 0.0035 - msle: 0.0035 - val_loss: 0.0038 - val_msle: 0.0038\n",
      "Epoch 28/70\n",
      " - 1s - loss: 0.0028 - msle: 0.0028 - val_loss: 0.0038 - val_msle: 0.0038\n",
      "Epoch 29/70\n",
      " - 1s - loss: 0.0023 - msle: 0.0023 - val_loss: 0.0037 - val_msle: 0.0037\n",
      "Epoch 30/70\n",
      " - 1s - loss: 0.0023 - msle: 0.0023 - val_loss: 0.0037 - val_msle: 0.0037\n",
      "Epoch 31/70\n",
      " - 1s - loss: 0.0022 - msle: 0.0022 - val_loss: 0.0035 - val_msle: 0.0035\n",
      "Epoch 32/70\n",
      " - 1s - loss: 0.0019 - msle: 0.0019 - val_loss: 0.0035 - val_msle: 0.0035\n",
      "Epoch 33/70\n",
      " - 1s - loss: 0.0020 - msle: 0.0020 - val_loss: 0.0034 - val_msle: 0.0034\n",
      "Epoch 34/70\n",
      " - 1s - loss: 0.0019 - msle: 0.0019 - val_loss: 0.0034 - val_msle: 0.0034\n",
      "Epoch 35/70\n",
      " - 1s - loss: 0.0019 - msle: 0.0019 - val_loss: 0.0033 - val_msle: 0.0033\n",
      "Epoch 36/70\n",
      " - 1s - loss: 0.0019 - msle: 0.0019 - val_loss: 0.0032 - val_msle: 0.0032\n",
      "Epoch 37/70\n",
      " - 1s - loss: 0.0015 - msle: 0.0015 - val_loss: 0.0031 - val_msle: 0.0031\n",
      "Epoch 38/70\n",
      " - 1s - loss: 0.0017 - msle: 0.0017 - val_loss: 0.0030 - val_msle: 0.0030\n",
      "Epoch 39/70\n",
      " - 1s - loss: 0.0017 - msle: 0.0017 - val_loss: 0.0030 - val_msle: 0.0030\n",
      "Epoch 40/70\n",
      " - 1s - loss: 0.0016 - msle: 0.0016 - val_loss: 0.0029 - val_msle: 0.0029\n",
      "Epoch 41/70\n",
      " - 1s - loss: 0.0015 - msle: 0.0015 - val_loss: 0.0029 - val_msle: 0.0029\n",
      "Epoch 42/70\n",
      " - 1s - loss: 0.0015 - msle: 0.0015 - val_loss: 0.0028 - val_msle: 0.0028\n",
      "Epoch 43/70\n",
      " - 1s - loss: 0.0014 - msle: 0.0014 - val_loss: 0.0028 - val_msle: 0.0028\n",
      "Epoch 44/70\n",
      " - 1s - loss: 0.0014 - msle: 0.0014 - val_loss: 0.0028 - val_msle: 0.0028\n",
      "Epoch 45/70\n",
      " - 1s - loss: 0.0013 - msle: 0.0013 - val_loss: 0.0027 - val_msle: 0.0027\n",
      "Epoch 46/70\n",
      " - 1s - loss: 0.0013 - msle: 0.0013 - val_loss: 0.0026 - val_msle: 0.0026\n",
      "Epoch 47/70\n",
      " - 1s - loss: 0.0014 - msle: 0.0014 - val_loss: 0.0025 - val_msle: 0.0025\n",
      "Epoch 48/70\n",
      " - 1s - loss: 0.0013 - msle: 0.0013 - val_loss: 0.0024 - val_msle: 0.0024\n",
      "Epoch 49/70\n",
      " - 1s - loss: 0.0012 - msle: 0.0012 - val_loss: 0.0024 - val_msle: 0.0024\n",
      "Epoch 50/70\n",
      " - 1s - loss: 0.0013 - msle: 0.0013 - val_loss: 0.0023 - val_msle: 0.0023\n",
      "Epoch 51/70\n",
      " - 1s - loss: 0.0013 - msle: 0.0013 - val_loss: 0.0023 - val_msle: 0.0023\n",
      "Epoch 52/70\n",
      " - 1s - loss: 0.0013 - msle: 0.0013 - val_loss: 0.0022 - val_msle: 0.0022\n",
      "Epoch 53/70\n",
      " - 1s - loss: 0.0012 - msle: 0.0012 - val_loss: 0.0021 - val_msle: 0.0021\n",
      "Epoch 54/70\n",
      " - 1s - loss: 0.0012 - msle: 0.0012 - val_loss: 0.0020 - val_msle: 0.0020\n",
      "Epoch 55/70\n",
      " - 1s - loss: 0.0011 - msle: 0.0011 - val_loss: 0.0020 - val_msle: 0.0020\n",
      "Epoch 56/70\n",
      " - 1s - loss: 0.0011 - msle: 0.0011 - val_loss: 0.0020 - val_msle: 0.0020\n",
      "Epoch 57/70\n",
      " - 1s - loss: 0.0011 - msle: 0.0011 - val_loss: 0.0020 - val_msle: 0.0020\n",
      "Epoch 58/70\n",
      " - 1s - loss: 0.0012 - msle: 0.0012 - val_loss: 0.0020 - val_msle: 0.0020\n",
      "Epoch 59/70\n",
      " - 1s - loss: 0.0010 - msle: 0.0010 - val_loss: 0.0019 - val_msle: 0.0019\n",
      "Epoch 60/70\n",
      " - 1s - loss: 0.0011 - msle: 0.0011 - val_loss: 0.0019 - val_msle: 0.0019\n",
      "Epoch 61/70\n",
      " - 1s - loss: 0.0012 - msle: 0.0012 - val_loss: 0.0020 - val_msle: 0.0020\n",
      "Epoch 62/70\n",
      " - 1s - loss: 0.0011 - msle: 0.0011 - val_loss: 0.0018 - val_msle: 0.0018\n",
      "Epoch 63/70\n",
      " - 1s - loss: 0.0010 - msle: 0.0010 - val_loss: 0.0021 - val_msle: 0.0021\n",
      "Epoch 64/70\n",
      " - 1s - loss: 0.0010 - msle: 0.0010 - val_loss: 0.0018 - val_msle: 0.0018\n",
      "Epoch 65/70\n",
      " - 1s - loss: 0.0010 - msle: 0.0010 - val_loss: 0.0017 - val_msle: 0.0017\n",
      "Epoch 66/70\n",
      " - 1s - loss: 0.0011 - msle: 0.0011 - val_loss: 0.0017 - val_msle: 0.0017\n",
      "Epoch 67/70\n",
      " - 1s - loss: 0.0012 - msle: 0.0012 - val_loss: 0.0025 - val_msle: 0.0025\n",
      "Epoch 68/70\n",
      " - 1s - loss: 0.0011 - msle: 0.0011 - val_loss: 0.0018 - val_msle: 0.0018\n",
      "Epoch 69/70\n",
      " - 1s - loss: 9.8120e-04 - msle: 9.8120e-04 - val_loss: 0.0016 - val_msle: 0.0016\n",
      "Epoch 70/70\n",
      " - 1s - loss: 0.0010 - msle: 0.0010 - val_loss: 0.0016 - val_msle: 0.0016\n",
      "PREDICTING VALUE FOR       close_19    ADX_19     RSI_19  close_18     ADX_18   RSI_18  close_17  \\\n",
      "1583  54721.03  22.73231  39.545878  57274.88  23.158874  45.8291  57776.25   \n",
      "\n",
      "         ADX_17     RSI_17  close_16  ...   close_2      ADX_2      RSI_2  \\\n",
      "1583  22.645288  46.993843  56950.56  ...  48343.28  34.452319  38.544703   \n",
      "\n",
      "       close_1      ADX_1      RSI_1   close_0      ADX_0      RSI_0     close  \n",
      "1583  48864.98  35.384648  40.071644  47632.38  35.870477  37.688977  48889.88  \n",
      "\n",
      "[1 rows x 61 columns]\n",
      "real [[48889.88]]\n",
      "Test RMSE: 2551.893\n",
      "Diff [[2551.89341999]]\n",
      "% Diff [[5.21967618]] %\n",
      "||||----|||| Current Orders: [] \n",
      "\n",
      "\n",
      "\n",
      "INDEX: 1427\n",
      "CLOSE: 32729.77\n",
      "MODE: sell\n",
      "CHECKING ORDERS...\n",
      "TRAINING MODEL:\n",
      "Input shape: (1427, 1, 60) (1427, 1)\n",
      "Model: \"sequential_29\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_85 (LSTM)               (None, 1, 100)            64400     \n",
      "_________________________________________________________________\n",
      "lstm_86 (LSTM)               (None, 1, 50)             30200     \n",
      "_________________________________________________________________\n",
      "dropout_57 (Dropout)         (None, 1, 50)             0         \n",
      "_________________________________________________________________\n",
      "lstm_87 (LSTM)               (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_58 (Dropout)         (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 1)                 51        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 114,851\n",
      "Trainable params: 114,851\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Y shape (1427, 1)\n",
      "Train on 1427 samples, validate on 286 samples\n",
      "Epoch 1/70\n",
      " - 6s - loss: 0.0103 - msle: 0.0103 - val_loss: 0.0062 - val_msle: 0.0062\n",
      "Epoch 2/70\n",
      " - 1s - loss: 0.0552 - msle: 0.0552 - val_loss: 0.0700 - val_msle: 0.0700\n",
      "Epoch 3/70\n",
      " - 1s - loss: 0.0478 - msle: 0.0478 - val_loss: 0.0692 - val_msle: 0.0692\n",
      "Epoch 4/70\n",
      " - 1s - loss: 0.0142 - msle: 0.0142 - val_loss: 0.0037 - val_msle: 0.0037\n",
      "Epoch 5/70\n",
      " - 1s - loss: 0.0068 - msle: 0.0068 - val_loss: 0.0051 - val_msle: 0.0051\n",
      "Epoch 6/70\n",
      " - 1s - loss: 0.0057 - msle: 0.0057 - val_loss: 0.0036 - val_msle: 0.0036\n",
      "Epoch 7/70\n",
      " - 1s - loss: 0.0042 - msle: 0.0042 - val_loss: 0.0039 - val_msle: 0.0039\n",
      "Epoch 8/70\n",
      " - 1s - loss: 0.0040 - msle: 0.0040 - val_loss: 0.0039 - val_msle: 0.0039\n",
      "Epoch 9/70\n",
      " - 1s - loss: 0.0033 - msle: 0.0033 - val_loss: 0.0035 - val_msle: 0.0035\n",
      "Epoch 10/70\n",
      " - 1s - loss: 0.0024 - msle: 0.0024 - val_loss: 0.0035 - val_msle: 0.0035\n",
      "Epoch 11/70\n",
      " - 1s - loss: 0.0024 - msle: 0.0024 - val_loss: 0.0033 - val_msle: 0.0033\n",
      "Epoch 12/70\n",
      " - 1s - loss: 0.0018 - msle: 0.0018 - val_loss: 0.0034 - val_msle: 0.0034\n",
      "Epoch 13/70\n",
      " - 1s - loss: 0.0021 - msle: 0.0021 - val_loss: 0.0033 - val_msle: 0.0033\n",
      "Epoch 14/70\n",
      " - 1s - loss: 0.0017 - msle: 0.0017 - val_loss: 0.0032 - val_msle: 0.0032\n",
      "Epoch 15/70\n",
      " - 1s - loss: 0.0017 - msle: 0.0017 - val_loss: 0.0031 - val_msle: 0.0031\n",
      "Epoch 16/70\n",
      " - 1s - loss: 0.0017 - msle: 0.0017 - val_loss: 0.0031 - val_msle: 0.0031\n",
      "Epoch 17/70\n",
      " - 1s - loss: 0.0015 - msle: 0.0015 - val_loss: 0.0030 - val_msle: 0.0030\n",
      "Epoch 18/70\n",
      " - 1s - loss: 0.0017 - msle: 0.0017 - val_loss: 0.0030 - val_msle: 0.0030\n",
      "Epoch 19/70\n",
      " - 1s - loss: 0.0015 - msle: 0.0015 - val_loss: 0.0029 - val_msle: 0.0029\n",
      "Epoch 20/70\n",
      " - 1s - loss: 0.0015 - msle: 0.0015 - val_loss: 0.0029 - val_msle: 0.0029\n",
      "Epoch 21/70\n",
      " - 1s - loss: 0.0015 - msle: 0.0015 - val_loss: 0.0029 - val_msle: 0.0029\n",
      "Epoch 22/70\n",
      " - 1s - loss: 0.0015 - msle: 0.0015 - val_loss: 0.0028 - val_msle: 0.0028\n",
      "Epoch 23/70\n",
      " - 1s - loss: 0.0014 - msle: 0.0014 - val_loss: 0.0027 - val_msle: 0.0027\n",
      "Epoch 24/70\n",
      " - 1s - loss: 0.0015 - msle: 0.0015 - val_loss: 0.0027 - val_msle: 0.0027\n",
      "Epoch 25/70\n",
      " - 1s - loss: 0.0014 - msle: 0.0014 - val_loss: 0.0026 - val_msle: 0.0026\n",
      "Epoch 26/70\n",
      " - 1s - loss: 0.0014 - msle: 0.0014 - val_loss: 0.0026 - val_msle: 0.0026\n",
      "Epoch 27/70\n",
      " - 1s - loss: 0.0014 - msle: 0.0014 - val_loss: 0.0025 - val_msle: 0.0025\n",
      "Epoch 28/70\n",
      " - 1s - loss: 0.0013 - msle: 0.0013 - val_loss: 0.0025 - val_msle: 0.0025\n",
      "Epoch 29/70\n",
      " - 1s - loss: 0.0014 - msle: 0.0014 - val_loss: 0.0024 - val_msle: 0.0024\n",
      "Epoch 30/70\n",
      " - 1s - loss: 0.0012 - msle: 0.0012 - val_loss: 0.0023 - val_msle: 0.0023\n",
      "Epoch 31/70\n",
      " - 1s - loss: 0.0012 - msle: 0.0012 - val_loss: 0.0022 - val_msle: 0.0022\n",
      "Epoch 32/70\n",
      " - 1s - loss: 0.0012 - msle: 0.0012 - val_loss: 0.0022 - val_msle: 0.0022\n",
      "Epoch 33/70\n",
      " - 1s - loss: 0.0012 - msle: 0.0012 - val_loss: 0.0022 - val_msle: 0.0022\n",
      "Epoch 34/70\n",
      " - 1s - loss: 0.0013 - msle: 0.0013 - val_loss: 0.0022 - val_msle: 0.0022\n",
      "Epoch 35/70\n",
      " - 1s - loss: 0.0012 - msle: 0.0012 - val_loss: 0.0021 - val_msle: 0.0021\n",
      "Epoch 36/70\n",
      " - 1s - loss: 0.0011 - msle: 0.0011 - val_loss: 0.0020 - val_msle: 0.0020\n",
      "Epoch 37/70\n",
      " - 1s - loss: 0.0013 - msle: 0.0013 - val_loss: 0.0020 - val_msle: 0.0020\n",
      "Epoch 38/70\n",
      " - 1s - loss: 0.0013 - msle: 0.0013 - val_loss: 0.0021 - val_msle: 0.0021\n",
      "Epoch 39/70\n",
      " - 1s - loss: 0.0010 - msle: 0.0010 - val_loss: 0.0019 - val_msle: 0.0019\n",
      "Epoch 40/70\n",
      " - 1s - loss: 0.0011 - msle: 0.0011 - val_loss: 0.0020 - val_msle: 0.0020\n",
      "Epoch 41/70\n",
      " - 1s - loss: 9.8615e-04 - msle: 9.8615e-04 - val_loss: 0.0020 - val_msle: 0.0020\n",
      "Epoch 42/70\n",
      " - 1s - loss: 0.0011 - msle: 0.0011 - val_loss: 0.0019 - val_msle: 0.0019\n",
      "Epoch 43/70\n",
      " - 1s - loss: 0.0011 - msle: 0.0011 - val_loss: 0.0018 - val_msle: 0.0018\n",
      "Epoch 44/70\n",
      " - 1s - loss: 0.0012 - msle: 0.0012 - val_loss: 0.0021 - val_msle: 0.0021\n",
      "Epoch 45/70\n",
      " - 1s - loss: 0.0011 - msle: 0.0011 - val_loss: 0.0020 - val_msle: 0.0020\n",
      "Epoch 46/70\n",
      " - 1s - loss: 0.0011 - msle: 0.0011 - val_loss: 0.0020 - val_msle: 0.0020\n",
      "Epoch 47/70\n",
      " - 1s - loss: 0.0011 - msle: 0.0011 - val_loss: 0.0018 - val_msle: 0.0018\n",
      "Epoch 48/70\n",
      " - 1s - loss: 0.0011 - msle: 0.0011 - val_loss: 0.0017 - val_msle: 0.0017\n",
      "Epoch 49/70\n",
      " - 1s - loss: 0.0011 - msle: 0.0011 - val_loss: 0.0020 - val_msle: 0.0020\n",
      "Epoch 50/70\n",
      " - 1s - loss: 0.0010 - msle: 0.0010 - val_loss: 0.0017 - val_msle: 0.0017\n",
      "Epoch 51/70\n",
      " - 1s - loss: 0.0011 - msle: 0.0011 - val_loss: 0.0017 - val_msle: 0.0017\n",
      "Epoch 52/70\n",
      " - 1s - loss: 0.0012 - msle: 0.0012 - val_loss: 0.0021 - val_msle: 0.0021\n",
      "Epoch 53/70\n",
      " - 1s - loss: 0.0012 - msle: 0.0012 - val_loss: 0.0021 - val_msle: 0.0021\n",
      "Epoch 54/70\n",
      " - 1s - loss: 9.8580e-04 - msle: 9.8580e-04 - val_loss: 0.0016 - val_msle: 0.0016\n",
      "Epoch 55/70\n",
      " - 1s - loss: 0.0012 - msle: 0.0012 - val_loss: 0.0017 - val_msle: 0.0017\n",
      "Epoch 56/70\n",
      " - 1s - loss: 0.0011 - msle: 0.0011 - val_loss: 0.0018 - val_msle: 0.0018\n",
      "Epoch 57/70\n",
      " - 1s - loss: 0.0011 - msle: 0.0011 - val_loss: 0.0021 - val_msle: 0.0021\n",
      "Epoch 58/70\n",
      " - 1s - loss: 9.6654e-04 - msle: 9.6654e-04 - val_loss: 0.0016 - val_msle: 0.0016\n",
      "Epoch 59/70\n",
      " - 1s - loss: 0.0010 - msle: 0.0010 - val_loss: 0.0017 - val_msle: 0.0017\n",
      "Epoch 60/70\n",
      " - 1s - loss: 0.0011 - msle: 0.0011 - val_loss: 0.0018 - val_msle: 0.0018\n",
      "Epoch 61/70\n",
      " - 1s - loss: 0.0010 - msle: 0.0010 - val_loss: 0.0017 - val_msle: 0.0017\n",
      "Epoch 62/70\n",
      " - 1s - loss: 9.2036e-04 - msle: 9.2036e-04 - val_loss: 0.0016 - val_msle: 0.0016\n",
      "Epoch 63/70\n",
      " - 1s - loss: 9.4355e-04 - msle: 9.4355e-04 - val_loss: 0.0016 - val_msle: 0.0016\n",
      "Epoch 64/70\n",
      " - 1s - loss: 9.2364e-04 - msle: 9.2364e-04 - val_loss: 0.0020 - val_msle: 0.0020\n",
      "Epoch 65/70\n",
      " - 1s - loss: 9.9489e-04 - msle: 9.9489e-04 - val_loss: 0.0018 - val_msle: 0.0018\n",
      "Epoch 66/70\n",
      " - 1s - loss: 9.2615e-04 - msle: 9.2615e-04 - val_loss: 0.0016 - val_msle: 0.0016\n",
      "Epoch 67/70\n",
      " - 1s - loss: 9.9337e-04 - msle: 9.9337e-04 - val_loss: 0.0016 - val_msle: 0.0016\n",
      "Epoch 68/70\n",
      " - 1s - loss: 9.2868e-04 - msle: 9.2868e-04 - val_loss: 0.0015 - val_msle: 0.0015\n",
      "Epoch 69/70\n",
      " - 1s - loss: 0.0010 - msle: 0.0010 - val_loss: 0.0020 - val_msle: 0.0020\n",
      "Epoch 70/70\n",
      " - 1s - loss: 9.6507e-04 - msle: 9.6507e-04 - val_loss: 0.0017 - val_msle: 0.0017\n",
      "PREDICTING VALUE FOR       close_19     ADX_19   RSI_19  close_18     ADX_18     RSI_18  close_17  \\\n",
      "1584  57274.88  23.158874  45.8291  57776.25  22.645288  46.993843  56950.56   \n",
      "\n",
      "         ADX_17     RSI_17  close_16  ...   close_2      ADX_2      RSI_2  \\\n",
      "1584  21.618234  45.267626  57184.07  ...  48864.98  35.384648  40.071644   \n",
      "\n",
      "       close_1      ADX_1      RSI_1  close_0      ADX_0      RSI_0     close  \n",
      "1584  47632.38  35.870477  37.688977  46131.2  36.352127  34.962371  48588.16  \n",
      "\n",
      "[1 rows x 61 columns]\n",
      "real [[48588.16]]\n",
      "Test RMSE: 3438.645\n",
      "Diff [[3438.64469014]]\n",
      "% Diff [[7.07712474]] %\n",
      "||||----|||| Current Orders: [] \n",
      "\n",
      "\n",
      "\n",
      "INDEX: 1428\n",
      "CLOSE: 32820.02\n",
      "MODE: sell\n",
      "CHECKING ORDERS...\n",
      "TRAINING MODEL:\n",
      "Input shape: (1428, 1, 60) (1428, 1)\n",
      "Model: \"sequential_30\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_88 (LSTM)               (None, 1, 100)            64400     \n",
      "_________________________________________________________________\n",
      "lstm_89 (LSTM)               (None, 1, 50)             30200     \n",
      "_________________________________________________________________\n",
      "dropout_59 (Dropout)         (None, 1, 50)             0         \n",
      "_________________________________________________________________\n",
      "lstm_90 (LSTM)               (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_60 (Dropout)         (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 1)                 51        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 114,851\n",
      "Trainable params: 114,851\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Y shape (1428, 1)\n",
      "Train on 1428 samples, validate on 286 samples\n",
      "Epoch 1/70\n",
      " - 6s - loss: 0.0111 - msle: 0.0111 - val_loss: 0.0089 - val_msle: 0.0089\n",
      "Epoch 2/70\n",
      " - 1s - loss: 0.0520 - msle: 0.0520 - val_loss: 0.0343 - val_msle: 0.0343\n",
      "Epoch 3/70\n",
      " - 1s - loss: 0.0570 - msle: 0.0570 - val_loss: 0.0899 - val_msle: 0.0899\n",
      "Epoch 4/70\n",
      " - 1s - loss: 0.0172 - msle: 0.0172 - val_loss: 0.0065 - val_msle: 0.0065\n",
      "Epoch 5/70\n",
      " - 1s - loss: 0.0064 - msle: 0.0064 - val_loss: 0.0048 - val_msle: 0.0048\n",
      "Epoch 6/70\n",
      " - 1s - loss: 0.0056 - msle: 0.0056 - val_loss: 0.0040 - val_msle: 0.0040\n",
      "Epoch 7/70\n",
      " - 1s - loss: 0.0038 - msle: 0.0038 - val_loss: 0.0035 - val_msle: 0.0035\n",
      "Epoch 8/70\n",
      " - 1s - loss: 0.0027 - msle: 0.0027 - val_loss: 0.0035 - val_msle: 0.0035\n",
      "Epoch 9/70\n",
      " - 1s - loss: 0.0027 - msle: 0.0027 - val_loss: 0.0032 - val_msle: 0.0032\n",
      "Epoch 10/70\n",
      " - 1s - loss: 0.0021 - msle: 0.0021 - val_loss: 0.0033 - val_msle: 0.0033\n",
      "Epoch 11/70\n",
      " - 1s - loss: 0.0020 - msle: 0.0020 - val_loss: 0.0032 - val_msle: 0.0032\n",
      "Epoch 12/70\n",
      " - 1s - loss: 0.0017 - msle: 0.0017 - val_loss: 0.0032 - val_msle: 0.0032\n",
      "Epoch 13/70\n",
      " - 1s - loss: 0.0018 - msle: 0.0018 - val_loss: 0.0030 - val_msle: 0.0030\n",
      "Epoch 14/70\n",
      " - 1s - loss: 0.0014 - msle: 0.0014 - val_loss: 0.0031 - val_msle: 0.0031\n",
      "Epoch 15/70\n",
      " - 1s - loss: 0.0016 - msle: 0.0016 - val_loss: 0.0029 - val_msle: 0.0029\n",
      "Epoch 16/70\n",
      " - 1s - loss: 0.0015 - msle: 0.0015 - val_loss: 0.0030 - val_msle: 0.0030\n",
      "Epoch 17/70\n",
      " - 1s - loss: 0.0015 - msle: 0.0015 - val_loss: 0.0029 - val_msle: 0.0029\n",
      "Epoch 18/70\n",
      " - 1s - loss: 0.0014 - msle: 0.0014 - val_loss: 0.0029 - val_msle: 0.0029\n",
      "Epoch 19/70\n",
      " - 1s - loss: 0.0014 - msle: 0.0014 - val_loss: 0.0028 - val_msle: 0.0028\n",
      "Epoch 20/70\n",
      " - 1s - loss: 0.0013 - msle: 0.0013 - val_loss: 0.0028 - val_msle: 0.0028\n",
      "Epoch 21/70\n",
      " - 1s - loss: 0.0014 - msle: 0.0014 - val_loss: 0.0028 - val_msle: 0.0028\n",
      "Epoch 22/70\n",
      " - 1s - loss: 0.0014 - msle: 0.0014 - val_loss: 0.0027 - val_msle: 0.0027\n",
      "Epoch 23/70\n",
      " - 1s - loss: 0.0014 - msle: 0.0014 - val_loss: 0.0026 - val_msle: 0.0026\n",
      "Epoch 24/70\n",
      " - 1s - loss: 0.0013 - msle: 0.0013 - val_loss: 0.0026 - val_msle: 0.0026\n",
      "Epoch 25/70\n",
      " - 1s - loss: 0.0014 - msle: 0.0014 - val_loss: 0.0025 - val_msle: 0.0025\n",
      "Epoch 26/70\n",
      " - 1s - loss: 0.0013 - msle: 0.0013 - val_loss: 0.0026 - val_msle: 0.0026\n",
      "Epoch 27/70\n",
      " - 1s - loss: 0.0014 - msle: 0.0014 - val_loss: 0.0024 - val_msle: 0.0024\n",
      "Epoch 28/70\n",
      " - 1s - loss: 0.0013 - msle: 0.0013 - val_loss: 0.0024 - val_msle: 0.0024\n",
      "Epoch 29/70\n",
      " - 1s - loss: 0.0014 - msle: 0.0014 - val_loss: 0.0024 - val_msle: 0.0024\n",
      "Epoch 30/70\n",
      " - 1s - loss: 0.0013 - msle: 0.0013 - val_loss: 0.0023 - val_msle: 0.0023\n",
      "Epoch 31/70\n",
      " - 1s - loss: 0.0013 - msle: 0.0013 - val_loss: 0.0023 - val_msle: 0.0023\n",
      "Epoch 32/70\n",
      " - 1s - loss: 0.0012 - msle: 0.0012 - val_loss: 0.0023 - val_msle: 0.0023\n",
      "Epoch 33/70\n",
      " - 1s - loss: 0.0011 - msle: 0.0011 - val_loss: 0.0022 - val_msle: 0.0022\n",
      "Epoch 34/70\n",
      " - 1s - loss: 0.0012 - msle: 0.0012 - val_loss: 0.0022 - val_msle: 0.0022\n",
      "Epoch 35/70\n",
      " - 1s - loss: 0.0012 - msle: 0.0012 - val_loss: 0.0021 - val_msle: 0.0021\n",
      "Epoch 36/70\n",
      " - 1s - loss: 0.0011 - msle: 0.0011 - val_loss: 0.0021 - val_msle: 0.0021\n",
      "Epoch 37/70\n",
      " - 1s - loss: 0.0012 - msle: 0.0012 - val_loss: 0.0021 - val_msle: 0.0021\n",
      "Epoch 38/70\n",
      " - 1s - loss: 0.0012 - msle: 0.0012 - val_loss: 0.0020 - val_msle: 0.0020\n",
      "Epoch 39/70\n",
      " - 1s - loss: 0.0012 - msle: 0.0012 - val_loss: 0.0023 - val_msle: 0.0023\n",
      "Epoch 40/70\n",
      " - 1s - loss: 0.0011 - msle: 0.0011 - val_loss: 0.0021 - val_msle: 0.0021\n",
      "Epoch 41/70\n",
      " - 1s - loss: 0.0011 - msle: 0.0011 - val_loss: 0.0019 - val_msle: 0.0019\n",
      "Epoch 42/70\n",
      " - 1s - loss: 0.0011 - msle: 0.0011 - val_loss: 0.0019 - val_msle: 0.0019\n",
      "Epoch 43/70\n",
      " - 1s - loss: 0.0011 - msle: 0.0011 - val_loss: 0.0019 - val_msle: 0.0019\n",
      "Epoch 44/70\n",
      " - 1s - loss: 0.0012 - msle: 0.0012 - val_loss: 0.0020 - val_msle: 0.0020\n",
      "Epoch 45/70\n",
      " - 1s - loss: 0.0012 - msle: 0.0012 - val_loss: 0.0019 - val_msle: 0.0019\n",
      "Epoch 46/70\n",
      " - 1s - loss: 0.0011 - msle: 0.0011 - val_loss: 0.0018 - val_msle: 0.0018\n",
      "Epoch 47/70\n",
      " - 1s - loss: 0.0011 - msle: 0.0011 - val_loss: 0.0019 - val_msle: 0.0019\n",
      "Epoch 48/70\n",
      " - 1s - loss: 0.0011 - msle: 0.0011 - val_loss: 0.0018 - val_msle: 0.0018\n",
      "Epoch 49/70\n",
      " - 1s - loss: 0.0011 - msle: 0.0011 - val_loss: 0.0022 - val_msle: 0.0022\n",
      "Epoch 50/70\n",
      " - 1s - loss: 0.0011 - msle: 0.0011 - val_loss: 0.0018 - val_msle: 0.0018\n",
      "Epoch 51/70\n",
      " - 1s - loss: 0.0010 - msle: 0.0010 - val_loss: 0.0018 - val_msle: 0.0018\n",
      "Epoch 52/70\n",
      " - 1s - loss: 9.8459e-04 - msle: 9.8459e-04 - val_loss: 0.0018 - val_msle: 0.0018\n",
      "Epoch 53/70\n",
      " - 1s - loss: 0.0011 - msle: 0.0011 - val_loss: 0.0016 - val_msle: 0.0016\n",
      "Epoch 54/70\n",
      " - 1s - loss: 0.0011 - msle: 0.0011 - val_loss: 0.0017 - val_msle: 0.0017\n",
      "Epoch 55/70\n",
      " - 1s - loss: 9.7906e-04 - msle: 9.7906e-04 - val_loss: 0.0017 - val_msle: 0.0017\n",
      "Epoch 56/70\n",
      " - 1s - loss: 0.0010 - msle: 0.0010 - val_loss: 0.0019 - val_msle: 0.0019\n",
      "Epoch 57/70\n",
      " - 1s - loss: 8.6524e-04 - msle: 8.6524e-04 - val_loss: 0.0016 - val_msle: 0.0016\n",
      "Epoch 58/70\n",
      " - 1s - loss: 8.7994e-04 - msle: 8.7994e-04 - val_loss: 0.0016 - val_msle: 0.0016\n",
      "Epoch 59/70\n",
      " - 1s - loss: 8.9495e-04 - msle: 8.9495e-04 - val_loss: 0.0017 - val_msle: 0.0017\n",
      "Epoch 60/70\n",
      " - 1s - loss: 0.0010 - msle: 0.0010 - val_loss: 0.0019 - val_msle: 0.0019\n",
      "Epoch 61/70\n",
      " - 1s - loss: 0.0011 - msle: 0.0011 - val_loss: 0.0019 - val_msle: 0.0019\n",
      "Epoch 62/70\n",
      " - 1s - loss: 9.4688e-04 - msle: 9.4688e-04 - val_loss: 0.0016 - val_msle: 0.0016\n",
      "Epoch 63/70\n",
      " - 1s - loss: 8.8922e-04 - msle: 8.8922e-04 - val_loss: 0.0015 - val_msle: 0.0015\n",
      "Epoch 64/70\n",
      " - 1s - loss: 9.1761e-04 - msle: 9.1761e-04 - val_loss: 0.0019 - val_msle: 0.0019\n",
      "Epoch 65/70\n",
      " - 1s - loss: 9.6448e-04 - msle: 9.6448e-04 - val_loss: 0.0016 - val_msle: 0.0016\n",
      "Epoch 66/70\n",
      " - 1s - loss: 0.0010 - msle: 0.0010 - val_loss: 0.0016 - val_msle: 0.0016\n",
      "Epoch 67/70\n",
      " - 1s - loss: 9.5610e-04 - msle: 9.5610e-04 - val_loss: 0.0019 - val_msle: 0.0019\n",
      "Epoch 68/70\n",
      " - 1s - loss: 0.0010 - msle: 0.0010 - val_loss: 0.0020 - val_msle: 0.0020\n",
      "Epoch 69/70\n",
      " - 1s - loss: 9.0732e-04 - msle: 9.0732e-04 - val_loss: 0.0015 - val_msle: 0.0015\n",
      "Epoch 70/70\n",
      " - 1s - loss: 9.9228e-04 - msle: 9.9228e-04 - val_loss: 0.0019 - val_msle: 0.0019\n",
      "PREDICTING VALUE FOR       close_19     ADX_19     RSI_19  close_18     ADX_18     RSI_18  \\\n",
      "1585  57776.25  22.645288  46.993843  56950.56  21.618234  45.267626   \n",
      "\n",
      "      close_17     ADX_17     RSI_17  close_16  ...   close_2      ADX_2  \\\n",
      "1585  57184.07  20.798744  45.873163  56480.34  ...  47632.38  35.870477   \n",
      "\n",
      "          RSI_2  close_1      ADX_1      RSI_1   close_0      ADX_0  \\\n",
      "1585  37.688977  46131.2  36.352127  34.962371  46834.48  37.196173   \n",
      "\n",
      "          RSI_0     close  \n",
      "1585  37.252626  50838.81  \n",
      "\n",
      "[1 rows x 61 columns]\n",
      "real [[50838.81]]\n",
      "Test RMSE: 5410.088\n",
      "Diff [[5410.08756771]]\n",
      "% Diff [[10.64164871]] %\n",
      "||||----|||| Current Orders: [] \n",
      "\n",
      "\n",
      "\n",
      "INDEX: 1429\n",
      "CLOSE: 31880.0\n",
      "MODE: sell\n",
      "CHECKING ORDERS...\n",
      "TRAINING MODEL:\n",
      "Input shape: (1429, 1, 60) (1429, 1)\n",
      "Model: \"sequential_31\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_91 (LSTM)               (None, 1, 100)            64400     \n",
      "_________________________________________________________________\n",
      "lstm_92 (LSTM)               (None, 1, 50)             30200     \n",
      "_________________________________________________________________\n",
      "dropout_61 (Dropout)         (None, 1, 50)             0         \n",
      "_________________________________________________________________\n",
      "lstm_93 (LSTM)               (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_62 (Dropout)         (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 1)                 51        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 114,851\n",
      "Trainable params: 114,851\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Y shape (1429, 1)\n",
      "Train on 1429 samples, validate on 286 samples\n",
      "Epoch 1/70\n",
      " - 6s - loss: 0.0754 - msle: 0.0754 - val_loss: 0.2896 - val_msle: 0.2896\n",
      "Epoch 2/70\n",
      " - 1s - loss: 0.0758 - msle: 0.0758 - val_loss: 0.2896 - val_msle: 0.2896\n",
      "Epoch 3/70\n",
      " - 1s - loss: 0.0758 - msle: 0.0758 - val_loss: 0.2896 - val_msle: 0.2896\n",
      "Epoch 4/70\n",
      " - 1s - loss: 0.0758 - msle: 0.0758 - val_loss: 0.2896 - val_msle: 0.2896\n",
      "Epoch 5/70\n",
      " - 1s - loss: 0.0758 - msle: 0.0758 - val_loss: 0.2896 - val_msle: 0.2896\n",
      "Epoch 6/70\n",
      " - 1s - loss: 0.0758 - msle: 0.0758 - val_loss: 0.2896 - val_msle: 0.2896\n",
      "Epoch 7/70\n",
      " - 1s - loss: 0.0758 - msle: 0.0758 - val_loss: 0.2896 - val_msle: 0.2896\n",
      "Epoch 8/70\n",
      " - 1s - loss: 0.0758 - msle: 0.0758 - val_loss: 0.2896 - val_msle: 0.2896\n",
      "Epoch 9/70\n",
      " - 1s - loss: 0.0758 - msle: 0.0758 - val_loss: 0.2896 - val_msle: 0.2896\n",
      "Epoch 10/70\n",
      " - 1s - loss: 0.0758 - msle: 0.0758 - val_loss: 0.2896 - val_msle: 0.2896\n",
      "Epoch 11/70\n",
      " - 1s - loss: 0.0758 - msle: 0.0758 - val_loss: 0.2896 - val_msle: 0.2896\n",
      "Epoch 12/70\n",
      " - 1s - loss: 0.0758 - msle: 0.0758 - val_loss: 0.2896 - val_msle: 0.2896\n",
      "Epoch 13/70\n",
      " - 1s - loss: 0.0758 - msle: 0.0758 - val_loss: 0.2896 - val_msle: 0.2896\n",
      "Epoch 14/70\n",
      " - 1s - loss: 0.0758 - msle: 0.0758 - val_loss: 0.2896 - val_msle: 0.2896\n",
      "Epoch 15/70\n",
      " - 1s - loss: 0.0758 - msle: 0.0758 - val_loss: 0.2896 - val_msle: 0.2896\n",
      "Epoch 16/70\n",
      " - 1s - loss: 0.0758 - msle: 0.0758 - val_loss: 0.2896 - val_msle: 0.2896\n",
      "Epoch 17/70\n",
      " - 1s - loss: 0.0758 - msle: 0.0758 - val_loss: 0.2896 - val_msle: 0.2896\n",
      "Epoch 18/70\n",
      " - 1s - loss: 0.0758 - msle: 0.0758 - val_loss: 0.2896 - val_msle: 0.2896\n",
      "Epoch 19/70\n",
      " - 1s - loss: 0.0758 - msle: 0.0758 - val_loss: 0.2896 - val_msle: 0.2896\n",
      "Epoch 20/70\n",
      " - 1s - loss: 0.0758 - msle: 0.0758 - val_loss: 0.2896 - val_msle: 0.2896\n",
      "Epoch 21/70\n",
      " - 1s - loss: 0.0758 - msle: 0.0758 - val_loss: 0.2896 - val_msle: 0.2896\n",
      "Epoch 22/70\n",
      " - 1s - loss: 0.0758 - msle: 0.0758 - val_loss: 0.2896 - val_msle: 0.2896\n",
      "Epoch 23/70\n",
      " - 1s - loss: 0.0758 - msle: 0.0758 - val_loss: 0.2896 - val_msle: 0.2896\n",
      "Epoch 24/70\n",
      " - 1s - loss: 0.0758 - msle: 0.0758 - val_loss: 0.2896 - val_msle: 0.2896\n",
      "Epoch 25/70\n",
      " - 1s - loss: 0.0758 - msle: 0.0758 - val_loss: 0.2896 - val_msle: 0.2896\n",
      "Epoch 26/70\n",
      " - 1s - loss: 0.0758 - msle: 0.0758 - val_loss: 0.2896 - val_msle: 0.2896\n",
      "PREDICTING VALUE FOR       close_19     ADX_19     RSI_19  close_18     ADX_18     RSI_18  \\\n",
      "1586  56950.56  21.618234  45.267626  57184.07  20.798744  45.873163   \n",
      "\n",
      "      close_17     ADX_17     RSI_17  close_16  ...  close_2      ADX_2  \\\n",
      "1586  56480.34  20.055789  44.283082  53601.05  ...  46131.2  36.352127   \n",
      "\n",
      "          RSI_2   close_1      ADX_1      RSI_1   close_0      ADX_0  \\\n",
      "1586  34.962371  46834.48  37.196173  37.252626  46681.23  37.941876   \n",
      "\n",
      "          RSI_0    close  \n",
      "1586  36.947303  50820.0  \n",
      "\n",
      "[1 rows x 61 columns]\n",
      "real [[50820.]]\n",
      "Test RMSE: 47831.403\n",
      "Diff [[47831.40299457]]\n",
      "% Diff [[94.11925028]] %\n",
      "||||----|||| Current Orders: [] \n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred_values = sim.simulate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>close_pred</th>\n",
       "      <th>close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>57974.351188</td>\n",
       "      <td>57138.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>55564.038729</td>\n",
       "      <td>58960.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>56290.418091</td>\n",
       "      <td>53726.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53537.650918</td>\n",
       "      <td>54721.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>53961.009954</td>\n",
       "      <td>57274.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2935.888443</td>\n",
       "      <td>57776.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3058.911371</td>\n",
       "      <td>56950.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3011.524913</td>\n",
       "      <td>57184.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>53225.556888</td>\n",
       "      <td>56480.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>53243.777132</td>\n",
       "      <td>53601.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3058.772529</td>\n",
       "      <td>49152.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3008.457084</td>\n",
       "      <td>49396.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2994.977822</td>\n",
       "      <td>50441.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>53773.988908</td>\n",
       "      <td>50588.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>51972.281658</td>\n",
       "      <td>50471.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>50114.621815</td>\n",
       "      <td>47545.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>3056.101385</td>\n",
       "      <td>47140.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>49171.658075</td>\n",
       "      <td>49389.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>48824.925265</td>\n",
       "      <td>50053.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2917.247452</td>\n",
       "      <td>46702.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>47295.536482</td>\n",
       "      <td>48343.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>46109.817607</td>\n",
       "      <td>48864.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2989.439115</td>\n",
       "      <td>47632.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2985.790119</td>\n",
       "      <td>46131.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>46076.677694</td>\n",
       "      <td>46834.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>46182.882586</td>\n",
       "      <td>46681.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>46782.283754</td>\n",
       "      <td>46914.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>46337.986580</td>\n",
       "      <td>48889.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>45149.515310</td>\n",
       "      <td>48588.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>45428.722432</td>\n",
       "      <td>50838.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2988.597005</td>\n",
       "      <td>50820.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      close_pred     close\n",
       "0   57974.351188  57138.29\n",
       "1   55564.038729  58960.36\n",
       "2   56290.418091  53726.53\n",
       "3   53537.650918  54721.03\n",
       "4   53961.009954  57274.88\n",
       "5    2935.888443  57776.25\n",
       "6    3058.911371  56950.56\n",
       "7    3011.524913  57184.07\n",
       "8   53225.556888  56480.34\n",
       "9   53243.777132  53601.05\n",
       "10   3058.772529  49152.47\n",
       "11   3008.457084  49396.33\n",
       "12   2994.977822  50441.92\n",
       "13  53773.988908  50588.95\n",
       "14  51972.281658  50471.19\n",
       "15  50114.621815  47545.59\n",
       "16   3056.101385  47140.54\n",
       "17  49171.658075  49389.99\n",
       "18  48824.925265  50053.90\n",
       "19   2917.247452  46702.75\n",
       "20  47295.536482  48343.28\n",
       "21  46109.817607  48864.98\n",
       "22   2989.439115  47632.38\n",
       "23   2985.790119  46131.20\n",
       "24  46076.677694  46834.48\n",
       "25  46182.882586  46681.23\n",
       "26  46782.283754  46914.16\n",
       "27  46337.986580  48889.88\n",
       "28  45149.515310  48588.16\n",
       "29  45428.722432  50838.81\n",
       "30   2988.597005  50820.00"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "df_predict = pd.DataFrame(np.reshape(pred_values[1], (31)), columns = ['close_pred'])\n",
    "df_real = sim.df.iloc[1399:1399+31,-1:]\n",
    "df_real.reset_index(drop=True, inplace=True)\n",
    "\n",
    "df = pd.concat([df_predict, df_real], ignore_index=False, sort=False, axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28678.803088375847"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse = ((df.close - df.close_pred) ** 2).mean() ** .5\n",
    "rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5608269987003833"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean = (df.close).mean()\n",
    "mean_rel_diff = rmse/mean\n",
    "mean_rel_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.plot()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5a26509f1ebfbe58e5b9c0be862da0478dce684822429b8f32e207fdb3de41b0"
  },
  "kernelspec": {
   "display_name": "Python 3.7.9 64-bit ('tf': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
